<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.3.3">Jekyll</generator><link href="https://ifuryst.github.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://ifuryst.github.io/" rel="alternate" type="text/html" hreflang="en"/><updated>2025-12-06T00:12:07+00:00</updated><id>https://ifuryst.github.io/feed.xml</id><title type="html">ifuryst</title><subtitle>📝 &amp; 💭 </subtitle><entry><title type="html">LeoTalk · Hacker News Daily · 2025.12.06</title><link href="https://ifuryst.github.io/blog/2025/leotalk-hacker-news-daily-december-6-2025/" rel="alternate" type="text/html" title="LeoTalk · Hacker News Daily · 2025.12.06"/><published>2025-12-06T00:00:00+00:00</published><updated>2025-12-06T00:00:00+00:00</updated><id>https://ifuryst.github.io/blog/2025/leotalk-hacker-news-daily-december-6-2025</id><content type="html" xml:base="https://ifuryst.github.io/blog/2025/leotalk-hacker-news-daily-december-6-2025/"><![CDATA[<h2 id="-今日重点top-picks">🔥 今日重点（Top Picks）</h2> <ul> <li><strong>Netflix宣布收购华纳兄弟</strong>：这一重磅交易预示着流媒体和内容制作行业将迎来巨变。<a href="https://about.netflix.com/en/news/netflix-to-acquire-warner-bros">Netflix News</a></li> <li><strong>Cloudflare遭遇大规模故障</strong>：全球多个网站受到影响，凸显关键网络基础设施的脆弱性，甚至DownDetector也一度瘫痪。（<a href="https://www.cloudflare.com/">Cloudflare</a>、<a href="https://blog.cloudflare.com/5-december-2025-outage/">博客</a>、<a href="https://news.ycombinator.com/item?id=46158200">HN</a>）</li> <li><strong>美国国务院将拒签“审查者”</strong>：新政策以“审查”为由，拒绝向事实核查员及其他内容审核人员发放签证，引发争议。<a href="https://www.npr.org/2025/12/04/nx-s1-5633444/trump-content-moderation-visas-censorship">NPR</a></li> <li><strong>Google发布Gemini 3 Pro</strong>：最新模型在视觉 AI 领域实现重大突破，推动了多模态能力的边界。<a href="https://blog.google/technology/developers/gemini-3-pro-vision/">Google Blog</a></li> <li><strong>AI反噬现象来临</strong>：公众对科技巨头和 AI 的耐心正在耗尽，引发对信任和监管的讨论。<a href="https://www.newsweek.com/ai-backlash-openai-meta-friend-10807425">Newsweek</a></li> </ul> <h2 id="-ai--开发工具">📦 AI &amp; 开发工具</h2> <ul> <li><strong>Netflix的AV1之旅</strong>：Netflix 披露其 AV1 视频编码技术进展，目前已支持 30% 的流媒体内容。<a href="https://netflixtechblog.com/av1-now-powering-30-of-netflix-streaming-02f592242d80">Netflix Tech Blog</a></li> <li><strong>Ubiquiti发布UniFi 5G</strong>：该公司正式进军 5G 网络解决方案市场，提供新设备和功能。<a href="https://blog.ui.com/article/introducing-unifi-5g">UniFi Blog</a></li> <li><strong>Framework Laptop 13支持ARM</strong>：通过升级套件，Framework 笔记本 13 将可选配 12 核 ARM 处理器。<a href="https://www.notebookcheck.net/Framework-Laptop-13-gets-ARM-processor-with-12-cores-via-upgrade-kit.1177930.0.html">Notebookcheck</a></li> <li><strong>NeurIPS 2025最佳论文奖</strong>：全球顶级 AI 会议公布了本年度的最佳论文，展示了前沿研究成果。<a href="https://blog.neurips.cc/2025/11/26/announcing-the-neurips-2025-best-paper-awards/">NeurIPS Blog</a></li> <li><strong>Synadia和TigerBeetle捐赠Zig</strong>：两家公司向 Zig 软件基金会承诺捐赠 51.2 万美元，支持该语言的持续发展。<a href="https://tigerbeetle.com/blog/2025-10-25-synadia-and-tigerbeetle-pledge-512k-to-the-zig-software-foundation/">TigerBeetle Blog</a></li> <li><strong>Framework赞助CachyOS</strong>：模块化硬件公司 Framework 宣布赞助 CachyOS，以支持开源操作系统社区。<a href="https://discuss.cachyos.org/t/framework-sponsorship-for-cachyos/19376">CachyOS Discuss</a></li> </ul> <h2 id="-思维激荡mind-food">🧠 思维激荡（Mind Food）</h2> <ul> <li><strong>技术问题往往是人的问题</strong>：一篇博客文章探讨了技术挑战背后的人性因素，强调沟通和团队的重要性。<a href="https://blog.joeschrag.com/2023/11/most-technical-problems-are-really.html">Joe Schrag Blog</a></li> <li><strong>广告是人类不满的根源</strong>：一篇经济学论文分析了广告如何通过引发欲望和比较，成为人们不满情绪的重要来源。<a href="https://www.andrewoswald.com/docs/AdvertisingMicheletal2019EasterlinVolume.pdf">Andrew Oswald PDF</a></li> </ul> <h2 id="-科技与社会趋势">🌐 科技与社会趋势</h2> <ul> <li><strong>宝马PHEV天价维修费</strong>：报告指出宝马插电混动车碰撞后安全熔断器更换成本极高，引发维修和环保争议。<a href="https://evclinic.eu/2025/12/04/2021-phev-bmw-ibmucp-21f37e-post-crash-recovery-when-eu-engineering-becomes-a-synonym-for-unrepairable-generating-waste/">EV Clinic</a></li> <li><strong>美国污染者改写欧盟法律</strong>：调查揭露美国污染企业如何秘密游说，试图改写欧盟人权和气候法规。<a href="https://www.somo.nl/the-secretive-cabal-of-us-polluters-that-is-rewriting-the-eus-human-rights-and-climate-law/">Somo</a></li> <li><strong>肯尼亚废除种子分享禁令</strong>：肯尼亚法院裁定禁止种子分享的法律违宪，对农民权利和生物多样性保护产生积极影响。<a href="https://apnews.com/article/kenya-seed-sharing-law-ruling-ad4df5a364299b3a9f8515c0f52d5f80">AP News</a></li> <li><strong>美国药价远超欧洲</strong>：报道揭示一款在欧洲售价 20 美元的药物，在美国需处方且售价高达 800 美元，凸显药价巨大差异。<a href="https://www.statnews.com/2025/10/31/why-miebo-costs-40-times-more-than-its-european-version/">STAT News</a></li> <li><strong>GPL案件Vizio方败诉信号</strong>：法官在 Software Freedom Conservancy 针对 Vizio 的 GPL 案件中发出有利信号，可能加强开源许可强制执行。<a href="https://fossforce.com/2025/12/judge-signals-win-for-software-freedom-conservancy-in-vizio-gpl-case/">FOSS Force</a></li> <li><strong>Ofcom监管文件第四部分</strong>：Preston Byrne 博客文章系列深入探讨了英国 Ofcom 监管机构的最新动态及对科技行业的影响。<a href="https://prestonbyrne.com/2025/12/04/the-ofcom-files-part-4-ofcom-rides-again/">Preston Byrne</a></li> </ul> <h2 id="-新奇项目--show-hn">📱 新奇项目 / Show HN</h2> <ul> <li><strong>Jolla手机开启预售</strong>：搭载 Sailfish OS 的 Jolla 手机再次开启预售，为用户提供另类移动体验。<a href="https://commerce.jolla.com/products/jolla-phone-preorder">Jolla Commerce</a></li> <li><strong>让RSS更有趣</strong>：一篇博客分享了通过创意方法，如使用 AI 或自动化，提升 RSS 阅读体验的技巧。<a href="https://matduggan.com/making-rss-more-fun/">Mat Duggan</a></li> </ul> <h2 id="-科学与健康">🔬 科学与健康</h2> <ul> <li><strong>新冠mRNA疫苗与全因死亡率</strong>：JAMA Network Open 发布研究，评估新冠 mRNA 疫苗接种与四年全因死亡率的关系。<a href="https://jamanetwork.com/journals/jamanetworkopen/fullarticle/2842305">JAMA Network Open</a></li> <li><strong>草甘膦安全性研究被撤回</strong>：一项关于草甘膦安全性的重要研究在发表 25 年后被撤回，引发了对科学诚信的广泛关注。<a href="https://www.lemonde.fr/en/environment/article/2025/12/03/influential-study-on-glyphosate-safety-retracted-25-years-after-publication_6748114_114.html">Le Monde</a></li> <li><strong>带状疱疹疫苗与痴呆症</strong>：Cell 期刊研究发现带状疱疹疫苗接种对不同痴呆症阶段的影响，为疾病预防提供新视角。<a href="https://www.cell.com/cell/fulltext/S0092-8674(25)01256-5">Cell</a></li> <li><strong>小行星Bennu样本发现糖类</strong>：NASA OSIRIS-REx 任务从小行星 Bennu 样本中首次发现糖类、胶状物质和星尘，可能揭示生命起源线索。<a href="https://www.nasa.gov/missions/osiris-rex/sugars-gum-stardust-found-in-nasas-asteroid-bennu-samples/">NASA</a></li> </ul> <h2 id="-快速浏览">🎯 快速浏览</h2> <ul> <li><strong>知名建筑师弗兰克·盖里去世</strong>：以解构主义建筑闻名全球的弗兰克·盖里享年 96 岁，其作品影响深远。<a href="https://www.bbc.co.uk/news/articles/c5y2p22z9gno">BBC News</a></li> <li><strong>YC和初创公司移民律师AMA</strong>：Peter Roberts 在 Hacker News 上举办 AMA，解答移民和初创公司相关的法律问题。<a href="https://news.ycombinator.com/item?id=46163121">Hacker News</a></li> </ul> <h2 id="-dev-tricks">🧰 Dev Tricks</h2> <ul> <li><strong>现代SVG Clickjacking攻击</strong>：一篇关于利用 SVG 实现现代 Clickjacking 攻击，绕过浏览器安全警告的技术分析。<a href="https://lyra.horse/blog/2025/12/svg-clickjacking/">Lyra Horse Blog</a></li> <li><strong>Rust防御性编程模式</strong>：深入探讨 Rust 语言中防御性编程的模式和最佳实践，提升代码健壮性。<a href="https://corrode.dev/blog/defensive-programming/">Corrode Blog</a></li> <li><strong>为何用Zig构建Lightpanda</strong>：Lightpanda 团队分享了选择 Zig 语言构建项目的原因、优势和实践经验。<a href="https://lightpanda.io/blog/posts/why-we-built-lightpanda-in-zig">Lightpanda Blog</a></li> </ul>]]></content><author><name></name></author><category term="微信公众号"/><category term="微信公众号"/><category term="Blog"/><summary type="html"><![CDATA[🔥 今日重点（Top Picks）]]></summary></entry><entry><title type="html">LeoTalk AI周知 11: VLA到世界模型</title><link href="https://ifuryst.github.io/blog/2025/leotalk-ai-weekly-11-vla-to-world-model/" rel="alternate" type="text/html" title="LeoTalk AI周知 11: VLA到世界模型"/><published>2025-12-01T00:00:00+00:00</published><updated>2025-12-01T00:00:00+00:00</updated><id>https://ifuryst.github.io/blog/2025/leotalk-ai-weekly-11-vla-to-world-model</id><content type="html" xml:base="https://ifuryst.github.io/blog/2025/leotalk-ai-weekly-11-vla-to-world-model/"><![CDATA[<p>可以明显感觉到这几个月来VLA和世界模型的提及率变高了。</p> <p>首先是以自动驾驶为主的企业，基本上都在押注VLA（Vision Language Action）。得益于大语言模型的发展，原来通过写规则的自动驾驶，在Tesla转向端到端模型之后，其他自动驾驶也纷纷跟进。现在基本上头部的自动驾驶都有相应的VLA模型了。通过相关的语料训练（更多后阶段），让模型可以基于视觉+文本，直接产出对应的行动指令。这个方向其实和机器人（或者具身智能）是匹配的，机器人也可以通过视觉+文本（指令等）来生成下一步的行动。</p> <p>其实我们也可以看到，现在有一些大模型开始直接是输出Agent和Tool了，也是一样的趋势，因为很多应用场景已经不在满足于纯文本输入输出了，很多时候输出并不需要是可阅读的文本，很多时候是需要输出下一步的Action，比如调用什么Agent、调用什么工具、执行什么命令等等。之前大多是在提示词级别来做，跟之前CoT一样，现在这部分也开始下沉到训练阶段来做了。所以我们也可以看到一些Agent模型的出现。</p> <p>再来说说世界模型，LeCun、李飞飞都开始押注世界模型，现在硅谷基本上也在世界模型方向上加大投入了。可以看到今年下半年来，不断有世界模型的出现。在某些情况下，世界模型和视频模型是有一定的overlap，不冲突，不过最重要的区别还是在于是否可接受输入来改变输出。比如单纯视频生成模型，一般给完文本提示词后一次生成，而世界模型则是可以通过类似前后左右的控制去影响下一帧的产生。</p> <p>从某种角度也可以理解，这个还是蛮符合直觉的，毕竟纯文本的信息密度和带宽还是远远不足的，就好像你看一篇文章和刷视频的差别一样。</p> <p>另外很重要的一点是，世界模型有很多可预见甚至是正在发生的有价值的应用场景。比如我们前面提到的VLA对于自动驾驶和机器人来说，世界模型是一个很重要的方向，甚至某种程度上可以是VLA的后续发展和结合的方向。</p> <p>现在一个非常重要的应用场景就是用世界模型去合成训练自动驾驶和机器人所需要的数据，尤其是机器人，这类数据的量特别少的，如果要人为去产生成本是极其大的（人遥控机器人，采集数据。或者人挂摄像头，采集人的行动数据等），合成数据应该是未来非常重要的方向。这个其实也不止这个方向，甚至大语言模型现在都开始借助合成数据来训练。合成数据的起点不高，但是天花板很高，毕竟人类产生的数据是不可能比机器产生的多和快，现在是在探索一些通过量和覆盖率来提升整体的基线，这样可以在质量赶不上真是数据的同时，用量级+算力来换质量</p> <p>差不多是这些碎片化的想法</p> <h1 id="产品模型发布">产品&amp;模型发布</h1> <ul> <li>Google<a href="https://developers.googleblog.com/introducing-code-wiki-accelerating-your-code-understanding/">推出</a><a href="https://codewiki.google/">CodeWiki</a>，和DeepWiki一样的产品</li> <li>Anthropic<a href="https://www.anthropic.com/news/claude-opus-4-5">推出</a>Claude Opus 4.5，看着主要还是应对来自Gemini3和GPT5.1-Codex-Max的压力</li> <li>DeepSeek<a href="https://github.com/deepseek-ai/DeepSeek-Math-V2">发布</a>DeepSeek-Math-V2</li> <li>腾讯开源<a href="https://github.com/Tencent-Hunyuan/HunyuanOCR">HunyuanOCR</a></li> <li>微软<a href="https://www.microsoft.com/en-us/research/blog/fara-7b-an-efficient-agentic-model-for-computer-use/">推出</a>Fara-7B，CUA场景</li> <li>Black Forest Labs推出<a href="https://bfl.ai/models/flux-2">FLUX.2</a>图片生成和编辑模型</li> </ul> <h1 id="投资商业">投资&amp;商业</h1> <ul> <li>Meta愿意接受TPU的背后表明了一个解决方案的可能性，之前NVIDIA提供显卡，不管上层平台和Infra，现在TPU的模式可以走Google的全家桶。我觉得这个点才是NVIDIA股价应声下跌的一个重要诱因。</li> </ul> <h1 id="其他阅读">其他阅读</h1> <ul> <li>Ilya的<a href="https://www.dwarkesh.com/p/ilya-sutskever-2">访谈</a>，大家都在讨论他说的Scaling时代结束，我觉得不如直接听听他的整体观点</li> <li><a href="https://github.com/VectorSpaceLab/general-agentic-memory">General Agentic Memory (GAM)</a></li> <li><a href="https://arxiv.org/abs/2511.17208">A Simple Yet Strong Baseline for Long-Term Conversational Memory of LLM Agents</a></li> <li><a href="https://blog.modelcontextprotocol.io/posts/2025-11-21-mcp-apps/">MCP Apps</a>扩展MCP，让MCP Server可以返回可交互UI给客户端</li> <li><a href="https://arxiv.org/abs/2511.21689">ToolOrchestra: Elevating Intelligence via Efficient Model and Tool Orchestration</a>：规模效应被质疑的同时，大量小参数模型表现出不错的推理能力的背后也是一个探索方向的分叉</li> <li><a href="https://www.youtube.com/watch?app=desktop&amp;v=AnTw_t21ayE">Stanford AI Club: Jeff Dean on Important AI Trends</a>DeepMind纪录片，30年跟拍，很牛</li> <li><a href="https://thinkinggamefilm.com/">DeepMind纪录片</a>，跟拍Demis的30年，牛</li> </ul>]]></content><author><name></name></author><category term="Blog"/><category term="Blog"/><category term="微信公众号"/><category term="Substack"/><summary type="html"><![CDATA[可以明显感觉到这几个月来VLA和世界模型的提及率变高了。]]></summary></entry><entry><title type="html">大模型采样策略</title><link href="https://ifuryst.github.io/blog/2025/llm-sampling/" rel="alternate" type="text/html" title="大模型采样策略"/><published>2025-11-30T00:00:00+00:00</published><updated>2025-11-30T00:00:00+00:00</updated><id>https://ifuryst.github.io/blog/2025/llm-sampling</id><content type="html" xml:base="https://ifuryst.github.io/blog/2025/llm-sampling/"><![CDATA[<p>在调用大模型的时候，你可以会看到过temperature，top-k甚至是top-p，min-p这些参数，它们的含义是什么呢？</p> <p>这些其实都涉及到了大模型的采样（Sampling）策略，这些内容可以影响模型的输出，甚至是输出风格，比如模型输出更具创造力还是，更加更倾向准确确定的方向。我们最多的应该是使用了Temperature来控制，我们知道大一点（比如1）可以输出更加创造性的内容，小一点（比如0.1）的可以输出更加准确的内容。这些其实都跟一个叫做Softmax有关</p> <h1 id="temperature">Temperature</h1> <p>在Transformer的Encoder环节，简化流程大概是这样：</p> <ol> <li>输入<code class="language-plaintext highlighter-rouge">我是Leo</code></li> <li>经过分词、向量、变换和计算，最终得到logit，如：<code class="language-plaintext highlighter-rouge">[4.8, 3.0, 2.9]</code> ，此时还没经过归一化</li> <li>我们计算softmax，<code class="language-plaintext highlighter-rouge">softmax([4.8, 3.0, 2.9])=~ [0.65, 0.13, 0.11]</code>（可以简单理解成做归一化+重点放大，就让概率变成0-1之间的数值，同时放大差异，也就是重要的概率更大点，不重要的概率更小点）</li> </ol> <p>temperature为什么能影响到结果呢，因为softmax的公式是：</p> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-11-30-llm-sampling/1764495648_15-480.webp 480w,/assets/img/2025-11-30-llm-sampling/1764495648_15-800.webp 800w,/assets/img/2025-11-30-llm-sampling/1764495648_15-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/2025-11-30-llm-sampling/1764495648_15.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> </div> </div> <p>其中T就是temperature，T的大小是可以控制sofmax的分布是否尖锐的。基本上看到这个解释直接晕倒，我们看这张图：</p> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-11-30-llm-sampling/1764495648_16-480.webp 480w,/assets/img/2025-11-30-llm-sampling/1764495648_16-800.webp 800w,/assets/img/2025-11-30-llm-sampling/1764495648_16-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/2025-11-30-llm-sampling/1764495648_16.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> </div> </div> <p>可以看到4种不同的T下表现差异不同，其中：</p> <ul> <li>横轴表示不同候选词</li> <li>纵轴表示这个词的概率（简化的说法）</li> </ul> <p>可以看到T越大，结果之间的的差异小了，表现为所有候选词的概率分布被拉平了，大家彼此更加接近，这种情况下模型更难分别出哪个词是合适的。</p> <p>而T变小后，差异会明显凸显，高概率的词会显得概率更大，有区分度</p> <p>实际例子看一下：</p> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-11-30-llm-sampling/1764495648_17-480.webp 480w,/assets/img/2025-11-30-llm-sampling/1764495648_17-800.webp 800w,/assets/img/2025-11-30-llm-sampling/1764495648_17-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/2025-11-30-llm-sampling/1764495648_17.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> </div> </div> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-11-30-llm-sampling/1764495648_18-480.webp 480w,/assets/img/2025-11-30-llm-sampling/1764495648_18-800.webp 800w,/assets/img/2025-11-30-llm-sampling/1764495648_18-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/2025-11-30-llm-sampling/1764495648_18.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> </div> </div> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-11-30-llm-sampling/1764495649_19-480.webp 480w,/assets/img/2025-11-30-llm-sampling/1764495649_19-800.webp 800w,/assets/img/2025-11-30-llm-sampling/1764495649_19-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/2025-11-30-llm-sampling/1764495649_19.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> </div> </div> <p>可以看到候选词的概率分布差异。所以我们用Temperature来改变模型输出风格就是这个原理。</p> <h2 id="top-k">Top-K</h2> <p>接下去是TOP K，这个就很好理解，在产生的多个候选词中，只筛选出概率最高的那K个，比如这里的：</p> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-11-30-llm-sampling/1764495649_20-480.webp 480w,/assets/img/2025-11-30-llm-sampling/1764495649_20-800.webp 800w,/assets/img/2025-11-30-llm-sampling/1764495649_20-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/2025-11-30-llm-sampling/1764495649_20.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> </div> </div> <p>最终只筛选了前3个。这种策略有个问题，就是适应性差，本质上就是完全不在乎候选词的情况，硬性选择前K个，比如K=10，在某些情况下可能太大（包含很多无关紧要的候选词进来），在另一个情况下可能有太小（把一些好的候选词都去掉了）</p> <p>因此我们会有一些进一步的策略来解决这些问题</p> <h1 id="top-p">Top-P</h1> <p>Top-P也叫Nucleus Sampling 核采样，原理是保留累积概率超过P的候选词，比如：</p> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-11-30-llm-sampling/1764495649_21-480.webp 480w,/assets/img/2025-11-30-llm-sampling/1764495649_21-800.webp 800w,/assets/img/2025-11-30-llm-sampling/1764495649_21-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/2025-11-30-llm-sampling/1764495649_21.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> </div> </div> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-11-30-llm-sampling/1764495649_22-480.webp 480w,/assets/img/2025-11-30-llm-sampling/1764495649_22-800.webp 800w,/assets/img/2025-11-30-llm-sampling/1764495649_22-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/2025-11-30-llm-sampling/1764495649_22.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> </div> </div> <p>P=0.2的时候，命中了2个候选词：了解13.35%+咨询7.63%=20.98%大于20%（0.2） P=0.25的时候，前面的2个候选词加起来就不够了，再加一个问6.98%=27.96%就大于25%了</p> <p>这个策略的好处是能自适应，比如在面临特别多候选词的时候，可以通过概率限定去干掉太多不相关的，在候选词不足的情况下也能补充到满足要求</p> <h1 id="min-p">Min-P</h1> <p>我们来看个情况</p> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-11-30-llm-sampling/1764495650_23-480.webp 480w,/assets/img/2025-11-30-llm-sampling/1764495650_23-800.webp 800w,/assets/img/2025-11-30-llm-sampling/1764495650_23-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/2025-11-30-llm-sampling/1764495650_23.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> </div> </div> <p>可以看到这个情况下，如果是top-p，P=0.1的情况下，只会得到<code class="language-plaintext highlighter-rouge">一个11.18%</code>，哪怕<code class="language-plaintext highlighter-rouge">了解9.47%</code> 也同样适合甚至更适合的情况下，这种时候Min-P可以通过设置最小的概率P=0.09来降这两个都高概率的结果捞出来，总体而言带来的好处是：</p> <ul> <li>保留“亚军词”，也就是前面说的这个情况</li> <li>解决长尾问题，比如累积P不足，大量捞到一些小概率的候选词，实际上不一定有什么帮助</li> <li>适应性更好，如果出现绝对领先，那不会有更多干扰进来，如果出现不确定性较强的候选词，可以让跟多接近的候选词进来</li> </ul> <h1 id="总结">总结</h1> <p>通常来说我们也不只是单独使用一个策略，而是将多个策略一起使用。除了前面介绍的这些采样策略以外，还有一些其他的，比如Exclude Top-K，也就是去掉Top K的结果，比如去掉Top1，这样有助于模型输出根据创造力的结果，减少模板化输出</p> <p>文中用到例子我开源放在了<a href="https://github.com/iFurySt/llm-sampling">这里</a>，可以本地直接通过python运行起来，默认会去HuggingFace上拉Qwen/Qwen3-0.6B模型，可以很方便的测试和查看</p>]]></content><author><name></name></author><category term="AI"/><category term="AI"/><category term="Tech"/><summary type="html"><![CDATA[在调用大模型的时候，你可以会看到过temperature，top-k甚至是top-p，min-p这些参数，它们的含义是什么呢？]]></summary></entry><entry><title type="html">大模型上下文工程实践指南-第7章：智能体</title><link href="https://ifuryst.github.io/blog/2025/ce101-6-agent/" rel="alternate" type="text/html" title="大模型上下文工程实践指南-第7章：智能体"/><published>2025-11-26T00:00:00+00:00</published><updated>2025-11-26T00:00:00+00:00</updated><id>https://ifuryst.github.io/blog/2025/ce101-6-agent</id><content type="html" xml:base="https://ifuryst.github.io/blog/2025/ce101-6-agent/"><![CDATA[<h1 id="71-智能体agent简述">7.1 智能体（Agent）简述</h1> <p>基于大语言模型的上层应用，已经从基于提示词、无状态、无计划和无记忆的阶段，进入到了更加复杂的阶段，这个阶段需要结合工程实践来赋能大语言模型，虽然大模型在推理阶段只是面向上下文，但是我们可以通过外挂的方式，通过一些传统的工程实现来使得整个AI应用和服务变成有状态、有计划和有记忆的存在。到这里我们就会触及AI Agent这个LLM上层应用形态，也是目前以及未来都会很流行的东西</p> <p>那么什么是AI Agent呢？很多人有不同的认知，我认为AI Agent就是给大模型<strong>工具</strong>和<strong>环境</strong>，这样大模型可以在思考后决定采用什么动作，这其中就有通过<strong>工具使用</strong>来<strong>感知环境</strong>，这样可以得到外部的信息，比如命令行执行的结果，请求API的结果，网页搜索的结果，甚至是物理世界的视觉反馈或传感器的结果。基于这些信息，AI Agent可以结合自身在训练阶段得到的通识能力去做决策、执行和判断。这种也是目前以ReAct为基础的一种AI Agent的通用范式</p> <p>另外，Agent相比于RAG和提示词技术这些来说是更加复杂的系统，需要在稳定且连续的情况之下，让大模型通过计划、执行和观察等手段实现多轮次的循环，直到最终解决问题。这其中不是简单的写下提示词，对接外部工具和大模型就行，更多的还是在于从系统层面进行调度的能力，推理和执行链路，以及状态和记忆的管理，包括一些边界情况的管控和收敛。因此我们会认为AI Agent的能力体现可以用以下的等式来表示：</p> <p><strong>AI Agent=80%的工程能力+20%的AI</strong></p> <p>因为底座是基于大语言模型（LLMs），也有一些提示词相关的技术，其他的更多还是涉及传统行业的工程技术，不管是缓存，还是上下文存储、置换等技术，因此到Agent这里，可以认为是<strong>需要有工程化能力的同时还具备AI思维</strong></p> <p>在脱离研究层面往应用层面走的过程中，我们会越来越容易感受到这个现象，我们需要从最基础的提示词设计开始，到记忆、知识库、工具的管理，再到整个Workflow的编排，甚至进一步到多Agent的编排和协作，除了这些以外，我们还需要涉及到一些可观测的铺设，数据采集回补调优，还需要弹性部署（可以是云原生那一套）和监控（也是云原生那一套），甚至还需要沙盒环境，长短周期任务执行引擎等</p> <p>可能看到这里有些人会觉得没有这么复杂，其实这恰巧反映了现在的情况。现在我们其实可以花几天就可以做出一个AI Agent，但是这是一个Toy Agent，大白话就是一个玩具，0-1的一个MVP，我们随便用一个AI Agent的框架就可以轻松Build出来，网上也有大把的教程，但是现实和理想之间的Gap是非常大的，一旦我们进入到追求有业务价值、有商业价值的AI Agent层面，不是一个人一个AI几天就能做出来的，通常需要花费团队很多时间精力和资源去优化，我相信这个也是2025年剩下的日子里和2026年最大的研究课题和应用方向了</p> <p>下面我们来看一张Letta<a href="https://www.letta.com/blog/ai-agents-stack">去年</a>整理的一张图：</p> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-11-26-ce101-6-agent/1764171647_2-480.webp 480w,/assets/img/2025-11-26-ce101-6-agent/1764171647_2-800.webp 800w,/assets/img/2025-11-26-ce101-6-agent/1764171647_2-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/2025-11-26-ce101-6-agent/1764171647_2.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> </div> </div> <p>虽然数据已经是一年前的了，但是我们也可以看出，现在AI Agent已经如雨后春笋不断涌现了，2025年更是被称为Agent之年。Agent也是目前业界统一共识的方向，因为Agent未来是可以继续演进的，甚至可以一直持续到AGI时代。接下去我们一起来看看AI Agent的相关设计范式</p> <h1 id="72-智能体设计范式">7.2 智能体设计范式</h1> <h2 id="721-react">7.2.1 ReAct</h2> <p>在基础提示技术章节中我们也有提到<a href="https://arxiv.org/abs/2210.03629">ReAct</a>，实际上ReAct的思想在Agent领域得到了最大的发挥，其思想也在很大程度上影响了后面出现的一些框架。ReAct也已经在生产环境得到了验证，<strong>是一个Agent Loop的通解</strong></p> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-11-26-ce101-6-agent/1764171650_3-480.webp 480w,/assets/img/2025-11-26-ce101-6-agent/1764171650_3-800.webp 800w,/assets/img/2025-11-26-ce101-6-agent/1764171650_3-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/2025-11-26-ce101-6-agent/1764171650_3.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> </div> </div> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-11-26-ce101-6-agent/1764171650_4-480.webp 480w,/assets/img/2025-11-26-ce101-6-agent/1764171650_4-800.webp 800w,/assets/img/2025-11-26-ce101-6-agent/1764171650_4-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/2025-11-26-ce101-6-agent/1764171650_4.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> </div> </div> <p>回归AI Agent的根本，其实就是<strong>Loop+Tokens</strong>，我们拆解来看看：</p> <ol> <li><strong>Loop</strong>：其实也就是循环，类比人类解决一个问题，就是不断去尝试，直到解决，这就是一个循环，只不过循环长短不同，人的一生也可以看作是一个大几十年上百年的Loop。</li> <li><strong>Tokens</strong>：这算是一个比较Tech的说法了，就是Loop中，就是不断的去让大模型思考决策，行动，和收集反馈信息继续下次的计划和执行。这个其实也是ReAct的核心思想了</li> </ol> <p>所以实际上我们要实现一个AI Agent，最简单的就是以ReAct为基础，去构建一个不断循环的推理（Reason），行动（Act）和观察（Observe）</p> <h2 id="722-self-reflection">7.2.2 Self-Reflection</h2> <p>Self-Reflection是Noah Shinn等人在2025年5月<a href="https://arxiv.org/abs/2303.11366">提出的</a>（后发布在当年的NeurIPS）。可以理解是带了复盘系统的Agent，架构如下：</p> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-11-26-ce101-6-agent/1764171651_5-480.webp 480w,/assets/img/2025-11-26-ce101-6-agent/1764171651_5-800.webp 800w,/assets/img/2025-11-26-ce101-6-agent/1764171651_5-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/2025-11-26-ce101-6-agent/1764171651_5.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> </div> </div> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-11-26-ce101-6-agent/1764171651_6-480.webp 480w,/assets/img/2025-11-26-ce101-6-agent/1764171651_6-800.webp 800w,/assets/img/2025-11-26-ce101-6-agent/1764171651_6-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/2025-11-26-ce101-6-agent/1764171651_6.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> </div> </div> <p>相比于ReAct来说，Self-Reflection在Action之后通过记忆来沉淀出一些策略，持续的纠错和优化改进。通过这样的手段来提升整体的效果</p> <h2 id="723-codeact">7.2.3 CodeAct</h2> <p><a href="https://github.com/xingyaoww/code-act">CodeAct</a>是以<a href="https://github.com/xingyaoww">Xingyao Wang</a>为首的几个人在<a href="https://arxiv.org/abs/2402.01030">2024年2月提出来的</a>，在那之后的2024年3月<a href="https://github.com/All-Hands-AI/OpenHands">OpenHands</a>（原OpenDevin）诞生了，Xingyao也把这个应用到了OpenHands中</p> <p>CodeAct的核心思想很简单，就是让大模型输出并执行可执行代码，实现高效、精准的工具调用，以进一步完成复杂任务的手段。说到这里聪明的你应该也想到这个怎么和工具调用或函数调用（Tool/Function Calling）有点类似？实际上CodeAct和函数调用都是为了让大模型调用外部工具而设计的机制，只不过有一些差别：</p> <ul> <li>函数调用通常定义对应的调用格式，比如JSON，难以实现复杂操作</li> <li>CodeAct可以通过LLM生成完整的可执行的Python代码，支持较为复杂的操作</li> </ul> <p>我们看个对比的例子，大模型吐出的函数调用为：</p> <div class="language-json highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">{</span><span class="w">
  </span><span class="nl">"function"</span><span class="p">:</span><span class="w"> </span><span class="s2">"get_weather"</span><span class="p">,</span><span class="w">
  </span><span class="nl">"parameters"</span><span class="p">:</span><span class="w"> </span><span class="p">{</span><span class="w"> </span><span class="nl">"location"</span><span class="p">:</span><span class="w"> </span><span class="s2">"Shanghai"</span><span class="p">,</span><span class="w"> </span><span class="nl">"date"</span><span class="p">:</span><span class="w"> </span><span class="s2">"2025-08-16"</span><span class="w"> </span><span class="p">}</span><span class="w">
</span><span class="p">}</span><span class="w">
</span></code></pre></div></div> <p>而同样情况下，CodeAct为：</p> <div class="language-json highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="err">get_weather(</span><span class="s2">"Shanghai"</span><span class="err">,</span><span class="w"> </span><span class="s2">"2025-08-16"</span><span class="err">)</span><span class="w">
</span></code></pre></div></div> <p>并且其实CodeAct可以完成更加复杂的操作，比如：</p> <div class="language-json highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="err">weather</span><span class="w"> </span><span class="err">=</span><span class="w"> </span><span class="err">get_weather(</span><span class="s2">"Shanghai"</span><span class="err">,</span><span class="w"> </span><span class="s2">"2025-08-16"</span><span class="err">)</span><span class="w">
</span><span class="err">send_email(to=</span><span class="s2">"user@example.com"</span><span class="err">,</span><span class="w"> </span><span class="err">content=weather)</span><span class="w">
</span></code></pre></div></div> <p>这样可以连续串联多个操作，也就是CodeAct的核心，输出完整的可操作代码，外部服务负责具体的执行逻辑。另外具备了一些流程控制的能力，比如条件、循环等，可以进一步降低任务复杂度。最后是复用已有基础设施，比如CodeAct最初提出就是针对Python常见，这种情况下是可以复用Python里的标准库或三方库，无需重复定义新的工具</p> <p>CodeAct正是因为其特性，现在也被众多AI Coding Assistant采用，很多跟Coding有关的Agent都会集成CodeAct或者以CodeAct思想为基础的变体</p> <h2 id="724-workflow">7.2.4 Workflow</h2> <p>我觉得<strong>工作流Workflow</strong>也可以列在Agent设计范式里，以<a href="https://github.com/coze-dev/coze-studio">Coze</a>、<a href="https://github.com/langgenius/dify">Dify</a>、<a href="https://github.com/n8n-io/n8n">n8n</a>等为主的工作流编排是一个很重要的应用分支。我们也可以看到很多人在讨论<strong>Agent or Workflow？</strong>这个就需要我们先分辨一下这两者的差别了</p> <p>引用n8n官方repo里的这张图：</p> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-11-26-ce101-6-agent/1764171651_7-480.webp 480w,/assets/img/2025-11-26-ce101-6-agent/1764171651_7-800.webp 800w,/assets/img/2025-11-26-ce101-6-agent/1764171651_7-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/2025-11-26-ce101-6-agent/1764171651_7.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> </div> </div> <p>典型的Workflow就是通过一个一个节点组成的流，这些节点有不同的类型和用途，有条件分支节点，有调用大模型的节点等等。Workflow通常是一个比较固定的流程，大模型没有太大的自主决策权， 通常是以<strong>DAG（Directed Acyclic Graph，有向无环图）</strong>存在的</p> <p>Anthropic的<a href="https://www.anthropic.com/engineering/building-effective-agents">这篇文章</a>划分了Workflow的好几种形态：</p> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-11-26-ce101-6-agent/1764171651_8-480.webp 480w,/assets/img/2025-11-26-ce101-6-agent/1764171651_8-800.webp 800w,/assets/img/2025-11-26-ce101-6-agent/1764171651_8-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/2025-11-26-ce101-6-agent/1764171651_8.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> </div> </div> <p>通过<strong>Prompt chaining（提示链）</strong>连接：</p> <blockquote> <p>Prompt chaining decomposes a task into a sequence of steps, where each LLM call processes the output of the previous one. You can add programmatic checks (see “gate” in the diagram below) on any intermediate steps to ensure that the process is still on track.</p> </blockquote> <p>Prompt Chaining就是前一个输出给到下一个输入，串联了多个节点，这多个节点可能同时都请求了大模型，但是可能拥有不同的Prompt。</p> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-11-26-ce101-6-agent/1764171651_9-480.webp 480w,/assets/img/2025-11-26-ce101-6-agent/1764171651_9-800.webp 800w,/assets/img/2025-11-26-ce101-6-agent/1764171651_9-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/2025-11-26-ce101-6-agent/1764171651_9.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> </div> </div> <p><strong>Routing（路由）</strong>通过路由将问题路由到不同的节点处理，可以应对不同场景的需求</p> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-11-26-ce101-6-agent/1764171652_10-480.webp 480w,/assets/img/2025-11-26-ce101-6-agent/1764171652_10-800.webp 800w,/assets/img/2025-11-26-ce101-6-agent/1764171652_10-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/2025-11-26-ce101-6-agent/1764171652_10.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> </div> </div> <p><strong>Parallelization（并行化）</strong>是通过并行执行，最后在进行结果聚合，适合一些可拆分成可并行执行的任务，多个子任务单元一起执行，可以获得很快的速度。</p> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-11-26-ce101-6-agent/1764171652_11-480.webp 480w,/assets/img/2025-11-26-ce101-6-agent/1764171652_11-800.webp 800w,/assets/img/2025-11-26-ce101-6-agent/1764171652_11-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/2025-11-26-ce101-6-agent/1764171652_11.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> </div> </div> <p><strong>Orchestrator-workers（编排工作者）</strong>是前面的并行化的提升，通过大模型对任务的拆解后分配对应的worker执行，有一定的弹性空间，但是依然还是在预定义的Worker里选择</p> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-11-26-ce101-6-agent/1764171652_12-480.webp 480w,/assets/img/2025-11-26-ce101-6-agent/1764171652_12-800.webp 800w,/assets/img/2025-11-26-ce101-6-agent/1764171652_12-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/2025-11-26-ce101-6-agent/1764171652_12.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> </div> </div> <p><strong>Evaluator-optimizer（评估-优化循环）</strong>一个节点生成结果一个节点做评估，不断循环直到结束</p> <p>正如前面Anthropic文章里提到的</p> <blockquote> <p>When to use this workflow: This workflow is ideal for situations where the task can be easily and cleanly decomposed into fixed subtasks. The main goal is to trade off latency for higher accuracy, by making each LLM call an easier task.</p> </blockquote> <p><strong>Workflow适合任务是可以被清除的解构成固定的子任务单元</strong>。Workflow相对于Agent有个天然的优势就是<strong>高效率</strong>，且效果非常<strong>稳定</strong>，执行基本都能在预期范围内，<strong>不可预知或者说未知性很低</strong>。缺点自然就是不够灵活了，面对一些开放的或者无法预定义的任务就无法处理了。有一句话特别好：<strong>Workflow和Agent的差别在于控制权，Workflow是程序控制模型，而Agent是模型控制程序</strong>。</p> <p><strong>现在大家的一个共识是基于Routing去做路由，可以路由到Workflow，也可以路由到Agent，这样可以让已知的场景可以稳定高效的执行，未知的场景可以Agent兜底自主决策。</strong></p> <p>简单用一个表格来对比Workflow和Agent：</p> <h2 id="725-multi-agent">7.2.5 Multi-Agent</h2> <p>当面对复杂任务的时候，通常会将任务拆解成多个子任务来处理，这样有助于追踪完成情况，也有助于Agent可以专注于某个子任务的执行。这个也是Planning+Action的思路，但是在实际应用中会发现，任务复杂度不断提高的情况下，Agent的上下文里会充满了各种工具调用的信息，哪怕前一个任务执行完后，执行那个任务的相关信息依然滞留在上下文里，导致上下文不断膨胀，最终可能影响后续任务的执行和最终结果的输出。</p> <p>基于这样的背景之下，结合我们之前学习的上下文隔离手段，现在行业里普遍的做法是使用多智能体（Multi-Agent）的架构来组织多智能体，这样可以将不同的子任务交给对应的Agent来执行，达到上下文隔离和每个Agent独立迭代优化的目的。</p> <p>从理论角度看有不少多智能体的组织方式（甚至类似网络拓扑的感觉），比如<a href="https://blog.dailydoseofds.com/p/7-patterns-in-multi-agent-systems">ddd</a>这张图就展示了7种：</p> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-11-26-ce101-6-agent/1764171652_13-480.webp 480w,/assets/img/2025-11-26-ce101-6-agent/1764171652_13-800.webp 800w,/assets/img/2025-11-26-ce101-6-agent/1764171652_13-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/2025-11-26-ce101-6-agent/1764171652_13.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> </div> </div> <p>但是在实践过程中最流行的是Supervisor（或LeadAgent、Orchestrator）+SubAgent的组织方式（对应图里的Hierarchical），其实就是主Agent+子Agent的方式。</p> <h2 id="726-小结">7.2.6 小结</h2> <p>到这里已经了解了一些流行的范式，其实从更高维度来划分是可以划分为：</p> <ul> <li><strong>Single Agent（单智能体）</strong>：以ReAct为主，Self-Reflection和CodeAct还有其他的变种都可算作这个分类</li> <li><strong>Workflow（工作流）</strong>：以DAG去编排节点，LangGraph、Dify、Coze等在一定程度上都可以看作是工作流的一种</li> <li><strong>Multi-Agent（多智能体）</strong>：不管是Swarm还是Supervisor，本质上都是将上下文隔离拆分进不同的Agent实例的一种多Agent组织和写作方式</li> <li><strong>Hybrid（混合模式）</strong>：可能混合以上的内容，最常见的就是通过Workflow形式来编排Agent，典型例子就是通过LangGraph编排，本质上是工作流，但是内部的节点有可能是Agent在执行。还有一种是通过意图判断和路由层来将已知的场景路由到工作流，未知的场景用Agent来兜底</li> </ul> <p>汇总成一个直观的表格：</p> <h1 id="73-总结">7.3 总结</h1> <p>相信前面的内容让我们对于Agent有了一个全局的认知了，接下去基本上是HandsOn去尝试，从Toy、Demo和MVP出发，最终打造出Production-Ready的Agent，在这期间有几个关键点有助于在选型和迭代过程中去辅助决策：</p> <ol> <li>权衡好<strong>延迟</strong>、<strong>费用</strong>和<strong>性能</strong>，这能进一步决定是采用workflow、agent还是混合两者</li> <li>平衡好<strong>控制</strong>和<strong>授权</strong>的关系，可以更好地选择合适的agent系统设计范式</li> <li>用最简单有效的手段达到既定目标</li> </ol> <p>但是知易行难，这也是行业快速发展背后最强的阻力，基本表现为就是效果不好，成本高企等等。这也是我们必须要正视的问题，也是上下文工程存在的必要。引用一段<a href="https://www.decodingai.com/p/getting-agent-architecture-right">这篇文章</a>里的内容：</p> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-11-26-ce101-6-agent/1764171653_14-480.webp 480w,/assets/img/2025-11-26-ce101-6-agent/1764171653_14-800.webp 800w,/assets/img/2025-11-26-ce101-6-agent/1764171653_14-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/2025-11-26-ce101-6-agent/1764171653_14.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> </div> </div> <p>可以看到，在Build一个Agent的过程中，会陆续遇到很多问题，心路历程也是一变再变。因此本质上还是没有银弹，一切应该回归业务和用户导向，Agent是手段而不是目的。</p> <p>至此，我们对于上下文工程的一些正在流行的技术有了全面的认知了，但是更多还是概念性或者理论性的，要做好这个工程并不容易，正如Anthropic<a href="https://www.anthropic.com/engineering/effective-context-engineering-for-ai-agents">这篇文章</a>里的一句话：</p> <blockquote> <p>Implementing this practice is much easier said than done</p> </blockquote> <p>我相信这也是现在为什么上下文工程是一个非共识的实践学科。因为好坏、合适之类的标准都是比较难以量化的。我坚信能不断推动效果提升的主要集中在这么几点上：</p> <ol> <li>有夯实的认知：对于现有的可行技术有个全面的认知，可以随意取用</li> <li>能积极跟进前沿技术的发展：不管是个人还是企业，都可以在这块赢得时间差的优势</li> <li>迭代，快速迭代：只有这样才可以不断推陈出新，包括不断试错和探索</li> <li>保持不断重构现有产品和架构的能力和意识：技术发展伴随着不断重建</li> <li>闭环能力：部署只是开始，需要不断收集数据进行调优和改进</li> </ol> <p>接下去，Let’s Rock!</p>]]></content><author><name></name></author><category term="AI"/><category term="AI"/><category term="CE101"/><category term="Book"/><summary type="html"><![CDATA[7.1 智能体（Agent）简述]]></summary></entry><entry><title type="html">LeoTalk AI周知 10: 基模&amp;amp;专模</title><link href="https://ifuryst.github.io/blog/2025/leotalk-ai-weekly-10-base-model-n-specialized-mode/" rel="alternate" type="text/html" title="LeoTalk AI周知 10: 基模&amp;amp;专模"/><published>2025-11-24T00:00:00+00:00</published><updated>2025-11-24T00:00:00+00:00</updated><id>https://ifuryst.github.io/blog/2025/leotalk-ai-weekly-10-base-model-n-specialized-mode</id><content type="html" xml:base="https://ifuryst.github.io/blog/2025/leotalk-ai-weekly-10-base-model-n-specialized-mode/"><![CDATA[<p>各厂商仍然在卷基模，但也只是头部的还在坚持。很多没那么头部的模型厂已经开始分化了，甚至很多上升到应用层了，实在是ROI很难评。尤其是本身没有现金牛的情况下，基本上属于在烧VC的钱，如果没办法做到行业TOP，基本上很难持续。</p> <p>最近OAI内部流出来的<a href="https://www.theinformation.com/articles/openai-ceo-braces-possible-economic-headwinds-catching-resurgent-google">memo</a>也表明了其对于Google这类互联网时代大厂的强力追赶表示出忧虑，Ed Zitron的<a href="https://www.wheresyoured.at/oai_docs/">分析</a>也表明OAI的推理成本是很高的。从这几个月来OAI的应用层产品迭代情况也可以窥见一些背后的动机。成本居高不下，非常吃投资，降本并探索应用层产品的更多盈利空间成为了必然。</p> <p>另外一个点是，很多实际的应用，并不依赖于最SOTA的模型，对于一个大而全模型的追求，似乎也不是完全的共识了。甚至现在专模专用成为了很多行业的现状，最SOTA的模型不一定能带来最大的价值，反而是小参数微调后的模型的价值有可能更高。</p> <p>期待基模的下次“涌现”，下次aha moment。在此之前，多关注基模之外的世界</p> <h1 id="产品模型发布">产品&amp;模型发布</h1> <ul> <li>xAI<a href="https://x.ai/news/grok-4-1">发布</a>Grok 4.1</li> <li>Google<a href="https://blog.google/products/gemini/gemini-3-gemini-app/">发布</a>Gemini3，反响不错，大家都在讨论</li> <li>Google发布<a href="https://antigravity.google/">Antigravity</a>，类似Cursor，可以免费使用Gemini 3 pro，小试了一下，体感不错</li> <li>OpenAI<a href="https://openai.com/index/gpt-5-1-codex-max/">推出</a>GPT‑5.1-Codex-Max</li> <li>Meta<a href="https://ai.meta.com/blog/segment-anything-model-3/">发布</a>SAM 3模型（Segment Anything Model 3），用文本、示例图像和视觉提示（如点、框）在图像和视频中进行对象检测、分割和跟踪</li> <li>AI2<a href="https://allenai.org/blog/olmo3">发布</a>OLMo 3（7B，32B），真正的开源，不仅开源权重，还开源了训练数据、训练过程、checkpoint、中间思维过程</li> <li>Google<a href="https://blog.google/technology/ai/nano-banana-pro/">推出</a>Nano Banana Pro</li> <li>微软<a href="https://www.microsoft.com/en-us/microsoft-365/blog/2025/11/18/microsoft-agent-365-the-control-plane-for-ai-agents/">推出</a>Agent 365</li> </ul> <h1 id="投资商业">投资&amp;商业</h1> <ul> <li>Cursor用2年达到了10亿美元的ARR，很猛</li> </ul> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-11-24-leotalk-ai-weekly-10-base-model-n-specialized-mode/1763997047_1-480.webp 480w,/assets/img/2025-11-24-leotalk-ai-weekly-10-base-model-n-specialized-mode/1763997047_1-800.webp 800w,/assets/img/2025-11-24-leotalk-ai-weekly-10-base-model-n-specialized-mode/1763997047_1-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/2025-11-24-leotalk-ai-weekly-10-base-model-n-specialized-mode/1763997047_1.jpeg" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> </div> </div> <ul> <li>BTC掉下9万刀了</li> <li>微软（$10B）和英伟达（$5B）一起投资Anthropic（估值达到$350B）</li> </ul> <h1 id="其他阅读">其他阅读</h1> <ul> <li><a href="https://github.com/ZHZisZZ/dllm">https://github.com/ZHZisZZ/dllm</a></li> <li><a href="https://arxiv.org/pdf/2511.14617">Seer: Online Context Learning for Fast Synchronous LLM Reinforcement Learning</a></li> <li><a href="https://arxiv.org/abs/2511.08923">TiDAR: Think in Diffusion, Talk in Autoregression</a></li> </ul>]]></content><author><name></name></author><category term="AI"/><category term="AI"/><category term="Tech"/><category term="LeoTalkAIWeekly"/><summary type="html"><![CDATA[各厂商仍然在卷基模，但也只是头部的还在坚持。很多没那么头部的模型厂已经开始分化了，甚至很多上升到应用层了，实在是ROI很难评。尤其是本身没有现金牛的情况下，基本上属于在烧VC的钱，如果没办法做到行业TOP，基本上很难持续。]]></summary></entry><entry><title type="html">LeoTalk AI周知 9: 算法or工程</title><link href="https://ifuryst.github.io/blog/2025/leotalk-ai-weekly-9-algorithm-or-engineering/" rel="alternate" type="text/html" title="LeoTalk AI周知 9: 算法or工程"/><published>2025-11-17T00:00:00+00:00</published><updated>2025-11-17T00:00:00+00:00</updated><id>https://ifuryst.github.io/blog/2025/leotalk-ai-weekly-9-algorithm-or-engineering</id><content type="html" xml:base="https://ifuryst.github.io/blog/2025/leotalk-ai-weekly-9-algorithm-or-engineering/"><![CDATA[<p>这周内容不多，也没有什么特别有亮点的。</p> <p>最近在思考算法和工程这两个东西。我们应该追求算法还是工程？前者更多是偏向研究和前沿探索，后者为Idea提供了实际应用落地的能力。</p> <p>虽然我是坚定的模糊学科边界的支持者，但是我还是会觉得对于大部分人来说是会有侧重的，毕竟牛人双修的还是少数。算法非常吃学历，或者进一步挖一下，非常吃个人的“学术”能力，这个和学历的高低有一定的正相关性。而后者更注重实操，学历和能力的正相关性没有前者高。</p> <p>没有算法也就没有大模型的出现，一代一代人不断研究和探索未知，技术才能不断发展，这个很重要，虽然现在模型增速放缓了，但是不代表未来也更远了，并且AI的发展本来也不是线形的，很多时候是跨越式的。</p> <p>没有工程化，大模型很难进一步挖掘出商业价值，进一步普适。很多商业价值的创造并不在于前沿科技的突破，而是行业化、规模化，这个也符合我们过往几十年互联网和移动互联网的认知。在行业或产业中大规模应用多种技术，不同的结合手段和规模创新，可以产生很好的产品和应用，进一步创造很大的商业价值，或许还能进一步反哺研究。</p> <p>其实我也不迷茫或困惑，我是偏工程侧的。只是最近看到不少青年朋友关于这块产生了很大的疑惑和撕扯感，会有一种很错配很怪诞的想法。或许问题的根源就不是算法还是工程的问题。</p> <h1 id="产品模型发布">产品&amp;模型发布</h1> <ul> <li>OpenAI<a href="https://openai.com/index/gpt-5-1/">推出</a>GPT 5.1，个人感觉没什么亮点需要关注</li> <li>百度推出<a href="https://huggingface.co/baidu/ERNIE-4.5-VL-28B-A3B-Thinking"><strong>ERNIE-4.5-VL-28B-A3B-Thinking</strong></a>模型，多模态推理开源模型，</li> <li>World Labs<a href="https://www.worldlabs.ai/blog/marble-world-model">推出</a>Marble，李飞飞他们推出的首个世界模型</li> <li>阿里抽调上百人团队准备打造千问APP，对标ChatGPT（也能理解，相对于豆包和DeepSeek，千问的C端产品认知一直很弱，一组数据：豆包1.59亿日活，通义只有7百万月活</li> <li>OpenAI<a href="https://openai.com/index/group-chats-in-chatgpt/">推出</a>群聊（部分地区）</li> <li>百度<a href="https://x.com/Baidu_Inc/status/1988820837898829918">推出</a>多模态大模型ERNIE 5.0</li> <li>LM Arena<a href="https://news.lmarena.ai/code-arena/">推出</a>Code Arena</li> <li>Cerebras推出<a href="https://huggingface.co/cerebras/MiniMax-M2-REAP-162B-A10B">MiniMax-M2-REAP-162B-A10B</a>，基于minimax m2的一个内存更高效的变体版本</li> </ul> <h1 id="投资商业">投资&amp;商业</h1> <ul> <li>软银清仓Nvidia股票58亿美元，为了all in OpenAI和其他AI bets</li> </ul> <h1 id="其他阅读">其他阅读</h1> <ul> <li><a href="https://arxiv.org/abs/2510.26658"><strong>The Era of Agentic Organization: Learning to Organize with Language Models</strong></a>：提出AsyncThink，推理通过fork分叉最后再合并来提高效果，需要runtime来支持<FORK-1>和<JOIN-1>这种特殊的token</JOIN-1></FORK-1></li> <li><a href="https://ai.meta.com/research/publications/omnilingual-asr-open-source-multilingual-speech-recognition-for-1600-languages/"><strong>Omnilingual ASR: Open-Source Multilingual Speech Recognition for 1600+ Languages</strong></a>：Meta FAIR推出的Omnilingual ASR，支持1600种语音的多语种语音识别，7B大小</li> <li><a href="https://arxiv.org/pdf/2511.03773">Scaling Agent Learning via Experience Synthesis</a></li> <li><a href="https://deepmind.google/blog/sima-2-an-agent-that-plays-reasons-and-learns-with-you-in-virtual-3d-worlds/"><strong>SIMA 2: An Agent that Plays, Reasons, and Learns With You in Virtual 3D Worlds</strong></a></li> <li><a href="https://github.com/GibsonAI/Memori"><strong>Memori</strong></a>：An open-source SQL-Native memory engine for AI</li> <li>Google发了一份<a href="https://www.kaggle.com/whitepaper-context-engineering-sessions-and-memory">上下文工程白皮书</a></li> </ul>]]></content><author><name></name></author><category term="AI"/><category term="AI"/><category term="Tech"/><category term="LeoTalkAIWeekly"/><summary type="html"><![CDATA[这周内容不多，也没有什么特别有亮点的。]]></summary></entry><entry><title type="html">LeoTalk · Hacker News Daily · 2025.11.13</title><link href="https://ifuryst.github.io/blog/2025/leotalk-hacker-news-daily-november-13-2025/" rel="alternate" type="text/html" title="LeoTalk · Hacker News Daily · 2025.11.13"/><published>2025-11-13T00:00:00+00:00</published><updated>2025-11-13T00:00:00+00:00</updated><id>https://ifuryst.github.io/blog/2025/leotalk-hacker-news-daily-november-13-2025</id><content type="html" xml:base="https://ifuryst.github.io/blog/2025/leotalk-hacker-news-daily-november-13-2025/"><![CDATA[<h2 id="-今日重点top-picks">🔥 今日重点（Top Picks）</h2> <ul> <li><strong>Valve发布全新Steam Machine、控制器和Steam Frame</strong>：Valve推出了新一代游戏硬件，包括主机、控制器及Steam Frame，引发市场关注。（<a href="https://www.phoronix.com/news/Steam-Machines-Frame-2026">Phoronix</a>、<a href="https://store.steampowered.com/sale/steammachine">Steam Machine</a>、<a href="https://store.steampowered.com/sale/steamframe">Steam Frame</a>）</li> <li><strong>Yann LeCun离开Meta创办AI公司</strong>：Meta首席AI科学家Yann LeCun宣布离职，将专注于“世界模型”领域创立新公司。（<a href="https://www.nasdaq.com/articles/metas-chief-ai-scientist-yann-lecun-depart-and-launch-ai-start-focused-world-models">Nasdaq</a>）</li> <li><strong>OpenAI推出GPT-5.1</strong>：新版本ChatGPT在智能和对话能力上进一步提升，提供更流畅的交互体验。（<a href="https://openai.com/index/gpt-5-1/">OpenAI</a>）</li> <li><strong>Anthropic斥资500亿美元投资美国AI基础设施</strong>：AI巨头Anthropic宣布在美进行大规模投资，旨在推动AI硬件及算力发展。（<a href="https://www.anthropic.com/news/anthropic-invests-50-billion-in-american-ai-infrastructure">Anthropic</a>）</li> <li><strong>Waymo自动驾驶出租车扩展至高速公路</strong>：Waymo无人驾驶车辆现已在洛杉矶、旧金山和凤凰城的城市高速公路上提供载客服务。（<a href="https://techcrunch.com/2025/11/12/waymo-robotaxis-are-now-giving-rides-on-freeways-in-these-3-cities/">TechCrunch</a>）</li> </ul> <h2 id="-思维激荡mind-food">🧠 思维激荡（Mind Food）</h2> <ul> <li><strong>你将一无所有并（不）快乐</strong>：一篇关于未来社会所有权模式及个人幸福感之间关系的思考文章。（<a href="https://racc.blog/you-will-own-nothing-and-be-unhappy/">racc.blog</a>）</li> <li><strong>Transmeta：最后一个大型互联网IPO的沉浮</strong>：回顾互联网泡沫时期，CPU设计公司Transmeta的兴衰史。（<a href="https://dfarq.homeip.net/what-happened-to-transmeta-the-last-big-dotcom-ipo/">dfarq.homeip.net</a>）</li> </ul> <h2 id="-科技与社会趋势">🌐 科技与社会趋势</h2> <ul> <li><strong>美国最后一枚便士铸造完成</strong>：最后一枚美国便士在费城铸造，标志着这一货币单位即将成为历史。（<a href="https://www.cnn.com/2025/11/12/business/last-penny-minted">CNN</a>）</li> <li><strong>OpenAI反击《纽约时报》隐私侵犯指控</strong>：OpenAI发布声明，反驳《纽约时报》对其用户隐私保护提出的质疑。（<a href="https://openai.com/index/fighting-nyt-user-privacy-invasion">OpenAI</a>）</li> <li><strong>Maestro Technology被曝将旧SSD作新销售</strong>：有报告揭露Maestro Technology公司涉嫌将二手固态硬盘重新包装为新品出售。（<a href="https://kozubik.com/items/MaestroTechnology/">kozubik.com</a>）</li> <li><strong>AI数据中心引发硬盘荒，交货期长达两年</strong>：由于AI数据中心对存储需求激增，企业级硬盘出现严重短缺，订单积压两年。（<a href="https://www.tomshardware.com/pc-components/hdds/ai-triggers-hard-drive-shortage-amidst-dram-squeeze-enterprise-hard-drives-on-backorder-by-2-years-as-hyperscalers-switch-to-qlc-ssds">Tom’s Hardware</a>）</li> <li><strong>英国暂停与美国在加勒比海域的情报共享</strong>：英国因地区空袭事件，暂停了与美国在加勒比海域可疑贩毒船只方面的情报合作。（<a href="https://www.theguardian.com/uk-news/2025/nov/11/uk-suspends-intelligence-sharing-with-us-amid-airstikes-in-the-caribbean">The Guardian</a>）</li> <li><strong>欧盟可能通过“后门”实施“聊天控制2.0”</strong>：警告指出，欧盟正酝酿通过隐蔽方式实施新的数字监控法案，或对用户通信进行广泛扫描。（<a href="https://www.patrick-breyer.de/en/chat-control-2-0-through-the-back-door-breyer-warns-the-eu-is-playing-us-for-fools-now-theyre-scanning-our-texts-and-banning-teens/">patrick-breyer.de</a>）</li> </ul> <h2 id="-新奇项目--show-hn">📱 新奇项目 / Show HN</h2> <ul> <li><strong>Perkeep：个人终身存储系统</strong>：一个开源的个人数据管理和存储系统，旨在帮助用户长期保存数字资产。（<a href="https://perkeep.org/">Perkeep</a>）</li> <li><strong>Micro.blog推出“Studio”视频托管服务</strong>：Micro.blog新增支持视频托管的订阅层，为创作者提供独立的YouTube替代方案。（<a href="https://heydingus.net/blog/2025/11/micro-blog-offers-an-indie-alternative-to-youtube-with-its-studio-video-hosting-plan">heydingus.net</a>）</li> </ul> <h2 id="-快速浏览">🎯 快速浏览</h2> <ul> <li><strong>巴基斯坦报纸误印AI生成提示</strong>：一张截图显示，某巴基斯坦报纸在文章中错误地刊登了AI写作的原始指令。（<a href="https://twitter.com/omar_quraishi/status/1988518627859951986">Twitter</a>）</li> <li><strong>呼吁捐款维护网络时间协议（NTP）</strong>：NTP项目正在寻求捐助，以确保全球网络时间同步服务的持续运行。（<a href="https://www.ntp.org/">NTP.org</a>）</li> <li><strong>Project Euler</strong>：一个提供一系列富有挑战性的数学和计算机科学问题的网站，适合程序员和数学爱好者锻炼思维。（<a href="https://projecteuler.net/">Project Euler</a>）</li> </ul> <h2 id="-dev-tricks">🧰 Dev Tricks</h2> <ul> <li><strong>Yt-dlp全功能YouTube支持需外部JS运行时</strong>：知名视频下载工具yt-dlp更新，现在需要外部JavaScript运行时以完全支持YouTube。（<a href="https://github.com/yt-dlp/yt-dlp/issues/15012">GitHub</a>）</li> <li><strong>Learn Prolog Now</strong>：一份在线教程，系统教授Prolog编程语言的基础知识和应用。（<a href="https://lpn.swi-prolog.org/lpnpage.php?pageid=top">lpn.swi-prolog.org</a>）</li> <li><strong>在GPU上模拟行星：第一部分</strong>：系列文章的第一篇，探讨如何利用GPU的并行计算能力进行逼真的行星模拟。（<a href="https://www.patrickcelentano.com/blog/planet-sim-part-1">patrickcelentano.com</a>）</li> <li><strong>FreeBSD简介</strong>：一篇简要概述FreeBSD操作系统的设计理念、特点及其应用领域的文章。（<a href="https://yorickpeterse.com/articles/a-brief-look-at-freebsd/">yorickpeterse.com</a>）</li> <li><strong>法线贴图背后的几何原理</strong>：深入解析法线贴图在3D渲染中工作的基础几何学原理，及其如何影响视觉细节。（<a href="https://www.shlom.dev/articles/geometry-behind-normal-maps/">shlom.dev</a>）</li> <li><strong>Homebrew不再允许绕过Gatekeeper安装未签名软件</strong>：Homebrew更新其策略，不再支持用户绕过macOS Gatekeeper安装未经签名或公证的应用程序。（<a href="https://github.com/Homebrew/brew/issues/20755">GitHub</a>）</li> </ul>]]></content><author><name></name></author><category term="HNDailyReport"/><category term="HNDailyReport"/><summary type="html"><![CDATA[🔥 今日重点（Top Picks）]]></summary></entry><entry><title type="html">LeoTalk · Hacker News Daily · 2025.11.12</title><link href="https://ifuryst.github.io/blog/2025/leotalk-hacker-news-daily-november-12-2025/" rel="alternate" type="text/html" title="LeoTalk · Hacker News Daily · 2025.11.12"/><published>2025-11-12T00:00:00+00:00</published><updated>2025-11-12T00:00:00+00:00</updated><id>https://ifuryst.github.io/blog/2025/leotalk-hacker-news-daily-november-12-2025</id><content type="html" xml:base="https://ifuryst.github.io/blog/2025/leotalk-hacker-news-daily-november-12-2025/"><![CDATA[<h2 id="-今日重点top-picks">🔥 今日重点（Top Picks）</h2> <ul> <li><strong>沃伦·巴菲特发布最后一封股东信</strong>：总结其投资哲学与伯克希尔哈撒韦的未来走向。<a href="https://berkshirehathaway.com/news/nov1025.pdf">[pdf]</a></li> <li><strong>软银出售英伟达全部股份</strong>：以58.3亿美元套现，引发市场广泛关注。<a href="https://www.cnbc.com/2025/11/11/softbank-sells-its-entire-stake-in-nvidia-for-5point83-billion.html">[CNBC]</a></li> <li><strong>德国法院裁定OpenAI未经许可不得使用歌词</strong>：为AI内容生成领域的版权问题设立重要判例。<a href="https://www.reuters.com/world/german-court-sides-with-plaintiff-copyright-case-against-openai-2025-11-11/">[Reuters]</a></li> <li><strong>加拿大失去麻疹清除认证</strong>：美国也可能步其后尘，凸显全球公共卫生挑战。<a href="https://www.bbc.com/news/articles/cy7e2lv4r8xo">[BBC]</a></li> <li><strong>监测到X5.1级太阳耀斑及G4级地磁暴警报</strong>：可能对地球通讯系统造成影响。<a href="https://www.spaceweatherlive.com/en/news/view/593/20251111-x5-1-solar-flare-g4-geomagnetic-storm-watch.html">[spaceweatherlive.com]</a></li> </ul> <h2 id="-ai--开发工具">📦 AI &amp; 开发工具</h2> <ul> <li><strong>FFmpeg呼吁谷歌资助或停止提交错误报告</strong>：凸显开源项目面临的资金挑战。<a href="https://thenewstack.io/ffmpeg-to-google-fund-us-or-stop-sending-bugs/">[The New Stack]</a></li> <li><strong>DeepWiki：可对话的AI文档平台</strong>：为每个代码仓库提供AI驱动的交互式文档。<a href="https://deepwiki.com/">[deepwiki.com]</a></li> <li><strong>扩展HNSW算法的深度探讨</strong>：深入分析如何优化分层导航小世界图索引的性能。<a href="https://antirez.com/news/156">[antirez.com]</a></li> <li><strong>Zig与C++互操作实践</strong>：探讨如何高效地在Zig项目中整合现有的C++代码。<a href="https://tuple.app/blog/zig-cpp-interop">[tuple.app]</a></li> <li><strong>Blender 5.1版本发布</strong>：带来多项新功能、改进和性能优化。<a href="https://developer.blender.org/docs/release_notes/5.1/">[developer.blender.org]</a></li> <li><strong>AI图像模型横向评测</strong>：通过600多次生成，详细比较前沿AI图像模型的表现。<a href="https://latenitesoft.com/blog/evaluating-frontier-ai-image-generation-models/">[latenitesoft.com]</a></li> </ul> <h2 id="-思维激荡mind-food">🧠 思维激荡（Mind Food）</h2> <ul> <li><strong>你记忆中的《玩具总动员》</strong>：一篇探讨人们对电影集体记忆与实际内容差异的文章。<a href="https://animationobsessive.substack.com/p/the-toy-story-you-remember">[animationobsessive.substack.com]</a></li> <li><strong>我讨厌文本截图</strong>：一篇吐槽并分析为何截取文本图片而非直接复制是低效行为的文章。<a href="https://parkscomputing.com/page/i-hate-screenshots-of-text">[parkscomputing.com]</a></li> <li><strong>协作的弊端</strong>：一篇文章探讨了在特定情况下，协作可能效率低下且令人沮丧的原因。<a href="https://newsletter.posthog.com/p/collaboration-sucks">[newsletter.posthog.com]</a></li> <li><strong>创意作品质量与投入精力超线性关系</strong>：分析为何感知质量的提升需要指数级的努力。<a href="https://markusstrasser.org/creative-work-landscapes.html">[markusstrasser.org]</a></li> <li><strong>“先写后读”规则</strong>：探讨这一原则在构建高性能、高可靠系统中的应用。<a href="https://tigerbeetle.com/blog/2025-11-06-the-write-last-read-first-rule/">[tigerbeetle.com]</a></li> </ul> <h2 id="-科技与社会趋势">🌐 科技与社会趋势</h2> <ul> <li><strong>Firefox加强指纹识别保护</strong>：进一步提升用户在线隐私安全。<a href="https://blog.mozilla.org/en/firefox/fingerprinting-protections/">[blog.mozilla.org]</a></li> <li><strong>美国AI采用每年增加约90万吨碳排放</strong>：研究揭示AI普及对环境的影响。<a href="https://techxplore.com/news/2025-11-ai-tons-annually/">[TechXplore]</a></li> <li><strong>科学家呼吁停止过度炒作AI</strong>：敦促欧盟委员会主席冯德莱恩关注AI的潜在风险。<a href="https://www.euractiv.com/news/stop-overhyping-ai-scientists-tell-von-der-leyen/">[euractiv.com]</a></li> </ul> <h2 id="-新奇项目--show-hn">📱 新奇项目 / Show HN</h2> <ul> <li><strong>iPhone Pocket</strong>：苹果探索iPhone全新佩戴与携带方式的概念产品。<a href="https://www.apple.com/newsroom/2025/11/introducing-iphone-pocket-a-beautiful-way-to-wear-and-carry-iphone/">[Apple Newsroom]</a></li> <li><strong>现代家用35mm胶片扫描仪</strong>：Soke Engineering推出高质量胶片扫描解决方案。<a href="https://www.soke.engineering/">[soke.engineering]</a></li> <li><strong>Gametje - 休闲在线游戏平台</strong>：提供轻松有趣的网页游戏体验。<a href="https://gametje.com">[gametje.com]</a></li> </ul> <h2 id="-科学与健康">🔬 科学与健康</h2> <ul> <li><strong>PETase酶细菌在全球海洋中广泛分布</strong>：有望为塑料降解提供生物解决方案。<a href="https://academic.oup.com/ismej/article/19/1/wraf121/8159680?login=false">[academic.oup.com]</a></li> <li><strong>焦虑症与大脑胆碱水平低下相关</strong>：为理解和治疗焦虑症提供新线索。<a href="https://medicalxpress.com/news/2025-11-anxiety-disorders-essential-nutrient-brain/">[MedicalXpress]</a></li> <li><strong>微塑料：不再是“可能”的威胁</strong>：强调微塑料问题已普遍存在且影响深远。<a href="https://ibbi.io/mp">[ibbi.io]</a></li> </ul> <h2 id="-快速浏览">🎯 快速浏览</h2> <ul> <li>🧦 <strong>iPod Socks</strong>：回顾苹果曾推出的多彩iPod保护袜。<a href="https://en.wikipedia.org/wiki/IPod_Socks">[Wikipedia]</a></li> <li>📝 <strong>象形文字版“Hello, world”</strong>：一篇2009年的文章展示了古埃及象形文字的编程趣味。<a href="https://optional.is/required/2009/12/03/welcome-the-entire-land/">[optional.is]</a></li> <li>💻 <strong>Z-Machine上的Advent of Code</strong>：一位开发者在复古虚拟机上挑战编程谜题。<a href="https://entropicthoughts.com/advent-of-code-on-z-machine">[entropicthoughts.com]</a></li> </ul> <h2 id="-dev-tricks">🧰 Dev Tricks</h2> <ul> <li>💼 <strong>2025年小型独立工作室招聘开发者</strong>：探讨招聘挑战与策略。<a href="https://www.ballardgames.com/tales/hiring-dev-2025/">[ballardgames.com]</a></li> <li>📅 <strong>Pikaday：前端日期选择器指南</strong>：帮助开发者选择和实现最佳方案。<a href="https://pikaday.dbushell.com">[pikaday.dbushell.com]</a></li> <li>⚙️ <strong>Rust实现缓存友好、低内存Lanczos算法</strong>：优化计算性能的技术细节。<a href="https://lukefleed.xyz/posts/cache-friendly-low-memory-lanczos/">[lukefleed.xyz]</a></li> <li>🚀 <strong>未来终端的构想</strong>：探讨如何改进终端工具以提升开发效率。<a href="https://jyn.dev/the-terminal-of-the-future">[jyn.dev]</a></li> </ul>]]></content><author><name></name></author><category term="HNDailyReport"/><category term="HNDailyReport"/><summary type="html"><![CDATA[🔥 今日重点（Top Picks）]]></summary></entry><entry><title type="html">LeoTalk AI周知 8: 注意力机制发展</title><link href="https://ifuryst.github.io/blog/2025/leotalk-ai-weekly-8-evolution-of-attention/" rel="alternate" type="text/html" title="LeoTalk AI周知 8: 注意力机制发展"/><published>2025-11-11T00:00:00+00:00</published><updated>2025-11-11T00:00:00+00:00</updated><id>https://ifuryst.github.io/blog/2025/leotalk-ai-weekly-8-evolution-of-attention</id><content type="html" xml:base="https://ifuryst.github.io/blog/2025/leotalk-ai-weekly-8-evolution-of-attention/"><![CDATA[<p>最近通过<a href="https://magazine.sebastianraschka.com/p/beyond-standard-llms">这篇文章</a>和<a href="https://www.xiaoyuzhoufm.com/episode/6908b9c80ceab2a71c48668c?s=eyJ1IjogIjY4Mzk3OTM0ZDFkMzUwNzI2OWRiOTQ4NCJ9">这个播客</a>，了解了一下现在一些模型厂探索的方向，以及Transformer和对应的注意力机制在行业如何演进的，有一种很清晰的认知提升了，推荐有时间的可以去看看和听听。用我自己的理解大概总结一下相关的内容：</p> <ol> <li>Transformer包含FFN和Attention，前者在DeepSeek的助推下，MoE已经全面流行，后者是会继续发展的一个方向</li> <li>DeepSeek走了稀疏注意力机制（Sparse Attention）的方向</li> <li>MiniMax原来M1走了线性注意力机制（Linear Attention）的方向，但是最新发布的M2又回到全局意力（Full Attention）</li> <li>Kimi还持续在Linear Attention方向探索</li> <li>OAI之类的硅谷模型厂不发paper了，但是应该也有在这些方面去探索</li> <li>Transformer不一定最好的架构，但却是最亲和GPU的架构，效率最大化</li> </ol> <p>关于几个注意力：</p> <ul> <li>全局注意力（Full Attention）：默认的，每个Token看所有Token；<strong>O(n²)</strong>，成本高，上下文变长就爆炸</li> <li>局部注意力/滑动窗口（Sliding Window Attention）：成本更低，适合长序列；只能看到局部，信息传播慢。OpenAI开源的OSS就走了这个方案</li> <li>稀疏注意力（Sparse Attention）：高效看重点信息；需要特殊设计</li> <li>线性注意力（Linear Attention）：理论可扩展到超长序列；可能损失精度</li> <li>混合注意力（Hybrid Attention）：多宗注意力机制混搭，让模型既能看长上下文，又能不爆内存，不降低速度</li> </ul> <p>最近明显感觉到AI for Science这种用于科学研究和探索的应用变多了，这周也能看到好几个类似的AI科学的应用，OAI也有相应的口径去表达这个。</p> <h1 id="研究报告">研究报告</h1> <ul> <li>Artificial Analysis发布<a href="https://artificialanalysis.ai/downloads/state-of-ai/2025/Q3-2025-Artificial-Analysis-State-of-AI-Highlights-Report.pdf">2025-Q3的AI报告</a>：大模型竞争剧烈；Agentic能力成为重点；开源模型加速度迭代发布；STS模型达到生产应用级别；图片编辑和视频生成成为主流</li> <li>麦肯锡发布<a href="https://www.mckinsey.com/capabilities/quantumblack/our-insights/the-state-of-ai"><strong>The state of AI in 2025</strong></a>：AI带来的重点不在于省人省事，而在于用AI重新设计工作方式、在全公司推广，并把它当成增长和创新的引擎</li> </ul> <h1 id="产品模型发布">产品&amp;模型发布</h1> <ul> <li>Chrome支持SplitView</li> <li>Kimi<a href="https://moonshotai.github.io/Kimi-K2/thinking.html">推出</a>K2 Thinking，可以在无人干预下连续执行200-300个工具调用</li> <li>Google<a href="https://blog.google/technology/developers/file-search-gemini-api/">推出</a>File Search Tool，包装好的RAG，通过接口提供，省心开发，对个开或者快速MVP landing来说是可行的</li> <li><a href="https://huggingface.co/mlfoundations/Gelato-30B-A3B">Gleato-30B-A3B</a>，用于GUI Computer-Use任务，基于Qwen3 VL</li> <li>Google<a href="https://cloud.google.com/blog/products/compute/ironwood-tpus-and-new-axion-based-vms-for-your-ai-workloads">推出</a>第七代TPU Ironwood，比v5p（5代里最强的版本）快10倍</li> <li>小鹏<a href="https://www.xpeng.com/news/019a56f54fe99a2a0a8d8a0282e402b7">推出</a>VLA2.0、RoboTaxi、 Iron机器人、飞行汽车</li> <li>OpenAI<a href="https://openai.com/index/introducing-indqa/">发了</a>一个能理解文化差异的基准测试IndQA</li> </ul> <h1 id="投资商业">投资&amp;商业</h1> <ul> <li>OpenAI与Amazon达成380亿美元的计算能力<a href="https://x.com/ajassy/status/1985351258333643172">交易</a>。（截至目前OAI和微软、Google、Oracle和亚马逊都有类似的交易了</li> <li>微软97亿美元从IREN购买算力，批准向UAE运送NVIDIA显卡，和Lambda达成数十亿美元协议</li> <li>Perplexity付4亿美元（现金+股权）给Snap，用于在Snapchat里集成Perplexity，Snap的股价涨了15%</li> </ul> <h1 id="热点论文">热点论文</h1> <ul> <li><a href="https://arxiv.org/abs/2511.01846"><strong>Towards Robust Mathematical Reasoning</strong></a>，Google DeepMind推出IMO-Bench基准测试</li> <li><a href="https://arxiv.org/abs/2511.03601"><strong>Step-Audio-EditX Technical Report</strong></a>：StepFun AI开源的3B Step-Audio-EditX音频编辑模型的技术报告</li> <li><a href="https://arxiv.org/abs/2511.02824"><strong>Kosmos: An AI Scientist for Autonomous Discovery</strong></a>：AI科学家，<a href="https://edisonscientific.com/">Edison Scientific</a>的</li> <li><a href="https://arxiv.org/pdf/2511.03929"><strong>NVIDIA Nemotron Nano V2 VL</strong></a></li> <li><a href="https://arxiv.org/abs/2511.04670"><strong>Cambrian-S: Towards Spatial Supersensing in Video</strong></a>：纽约大学和斯坦福大学推出的Cambrian-S模型，用于空间推理，还提出一个benchmark</li> <li><a href="https://research.google/blog/introducing-nested-learning-a-new-ml-paradigm-for-continual-learning/"><strong>Introducing Nested Learning: A new ML paradigm for continual learning</strong></a> by Google</li> <li><a href="https://arxiv.org/abs/2511.03773"><strong>Scaling Agent Learning via Experience Synthesis</strong></a> by Meta，提出了DreamGym框架，用模拟和推理生成的经验来训练Agent，RL就不在依赖于真实环境跑任务。</li> <li><a href="https://www.microsoft.com/en-us/research/blog/magentic-marketplace-an-open-source-simulation-environment-for-studying-agentic-markets/"><strong>Magentic Marketplace: an open-source simulation environment for studying agentic markets</strong></a> by Microsoft，推出Magentic Marketplace，一个开源仿真平台，模拟未来AI Agent经济</li> <li><a href="https://arxiv.org/abs/2510.26493"><strong>Context Engineering 2.0: The Context of Context Engineering</strong></a>：把上下文工程定义为降低熵的过程，定义了上下文的4个时代，从最早人类负责把混乱世界压缩成AI能懂的内容，到逐渐转向AI自主去构建上下文的未来</li> <li><a href="https://arxiv.org/abs/2510.27246"><strong>Beyond a Million Tokens: Benchmarking and Enhancing Long-Term Memory in LLMs</strong></a></li> </ul> <h1 id="其他阅读">其他阅读</h1> <ul> <li>李飞飞在写Substack了，第一篇文章聊了<a href="https://drfeifei.substack.com/p/from-words-to-worlds-spatial-intelligence">空间智能（Spatial Intelligence）</a>，空间智能基于世界模型，有三个原则：可生成generative，多模态multimodal，可交互interactive。（Substack助推了一群反碎片化信息摄入人群的需求，顺势而为，越做越大</li> </ul>]]></content><author><name></name></author><category term="AI"/><category term="AI"/><category term="Tech"/><category term="LeoTalkAIWeekly"/><summary type="html"><![CDATA[最近通过这篇文章和这个播客，了解了一下现在一些模型厂探索的方向，以及Transformer和对应的注意力机制在行业如何演进的，有一种很清晰的认知提升了，推荐有时间的可以去看看和听听。用我自己的理解大概总结一下相关的内容：]]></summary></entry><entry><title type="html">LeoTalk · Hacker News Daily · 2025.11.11</title><link href="https://ifuryst.github.io/blog/2025/leotalk-hacker-news-daily-november-11-2025/" rel="alternate" type="text/html" title="LeoTalk · Hacker News Daily · 2025.11.11"/><published>2025-11-11T00:00:00+00:00</published><updated>2025-11-11T00:00:00+00:00</updated><id>https://ifuryst.github.io/blog/2025/leotalk-hacker-news-daily-november-11-2025</id><content type="html" xml:base="https://ifuryst.github.io/blog/2025/leotalk-hacker-news-daily-november-11-2025/"><![CDATA[<h2 id="-今日重点top-picks">🔥 今日重点（Top Picks）</h2> <ul> <li><strong>警方如何获取你的线上私人数据</strong>：深入探讨执法部门获取个人网络数据的方法与隐私风险。<a href="https://www.eff.org/deeplinks/2025/06/how-cops-can-get-your-private-online-data">EFF</a></li> <li><strong>DNS提供商Quad9面临存亡威胁</strong>：因反盗版指令被迫屏蔽内容，引发互联网自由担忧。<a href="https://torrentfreak.com/dns-provider-quad9-sees-piracy-blocking-orders-as-existential-threat/">TorrentFreak</a></li> <li><strong>雷德蒙市关闭公共安全摄像头</strong>：在移民逮捕事件后，当地社区要求关闭警用监控系统。<a href="https://www.seattletimes.com/seattle-news/law-justice/redmond-turns-off-flock-safety-cameras-after-ice-arrests/">Seattle Times</a></li> <li><strong>微软品控问题失控</strong>：TechRegister 撰文批评微软在软件质量控制方面的严重滑坡。<a href="https://www.theregister.com/2025/11/08/microsoft_lacks_quality_control/">The Register</a></li> <li><strong>空间智能是AI的下一个前沿</strong>：李飞飞教授探讨空间智能对AI发展的重要性，从文字到世界的转变。<a href="https://drfeifei.substack.com/p/from-words-to-worlds-spatial-intelligence">Dr. Fei-Fei’s Substack</a></li> </ul> <h2 id="-ai--开发工具">📦 AI &amp; 开发工具</h2> <ul> <li><strong>ClickHouse收购开源AI聊天平台LibreChat</strong>：构建代理式数据堆栈，深化AI能力。<a href="https://clickhouse.com/blog/librechat-open-source-agentic-data-stack">ClickHouse Blog</a></li> <li><strong>AI Agent基准测试Google reCAPTCHA v2</strong>：研究团队测试AI Agent在对抗验证码方面的表现。<a href="https://research.roundtable.ai/captcha-benchmarking/">Roundtable.ai</a></li> <li><strong>LLM政策讨论？</strong>：runc项目GitHub上关于LLM策略与安全的讨论。<a href="https://github.com/opencontainers/runc/issues/4990">GitHub Issue</a></li> <li><strong>华硕Ascent GX10</strong>：一款面向边缘AI应用的超小型AI超级计算机。<a href="https://www.asus.com/networking-iot-servers/desktop-ai-supercomputer/ultra-small-ai-supercomputers/asus-ascent-gx10/">ASUS</a></li> </ul> <h2 id="-思维激荡mind-food">🧠 思维激荡（Mind Food）</h2> <ul> <li><strong>毕业即失业，应届生观察就业市场崩盘</strong>：一位失业应届毕业生对当前招聘市场困境的深度思考与笔记。<a href="https://urlahmed.com/2025/11/05/work-after-work-notes-from-an-unemployed-new-grad-watching-the-job-market-break/">Ahmed’s Blog</a></li> <li><strong>意想不到的“人类”事物</strong>：探讨那些非生物却展现出人类特性的概念和现象。<a href="https://bengoldhaber.substack.com/p/unexpected-things-that-are-people">Ben Goldhaber</a></li> <li><strong>LLM是达克效应的类固醇</strong>：一篇文章讨论大型语言模型如何加剧用户的达克效应（Dunning-Kruger Effect）。<a href="https://bytesauna.com/post/dunning-kruger">ByteSauna</a></li> <li><strong>英国造船业是如何衰落的</strong>：分析英国造船业历史性衰落的经济与社会原因。<a href="https://www.construction-physics.com/p/how-the-uk-lost-its-shipbuilding">Construction Physics</a></li> </ul> <h2 id="-科技与社会趋势">🌐 科技与社会趋势</h2> <ul> <li><strong>是时候“去苹果化”了</strong>：作者呼吁脱离苹果生态系统，追求更开放和可控的数字生活。<a href="https://heatherburns.tech/2025/11/10/time-to-start-de-appling/">Heather Burns</a></li> <li><strong>欧洲决定6 GHz频段是否由Wi-Fi和蜂窝网络共享</strong>：一项关乎未来无线通信基础设施的重要频谱分配决策。<a href="https://www.theregister.com/2025/11/09/europe_to_decide_if_6/">The Register</a></li> <li><strong>欧盟旨在遏制塑料颗粒污染</strong>：欧盟正采取措施，防止塑料微粒对环境造成灾难性影响。<a href="https://www.yahoo.com/news/articles/eu-takes-aim-plastic-pellets-030314496.html">Yahoo News</a></li> <li><strong>游戏保存困难重重，有时甚至需要私家侦探</strong>：揭示游戏内容保存工作面临的挑战，以及为对抗DRM等问题所做的努力。<a href="https://kotaku.com/gog-preservation-program-private-detectives-drm-2000635611">Kotaku</a></li> </ul> <h2 id="-新奇项目--show-hn">📱 新奇项目 / Show HN</h2> <ul> <li>🎵 <strong>Beets</strong>：一款面向音乐爱好者的命令行音乐媒体管理器，高效整理你的音乐库。<a href="https://beets.io/">beets.io</a></li> <li>🚆 <strong>实时BART到站显示器</strong>：一个定制的实时交通信息显示项目，展示旧金山湾区捷运系统到站情况。<a href="https://filbot.com/real-time-bart-display/">Filbot</a></li> <li>😴 <strong>懒人Git UI</strong>：一款你可能不知道自己需要的、能极大简化Git操作的UI工具。<a href="https://www.bwplotka.dev/2025/lazygit/">bwplotka.dev</a></li> </ul> <h2 id="-快速浏览">🎯 快速浏览</h2> <ul> <li>☠️ <strong>XSLT安息吧</strong>：对XML样式表语言转换（XSLT）技术的一种幽默回顾和告别。<a href="https://xslt.rip/">xslt.rip</a></li> <li>⚖️ <strong>被任天堂起诉</strong>：关于被任天堂提起诉讼的趣闻或警示。<a href="https://www.suedbynintendo.com/">Sued by Nintendo</a></li> <li>✈️ <strong>瑞安航空提醒旅客全面启用数字登机牌</strong>：从11月12日起，瑞安航空将全部采用数字登机牌，请旅客注意。<a href="https://corporate.ryanair.com/news/ryanair-issues-reminder-to-passengers-ahead-of-move-to-100-digital-boarding-passes-from-wednesday-12-nov/">Ryanair Corporate</a></li> </ul> <h2 id="-dev-tricks">🧰 Dev Tricks</h2> <ul> <li>⚠️ <strong>Vibe Code Warning – 个人案例研究</strong>：一个关于代码“坏味道”或潜在问题，以及个人如何解决的案例分析。<a href="https://github.com/jackdoe/pico2-swd-riscv">GitHub/jackdoe</a></li> <li>🐧 <strong>安装和使用HP-UX 9</strong>：一篇关于如何在现代系统上安装和体验老旧Unix操作系统的指南。<a href="https://thejpster.org.uk/blog/blog-2025-11-08/">TheJPster Blog</a></li> <li>⚙️ <strong>Zig及其设计选择</strong>：深入探讨Zig编程语言的设计哲学和其背后的决策考量。<a href="https://blueberrywren.dev/blog/on-zig/">blueberrywren.dev</a></li> <li>💡 <strong>iCE40 FPGA的SPI路由技巧</strong>：关于如何在iCE40系列FPGA上实现高效SPI路由的有趣技术文章。<a href="https://danielmangum.com/posts/spi-routing-ice40-fpga/">Daniel Mangum</a></li> <li>🤝 <strong>Linux内核考虑启用微软C扩展</strong>：Linux内核社区正在讨论“痛下决心”以支持微软C语言扩展的补丁。<a href="https://www.phoronix.com/news/Linux-6.19-Patch-Would-MS-Ext">Phoronix</a></li> </ul>]]></content><author><name></name></author><category term="HNDailyReport"/><category term="HNDailyReport"/><summary type="html"><![CDATA[🔥 今日重点（Top Picks）]]></summary></entry></feed>
<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.3.3">Jekyll</generator><link href="https://ifuryst.github.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://ifuryst.github.io/" rel="alternate" type="text/html" hreflang="en"/><updated>2025-06-18T08:22:15+00:00</updated><id>https://ifuryst.github.io/feed.xml</id><title type="html">ifuryst</title><subtitle>📝 &amp; 💭 </subtitle><entry><title type="html">从互联网的历史思考AI时代</title><link href="https://ifuryst.github.io/blog/2025/echoes-of-the-internet-in-the-ai-era/" rel="alternate" type="text/html" title="从互联网的历史思考AI时代"/><published>2025-06-06T05:47:00+00:00</published><updated>2025-06-06T05:47:00+00:00</updated><id>https://ifuryst.github.io/blog/2025/echoes-of-the-internet-in-the-ai-era</id><content type="html" xml:base="https://ifuryst.github.io/blog/2025/echoes-of-the-internet-in-the-ai-era/"><![CDATA[<p>上周参加完Google I/O migle后，加上前一周在美国结束的Google I/O 2025，结合近几个月Google在LLMs上持续的发力。有一些想法</p> <p>我们喜欢从历史里学习到一些范式可以应用到预测未来的时候做佐证，我们可以把以前互联网时代的一些案例映射到AI时代来做一个类比和思考。我们知道思科随着互联网爆发式增长，成为全球最大的网络设备供应商，但是后来的故事我们都知道了，随着互联网的发展，最终硬件或者基础设施本身并不是最大的价值所在，最有价值的是上层的应用，我们可以看到目前顶尖的Big Tech大部分是在应用层拥有拳头产品。这个也是互联网时代可以告诉我们的，一开始硬件或者基础设施层面是巨大的价值所在，但是随着时间推进，应用层价值占比会不断提升，硬件成本则会持续的下降到一个阈值后趋于稳定。</p> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-06-06-echoes-of-the-internet-in-the-ai-era/MarketCap-480.webp 480w,/assets/img/2025-06-06-echoes-of-the-internet-in-the-ai-era/MarketCap-800.webp 800w,/assets/img/2025-06-06-echoes-of-the-internet-in-the-ai-era/MarketCap-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/2025-06-06-echoes-of-the-internet-in-the-ai-era/MarketCap.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption mt-0"> Top 10 Tech Companies by Market Capitalization (June 2025) </div> <p>回到现在，我们看看目前市值排行情况，NVIDIA在这里是尤其的“异类”，NVIDIA目前市值在3.352万亿美元的规模，几乎要问鼎Top1了，对比思科的例子来看，似乎有一点相似的味道。这个就是我们前面说到的历史过往可以印证思考现在及未来。但是我们需要分清楚过往不代表未来，趋势不代表公司命运。未来GPU或者说支持AI训练和推理运算的硬件成本是会持续下降的，会使得这一部分的市场规模在模型层或者应用层的规模占比来看小很多。不过我们可以看到NVIDIA目前其实出来在硬件基建层的持续供应以外，还在上层也开始推进，也就是上探到应用层，这个能在一定程度上对冲掉底层基建市场规模占比缩小的风险。</p> <p>反观一下Google（Alphabet）的市值只有2.067万亿美元，这个是我想探讨的一个点。我觉得Google的市值被严重低估了。我们知道在OpenAI（截至202506的市场估值3千亿美元，仅次于SpaceX的3.5千亿美元，和字节差不多）出来之前，Google在AI领域基本是Top1的，有人有钱有技术。开头也提到，随着这一两年Google在AI领域持续发展（Google CEO Sundar Pichai在Google I/O 2017的时候提出AI First），已经能感受到Google慢慢回到了它以前在的位置了，今年也是AI在B端和应用层大爆发的一年，我们或许可以叫做应用层元年，AI时代的发展阶段被大大缩短和加速了。可以预见未来在模型层和应用层还会有大量的爆发式增长。</p> <p>当然Google现在也有它的问题，包括被两起主要的反垄断诉讼（搜索引擎市场垄断和数字广告技术垄断）都是投资者慎重的重要原因，包括Google成为大公司后自然衍生出的一些所谓的“大公司病”。因此就如前面说的，过去不代表未来，只不过如果Google可以延续过往在AI领域的人才储备和科研投入，那么Google依然有可能在未来的AI领域持续增长</p> <p><strong>不构成投资建议，就是记录一下想法</strong></p>]]></content><author><name></name></author><category term="Thoughts"/><category term="Thoughts"/><summary type="html"><![CDATA[上周参加完Google I/O migle后，加上前一周在美国结束的Google I/O 2025，结合近几个月Google在LLMs上持续的发力。有一些想法]]></summary></entry><entry><title type="html">Google IO开发者小会</title><link href="https://ifuryst.github.io/blog/2025/google-io/" rel="alternate" type="text/html" title="Google IO开发者小会"/><published>2025-05-30T20:00:00+00:00</published><updated>2025-05-30T20:00:00+00:00</updated><id>https://ifuryst.github.io/blog/2025/google-io</id><content type="html" xml:base="https://ifuryst.github.io/blog/2025/google-io/"><![CDATA[<p>今天受小红书邀请，作为30位独立开发者之一参与了Google IO，突然的行程，受益颇丰。</p> <div class="row mt-3"> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-05-31-google-io/p1-480.webp 480w,/assets/img/2025-05-31-google-io/p1-800.webp 800w,/assets/img/2025-05-31-google-io/p1-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/2025-05-31-google-io/p1.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <div class="col-sm mt-0 mb-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-05-31-google-io/p2-480.webp 480w,/assets/img/2025-05-31-google-io/p2-800.webp 800w,/assets/img/2025-05-31-google-io/p2-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/2025-05-31-google-io/p2.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-05-31-google-io/1-480.webp 480w,/assets/img/2025-05-31-google-io/1-800.webp 800w,/assets/img/2025-05-31-google-io/1-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/2025-05-31-google-io/1.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <div class="col-sm mt-0 mb-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-05-31-google-io/2-480.webp 480w,/assets/img/2025-05-31-google-io/2-800.webp 800w,/assets/img/2025-05-31-google-io/2-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/2025-05-31-google-io/2.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-05-31-google-io/3-480.webp 480w,/assets/img/2025-05-31-google-io/3-800.webp 800w,/assets/img/2025-05-31-google-io/3-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/2025-05-31-google-io/3.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <div class="col-sm mt-0 mb-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-05-31-google-io/4-480.webp 480w,/assets/img/2025-05-31-google-io/4-800.webp 800w,/assets/img/2025-05-31-google-io/4-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/2025-05-31-google-io/4.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> </div> <div class="caption mt-0"> Google IO 2025 in Beijing </div> <h2 id="googleai">Google+AI</h2> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-05-31-google-io/5-480.webp 480w,/assets/img/2025-05-31-google-io/5-800.webp 800w,/assets/img/2025-05-31-google-io/5-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/2025-05-31-google-io/5.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <p>首先第一趴来自Google侧的分享（包含一些他们回答问题时的想法和见解），结合这几个月来Google的动作，可以很明显的感受到Google在AI领域慢慢追上来了，有钱有人有技术的屠龙少年（虽然现在被诟病屠龙后自己也逐渐成为恶龙）开始继续在技术力上发挥了（虽然Google一直在产品力上比不上其他几家big tech，但是技术力是很顶的）。对于开发者或者用户来说，我和很多人一样是喜闻乐见的，我非常期待底层模型效果持续增加，费用持续降低的道路上持续下去，这样可以让应用层的风吹到世界每个角落。就好像去年到今年AI Agent和Agenic AI持续发展却不够杀手不够普遍（简单问一句几个人用个Devin、Manus这类产品呢？），其中原因就是费用问题，而不是效果和门槛。最近Devin开的credit 3个PR就烧没了，同等情况下cursor这类产品也可以做到，多喝两口茶的事情，这就限制了Agent的流行。我坚信费用持续下探到一个水平的时候，会迎来一波在各个领域的Agent爆发，现在这个阶段很多人其实是在抢滩，都希望大风来了自己是风口上的🐷。我也是其中的一只想成为🐷的人</p> <p>和与会的一些人的观点一样，我对于Gemini最看好的就是多模态能力，有人（坐在我后面的，但是我不知道叫什么名字😨）表示是SOTA级别的，我认可，我觉得这个也是大语言模型未来一个必然的方向，我们可以有垂类区分的LLMs，但是一定不会缺少全能的LLMs，这点我觉得也是头部AI企业会持续深耕的方向。</p> <p>Gemini的上下文长度确实是很重要的一点，有位Google某个事业部的研发负责人分享的客户案例我觉得有点启发性，在上下文足够大的情况下，可以直接把整部电影丢进去，然后做一些解说、去水、压缩等动作的时候就可以非常的方便，这和切片后处理的效果完全不同。我觉得这个也是很多垂直行业可以探索的，大公司的市场是给各个行业赋能，这个是他们的能力和价值体现，作为独立开发者，我们能做的面很广，但是能做的事情却很少，我们能做的只有我们熟知的部分行业，我发现现场的大部分人都是从自身或者周边的需求开始以点到面再到一个实际的产品，坚持落地才成就了自己。所以不同的行业机会都特别多，别顾着FOMO，别顾着跟进趋势，一定要持续保持发现，持续去执行，你能找到你的赛道</p> <p>另外关于LLMs的智能水平，之前的Scale Law其实大家还在持续的探索，毕竟就文本而言，互联网的语料已经被大家吃的差不多了，音视频的切片转化也在做，目前最前沿的模型几十万张卡训练出来的，如果未来可以上升到百万张卡的级别，可能会将智能程度往前推一个级别</p> <p>目前AI和人类的关系很暧昧也很模糊，这个导致人类认为界定的一些职业或者角色也在模糊化，比如现在产品和研发的边界已经逐渐模糊了，产品可以借助AI达到一部分研发的职能，而研发也可以借助AI放大自己的产品能力和思维。所以不要被天然的职业规划限制了你的想法，回到文艺复兴时代，达芬奇就是一位全才（<strong>Polymath</strong>），他不仅在艺术领域有极高的造诣，在科学、工程、解剖、建筑等多个学科也有深入探索，是通才或者博学的典范。我觉得现代人为的划定学科是为了应对现代社会的分工，让每个人可以更加专精于自己的学科领域，这样可以出现高精尖人才，但是这也天然的给后来者上了精神枷锁，先入为主的被学科和职业所限制，少数人会意识到这个问题，主动被动的去弱化或对抗这个观念，我觉得创业者需要这方面的探索，会很有助力。（我觉得一些T型、π型之类的人才定义，其实就是有了这方面的意识后才去提出这样的概念，对冲固有的界定）</p> <h3 id="model-is-agent">model is agent</h3> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-05-31-google-io/6-480.webp 480w,/assets/img/2025-05-31-google-io/6-800.webp 800w,/assets/img/2025-05-31-google-io/6-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/2025-05-31-google-io/6.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <p>这个是一个Google解决方案的老师提出来的，我觉得也合理，和另外一位朋友提出来的有一些匹配：水漫金山还是水涨船高（林神龙老师在他朋友圈看到的，分享的）。大体就是说随着LLMs的能力提升，他的杀伤区内的应用都会被干死，一个简单的例子，我们可以看到之前存在很多GPTs，现在其实没多少人再用了，因为ChatGPT自身的能力不断提升，已经完全吃掉那些基于Prompt调整的GPTs了，一个道理，现在大家在持续推进Agent，当模型能力达到一定程度的时候，模型本身就可以是Agent，其实我们对于Agent的概念由来以久了，对于浏览器有关注的人应该知道浏览器本身就是一个Agent，我们可以在HTTP请求头里看到一个字段叫做User-Agent，就是用来代表代表用户的Agent是什么，可以是浏览器，可以是一个Python写的程序，也可以是curl之类命令行。现在大家说Agent只会联想到AI Agent，这个就是大背景下大家都在唱这个东西，但是本身就是代理的不断演进，从计算机远古时代就持续存在的理念，我们有理由相信大模型是有成为Agent的那一天的。</p> <h3 id="通用-or-垂直">通用 or 垂直？</h3> <p>这个问题和以前我聊芯片时候的想法有点类似，现在其实大家在追求的通用的还是垂直/专用的LLMs？我觉得是都有的，就像其他人提出的，还是要以问题为导向，以客户为导向，专注于交付，不然就是本末倒置了。这其实也是一个很简单的道理，你打造了一把贼风里的刀，你看到什么都想砍两下，你觉得要找到东西砍一砍才能发挥他的威力，但是如果你本身没有切西瓜的需求，你拿一把西瓜刀也没什么用。所以哪怕有把贼牛的刀，你要剪指甲的时候还是需要指甲刀，而不是用那把贼牛逼的刀。</p> <h2 id="创业者">创业者</h2> <p>第二批是几位创业者的分享，这一趴我太喜欢了，是我收获最大的，我觉得很多时候最棒的东西是来源于走在同一条道路上的同行人，因为大家很有可能面临一样的困难，收获类似的喜悦，吃过成吨的苦。</p> <p>不得不说大家的嘴炮能力是真的厉害，每个人都是张嘴成河，还讲得贼好的那种，这个或许也是成功的一部分因素，能推销自己的观念和主张在很多场合是正向收益的。</p> <p>我认真在听大家的分享，随手就写了我觉得比较有共鸣的点到笔记里，我稍微沿着我的记录的笔记去展开结合一下我自己的想法聊聊。不过这里我忘记记录是谁发言的，加上我是第一次见大家，我已经不记得哪句话是哪位讲的了，不能标注出处，还请见谅（但是范围很小，大部分来源于下面这6位朋友的分享内容，加上一些Google或者小红书侧的一些发言）</p> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-05-31-google-io/7-480.webp 480w,/assets/img/2025-05-31-google-io/7-800.webp 800w,/assets/img/2025-05-31-google-io/7-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/2025-05-31-google-io/7.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <h3 id="赚钱这回事">赚钱这回事</h3> <p>做产品的第一要务是赚钱，哈哈，很现实，但是我很喜欢。包括我自己，我觉得有很多人很容易走进误区，一定要直面自己的问题，努力去调整。就像今天有人分享的：产品不是表达自己，而是服务用户。我觉得一开始你可以有很好的Idea或者个性去表达自己，很容易收到有共感的用户，在此之后，应该聚焦于服务用户，你的受众才是你的产品持续发光发热的源头。包括那句：匠人精神到商人精神的转变，是个很棒的概括。</p> <p>订阅制对于独立开发者的重要性，这个确实是能长期支持独立开发者或小团队的一个持续源动力，所以围绕着这个展开的就是我们如何让用户接受订阅？可以是好产品，也可以有其他的手段</p> <h3 id="创业思维">创业思维</h3> <div class="row mt-3"> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-05-31-google-io/8-480.webp 480w,/assets/img/2025-05-31-google-io/8-800.webp 800w,/assets/img/2025-05-31-google-io/8-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/2025-05-31-google-io/8.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <div class="col-sm mt-0 mb-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-05-31-google-io/9-480.webp 480w,/assets/img/2025-05-31-google-io/9-800.webp 800w,/assets/img/2025-05-31-google-io/9-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/2025-05-31-google-io/9.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> </div> <ol> <li>提升自身信息敏感度</li> <li>自身技术涉猎范围</li> <li>体验产品广度</li> </ol> <p>上面这三个点是我非常认可的。</p> <p>信息敏感度这点是十分重要的，我们时刻要保持敏锐的嗅觉，去思考某个需求是否可以转化成产品，甚至是在和别人的交流中都能产生出很棒的点子，这个也是social的意义之一。</p> <p>第二点和前面我说的通才那边的观点一直，尤其是AI时代，去年的技术你敢说不旧么？小时候那个词：日新月异，现在真的是感受到了，比互联网时代更加真实的感受。</p> <p>第三点之前我也和别人说过类似的观点，简单说就是dirt your hands，一定要自己去尝试！千万不要以为简单看一下新闻、自媒体的评测和言论就以为了解这个东西了，很多东西你真实去感受有可能得到的完全不一样的结论和收获</p> <div class="row mt-3"> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-05-31-google-io/10-480.webp 480w,/assets/img/2025-05-31-google-io/10-800.webp 800w,/assets/img/2025-05-31-google-io/10-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/2025-05-31-google-io/10.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <div class="col-sm mt-0 mb-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-05-31-google-io/11-480.webp 480w,/assets/img/2025-05-31-google-io/11-800.webp 800w,/assets/img/2025-05-31-google-io/11-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/2025-05-31-google-io/11.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> </div> <p>有一些对于当代社会的认知我觉得特别棒， 尤其是对于感受力经济的洞察，社会发展至今，现代化进程都走得七七八八了，现在新世代群体对于基础的温饱需求已经不是问题了，他（她）们更多会追求一些精神层次的东西，其中感受是一个很重要的组成部分，也就是前面说到的感受力经济。提到这个我想展开说一下，今天我观察了几位分享的产品，我觉得有一个很大占比是情感类的（很笼统，大体是这个意思，但是其实细化还有一些心理、感受、情绪之类的），女性群体是一个巨大的受众群体，这点其实是我之前了解但是却没有重视过的（像星野这个产品，我第一次在杂志上看到的时候也蛮惊讶的），这个也是一个很大的收获，虽然我没有toC的产品直接面向这类受众群体，但是我相信我已经在重视这个群体了。</p> <p>所以其实现代社会，人均教育水平和生活水平的提高，很多人都是斜杠青年了，每个人都是多面人，在生活中扮演了不同的角色，所以我们不应该用刻板的印象去面对用户，比如简单定义这个是18-28的男性用户群体，而是应该更加细化的去服务好不同的群体，我相信这个也是AI时代会带来改变的一个方面，哪怕再小众的群体，也有机会且值得被好的产品所感动</p> <p>互联网发展至今，很多基建都做得差不多了，现在很多平台都在寻找增量空间，而AI就是一个很大的方向。现在做项目出门融资，不和AI沾点边，估计还不太行</p> <h3 id="节奏">节奏</h3> <p>对于独立开发者而言，节奏比方向更重要。在一定程度上我是很认可的，不过我是觉得方向也挺重要的，或者换句话说，选对赛道很重要，这个一定是在对需求的深刻洞察和对于自我拥有的一切可调动资源的合理感知之下走进适合你的赛道，然后就是节奏。我和大多数人一样，不可免俗的对快速变化的世界，不断消逝的机会有一些FOMO的心态，我觉得这是一把双刃剑，看你怎么舞动他，就好像欲望一样，可以驱使人们做出很恐怖的事情，也可以做出“很恐怖”的事情。</p> <h3 id="ai人">AI&amp;人</h3> <p>以前是AI辅助人类变成，现在是人类辅助AI变成，未来可能是AI编程。我觉得很有道理，如果还没有意识到这个阶段的变化，那么你很有可能已经错过了第一波AI浪头，停下来仔细想一下吧，真实去使用去感受一下。</p> <div class="row mt-3"> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-05-31-google-io/12-480.webp 480w,/assets/img/2025-05-31-google-io/12-800.webp 800w,/assets/img/2025-05-31-google-io/12-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/2025-05-31-google-io/12.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <div class="col-sm mt-0 mb-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-05-31-google-io/13-480.webp 480w,/assets/img/2025-05-31-google-io/13-800.webp 800w,/assets/img/2025-05-31-google-io/13-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/2025-05-31-google-io/13.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> </div> <p>关于这点我之前也说过很多类似的言论，今天听到依然觉得很棒，就是心光的禹效分享的逆学习Unlearning这个概念：忘掉你之前掌握的东西！</p> <p>空杯心态非常适合应用到这里：技术特别好的人用AI用的少，反而是那种什么都不懂的人用的多。我太认可这个点了，身边对于AI的态度基本上就是2派，超级认可和超级不认可，如果你至今还觉得AI做得还不如自己做得快做得好，那你很有可能已经out了，需要alarm了。有个Google的高管提到一点，就是你好像是老板，AI好像是员工，没有理由AI写的代码你需要去看去改，你要做的只是不断提需求，验收需求即可。随着LLMs的效果不断提升，这个场景是必然到来的，到时候你会怎么选择呢？</p> <p>关于有时候大骂AI太垃圾，有时候夸到天上去了的这件事，也很有意思，就是对于结果是否Align我们脑子里想的，真的就是这么回事，和前面一个道理，对于有一定研发背景的人来说，很可能描述给AI到最后做出来的，有一个巨大的差距，就会开始觉得AI不行，适应性强的人会重新roll一遍，就好像抽卡一样，适应性不行的人就会骂骂咧咧自己修改。期间的味道大家自行品味</p> <p>所以一定要始终保持空杯心态，这个时代只要你下决心想学，人类已有的旧知识体系里的知识，没有你学不会的，所以千万不要限制自己的心态，保持成长心态，保持成长。理论上老年人的学习能力应该可以很强的，因为他（她）们已经看遍世间百态，了解了特别的东西，是活化石了，但是为什么事实是反过来的呢？依然是双刃剑，知识和阅历是把双刃剑，可以给你很高的视野和认知，也可以把你限制在这座高峰之上，但是你不知道的是，当你下山后，走过一段平路，越过你看不到的地平线的那边，有一座更高的山峰正在拔地而起，你是选择在这座山峰洋洋自得，还是选择去远方看看不同的风景？放下或许是一种智慧</p> <p>另外关于前面提到的职业划分，换到行业和专业也是一个道理，这些都是现代社会人为根据经验进行划分的。在LLMs的眼里，并没有行业和专业的区分，在LLMs的眼里一视同仁，这些限制仅仅是对于人来说的，因为人的能力范围是有限的，反过来这个也限制了我们能与AI交互的边界范围。所以我认为目前其实我们没办法完全释放LLMs的能力，我们只是在LLMs的一个子集范围内去与其交互，有打算在超级个体方向持续深耕的朋友或许该思考的是，我们该如何以个体的角度去最大化释放LLMs的能力。我有一个很sci-fi的想法，一群人从不同的领域组成一个超级个体（或超级群体？），然后这个超级个体去与LLMs交互，这样可以最大限度释放LLMs的能力。</p> <h2 id="总结">总结</h2> <p>最后引用一句忘记是谁说的了：技术快速变化，有些人抓住变化，有些人引领变化。</p> <p>今天在场几十个人，只是这个新时代之际的一小撮人，还有无数分布在全球的这样的人，对于未来充满了希望和信心，也感叹自己生活在一个能经历历史变迁的时代（高晓松近段时间分享过这个观点），何其有幸！我们需要做的就是做好长战线的学习、敏捷迭代并持续执行落地，做好付出没有任何回报的心理准备，除此之外，干就完事了。你能决定的只有你自己❤️</p> <p><em>今天早上起来一天都忙没停，Google开完会和老同事喝了两杯精酿后回酒店还和人谈了一个项目，又开了电脑卷了一下新项目后又去机场接人，回来就马不停蹄地写下今天的经历和收获，我也懒得勘误和排版了，随性一点，大家也就随性看看，有收获自然是好的，没有收获就当一厕所读物吧。明天去颐和园放空一下心灵，为下半年的腥风血雨做个准备</em></p> <p><em>最后还是对与会分享的人道个歉，我觉得国内的教育和环境并没有教会我们在引用别人说的话适合应该标注出处，我是非常乐意告诉大家这句话是谁说的，但是当时我确实没有这个意识要记下来，全身心的专注在内容本身了，如果有需要可以告诉我哪些话是你说的，我可以再次标注</em></p>]]></content><author><name></name></author><category term="Events"/><category term="Events"/><summary type="html"><![CDATA[今天受小红书邀请，作为30位独立开发者之一参与了Google IO，突然的行程，受益颇丰。]]></summary></entry><entry><title type="html">Duolingo w/ AI</title><link href="https://ifuryst.github.io/blog/2025/duolingo-with-ai/" rel="alternate" type="text/html" title="Duolingo w/ AI"/><published>2025-05-28T14:51:00+00:00</published><updated>2025-05-28T14:51:00+00:00</updated><id>https://ifuryst.github.io/blog/2025/duolingo-with-ai</id><content type="html" xml:base="https://ifuryst.github.io/blog/2025/duolingo-with-ai/"><![CDATA[<div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-05-28-duolingo-with-ai/ChatHistory-480.webp 480w,/assets/img/2025-05-28-duolingo-with-ai/ChatHistory-800.webp 800w,/assets/img/2025-05-28-duolingo-with-ai/ChatHistory-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/2025-05-28-duolingo-with-ai/ChatHistory.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <p>上面这张图是之前看到新闻时分享给别人的聊天记录，今天就看到了Duolingo的CEO发布声明开始”撤回”之前的声明了。我觉得这个事件还挺有趣的，反应了AI时代的个体和企业的决策和行为</p> <p>背景概览大体是</p> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-05-28-duolingo-with-ai/DuolingoPost1-480.webp 480w,/assets/img/2025-05-28-duolingo-with-ai/DuolingoPost1-800.webp 800w,/assets/img/2025-05-28-duolingo-with-ai/DuolingoPost1-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/2025-05-28-duolingo-with-ai/DuolingoPost1.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <div class="col-sm mt-0 mb-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-05-28-duolingo-with-ai/DuolingoPost2-480.webp 480w,/assets/img/2025-05-28-duolingo-with-ai/DuolingoPost2-800.webp 800w,/assets/img/2025-05-28-duolingo-with-ai/DuolingoPost2-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/2025-05-28-duolingo-with-ai/DuolingoPost2.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <p>2025年4月底的时候就是Duolingo账号在LinkedIn发了CEO Luis von Ahn的全员信说要公司要逐步用AI替代外包，AI优先的战略</p> <blockquote> <p>Duolingo is going to be Al-first.</p> </blockquote> <p>然后在几天前，也就是一个月后的5月底，CEO自己出来发了Post，试图挽回….</p> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-05-28-duolingo-with-ai/DuolingoPost3-480.webp 480w,/assets/img/2025-05-28-duolingo-with-ai/DuolingoPost3-800.webp 800w,/assets/img/2025-05-28-duolingo-with-ai/DuolingoPost3-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/2025-05-28-duolingo-with-ai/DuolingoPost3.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <div class="col-sm mt-0 mb-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-05-28-duolingo-with-ai/DuolingoPost4-480.webp 480w,/assets/img/2025-05-28-duolingo-with-ai/DuolingoPost4-800.webp 800w,/assets/img/2025-05-28-duolingo-with-ai/DuolingoPost4-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/2025-05-28-duolingo-with-ai/DuolingoPost4.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <p>原文我都截图了，顺带随手截了一下评论区，大家可以自行感受一般</p> <p>大体上就是声明AI取代人，然后被喷飞，甚至大量取消订阅，总而言之就是引起品牌的负面影响，然后CEO跳出来试图挽回</p> <p>Duolingo本质上是一个toC的产品，受众是普罗大众，我觉得用AI取代人这种话对这个群体的杀伤力是非常大的。从另外一方面讲，语言这个东西多少和文艺搭边，这种情况下会让相关从业者极度反感用AI取代人的这种趋势。</p> <p>反观硅谷，很过公司不是直接toC的，目前阶段很多其实只到toD之类的层面，更多还是提效的，而不是直接取代什么。并且更多startup还是面向投资人的，所以引发负面情绪小一点。</p> <p>我们可以看到之前好莱坞大量编剧和演员罢工本质上也是反应了科技发展和现存就业者的客观现实冲突。历史上在工业革命时期也出现过卢德派（Luddites），机械化导致大量工人失业，Luddites就在夜间潜入工厂砸毁机械。</p> <p>我觉得这个话题本身就是非常两面的，我觉得两边都很容易找人站台支持，科技发展，旧职业消失，新的职业出现，这前后是否存在数量差异，更迭速度如何，是否会牺牲一代人成就另一代人，个体在里面似乎微不足道，人类社会取得成就可能是构筑在大量个体悲惨命运之上？我觉得这些很难给出一个统一的答案，很多答案或多或少都带了一定的主观意识。世界的运作本就不是做题，没有唯一的答案，未来技术的发展也是一样，我们起于无知，面向未知。</p> <p>最近MCP Gateway也达到了第一个milestone（达到1k stars），我也在着手成立Lab，目前是一个SoloLab，有一句Slogan就是</p> <p>Born to Hack the Future</p> <p>我觉得个体很难抵抗时代发展的车轮，能碾碎无数个体甚至国家，我们唯一能做的就是让自己不断强大，更加敏捷，才能应对快速变化的未来</p> <h2 id="references">References</h2> <ul> <li>https://htxt.co.za/2025/05/duolingo-ceo-tries-to-walk-back-ai-first-comments-fails/</li> <li>https://www.linkedin.com/feed/update/urn:li:activity:7322560534824865792/</li> <li>https://www.linkedin.com/posts/luis-von-ahn-duolingo_one-of-the-most-important-things-leaders-activity-7331386411670982658-jpfX/</li> </ul>]]></content><author><name></name></author><category term="Insights"/><category term="Insights"/><summary type="html"><![CDATA[]]></summary></entry><entry><title type="html">关于转向灯的思考</title><link href="https://ifuryst.github.io/blog/2025/signals-we-miss/" rel="alternate" type="text/html" title="关于转向灯的思考"/><published>2025-05-22T14:51:00+00:00</published><updated>2025-05-22T14:51:00+00:00</updated><id>https://ifuryst.github.io/blog/2025/signals-we-miss</id><content type="html" xml:base="https://ifuryst.github.io/blog/2025/signals-we-miss/"><![CDATA[<p>反正我觉得这是一个挺奇怪的标题，但是今天中午游泳的时候，我确实在思考这个问题。</p> <p>这个思考的由来是今年1月底我去美国旅行的感悟，这次去美国在美西十来天就开着一辆在SFO租来的迈锐宝在几个城市和国家公园来回穿梭，不得不提这个在美国开车之爽，和在国内开车是2个体验。</p> <p>在那边基本上你就认着一条路无脑踩油门直开就行了，大部分情况下是不会有人别车的，拥有路权意识的国家开车就是这么爽，也因此经过了开始的小心翼翼阶段后，开始肆无忌惮的飙车了，刚好2个人，路上经常可以进到Carpool的道路开（在美国尤其以SF和LA这种城市周边的高速公路有专门给一辆车超过2个或者3个人以上的车辆，或者交了钱的车跑的快速车道，本质上是鼓励更多人共乘提高车载率，跟环保什么的多少也有关系），开得更快了。</p> <p>那天晚上我们从海豹观景点一路沿着1号公路南下，准备去LA市区过夜，当晚住宿其实没有提前定，本来是打算在Solvang或者圣巴巴拉停留的，后来因为发现通行速度实在是快，并且第二天打算在LA多逛逛，所以在Solvang逛完这个欧洲风情的小城镇后就一路要杀到LA了，路上下了山到圣巴巴拉的时候就想起来打算拐去Gelson’s买点吃的，然后就是在我到了Gelson’s外面路上的时候，我发现到了，就直接右拐进去了，此时右后方就发出一阵奇怪的声响，然后一个小哥骑着自行车上来马上质问我说他没有看到任何转向灯。重复了好几次，我愣了一下后确认下车确认他有没有问题，当时是他及时刹停了，我连忙和他say sorry，然后他一转刚才质问的态度，马上跟我说兄弟没事了，然后跟我解释，他说他是一个很棒的自行车骑手，他很快反应过来了，说他没有事情，我们就交流一下他就走了。</p> <p>这件事事后我自己得出了几个结论：</p> <ol> <li>转向灯在美国路上尤其的重要，因为大家的车速尤其的快，且路权意识特别强，你不打灯直接转很容易出事故。这点和在国内开车天壤地别，在国内大部分老司机变道过湾几乎不会打灯的，我记得我刚买车那会，我的车还有变道辅助系统，也就是你变道你不打灯方向盘会在你强行变道的时候把你拉回来一点，就是给施加一点阻力告诉你要打灯才能变道。我还记得当时我朋友问我为什么变道要一直打灯。现在想想转向灯在国内的用武之地小太多了，很多时候我们是通过对方车速、车身姿态来确认他要变道，有一种车身姿态语言的无声交流。毕竟车这个东西原产于西方国家，基于他们社会和大家的习惯下产生的自然需要转向灯告诉大家我要变道转向了。我觉得当时我能打灯无论如何能让小哥提前知道并提前规避</li> <li>后视镜的重要性，其实打灯我觉得不是根本原因，是直接原因。根本原因是因为这个后视镜视野太早了，这辆车左右后视镜放大倍数太大，导致两侧存在很大的死角空间，经常要探头缩头的看，这点真的是教训啊，后面从LAS去布莱斯国家公园的高速路上我也是因为这个连变2道以为没车的情况下差点撞上后方来车，那位女司机反应不可谓不快，马上急转打到左侧应急车道上去再回来，一路烧胎，颇有点速度与激情的feeling了，她马上油门一带就走了，留我在那后怕</li> <li>南加州人的热情，以前高晓松在晓说里有提到这点，真该庆幸自己是在南加州遇到这档事，要是在Texas之类的州，有可能没啥好果子吃，南加州在城市里的人确实非常的热情，和纽约完全是两个样子，至于乡下道Utah之类的地方也都蛮好的，当然那可能跟去的地方在旅游景点范畴有点关系。总而言之LA的人感觉都挺友善的，在SF我们出去City Walk了一天，一路上遇到的人，不管是晨跑、遛狗之类的，都挺热情的Say Hi</li> </ol> <p>总而言之，很多东西它不是换个地区或国家就能适用的。就好比以前我从澳洲回来后我就一直觉得为什么我们在一些行人较少的路段的人行道不能做那种行人按一下一会就可以通过的那种机制，而是固定死的周期红绿灯，我觉得在一些路段这样设置是合理的，但是在大部分路段不行，因为我们的行人数量足够多，这个本身也是国情或者社会形式不同，所以很难把一个东西硬套，很容易水土不服。</p> <p>这或许也是旅行的意义，开阔眼界，带来更多的思考方式和方向，本来打算分享一些相关的照片的，但是数据线被拿走了，改天我整理出来，写一些关于去美国旅行的一些感悟，我觉得我再不写，很多东西就要忘记了</p>]]></content><author><name></name></author><category term="Thoughts"/><category term="Thoughts"/><summary type="html"><![CDATA[反正我觉得这是一个挺奇怪的标题，但是今天中午游泳的时候，我确实在思考这个问题。]]></summary></entry><entry><title type="html">MCP鉴权</title><link href="https://ifuryst.github.io/blog/2025/mcp-authorization/" rel="alternate" type="text/html" title="MCP鉴权"/><published>2025-05-12T05:30:00+00:00</published><updated>2025-05-12T05:30:00+00:00</updated><id>https://ifuryst.github.io/blog/2025/mcp-authorization</id><content type="html" xml:base="https://ifuryst.github.io/blog/2025/mcp-authorization/"><![CDATA[<p>官方新的<a href="https://modelcontextprotocol.io/specification/2025-03-26/basic/authorization#2-3-1-server-metadata-discovery-headers">修订版本</a>支持了OAuth2的鉴权方式，我们一起来看看</p> <p>首先是协议要求：</p> <ul> <li>STDIO不支持，STDIO只支持通过env传入</li> <li>SSE/Streamable HTTP应该支持（非强制性）</li> </ul> <p>MCP遵循了OAuth2的标准，主要涉及：</p> <ul> <li><a href="https://datatracker.ietf.org/doc/html/draft-ietf-oauth-v2-1-12"><strong>OAuth 2.1 IETF DRAFT</strong></a></li> <li>OAuth 2.0 Authorization Server Metadata (<a href="https://datatracker.ietf.org/doc/html/rfc8414"><strong>RFC8414</strong></a>)</li> <li>OAuth 2.0 Dynamic Client Registration Protocol (<a href="https://datatracker.ietf.org/doc/html/rfc7591"><strong>RFC7591</strong></a>)</li> </ul> <p>其中OAuth2.1还在草案阶段，还没成为正式的RFC标准。这边我们简单汇总一下OAuth相关的RFC</p> <table> <thead> <tr> <th>标准/草案</th> <th>类型</th> <th>状态</th> <th>是否核心</th> <th>简介</th> </tr> </thead> <tbody> <tr> <td>RFC 6749</td> <td>OAuth 2.0 框架</td> <td>✅ 已发布</td> <td>✅ 是</td> <td>定义了授权流程（授权码、隐式、密码、客户端凭证）和四大角色（客户端、资源拥有者、授权服务器、资源服务器）</td> </tr> <tr> <td>RFC 6750</td> <td>Bearer Token 使用</td> <td>✅ 已发布</td> <td>✅ 是</td> <td>描述如何在 HTTP 中安全使用访问令牌（Bearer Token）</td> </tr> <tr> <td>RFC 7591</td> <td>动态客户端注册</td> <td>✅ 已发布</td> <td>❌ 扩展</td> <td>允许客户端通过 API 动态注册到授权服务器</td> </tr> <tr> <td>RFC 8414</td> <td>授权服务器元数据</td> <td>✅ 已发布</td> <td>❌ 扩展</td> <td>提供 .well-known 端点用于公开服务器配置信息，支持自动发现</td> </tr> <tr> <td>draft-ietf-oauth-v2-1</td> <td>OAuth 2.1 草案</td> <td>⏳ 草案中</td> <td>✅ 拟核心</td> <td>汇总和更新 OAuth 2.0 核心内容，合并并替代 RFC 6749 和 RFC 6750，剔除不安全授权方式（如隐式授权）并强制使用 PKCE</td> </tr> </tbody> </table> <h2 id="oauth-20--21">OAuth 2.0 &amp; 2.1</h2> <h3 id="oauth-20---rfc-6749--rfc-6750">OAuth 2.0 - RFC 6749 &amp; RFC 6750</h3> <p>这边简单过一下OAuth的内容，RFC 6749，涉及了OAuth2.0的定义，我们就关注重要的</p> <ol> <li>注册Client，获得ClientID和ClientSecret</li> <li> <p>配置在Client上，需要授权的时候，Client（通常是浏览器）跳转/authorize要求用户授权</p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>GET /authorize?
  <span class="nv">response_type</span><span class="o">=</span>code&amp;
  <span class="nv">client_id</span><span class="o">=</span>abc123&amp;
  <span class="nv">redirect_uri</span><span class="o">=</span>https://client.com/callback&amp;
  <span class="nv">scope</span><span class="o">=</span><span class="nb">read </span>write&amp;
  <span class="nv">state</span><span class="o">=</span>xyz123
</code></pre></div> </div> </li> <li> <p>授权服务器重定向并带回code</p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>HTTP/1.1 302 Found
Location: https://client.com/callback?code<span class="o">=</span>SplxlOBeZQQYbYS6WxSbIA&amp;state<span class="o">=</span>xyz123
</code></pre></div> </div> </li> <li> <p>Client或者Server用授权吗code去换AccessToken和RefreshToken</p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>POST /token
Content-Type: application/x-www-form-urlencoded

<span class="nv">grant_type</span><span class="o">=</span>authorization_code&amp;
<span class="nv">code</span><span class="o">=</span>SplxlOBeZQQYbYS6WxSbIA&amp;
<span class="nv">redirect_uri</span><span class="o">=</span>https%3A%2F%2Fclient.com%2Fcallback&amp;
<span class="nv">client_id</span><span class="o">=</span>abc123&amp;
<span class="nv">client_secret</span><span class="o">=</span>secret456
</code></pre></div> </div> </li> <li> <p>使用token就可以去请求对应的资源了（根据scope决定资源范围）</p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">{</span>
  <span class="s2">"access_token"</span>: <span class="s2">"2YotnFZFEjr1zCsicMWpAA"</span>,
  <span class="s2">"token_type"</span>: <span class="s2">"Bearer"</span>,
  <span class="s2">"expires_in"</span>: 3600,
  <span class="s2">"refresh_token"</span>: <span class="s2">"tGzv3JOkF0XG5Qx2TlKWIA"</span>
<span class="o">}</span>
</code></pre></div> </div> </li> </ol> <p>RFC 6750基本就是对OAuth 2.0进行补充了，主要就是AccessToken用Bearer Token来表示（Authorization: Bearer <token>）。这里需要注意的是，不一定是JWT，很多地方用了JWT但是Bearer Token不等价于JWT，可能是JWT也可能是一串随机的字符串</token></p> <h3 id="oauth-20-authorization-server-metadata---rfc-8414">OAuth 2.0 Authorization Server Metadata - RFC 8414</h3> <p>前面提到的/authorize /token 这类端点都是固定的，或者提前约定配置好的，有些场景就不方便，因此这份RFC提供了一个自动发现的机制，有点类似OIDC中的openid-configuration</p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>GET https://auth.example.com/.well-known/oauth-authorization-server

<span class="c"># 多租户</span>
GET https://auth.example.com/.well-known/oauth-authorization-server?issuer<span class="o">=</span>https://issuer.example.com
</code></pre></div></div> <p>就是增加这个端点（就是Discovery Endpoint，.well-known/oauth-authorization-server），用于发现相关的配置，配置（就是Metadata Document，JSON格式的授权服务器元数据）可能如下：</p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">{</span>
  <span class="s2">"issuer"</span>: <span class="s2">"https://mcp-github-oauth.ifuryst.workers.dev"</span>,
  <span class="s2">"authorization_endpoint"</span>: <span class="s2">"https://mcp-github-oauth.ifuryst.workers.dev/authorize"</span>,
  <span class="s2">"token_endpoint"</span>: <span class="s2">"https://mcp-github-oauth.ifuryst.workers.dev/token"</span>,
  <span class="s2">"registration_endpoint"</span>: <span class="s2">"https://mcp-github-oauth.ifuryst.workers.dev/register"</span>,
  <span class="s2">"response_types_supported"</span>: <span class="o">[</span>
    <span class="s2">"code"</span>
  <span class="o">]</span>,
  <span class="s2">"response_modes_supported"</span>: <span class="o">[</span>
    <span class="s2">"query"</span>
  <span class="o">]</span>,
  <span class="s2">"grant_types_supported"</span>: <span class="o">[</span>
    <span class="s2">"authorization_code"</span>,
    <span class="s2">"refresh_token"</span>
  <span class="o">]</span>,
  <span class="s2">"token_endpoint_auth_methods_supported"</span>: <span class="o">[</span>
    <span class="s2">"client_secret_basic"</span>,
    <span class="s2">"client_secret_post"</span>,
    <span class="s2">"none"</span>
  <span class="o">]</span>,
  <span class="s2">"revocation_endpoint"</span>: <span class="s2">"https://mcp-github-oauth.ifuryst.workers.dev/token"</span>,
  <span class="s2">"code_challenge_methods_supported"</span>: <span class="o">[</span>
    <span class="s2">"plain"</span>,
    <span class="s2">"S256"</span>
  <span class="o">]</span>
<span class="o">}</span>
</code></pre></div></div> <table> <thead> <tr> <th>字段名</th> <th>是否必需</th> <th>类型</th> <th>说明</th> </tr> </thead> <tbody> <tr> <td>issuer</td> <td>✅ 是</td> <td>string</td> <td>授权服务器的唯一标识符（URL），必须是 https，不能带参数或 fragment</td> </tr> <tr> <td>authorization_endpoint</td> <td>✅ 是（除非不支持基于授权码的 flow）</td> <td>string</td> <td>OAuth 授权端点地址，用于获取用户授权</td> </tr> <tr> <td>token_endpoint</td> <td>✅ 是（除非只支持 implicit）</td> <td>string</td> <td>Token 端点，客户端在此获取 access token</td> </tr> <tr> <td>jwks_uri</td> <td>⛔ 可选</td> <td>string</td> <td>JWK Set 的地址，包含公钥供客户端验证 JWT 签名</td> </tr> <tr> <td>registration_endpoint</td> <td>⛔ 可选</td> <td>string</td> <td>支持动态客户端注册时用于注册客户端的端点</td> </tr> <tr> <td>scopes_supported</td> <td>⛔ 推荐</td> <td>array</td> <td>支持的 scope 列表</td> </tr> <tr> <td>response_types_supported</td> <td>✅ 是</td> <td>array</td> <td>支持的响应类型，如 code、token</td> </tr> <tr> <td>response_modes_supported</td> <td>⛔ 可选</td> <td>array</td> <td>支持的 response mode，如 query、fragment、form_post</td> </tr> <tr> <td>grant_types_supported</td> <td>⛔ 可选</td> <td>array</td> <td>支持的授权类型，如 authorization_code、client_credentials</td> </tr> <tr> <td>token_endpoint_auth_methods_supported</td> <td>⛔ 可选</td> <td>array</td> <td>token endpoint 支持的客户端认证方式，如 client_secret_basic</td> </tr> <tr> <td>token_endpoint_auth_signing_alg_values_supported</td> <td>⛔ 可选</td> <td>array</td> <td>token endpoint 使用 JWT 认证时支持的签名算法，如 RS256</td> </tr> <tr> <td>service_documentation</td> <td>⛔ 可选</td> <td>string</td> <td>开发者文档地址</td> </tr> <tr> <td>ui_locales_supported</td> <td>⛔ 可选</td> <td>array</td> <td>UI 支持的语言列表（如 zh-CN）</td> </tr> <tr> <td>op_policy_uri</td> <td>⛔ 可选</td> <td>string</td> <td>授权服务器对客户端使用数据的策略说明 URL</td> </tr> <tr> <td>op_tos_uri</td> <td>⛔ 可选</td> <td>string</td> <td>服务条款 URL</td> </tr> <tr> <td>revocation_endpoint</td> <td>⛔ 可选</td> <td>string</td> <td>token 撤销端点（见 RFC 7009）</td> </tr> <tr> <td>revocation_endpoint_auth_methods_supported</td> <td>⛔ 可选</td> <td>array</td> <td>revocation endpoint 支持的认证方式</td> </tr> <tr> <td>revocation_endpoint_auth_signing_alg_values_supported</td> <td>⛔ 可选</td> <td>array</td> <td>revocation endpoint 支持的 JWT 签名算法</td> </tr> <tr> <td>introspection_endpoint</td> <td>⛔ 可选</td> <td>string</td> <td>token 状态检查端点（见 RFC 7662）</td> </tr> <tr> <td>introspection_endpoint_auth_methods_supported</td> <td>⛔ 可选</td> <td>array</td> <td>introspection endpoint 支持的认证方式</td> </tr> <tr> <td>introspection_endpoint_auth_signing_alg_values_supported</td> <td>⛔ 可选</td> <td>array</td> <td>introspection endpoint 支持的 JWT 签名算法</td> </tr> <tr> <td>code_challenge_methods_supported</td> <td>⛔ 可选</td> <td>array</td> <td>支持的 PKCE code_challenge_method（如 S256）</td> </tr> </tbody> </table> <p>另外服务商还可以增加自定义字段</p> <h3 id="oauth-20-dynamic-client-registration-protocol---rfc-7591">OAuth 2.0 Dynamic Client Registration Protocol - RFC 7591</h3> <p>之前注册获得ClientID的步骤是手动的，这个RFC本质上就是让客户端可以自动注册自身拿到ClientID和ClientSecret，而不需要人为提前注册</p> <p>注册示例</p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>POST /register HTTP/1.1
Host: server.example.com
Content-Type: application/json

<span class="o">{</span>
  <span class="s2">"client_name"</span>: <span class="s2">"AwesomeApp"</span>,
  <span class="s2">"redirect_uris"</span>: <span class="o">[</span>
    <span class="s2">"https://awesome.example.com/oauth/callback"</span>
  <span class="o">]</span>,
  <span class="s2">"grant_types"</span>: <span class="o">[</span><span class="s2">"authorization_code"</span>, <span class="s2">"refresh_token"</span><span class="o">]</span>,
  <span class="s2">"response_types"</span>: <span class="o">[</span><span class="s2">"code"</span><span class="o">]</span>,
  <span class="s2">"scope"</span>: <span class="s2">"read write"</span>,
  <span class="s2">"token_endpoint_auth_method"</span>: <span class="s2">"client_secret_basic"</span>
<span class="o">}</span>
</code></pre></div></div> <p>可能会返回</p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">{</span>
  <span class="s2">"client_id"</span>: <span class="s2">"s6BhdRkqt3"</span>,
  <span class="s2">"client_secret"</span>: <span class="s2">"7Fjfp0ZBr1KtDRbnfVdmIw"</span>,
  <span class="s2">"registration_access_token"</span>: <span class="s2">"access-token-123"</span>,
  <span class="s2">"registration_client_uri"</span>: <span class="s2">"https://server.example.com/register/s6BhdRkqt3"</span>,
  <span class="s2">"client_id_issued_at"</span>: 1599389946,
  <span class="s2">"client_secret_expires_at"</span>: 0
<span class="o">}</span>
</code></pre></div></div> <h3 id="oauth-21">OAuth 2.1</h3> <p>对OAuth 2.0进行修订，而不是完全重写，主要差异：</p> <ul> <li>Implicit和Resource Owner Password Credentials方式因不安全被移除了</li> <li>强制所有客户端都需要使用PKCE</li> <li>推荐refresh token启用rotation（也就是刷新时会废弃旧的）</li> </ul> <p>我觉得这里最重要的明显差异就是强制使用PKCE(Proof Key for Code Exchange)，为了防止授权码被拦截重放而设计的机制，大体是:</p> <ol> <li>客户端随机生成一串字符串，这串字符串就是code_verifier</li> <li>将code_verifier进行SHA256哈希后Base64编码，就可以得到另外一串随机字符串，就是code_challenge</li> <li>客户端请求的时候就可以发送code_challenge和对应的哈希算法code_challenge_method=S256</li> <li>用户同意授权后，服务端记录code_challenge</li> <li>客户端用authorization_code换token的时候，要带上原始的code_verifier</li> <li>授权服务会对code_verifier哈希后对比，以确认是否接受请求</li> </ol> <p>通过代码看看</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">secrets</span>
<span class="kn">import</span> <span class="n">hashlib</span>
<span class="kn">import</span> <span class="n">base64</span>

<span class="k">def</span> <span class="nf">generate_code_verifier</span><span class="p">(</span><span class="n">length</span><span class="o">=</span><span class="mi">64</span><span class="p">):</span>
    <span class="c1"># PKCE 规范推荐长度在 43～128 字符之间
</span>    <span class="k">return</span> <span class="n">base64</span><span class="p">.</span><span class="nf">urlsafe_b64encode</span><span class="p">(</span><span class="n">secrets</span><span class="p">.</span><span class="nf">token_bytes</span><span class="p">(</span><span class="n">length</span><span class="p">)).</span><span class="nf">rstrip</span><span class="p">(</span><span class="sa">b</span><span class="sh">'</span><span class="s">=</span><span class="sh">'</span><span class="p">).</span><span class="nf">decode</span><span class="p">(</span><span class="sh">'</span><span class="s">utf-8</span><span class="sh">'</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">generate_code_challenge</span><span class="p">(</span><span class="n">code_verifier</span><span class="p">):</span>
    <span class="n">code_verifier_bytes</span> <span class="o">=</span> <span class="n">code_verifier</span><span class="p">.</span><span class="nf">encode</span><span class="p">(</span><span class="sh">'</span><span class="s">utf-8</span><span class="sh">'</span><span class="p">)</span>
    <span class="n">sha256_digest</span> <span class="o">=</span> <span class="n">hashlib</span><span class="p">.</span><span class="nf">sha256</span><span class="p">(</span><span class="n">code_verifier_bytes</span><span class="p">).</span><span class="nf">digest</span><span class="p">()</span>
    <span class="n">code_challenge</span> <span class="o">=</span> <span class="n">base64</span><span class="p">.</span><span class="nf">urlsafe_b64encode</span><span class="p">(</span><span class="n">sha256_digest</span><span class="p">).</span><span class="nf">rstrip</span><span class="p">(</span><span class="sa">b</span><span class="sh">'</span><span class="s">=</span><span class="sh">'</span><span class="p">).</span><span class="nf">decode</span><span class="p">(</span><span class="sh">'</span><span class="s">utf-8</span><span class="sh">'</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">code_challenge</span>

<span class="c1"># 示例
</span><span class="n">code_verifier</span> <span class="o">=</span> <span class="nf">generate_code_verifier</span><span class="p">()</span>
<span class="n">code_challenge</span> <span class="o">=</span> <span class="nf">generate_code_challenge</span><span class="p">(</span><span class="n">code_verifier</span><span class="p">)</span>

<span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">code_verifier:</span><span class="sh">"</span><span class="p">,</span> <span class="n">code_verifier</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">code_challenge:</span><span class="sh">"</span><span class="p">,</span> <span class="n">code_challenge</span><span class="p">)</span>
<span class="c1"># code_verifier: 92Foogx4d9Q5cbDbmLrz7eCHfAxX06q-6FHhmyKQ0OMcGpRbu6CWzknxCUSuvJ6b5-D_dIaJB5mHfAIfk_Qu1A
# code_challenge: GFc8vy-W93jTehp7I3Fvzma2DH5JNjnRAoktZuHtywA
</span></code></pre></div></div> <p>所以类似的请求是</p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># 发起是授权请求</span>
GET /authorize?
  <span class="nv">response_type</span><span class="o">=</span>code&amp;
  <span class="nv">client_id</span><span class="o">=</span>abc123&amp;
  <span class="nv">redirect_uri</span><span class="o">=</span>https://client.example.com/cb&amp;
  <span class="nv">code_challenge</span><span class="o">=</span>E9Melhoa2OwvFrEMTJguCHaoeK1t8URWbuGJSstw-cM&amp;
  <span class="nv">code_challenge_method</span><span class="o">=</span>S256&amp;
  <span class="nv">state</span><span class="o">=</span>xyz

<span class="c"># 换取token</span>
POST /token
Content-Type: application/x-www-form-urlencoded

<span class="nv">grant_type</span><span class="o">=</span>authorization_code&amp;
<span class="nv">code</span><span class="o">=</span>SplxlOBeZQQYbYS6WxSbIA&amp;
<span class="nv">redirect_uri</span><span class="o">=</span>https://client.example.com/cb&amp;
<span class="nv">client_id</span><span class="o">=</span>abc123&amp;
<span class="nv">code_verifier</span><span class="o">=</span>dBjftJeZ4CVP-mB92K27uhbUJU1p1r_wW1gFWFOEjXk
</code></pre></div></div> <h2 id="实操案例">实操案例</h2> <h3 id="github配置oauth-app">GitHub配置OAuth APP</h3> <div class="row mt-3"> <div class="col-sm mt-3"> <div class="col-sm mt-0 mb-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-05-12-mcp-authorization/GitHubOAuth1-480.webp 480w,/assets/img/2025-05-12-mcp-authorization/GitHubOAuth1-800.webp 800w,/assets/img/2025-05-12-mcp-authorization/GitHubOAuth1-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/2025-05-12-mcp-authorization/GitHubOAuth1.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="col-sm mt-3"> <div class="col-sm mt-0 mb-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-05-12-mcp-authorization/GitHubOAuth2-480.webp 480w,/assets/img/2025-05-12-mcp-authorization/GitHubOAuth2-800.webp 800w,/assets/img/2025-05-12-mcp-authorization/GitHubOAuth2-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/2025-05-12-mcp-authorization/GitHubOAuth2.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <div class="col-sm mt-0 mb-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-05-12-mcp-authorization/GitHubOAuth3-480.webp 480w,/assets/img/2025-05-12-mcp-authorization/GitHubOAuth3-800.webp 800w,/assets/img/2025-05-12-mcp-authorization/GitHubOAuth3-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/2025-05-12-mcp-authorization/GitHubOAuth3.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <div class="col-sm mt-0 mb-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-05-12-mcp-authorization/GitHubOAuth4-480.webp 480w,/assets/img/2025-05-12-mcp-authorization/GitHubOAuth4-800.webp 800w,/assets/img/2025-05-12-mcp-authorization/GitHubOAuth4-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/2025-05-12-mcp-authorization/GitHubOAuth4.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> </div> <p>按照上面截图方式配置，最后得到对应的Client ID和Client Secret</p> <h3 id="cf-worker部署">CF Worker部署</h3> <p>参考这里https://github.com/cloudflare/ai/tree/main/demos/remote-mcp-github-oauth</p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># 1. 初始化项目，前两步yes，最后no，因为还没配置也deploy不上去</span>
npm create cloudflare@latest <span class="nt">--</span> mcp-github-oauth <span class="nt">--template</span><span class="o">=</span>cloudflare/ai/demos/remote-mcp-github-oauth
<span class="c"># 2. 安装wrangler</span>
npm <span class="nb">install</span> <span class="nt">-g</span> wrangler
<span class="c"># 3. 配置client id 和 client secret</span>
<span class="nb">cd </span>mcp-github-oauth
wrangler secret put GITHUB_CLIENT_ID
<span class="c"># 输入GitHub Client ID，然后y</span>
wrangler secret put GITHUB_CLIENT_SECRET
<span class="c"># 输入GitHub Client Secret</span>
wrangler secret put COOKIE_ENCRYPTION_KEY
<span class="c"># 输入随机字符串，可以用openssl rand -hex 32</span>
<span class="c"># 4. 设置KV命名空间</span>
wrangler kv:namespace create <span class="s2">"OAUTH_KV"</span>
<span class="c"># 会生成对应的id，拷贝写到wrangler.jsonrc文件里的</span>
	<span class="s2">"kv_namespaces"</span>: <span class="o">[</span>
		<span class="o">{</span>
			<span class="s2">"binding"</span>: <span class="s2">"OAUTH_KV"</span>,
			<span class="s2">"id"</span>: <span class="s2">"abc123"</span>
		<span class="o">}</span>
	<span class="o">]</span>,
<span class="c"># 5. 部署到Wroker，这里会跳到浏览器登录之类的操作，最后选择好用户就可以上传</span>
npm run deploy
</code></pre></div></div> <p>相关操作截图如下</p> <div class="row mt-3"> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-05-12-mcp-authorization/MCPGitHubOAuth1-480.webp 480w,/assets/img/2025-05-12-mcp-authorization/MCPGitHubOAuth1-800.webp 800w,/assets/img/2025-05-12-mcp-authorization/MCPGitHubOAuth1-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/2025-05-12-mcp-authorization/MCPGitHubOAuth1.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <div class="col-sm mt-0 mb-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-05-12-mcp-authorization/MCPGitHubOAuth2-480.webp 480w,/assets/img/2025-05-12-mcp-authorization/MCPGitHubOAuth2-800.webp 800w,/assets/img/2025-05-12-mcp-authorization/MCPGitHubOAuth2-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/2025-05-12-mcp-authorization/MCPGitHubOAuth2.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-05-12-mcp-authorization/MCPGitHubOAuth3-480.webp 480w,/assets/img/2025-05-12-mcp-authorization/MCPGitHubOAuth3-800.webp 800w,/assets/img/2025-05-12-mcp-authorization/MCPGitHubOAuth3-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/2025-05-12-mcp-authorization/MCPGitHubOAuth3.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <div class="col-sm mt-0 mb-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-05-12-mcp-authorization/MCPGitHubOAuth4-480.webp 480w,/assets/img/2025-05-12-mcp-authorization/MCPGitHubOAuth4-800.webp 800w,/assets/img/2025-05-12-mcp-authorization/MCPGitHubOAuth4-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/2025-05-12-mcp-authorization/MCPGitHubOAuth4.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> </div> <h3 id="测试">测试</h3> <p>现在支持MCP认证的客户端比较少，cursor目前也没计划支持，我们用官方的inspector来测试</p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>npx @modelcontextprotocol/inspector@latest
</code></pre></div></div> <p>通过SSE来连接，比如 https://mcp-github-oauth.ifuryst.workers.dev/sse</p> <p>大体流程是：连接后因为没有认证授权所以会返回401，这个时候MCP Client会根据MCP Servers暴露的Server Metadata Discovery（在https://mcp-github-oauth.ifuryst.workers.dev/.well-known/oauth-authorization-server）去发现认证的信息，然后跳转到对应的地址去做认证。这里会先到CF Worker上部署的这个服务的页面，然后点击确认后会跳到GitHub做实际的认证，最后跳回MCP Client的callback接口，通常是/oauth/callback，比如Inspector这里是http://127.0.0.1:6274/oauth/callback</p> <div class="row mt-3"> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-05-12-mcp-authorization/MCPGitHubOAuth5-480.webp 480w,/assets/img/2025-05-12-mcp-authorization/MCPGitHubOAuth5-800.webp 800w,/assets/img/2025-05-12-mcp-authorization/MCPGitHubOAuth5-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/2025-05-12-mcp-authorization/MCPGitHubOAuth5.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <div class="col-sm mt-0 mb-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-05-12-mcp-authorization/MCPGitHubOAuth6-480.webp 480w,/assets/img/2025-05-12-mcp-authorization/MCPGitHubOAuth6-800.webp 800w,/assets/img/2025-05-12-mcp-authorization/MCPGitHubOAuth6-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/2025-05-12-mcp-authorization/MCPGitHubOAuth6.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-05-12-mcp-authorization/MCPGitHubOAuth7-480.webp 480w,/assets/img/2025-05-12-mcp-authorization/MCPGitHubOAuth7-800.webp 800w,/assets/img/2025-05-12-mcp-authorization/MCPGitHubOAuth7-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/2025-05-12-mcp-authorization/MCPGitHubOAuth7.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <div class="col-sm mt-0 mb-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-05-12-mcp-authorization/MCPGitHubOAuth8-480.webp 480w,/assets/img/2025-05-12-mcp-authorization/MCPGitHubOAuth8-800.webp 800w,/assets/img/2025-05-12-mcp-authorization/MCPGitHubOAuth8-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/2025-05-12-mcp-authorization/MCPGitHubOAuth8.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-05-12-mcp-authorization/MCPGitHubOAuth9-480.webp 480w,/assets/img/2025-05-12-mcp-authorization/MCPGitHubOAuth9-800.webp 800w,/assets/img/2025-05-12-mcp-authorization/MCPGitHubOAuth9-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/2025-05-12-mcp-authorization/MCPGitHubOAuth9.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> </div> <p>在浏览器整个流程相对丝滑，如果是客户端的MCP Client，通常是跳转浏览器做登录或者应用内打开外部网页做登录，这里涉及到应用本身也需要监听，因为需要对callback做处理</p> <h2 id="结论">结论</h2> <p>MCP是个年轻的协议，提出大半年，鉴权方案也是3月份新的修订才有的，这里其实存在一定的争议，有人认为这不是最佳实践，我们可以看<a href="https://github.com/modelcontextprotocol/modelcontextprotocol/issues/205">这里的讨论</a>。也就是现在其实更多是把MCP Server当作OAuth授权服务器，这样对于MCP Server的提供者是一个负担，大部分MCP Server更偏向于一个轻量的或者微服务形态的，还需要他们去集成对应的鉴权，无疑是巨大的Effort。</p> <p>基于这个，目前MCP Gateway正在开发面向端侧的鉴权体系，这样可以让MCP Gateway适应更多的场景，各类服务也可以接入MCP Gateway快速适配认证场景。</p> <p>如果你感兴趣我的开源项目，欢迎使用、反馈和任何的贡献参与</p> <p>https://github.com/mcp-ecosystem/mcp-gateway</p>]]></content><author><name></name></author><category term="AI"/><category term="AI"/><summary type="html"><![CDATA[官方新的修订版本支持了OAuth2的鉴权方式，我们一起来看看]]></summary></entry><entry><title type="html">MCP之于HTTP</title><link href="https://ifuryst.github.io/blog/2025/mcp-vs-http/" rel="alternate" type="text/html" title="MCP之于HTTP"/><published>2025-05-08T05:30:00+00:00</published><updated>2025-05-08T05:30:00+00:00</updated><id>https://ifuryst.github.io/blog/2025/mcp-vs-http</id><content type="html" xml:base="https://ifuryst.github.io/blog/2025/mcp-vs-http/"><![CDATA[<p>MCP可以类比HTTP之于Web时代的意义，或许MCP是AI时代的一个常用协议之一</p> <p>过去一个月，行业动作频频：</p> <ul> <li>OpenAI和Amazon前两周都声明他们会采用MCP标准</li> <li>Google CEO上个月也在X上说会考虑采用MCP标准</li> </ul> <p>MCP 会成为 AI 时代的HTTP吗？</p> <p>我觉得现在下这个结论太早了，更多是自媒体或者相关从业者自嗨的标题。但是我们依然无法阻挡MCP被大量adopt的趋势，过去2个月得益于各种媒体的传播，MCP的风刮到了技术和非技术人的视野里。</p> <p>在这样的趋势之下，我也开始了自己的探索，这一直是我在做的事情，我发现已经很多人做起了MCP应用市场的行当了，包括一些诸如Cline之类的MCP Client自己也在做，类似App Store帮助大家更方便的搜索安装MCP Server。在目前这个阶段似乎大家的关注点都在重MCP Client的方向，包括Anthropic一开始制订的stdio（大量的MCP Server走了这个）和SSE来看也是偏Client的。非常能理解，端侧的应用是一个极大的应用场景，加上现在大家深耕Agentic AI，等于AI帮你代理了在终端的各类操作，终端也有你平时使用的各类环境，非常方便直接无缝集成，所以我认为这个趋势没有问题</p> <p>在大家还没有投入重视的远端、云端和服务端场景，未来也会大量爆发应用，可想而知上面的重端侧场景并不适应企业或者更加专业的玩家，MCP的应用也不只是针对端侧，在服务端，企业内部，企业对外的服务都会大量的应用，我觉得原来的FunctionCalling都会陆续转MCP，另外一点就是很多存量的API服务需要改造MCP，我觉得这个过程必然衍生出一些助力这个过程的软件或服务</p> <p>基于这个背景，MCP Gateway就诞生了，上个月中我开源了这个项目，几个目的和愿景：</p> <ol> <li>旨在通过配置的方式将存量API转成MCP Servers，完全无需任何改造</li> <li>代理MCP Servers，比如stdio、SSE和Streamable HTTP的协议互转</li> <li>统一网关分发，大胆的类比MCP领域的Nginx</li> <li>延伸的MCP服务治理，MCP想象空间足够大，可想如果几十上百的MCP接入，该如何治理呢？</li> <li>企业级的性能、稳定性、高可用和扩展性</li> </ol> <p>还有一周这个项目满1个月，我已经完成了160个Commits，迭代了13个版本，并且收获到了600+的🌟，对于大家的反馈，让我感受到这个项目的潜力和应用的前景。目前我还在持续迭代，欢迎大家使用和反馈。在这里也欢迎有想法的朋友一起共建❤️</p>]]></content><author><name></name></author><category term="AI"/><category term="AI"/><summary type="html"><![CDATA[MCP可以类比HTTP之于Web时代的意义，或许MCP是AI时代的一个常用协议之一]]></summary></entry><entry><title type="html">【Iter-X】 79/100days</title><link href="https://ifuryst.github.io/blog/2025/iter-x-79-100/" rel="alternate" type="text/html" title="【Iter-X】 79/100days"/><published>2025-05-06T15:59:59+00:00</published><updated>2025-05-06T15:59:59+00:00</updated><id>https://ifuryst.github.io/blog/2025/iter-x-79-100</id><content type="html" xml:base="https://ifuryst.github.io/blog/2025/iter-x-79-100/"><![CDATA[<p>Day7️⃣9️⃣</p> <p>仔细思考了一下，我决定还是停止继续这个Build in Public 100 Days的系列，几个原因：</p> <p>1️⃣ 一个是因为到后面观看的人数越来越少，我觉得流水账本身就不足以吸引人</p> <p>2️⃣ Iter-X的优先级被我降低了，目前另外两个项目的推进速度和收益更加充足</p> <p>3️⃣ 我希望用独立文章的形式来发表内容，目前其实我的标题是固定的，但是我经常会产出一些不错的内容，似乎被标题或者整个系列影响了，更难触及到受众</p> <p>综合这些原因，我考虑暂停此次这个系列。总体而言这次我收获到很多，79天，如同过山车一样，也结实了不少的朋友。也进一步夯实我的书写能力，我有信心能写出更多好的文章。对于还关注我的朋友，可以到GitHub和我的Blog里follow我的动态，后续我会收敛一下，不会把这些内容过多的抛到社交媒体上，社交媒体上我还是会继续做一些旅游相关的内容，开发、产品和创业相关的，还有一些思想和见闻我都会集中收录在我的blog里，社交媒体的书写长度天然限制表达，我不想要在表达这方面做妥协。我会在个人的思考，个人创作创业，前沿AI和Tech见闻，商业世界的见解等方面去发表内容，如果你感兴趣，欢迎follow</p> <p>山高路远，我会持续活跃的，我不是很优秀的人，也不是很聪明很厉害的人，但是我相信我是很坚持很有行动力的那一批人，我会持续把自己的想法付诸行动，不论成败，不唯结果论。</p>]]></content><author><name></name></author><category term="products"/><category term="products"/><summary type="html"><![CDATA[Day7️⃣9️⃣]]></summary></entry><entry><title type="html">【Iter-X】 78/100days</title><link href="https://ifuryst.github.io/blog/2025/iter-x-78-100/" rel="alternate" type="text/html" title="【Iter-X】 78/100days"/><published>2025-05-05T15:59:59+00:00</published><updated>2025-05-05T15:59:59+00:00</updated><id>https://ifuryst.github.io/blog/2025/iter-x-78-100</id><content type="html" xml:base="https://ifuryst.github.io/blog/2025/iter-x-78-100/"><![CDATA[<p>Day7️⃣8️⃣</p> <p>这次出行收获很大，不仅仅是放松休息了一波，还有很多额外的收获，这个也是旅行的一部分一样，不过这次不算是一个常规的旅行，因为还有很多非旅行的东西在里面。这次确实经历了很多东西，昨晚其实是在喝了酒之后写的东西，看了一下还没喝醉，哈哈。</p> <p>这次出行也意外了获得了一些生意上的机会，我觉得是个不错的机会，算是对于这一两年来在AI方面的沉淀的一个正向反馈，我觉得AI在应用层和不同的行业的渗透才在初期阶段，后续会有更多这种机会不断浮现，头部玩家有其玩法，中小玩家也有另一套的玩法，toCtoBtoG都有不同的玩法，我觉得能把资金、技术、渠道、商务和市场结合在一起的人或团队，有机会在这次浪潮中抢滩。如同互联网浪潮，泡沫很大，但是也释放出足够多的机会，也有很长的长尾效应持续让各种传统行业进行互联网化。AI时代同样也有泡沫，也可能破掉，但是不可否认这其中多大的市场空间可以去有作为。</p> <p>虽然我写的东西基本上是一个小范围的技术人看到的，但是我仍然开放心态面对非技术人员，如果你是在某个行业想要借助AI去搞一些事情的话，欢迎你找我聊聊，不管是简单的咨询还是存在进一步合作的可能性，1+1一定大于2，很容易有双赢的局面的</p>]]></content><author><name></name></author><category term="products"/><category term="products"/><summary type="html"><![CDATA[Day7️⃣8️⃣]]></summary></entry><entry><title type="html">【Iter-X】 77/100days</title><link href="https://ifuryst.github.io/blog/2025/iter-x-77-100/" rel="alternate" type="text/html" title="【Iter-X】 77/100days"/><published>2025-05-04T15:59:59+00:00</published><updated>2025-05-04T15:59:59+00:00</updated><id>https://ifuryst.github.io/blog/2025/iter-x-77-100</id><content type="html" xml:base="https://ifuryst.github.io/blog/2025/iter-x-77-100/"><![CDATA[<p>Day7️⃣7️⃣</p> <p>充实的一天，从早上到晚上，几乎没怎么停过，去了好几个地方，见了很多人，感受了生死，也聊了人生的起落。人生几十年，很快就过了，在面对死亡，我们可以更好的思考自己想要如何过完这一生，对于人生起落的思考，也加深了对于人生重要节点所带来的一系列因果的理解。世俗的成功是我们一直在追求的，但是除此之外，或许有一些更深次的东西值得我们追求，很多时候前者的优先级高于后者。现在是能看到很多新世代可以用精神满足对抗物质的不足，是一个很好的迹象，我觉得可以理解为一种精神层次的进步，不过大多数人还是逃不过这个固有的模式。</p> <p>明晚回归，一切会陆续回归正轨，继续持续输出。No pain, no gain — and I’m not done yet.✊</p>]]></content><author><name></name></author><category term="products"/><category term="products"/><summary type="html"><![CDATA[Day7️⃣7️⃣]]></summary></entry><entry><title type="html">【Iter-X】 76/100days</title><link href="https://ifuryst.github.io/blog/2025/iter-x-76-100/" rel="alternate" type="text/html" title="【Iter-X】 76/100days"/><published>2025-05-03T15:59:59+00:00</published><updated>2025-05-03T15:59:59+00:00</updated><id>https://ifuryst.github.io/blog/2025/iter-x-76-100</id><content type="html" xml:base="https://ifuryst.github.io/blog/2025/iter-x-76-100/"><![CDATA[<p>Day7️⃣6️⃣</p> <p>每次出门旅行或者大量现充的生活节奏下，和平时不断Build各种东西的节奏都不太一样，整个人的想法都有明显的不同。</p> <p>平时更多是关注在个人的积累，持续的输出，项目和产品的方向进度等等东西。现充的场合下会充斥大量的社交，会让你没有空去思考处理那些东西，大量的时间被释放到社交层面，旅行的时候则是大量时间精力投入到去经历去感受新的事物，产生新的经历和想法。</p> <p>就我个人而言，我觉得这三种模式都是不可获取的，只是占比有所不同，如何取舍如何平衡就能映射出个人的追求方向了，虽然社交需要投入很多时间精力，成年人的世界追求的更多是“有效社交”，但我还挺喜欢偶尔的随心社交，似乎能带来一种特别的视野，对冲掉了长期专注于个人事业或商业化成功这类事情的一个固化心态，更像是一种打破，所以对我而言是一种补偿机制。旅行也是，我喜欢旅行不仅仅是可以给我带来对于不同事物的感受，也就是增加视野，我也喜欢旅行过程中可以有的一种不同场地之下可以进行不同程度和角度的思考，不见得是很深刻的，但是可以是很新奇很有趣的。</p> <p>这两天的日记更像是日记了，开始写起了自己的经历和想法，对于项目或产品上的输出变少了，感觉这个Build In Public的系列和前面的节奏不太一样了，哈哈。Keep It Real. 不管Day 100的时候如何，我觉得都是一个很好的过程和经历，我希望后续自己能持续输出，这是一个正向循环，目前写作能力和速度都得到了比较明显的提升，我需要能快速的把想法落下来分享出来，对于信息的摄入和成果的转化输出非常有帮助。不过目前IterX的进度或许让一些持续关注的朋友失望了，这块等我51回去后会再来盘一下</p> <p>汇总目前情况：</p> <ol> <li>原型设计&amp;UI/UX设计：33%</li> <li>后端（Go）开发：60%</li> <li>客户端（flutter）进度：58%</li> <li>数据：14%</li> </ol> <p>如果你认为你符合以下条件，欢迎来聊：</p> <ol> <li>能坚持</li> <li>有梦想</li> <li>有兴趣</li> </ol>]]></content><author><name></name></author><category term="products"/><category term="products"/><summary type="html"><![CDATA[Day7️⃣6️⃣]]></summary></entry></feed>
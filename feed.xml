<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.3.3">Jekyll</generator><link href="https://ifuryst.github.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://ifuryst.github.io/" rel="alternate" type="text/html" hreflang="en"/><updated>2024-08-29T15:21:15+00:00</updated><id>https://ifuryst.github.io/feed.xml</id><title type="html">ifuryst</title><subtitle>📝 &amp; 💭 </subtitle><entry><title type="html">Kafka Design Concept 📝</title><link href="https://ifuryst.github.io/blog/2024/kafka-design-concept/" rel="alternate" type="text/html" title="Kafka Design Concept 📝"/><published>2024-08-29T14:18:27+00:00</published><updated>2024-08-29T14:18:27+00:00</updated><id>https://ifuryst.github.io/blog/2024/kafka-design-concept</id><content type="html" xml:base="https://ifuryst.github.io/blog/2024/kafka-design-concept/"><![CDATA[<p><a href="https://notes.stephenholiday.com/Kafka.pdf">https://notes.stephenholiday.com/Kafka.pdf</a></p> <p>依然建议点开这个链接，先读一下原始信息，读完后仍然感觉有必要的情况下再来阅读本文，避免被我提供的信息先入为主影响你的思考。 当然你反过来阅读也可以，可以先通俗阅读后去原文里印证一下想法，也是一种方式。Whatever you prefer.</p> <h2 id="背景">背景</h2> <p>Kafka是2011年LinkedIn开源的，后来捐给ASF了，现今到一定规模的企业基本没有不涉及到使用Kafka的可能，这是一个很重要的基础设施。</p> <p>Kafka诞生的初衷是因为传统的日志处理、聚合和消息系统在某些程度上都不满足一些场景下的需求，包括：</p> <ol> <li>过度递送保证了，比如强事务、强ACK等，这个在某种程度上会牺牲能处理的量级，并且在某些场景并不是完完全全关心这个保证，比如某些日志丢失一两条可能并没有什么问题。</li> <li>大多数系统并不是以吞吐量优先的原则进行设计的，比如里面提到的JMS甚至不支持批量发送消息，这会导致每个消息都需要一个完整的网络请求来回时间（Roundtrip）</li> <li>对于分布式支持较弱</li> <li>大多数消息系统都假设下游接近实时消费，堆积量很小。这个在大量堆积的场景会引发很严重的性能问题（某些采用push给下游的，还可能导致更严重的问题）</li> </ol> <p>所以我个人感觉，Kafka其实是技术或者说行业量级发展到一定程度必然会产生的一个产物，因为在数据量级日益增长的情况下，必然需要这样一个基础设施、 中间件、消息队列来持续以高吞吐可靠的处理高量级（High Volume）的数据，并且能有分布式的支持来应对灾难， 其他的就是一些相应的feature了， 比如可靠性、可堆积、可重复消费、PULL代替PUSH等</p> <h2 id="设计理念">设计理念</h2> <p>基于前面的背景，大概也能知道Kafka会是什么样子的，以下是一些基础的概念、术语：</p> <ol> <li>Message：经过的数据都叫消息</li> <li>Topic：特定的消息流被定义在topic里</li> <li>Producer：可以发布消息到topic</li> <li>Broker：实际保存数据的服务器</li> <li>Consumer：可以从一个或多个topic里订阅读取消息（PULL）</li> <li>Partition：基于topic下的逻辑分区</li> </ol> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2024-08-28-kafka-design-concept/kafka_architecture.2024-08-28_13-44-48-480.webp 480w,/assets/img/2024-08-28-kafka-design-concept/kafka_architecture.2024-08-28_13-44-48-800.webp 800w,/assets/img/2024-08-28-kafka-design-concept/kafka_architecture.2024-08-28_13-44-48-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/2024-08-28-kafka-design-concept/kafka_architecture.2024-08-28_13-44-48.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption mt-0"> Git History </div> <h3 id="简单存储">简单存储</h3> <p>日志被分成固定大小的文件（Segment file），比如1G。为了提高性能，每次收到消息后会换存在内存，等到一定消息量或经过一定时间后， 才会被写到（flush）磁盘，只有在写到磁盘后才可以被消费者消费</p> <p>Kafka的消息并没有message id，而是以逻辑偏移（logical offset）来定位。这能避免寻址的开销，如随机访问等。kafka的id是递增的但是不连续， 因为下一个消息的偏移需要用当前的消息id+消息长度</p> <h3 id="传输效率">传输效率</h3> <p>利用了底层操作系统的页缓存（page cache），这样的好处是Kafka自己不需要管理这些内存了，操作系统自己管就行了，没有命中的页再去磁盘load进来， 操作系统自己有一套完备的内存页管理机制；另外就是减少了GC的开销了，不需要对这部分数据的GC头疼了。这种情况下可以支持TB级别的数据消费</p> <p>另外就是利用了系统调用（system cal）来减少数据在内核和用户空间拷贝的开销，这个也是很聪明的一个设计， 按照常规从磁盘读数据通过网络发送的应用来说，大体是这样一个过程：</p> <ol> <li>从磁盘读取数据到操作系统页缓存，此时数据在内核态</li> <li>从内核拷贝数据到用户空间的缓存里</li> <li>然后要通过网络发出去的话，从用户空间的应用缓存里再拷贝到内核缓存空间</li> <li>从内核缓存空间发给socket</li> </ol> <p>前后经过4次数据拷贝，2次系统调用。在这种情况下Kafka通过系统调用（如linux里的sendfile）可以直接把数据从磁盘给到socket， 可以减少步骤2、3的操作了，等于简化到2次数据拷贝，1次系统调用（也有的地方会称为0拷贝，我觉得这个说法应该是针对0次拷贝到用户空间的说法）</p> <h3 id="无状态broker">无状态Broker</h3> <p>broker不知道消费者的任务信息，都有消费者自己管理，因此broker极度简化，但是这也带来一个问题，就是broker不知道什么时候才能删掉消息， 所以Kafka采用了通过以时间为基准的SLA保留策略，比如7d、30d、90d这种，在实际生产环境中是完全可行的，正常下游不会不可用或者lag到这么久， 这个设计的另外一个好处是，消费者可以自主回滚offset或者重新拉取之前的消息，在某些故障场景下， 可以很好的结合一些诸如checkpoint机制来保障下游数据的可靠性。</p> <p>当然这个设计是违背常规队列的设计的。这也是一个很不错的点，就好比人人都和你说队列就应该这样设计，如果你一直遵从这种思维， 你设计的消息队列就有可能先入为主的沿着这个方向去思考，所以有时候能打破旧有的标准，敢于挑战权威是一种勇气也是一种能力</p> <h3 id="分布式协调">分布式协调</h3> <p>抛弃主节点的设计，结合了Zookeeper做Consumer的协调，主要针对topic和partition以及offset，具体涉及了4个注册表（registry）：</p> <ol> <li>Broker Registry(ephemeral)：存放broker注册信息，启动时会注册</li> <li>Consumer Registry(ephemeral)：消费者加入consumer group的时候会创建注册</li> <li>Ownership Registry(ephemeral)：当一个消费者声明自己负责某个partition的时候，会创建表明所有权</li> <li>Offset Registry(Persistent)：存储消费者消费到的偏移量，每个partition一个节点，值表示最新已提交的消息偏移量</li> </ol> <h3 id="递送保证">递送保证</h3> <p>Kafka只支持至少一次，并不支持准确一次。但后面的迭代中还是加入了ACK等机制，只是最初设计是还没有做这个。</p> <h2 id="结论">结论</h2> <p>整体从最初的设计理念可以看出，Kafka对于非常重要的数据的保障并没有做到最好，也就是跟传统的日志服务不同，更注重低时延高吞吐。 比如一开始并没有ACK机制，Broker也不支持数据副本，这些也在后续陆续被支持。Kafka后续也迭代增加了很多Feature，甚至现在都用KRaft取代了ZK， 单看一篇最初始的Paper并不能了解所有，只能窥探最初的设计理念，但是后面演进过程中也有很多的有趣、很棒的设计， 具体可以看相关的<a href="https://cwiki.apache.org/confluence/display/KAFKA/Kafka+Improvement+Proposals">KIP（Kafka Improvement Proposal）</a></p> <p>PULL vs PUSH模型也是一个很有意思的选择，Prometheus和Kafka在他们的场景都采用了PULL，是从一定的出发点、设计理念和背景下做出的这个选择。 进一步可以说明并没有什么银弹，很多时候是在一定的背景和场景之下去选择合适的方案，是一种能力也是一种智慧。</p> <h2 id="appendix-1">Appendix 1</h2> <p>以下内容基于Kafka 2.4.1</p> <table> <thead> <tr> <th>ZK路径</th> <th>内容示例</th> <th>作用</th> </tr> </thead> <tbody> <tr> <td>/admin</td> <td> </td> <td>Kafka管理任务的信息</td> </tr> <tr> <td>/admin/delete_topics</td> <td> </td> <td>删除topic操作信息存在这里</td> </tr> <tr> <td>/brokers</td> <td> </td> <td>broker信息</td> </tr> <tr> <td>/brokers/ids/<broker_id></broker_id></td> <td>{<br/> “listener_security_protocol_map”:<br/> {<br/> “PLAINTEXT”: “PLAINTEXT”<br/> },<br/> “endpoints”:<br/> [<br/> “PLAINTEXT://10.123.123.1:9092”<br/> ],<br/> “jmx_port”: 9989,<br/> “host”: “10.123.123.1”,<br/> “timestamp”: “1722923239941”,<br/> “port”: 9092,<br/> “version”: 4<br/>}</td> <td>具体的broker信息，ID，端口，注册时间等</td> </tr> <tr> <td>/brokers/seqid</td> <td> </td> <td> </td> </tr> <tr> <td>/brokers/topics</td> <td> </td> <td> </td> </tr> <tr> <td>/cluster</td> <td> </td> <td>集群信息</td> </tr> <tr> <td>/cluster/id</td> <td>{<br/> “version”: “1”,<br/> “id”: “tsc3VC-yQeeCkti2jdaX-Q”<br/>}</td> <td> </td> </tr> <tr> <td>/config</td> <td> </td> <td>配置相关，如topic或客户端相关的配置</td> </tr> <tr> <td>/config/brokers/<broker_id></broker_id></td> <td>{<br/> “version”: 1,<br/> “config”: {}<br/>}</td> <td> </td> </tr> <tr> <td>/config/changes/config<em>change</em><nums></nums></td> <td>{<br/> “version”: 2,<br/> “entity_path”: “topics/xxxxxx”<br/>}</td> <td>记录所有配置变更</td> </tr> <tr> <td>/config/clients</td> <td> </td> <td> </td> </tr> <tr> <td>/config/topics/__consumer_offsets</td> <td>{<br/> “version”: 1,<br/> “config”:<br/> {<br/> “segment.bytes”: “104857600”,<br/> “compression.type”: “producer”,<br/> “cleanup.policy”: “compact”<br/> }<br/>}</td> <td> </td> </tr> <tr> <td>/config/topics/<topic_name></topic_name></td> <td>{“version”:1,”config”:{}}</td> <td>topic配置</td> </tr> <tr> <td>/config/users</td> <td> </td> <td> </td> </tr> <tr> <td>/consumers</td> <td> </td> <td>消费组信息</td> </tr> <tr> <td>/controller</td> <td>{<br/> “version”: 1,<br/> “brokerid”: 2,<br/> “timestamp”: “1722923238927”<br/>}</td> <td>集群中controller的信息（特殊的broker，负责协调选举等控制任务）</td> </tr> <tr> <td>/controller_epoch</td> <td>37</td> <td>记录epoch，每次选举后增加</td> </tr> <tr> <td>/isr_change_notification</td> <td> </td> <td>临时节点，用于通知ISR中的变更</td> </tr> <tr> <td>/latest_producer_id_block</td> <td>{<br/> “version”: 1,<br/> “broker”: 1,<br/> “block_start”: “54000”,<br/> “block_end”: “54999”<br/>}</td> <td>存储producer的id范围最新状态</td> </tr> <tr> <td>log_dir_event_notification</td> <td> </td> <td>用于触发和管理日志目录变更的通知机制</td> </tr> </tbody> </table>]]></content><author><name></name></author><category term="distributed-systems"/><category term="distributed-systems"/><summary type="html"><![CDATA[从Kafka Paper中感受其设计思想]]></summary></entry><entry><title type="html">RAFT paper reading notes 📝</title><link href="https://ifuryst.github.io/blog/2024/raft/" rel="alternate" type="text/html" title="RAFT paper reading notes 📝"/><published>2024-08-21T12:51:27+00:00</published><updated>2024-08-21T12:51:27+00:00</updated><id>https://ifuryst.github.io/blog/2024/raft</id><content type="html" xml:base="https://ifuryst.github.io/blog/2024/raft/"><![CDATA[<p><a href="https://raft.github.io/raft.pdf">https://raft.github.io/raft.pdf</a></p> <p>建议读一下原Paper</p> <h2 id="背景">背景</h2> <p><code class="language-plaintext highlighter-rouge">RAFT</code>是一个分布式领域内的共识算法（Consensus Algorithm），目的是为了提供一个更加直观易懂（Understandability）、 更易于实现且不丧失相关的强一致性，可以理解就是<code class="language-plaintext highlighter-rouge">PAXOS</code>的通识版</p> <p>因为此前<code class="language-plaintext highlighter-rouge">PAXOS</code>在这个领域占据主导地位，大量的教科书里都是用<code class="language-plaintext highlighter-rouge">PAXOS</code>来教学，初学者有较大的学习成本，并且工程实践方面也比较困难，表现在2点：</p> <ol> <li>理解的难度，再加上理论和实践的差距</li> <li><code class="language-plaintext highlighter-rouge">PAXOS</code>对于很多细节并没有阐述清晰，导致各方在实现的时候就会根据情况去变形，导致最终大家实现的都是有出入的</li> </ol> <p>Conclusion里的这段我觉得能挺清晰的表达出<code class="language-plaintext highlighter-rouge">RAFT</code>对于易理解的追求：</p> <blockquote> <p>Algorithms are often designed with correctness, efficiency, and/or conciseness as the primary goals. Although these are all worthy goals, we believe that understandability is just as important. None of the other goals can be achieved until developers render the algorithm into a practical implementation, which will inevitably deviate from and expand upon the published form. Unless developers have a deep understanding of the algorithm and can create intuitions about it, it will be difficult for them to retain its desirable properties in their implementation.</p> </blockquote> <p>整体就是说，追求正确、效率和简洁明了通常是设计算法里的首要目的，但是<code class="language-plaintext highlighter-rouge">RAFT</code>的作者认为易于理解同样重要。除非深入的理解， 否则在实现或者在不同形式的传播中，很难一直保持其原有的设计思想或理念，也就是咱们前面说到的，实现中要根据情况、经验和认知去决定实现方式， 不可避免的结果就是会导致很多“版本”的流通</p> <h2 id="设计理念">设计理念</h2> <p><code class="language-plaintext highlighter-rouge">RAFT</code>借鉴了现实社会中的领导选举机制，还挺方便理解。从全局的角度看，整体遵循了这么几个点：</p> <ol> <li>只有三种角色：Leader（主，领导者）、Candidate（候选者）、Follower（跟随者）</li> <li>任期制：确保节点不可用时（尤其Leader）能快速感知和切换</li> <li>所有的操作只能在Leader上进行（需要注意，这种情况下性能层面会有一定问题，因此在某些应用场景还是需要结合一些其他缓存系统来保障高效的读写，这就是架构设计中需要注意的，没有银弹，一切都是取舍Tradeoff，当然要做tradeoff之前你是需要对涉及到的技术、系统的设计理念和应用场景有一定的认知，才能做出正确的判断）</li> <li>追加日志，日志从Leader复制到其他Follower</li> <li>安全性：日志复制需要经过一致性检查，大多数节点确认才可提交</li> </ol> <p>其他的就是基于这些点下沉的一些细节，比如：</p> <ul> <li>怎么选举</li> <li>角色如何切换</li> <li>怎么防止切换时日志被新主覆盖</li> <li>节点故障的具体处理细节</li> <li>如何保持心跳</li> <li>如何处理在相同下标下的不同数据</li> </ul> <h2 id="选举">选举</h2> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2024-08-21-raft-paper-reading-notes/electoral_process.2024-08-21_23-26-19-480.webp 480w,/assets/img/2024-08-21-raft-paper-reading-notes/electoral_process.2024-08-21_23-26-19-800.webp 800w,/assets/img/2024-08-21-raft-paper-reading-notes/electoral_process.2024-08-21_23-26-19-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/2024-08-21-raft-paper-reading-notes/electoral_process.2024-08-21_23-26-19.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <div class="col-sm mt-0 mb-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2024-08-21-raft-paper-reading-notes/requestvote_rpc.2024-08-21_23-26-35-480.webp 480w,/assets/img/2024-08-21-raft-paper-reading-notes/requestvote_rpc.2024-08-21_23-26-35-800.webp 800w,/assets/img/2024-08-21-raft-paper-reading-notes/requestvote_rpc.2024-08-21_23-26-35-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/2024-08-21-raft-paper-reading-notes/requestvote_rpc.2024-08-21_23-26-35.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption mt-0"> Left: Electoral Process, Right: RequestVote RPC </div> <ol> <li>刚启动，所有节点都是Follower（或者Leader没了，剩余的都是Follower）</li> <li>发现没有来自Leader的心跳同步包（Leader发送的心跳是跟着AppendEntriesRPC请求一起的，哪怕没有数据也可以发空payload代表这个请求只用于心跳用途），等待任期超时（每个节点的超时时间都是不同的，随机的，意图是这样能有效避免选票分散在多个同时发起选举的候选人身上）</li> <li>某些节点超时了，触发选举，将自己从Follower提升到Candidate，发送投票请求（RequestVote RPC）给所有节点（会携带上任期号term和最新的日志下标lastLogIndex, lastLogTerm）</li> <li>节点收到投票请求，会和本身的当前任期对比，如果自己所处的任期大于对方的，或者自己的日志比对方更多，拒绝投给对方，否则就投票给对方（同节点可能会收到多个投票请求，也是基于这个逻辑来确认投给谁）</li> <li>最终票数多的成为Leader（也有可能票数一样导致没有Leader产生，就会等下一任期到来再选举一波），开始定期发心跳维持自己的地位（某个节点在超时时间内收到Leader的心跳会重启超时等待，直到没收到就会回到Step 2.开启新的选举），此时其他节点全部退回Follower状态</li> </ol> <h2 id="日志复制">日志复制</h2> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2024-08-21-raft-paper-reading-notes/state.2024-08-21_23-26-51-480.webp 480w,/assets/img/2024-08-21-raft-paper-reading-notes/state.2024-08-21_23-26-51-800.webp 800w,/assets/img/2024-08-21-raft-paper-reading-notes/state.2024-08-21_23-26-51-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/2024-08-21-raft-paper-reading-notes/state.2024-08-21_23-26-51.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <div class="col-sm mt-0 mb-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2024-08-21-raft-paper-reading-notes/appendentries_rpc.2024-08-21_23-27-04-480.webp 480w,/assets/img/2024-08-21-raft-paper-reading-notes/appendentries_rpc.2024-08-21_23-27-04-800.webp 800w,/assets/img/2024-08-21-raft-paper-reading-notes/appendentries_rpc.2024-08-21_23-27-04-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/2024-08-21-raft-paper-reading-notes/appendentries_rpc.2024-08-21_23-27-04.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption mt-0"> Left: State, Right: AppendEntries RPC </div> <p>每个节点自身都维持了一个状态机（State）在内存，代表目前的数据情况，只有被确认提交的数据会进到这里，收到但还没确认的不会</p> <p>日志追加的方式，通过AppendEntriesRPC请求同步给其他的节点，在大多数的节点确认后，会进行提交， 这样能有效确保Leader切换后数据不会丢失（拥有的日志越多的节点约有可能成为下一任Leader）</p> <p>整体流程如下：</p> <ol> <li>收到写数据请求，操作附加到自己的日志中（此时还没提交生效）</li> <li>发送日志给其他节点（发AppendEntriesRPC请求），信息里面会包含一些诸如任期号、LeaderID，日志条目和下标等信息</li> <li>Follower节点收到后，检查自己的日志条目情况，如果匹配就追加最新的，不匹配的话拒绝（Leader给的前面的Log的任期不同之类的情况）</li> <li>Leader收到超过半数节点的成功响应后，确认已经传播到多数节点了，该日志条目被标记为提交（commited），应用条目到自己的状态机中（下一次AppendEntriesRPC就会告知Follower已经提交到这个位置，Follower也可以跟着提交到这个下标位置的Log）</li> <li>Leader响应客户端</li> </ol> <p>在此期间，Step 3.会有个分叉逻辑，就是Leader需要补发Follower缺失的Log， Log下标会往前推直到这个Follower最后的Log位置（此时会借助一些任期号来加快定位到需要补的日志的开头）</p> <h2 id="安全性">安全性</h2> <p><code class="language-plaintext highlighter-rouge">RAFT</code>通过任期号、多数投票选举、日志的一些机制保障了安全性，以下列举几个点：</p> <ul> <li>多数投票选举机制和任期号机制，防止出现脑裂（No Split-Brain）</li> <li>Leader包含所有已提交条目（Leader Completeness Property），统一负责读写，包括线性一致性读（Linearizable reads）</li> <li>只有Follower的日志可以被覆盖，Leader的日志只能不断追加，不可再覆盖旧的</li> <li>多数确认提交，确保多数确认的情况下才会提交</li> </ul> <h2 id="写在最后">写在最后</h2> <p>整体过了一下<code class="language-plaintext highlighter-rouge">RAFT</code>的一些设计理念，从paper里的一些表述中能很明确的感受到作者的意图和想法，尽可能阅读最一手的资料是追求有效信息的好方法， 也可以避免信息传播过程中产生的变形（不过也有利弊，有些人会有更加翔实的分析和剖析，就像这篇文章一样也是二手信息）</p> <p>值得一提的是，在paper里一句带过的Leader租约（Lease）机制，在实际应用中也是一个挺重要的点， 比如Consul和Etcd都实现这个机制，可以增加读的性能（风险取决于节点间的时钟差异程度和可接受的时钟漂移范围）</p>]]></content><author><name></name></author><category term="distributed-systems"/><category term="distributed-systems"/><summary type="html"><![CDATA[从Raft paper中感受其设计思想]]></summary></entry><entry><title type="html">zsh nice 5 🧐</title><link href="https://ifuryst.github.io/blog/2024/zsh-nice-5/" rel="alternate" type="text/html" title="zsh nice 5 🧐"/><published>2024-08-07T12:51:27+00:00</published><updated>2024-08-07T12:51:27+00:00</updated><id>https://ifuryst.github.io/blog/2024/zsh-nice-5</id><content type="html" xml:base="https://ifuryst.github.io/blog/2024/zsh-nice-5/"><![CDATA[<blockquote> <p>The English Version is <a href="https://medium.com/@ifuryst./zsh-nice-5-f520a70d0f90">here</a></p> </blockquote> <p>今天在排查一个服务吞吐量上不去的问题，在做压力测试，期间刚好在观测CPU使用率，系统是32c的。 除了关注进程的CPU消耗情况，我还会关注每个核心的使用率，确保不会出现核心利用率不均衡（之前在NUMA Node时因为大量网卡软中断出现过，所以现在习惯性会关注一下） ， 一开始一切都蛮正常的，类似这样：</p> <div class="row mt-3"> <div class="col-12 col-md-8 col-lg-6 col-xl-6 col-xxl-6 mt-0 mb-0 mx-auto"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2024-08-07-zsh-nice-5/normal_cpu_usage.2024-08-07_17-49-16-480.webp 480w,/assets/img/2024-08-07-zsh-nice-5/normal_cpu_usage.2024-08-07_17-49-16-800.webp 800w,/assets/img/2024-08-07-zsh-nice-5/normal_cpu_usage.2024-08-07_17-49-16-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/2024-08-07-zsh-nice-5/normal_cpu_usage.2024-08-07_17-49-16.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption mt-0"> Normal CPU Usage </div> <p>可以看到，进程使用了28c，约为87%的使用率。整体其实已经跑了挺满的，在单核上也可以观测到us都蛮高且相对均衡（77%~90%）</p> <blockquote> <h5 id="tip">TIP</h5> <p class="block-tip">top里是按照绝对值计算百分比的，因此不是传统的0-100%的认知，比如我32c，实际上最大是跑到3200%</p> </blockquote> <div class="row mt-3"> <div class="col-12 col-md-8 col-lg-6 col-xl-6 col-xxl-6 mt-0 mb-0 mx-auto"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2024-08-07-zsh-nice-5/abnormal_cpu_usage.2024-08-07_17-51-01-480.webp 480w,/assets/img/2024-08-07-zsh-nice-5/abnormal_cpu_usage.2024-08-07_17-51-01-800.webp 800w,/assets/img/2024-08-07-zsh-nice-5/abnormal_cpu_usage.2024-08-07_17-51-01-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/2024-08-07-zsh-nice-5/abnormal_cpu_usage.2024-08-07_17-51-01.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption mt-0"> Abnormal CPU Usage </div> <p>在经过几次调整测试的过程中，突然之间，我留意到单核的us都接近0了，但是进程级别的使用率看起来和之前保持相似的使用率，此时脑子过了好几个想法：</p> <ul> <li>是不是top的显示有问题？</li> <li>top发生某种奇怪的错误统计？</li> </ul> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2024-08-07-zsh-nice-5/grafana_total_cpu_usage.2024-08-07_17-59-21-480.webp 480w,/assets/img/2024-08-07-zsh-nice-5/grafana_total_cpu_usage.2024-08-07_17-59-21-800.webp 800w,/assets/img/2024-08-07-zsh-nice-5/grafana_total_cpu_usage.2024-08-07_17-59-21-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/2024-08-07-zsh-nice-5/grafana_total_cpu_usage.2024-08-07_17-59-21.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <div class="col-sm mt-0 mb-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2024-08-07-zsh-nice-5/grafana_core_cpu_usage.2024-08-07_17-59-48-480.webp 480w,/assets/img/2024-08-07-zsh-nice-5/grafana_core_cpu_usage.2024-08-07_17-59-48-800.webp 800w,/assets/img/2024-08-07-zsh-nice-5/grafana_core_cpu_usage.2024-08-07_17-59-48-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/2024-08-07-zsh-nice-5/grafana_core_cpu_usage.2024-08-07_17-59-48.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption mt-0"> Grafana CPU Usage: Total Left, Core Right </div> <p>然后我马上打开<code class="language-plaintext highlighter-rouge">Grafana</code>查看了机器层面的自监控，在<code class="language-plaintext highlighter-rouge">Grafana</code>上查看总体CPU使用率和分核使用率都是在高位，符合预期，略奇怪（此时仍然不知道自己粗心没留意到ni）</p> <p>结合前面的想法，我找了设备运维大佬，请教了问题，然后他一下指出ni很高，不太对，还指明正常我们的设备不会调整进程的nice。 这个时候我才恍然大悟，哦，确实ni列的值都很高呀，然后我开始从乡村土路开回了高速</p> <p>首先明确一下<a href="https://en.wikipedia.org/wiki/Nice_(Unix)">nice</a>的定义，nice越小优先级越高（范围从-20 ~ 19 or -20 ~ 20） 系统级别的正常-20，用户态进程是0，我看了一下我的进程是5🤔，what’s going on? 直到这里已经能解释清楚，为什么ni那么高了，因为进程的<code class="language-plaintext highlighter-rouge">nice=5</code>， 被认为是较低优先级的进程，同等条件下比0或者-20更加小的机会被CPU调度执行，但是因为我的进程在压测，进程过于强势，吃掉了80+%的CPU时间片， 此时就单核心的ni列代表就是CPU被低优先级的进程占用的百分比，其实这种情况下是符合预期的，也就是我们认为的单核使用率=us+ni，在这种场景下， 没有任何问题。</p> <p>回过头来，问题在于，为什么进程变成了<code class="language-plaintext highlighter-rouge">ni 5</code>？什么时候开始的？为什么？</p> <p>于是开始回溯，开始挖掘，因为压测过程中会调整各类参数，甚至也会调优一下代码，所以还是有比较多的变量，好在我能明确是那次变化出现的， 不过挖掘了半天没再出现，直到某刻突然灵光一闪，不会是<code class="language-plaintext highlighter-rouge">bg job</code>吧？因为要调整启动参数，有时候为了快速切换我会直接kill掉服务然后用类似<code class="language-plaintext highlighter-rouge">commd &amp;</code>的方式直接手动拉一下， 然后我试了一下，bingo，就是你了，然后我就写了一个shell进一步确认了一下</p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c">#!/bin/sh</span>

<span class="nb">sleep </span>333<span class="p">;</span>
</code></pre></div></div> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2024-08-07-zsh-nice-5/bg_job_in_zsh_bash.2024-08-07_18-05-18-480.webp 480w,/assets/img/2024-08-07-zsh-nice-5/bg_job_in_zsh_bash.2024-08-07_18-05-18-800.webp 800w,/assets/img/2024-08-07-zsh-nice-5/bg_job_in_zsh_bash.2024-08-07_18-05-18-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/2024-08-07-zsh-nice-5/bg_job_in_zsh_bash.2024-08-07_18-05-18.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption mt-0"> bg job in zsh &amp; bash </div> <p>确实是，通过这种方式启动的，会导致nice被打成5，然后我就开始在网上找资料，并且也问了ChatGPT，但是并没有任何相关的信息明确表示<code class="language-plaintext highlighter-rouge">bg job</code>会将nice设成<code class="language-plaintext highlighter-rouge">5</code>， 并且有些地方明确表示除非主动设置否则不会改变进程的nice值，此时我灵光一想，从zsh切到bash，测了一下，emmmm，确实不会改变nice，至少在bash下不会， 问题面进一步缩小了，问题出在zsh身上，继续查资料问AI，依然没有明确的结果，我还进一步检查了包括.zshrc在内相关的配置文件里也没有任何nice相关的设置，很疑惑</p> <p>过了一会我放弃在网上搜索结果了，我开始找<a href="https://zsh.sourceforge.io/Arc/git.html">zsh的源码</a>，当我把源码clone下来，我开始翻看源码， C写的，我有两个线索，一个是<code class="language-plaintext highlighter-rouge">nice=5</code>，一个是<code class="language-plaintext highlighter-rouge">bg job(&amp;)</code>，开始围绕这两个去针对性挖掘就好了，在这里我依然还是背靠大山，ChatGPT一下就帮我缩小范围到某几个文件上了，分别是</p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>	•	Src/parse.c：包含 zsh 的语法解析器代码。
	•	Src/exec.c：包含命令执行相关的代码。
	•	Src/jobs.c：处理作业控制和后台进程的代码。
</code></pre></div></div> <p>我在<code class="language-plaintext highlighter-rouge">jobs.c</code>找到了<code class="language-plaintext highlighter-rouge">spawnjob</code>这个函数，但是这个文件没有涉及nice的调整，继续翻看了<code class="language-plaintext highlighter-rouge">exec.c</code>，在<code class="language-plaintext highlighter-rouge">execcmd_fork</code>这个函数内部，看到了目标代码</p> <ul id="execcmd-fork" class="tab" data-tab="64fa9433-9b3d-4a30-a9c8-a09d73b3e7fd" data-name="execcmd-fork"> <li class="active" id="execcmd-fork-newest-version"> <a href="#">newest version </a> </li> <li id="execcmd-fork-oldest-version"> <a href="#">oldest version </a> </li> </ul> <ul class="tab-content" id="64fa9433-9b3d-4a30-a9c8-a09d73b3e7fd" data-name="execcmd-fork"> <li class="active"> <div class="language-c highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="cm">/**/</span>
<span class="k">static</span> <span class="kt">int</span>
<span class="nf">execcmd_fork</span><span class="p">(</span><span class="n">Estate</span> <span class="n">state</span><span class="p">,</span> <span class="kt">int</span> <span class="n">how</span><span class="p">,</span> <span class="kt">int</span> <span class="n">type</span><span class="p">,</span> <span class="n">Wordcode</span> <span class="n">varspc</span><span class="p">,</span>
	     <span class="n">LinkList</span> <span class="o">*</span><span class="n">filelistp</span><span class="p">,</span> <span class="kt">char</span> <span class="o">*</span><span class="n">text</span><span class="p">,</span> <span class="kt">int</span> <span class="n">oautocont</span><span class="p">,</span>
	     <span class="kt">int</span> <span class="n">close_if_forked</span><span class="p">)</span>
<span class="p">{</span>
<span class="c1">// ...</span>
<span class="cp">#ifdef HAVE_NICE
</span>    <span class="cm">/* Check if we should run background jobs at a lower priority. */</span>
    <span class="k">if</span> <span class="p">((</span><span class="n">how</span> <span class="o">&amp;</span> <span class="n">Z_ASYNC</span><span class="p">)</span> <span class="o">&amp;&amp;</span> <span class="n">isset</span><span class="p">(</span><span class="n">BGNICE</span><span class="p">))</span> <span class="p">{</span>
	<span class="n">errno</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span>
	<span class="k">if</span> <span class="p">(</span><span class="n">nice</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span> <span class="o">==</span> <span class="o">-</span><span class="mi">1</span> <span class="o">&amp;&amp;</span> <span class="n">errno</span><span class="p">)</span>
	    <span class="n">zwarn</span><span class="p">(</span><span class="s">"nice(5) failed: %e"</span><span class="p">,</span> <span class="n">errno</span><span class="p">);</span>
    <span class="p">}</span>
<span class="cp">#endif </span><span class="cm">/* HAVE_NICE */</span><span class="cp">
</span>
    <span class="k">return</span> <span class="mi">0</span><span class="p">;</span>
<span class="p">}</span>
</code></pre></div></div> </li> <li> <div class="language-c highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="cp">#ifdef HAVE_NICE
</span>	<span class="cm">/* Check if we should run background jobs at a lower priority. */</span>
	<span class="k">if</span> <span class="p">((</span><span class="n">how</span> <span class="o">&amp;</span> <span class="n">Z_ASYNC</span><span class="p">)</span> <span class="o">&amp;&amp;</span> <span class="n">isset</span><span class="p">(</span><span class="n">BGNICE</span><span class="p">))</span>
	    <span class="n">nice</span><span class="p">(</span><span class="mi">5</span><span class="p">);</span>
<span class="cp">#endif </span><span class="cm">/* HAVE_NICE */</span><span class="cp">
</span></code></pre></div></div> </li> </ul> <p>可以看到这个条件编译（即在支持nice的系统上才会调用）内部包含了判断：当是异步作业的时候，并且<code class="language-plaintext highlighter-rouge">BGNICE</code>设置的话，就会把<code class="language-plaintext highlighter-rouge">nice设置5</code>， 翻看了一下git历史，从<code class="language-plaintext highlighter-rouge">1999年4月16日</code>最初的版本就已经带上了这个核心逻辑了，只是后来针对<code class="language-plaintext highlighter-rouge">cmd fork</code>和相关的错误捕获做了几次修订</p> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2024-08-07-zsh-nice-5/git_history.2024-08-07_18-25-28-480.webp 480w,/assets/img/2024-08-07-zsh-nice-5/git_history.2024-08-07_18-25-28-800.webp 800w,/assets/img/2024-08-07-zsh-nice-5/git_history.2024-08-07_18-25-28-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/2024-08-07-zsh-nice-5/git_history.2024-08-07_18-25-28.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption mt-0"> Git History </div> <p>所以我们可以明确从最开始zsh就已经明确后台执行的任务优先级不会比前台的任务高，也就一直遗留至今了，至于历史原因，我是没找到任何相关的资料文献， 我看到最初<code class="language-plaintext highlighter-rouge">Inital reversion</code>是<code class="language-plaintext highlighter-rouge">Tanaka Akira</code>提交的，我写了一封邮件给他，希望能了解一下历史原因和背景。但是可惜的是，他的邮箱已经不再使用了， 被退信了。</p> <p>其实在此基础上其实还可以继续挖一下how, Z_ASYNC, BGNICE的来源，在哪些地方被更改设置了，甚至进一步再回顾一下CPU调度策略，尤其结合优先级来测一下， 但是最近有点忙，社区里还有几个PR需要处理。whatever, casual tech just for casual :)</p> <p>只是好奇心作祟下的一次探索 💀</p>]]></content><author><name></name></author><category term="casual-tech"/><category term="linux"/><summary type="html"><![CDATA[How the nice value disturb the observation for CPU usage]]></summary></entry><entry><title type="html">zsh nice 5 🧐. How the nice value disturb the… | by ifuryst | Aug, 2024 | Medium</title><link href="https://ifuryst.github.io/blog/2024/zsh-nice-5-how-the-nice-value-disturb-the-by-ifuryst-aug-2024-medium/" rel="alternate" type="text/html" title="zsh nice 5 🧐. How the nice value disturb the… | by ifuryst | Aug, 2024 | Medium"/><published>2024-08-07T00:00:00+00:00</published><updated>2024-08-07T00:00:00+00:00</updated><id>https://ifuryst.github.io/blog/2024/zsh-nice-5--how-the-nice-value-disturb-the--by-ifuryst--aug-2024--medium</id><content type="html" xml:base="https://ifuryst.github.io/blog/2024/zsh-nice-5-how-the-nice-value-disturb-the-by-ifuryst-aug-2024-medium/"><![CDATA[]]></content><author><name></name></author><category term="linux"/><category term="casual-tech"/><summary type="html"><![CDATA[Today, I was troubleshooting an issue with a service’s throughput during a stress test. While observing the CPU usage, I paid attention not only to the process’s CPU consumption but also to the usage…]]></summary></entry><entry><title type="html">TCP congestion control. Statement!!! | by ifuryst | Medium</title><link href="https://ifuryst.github.io/blog/2024/tcp-congestion-control-statement-by-ifuryst-medium/" rel="alternate" type="text/html" title="TCP congestion control. Statement!!! | by ifuryst | Medium"/><published>2024-03-12T00:00:00+00:00</published><updated>2024-03-12T00:00:00+00:00</updated><id>https://ifuryst.github.io/blog/2024/tcp-congestion-control-statement--by-ifuryst--medium</id><content type="html" xml:base="https://ifuryst.github.io/blog/2024/tcp-congestion-control-statement-by-ifuryst-medium/"><![CDATA[]]></content><author><name></name></author><category term="TCP"/><category term="networking"/><summary type="html"><![CDATA[I am sharing a draft article from a field I no longer focus on but believe the insights within are too valuable not to share. Please note, this manuscript is presented as-is :) All of these…]]></summary></entry></feed>
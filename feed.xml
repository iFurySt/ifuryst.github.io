<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.3.3">Jekyll</generator><link href="https://ifuryst.github.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://ifuryst.github.io/" rel="alternate" type="text/html" hreflang="en"/><updated>2024-09-19T03:33:08+00:00</updated><id>https://ifuryst.github.io/feed.xml</id><title type="html">ifuryst</title><subtitle>📝 &amp; 💭 </subtitle><entry><title type="html">目标制定、标准衡量和人心管理 / Goal Planning, Performance Assessment, and Team Cohesion</title><link href="https://ifuryst.github.io/blog/2024/goals-metrics-n-team-spirit/" rel="alternate" type="text/html" title="目标制定、标准衡量和人心管理 / Goal Planning, Performance Assessment, and Team Cohesion"/><published>2024-09-17T13:41:27+00:00</published><updated>2024-09-17T13:41:27+00:00</updated><id>https://ifuryst.github.io/blog/2024/goals-metrics-n-team-spirit</id><content type="html" xml:base="https://ifuryst.github.io/blog/2024/goals-metrics-n-team-spirit/"><![CDATA[<p>在做OKR或者目标的制定中，不管是季度还是年度的，本意应是好的，毕竟从企业的角度来看，能让一线的员工也能感知到公司级别的战略或者目标是一件很好的事情。但是在关于目标制定、迭代和最终结果评定以及绩效发放的过程中，有可能会变形。这个问题我思考过几次，现在我稍微有一些想法了。</p> <p>我想探讨的是个人的差异带来的向心力不足的问题，也就是减少团队内部猜忌所带来的的内耗。</p> <p>在一个团队内，通常是存在不同级别的人员的，有初级工程师也会有高级工程，甚至是资深工程师。在这种情况下，每个级别能达成的目标必然是不同的，因为能力、薪资待遇水平的差异，注定了高级别的人员理应产出更多的成果（先不论这些成果的价值），因此在制定目标的时候，最合理的必然是有差异化的难度水平，因为对于低级别的工程师来说，要起完成高级别工程师才能完成的目标，是有些强人所难了，也对他们不公平，因此对于每个级别，甚至是每个人都能有一个专门的目标，会最大化团队的能力。</p> <p>但是这也带来一定的问题：</p> <ol> <li>这就注定了，个人的目标在团队或公司级别的高纬度的目标内的体现有可能是一句话或者压根没体现。</li> <li>团队内除了Leader以外，可能某人对于其他人的目标情况和难易程度（在制定阶段）可能完全不care</li> <li>Leader有可能没有办法面面俱到地帮助每个人审核和把控其目标是否合理，可能只是做到了目标和上级的目标是否一致</li> </ol> <p>上面这些问题会分别带来一些不同的问题：</p> <ol> <li>某些幸运儿会拿到上一层级目标的完整词条，也就是上一层别的目标会落到某个或某几个员工身上，这会让这些人会有更大的压力和动力，相应的会更有价值感；而在上一层级目标中没有体现的人，会走向相反的方向，会更加没有价值感，驱动力可能会更加弱</li> <li>这个在制定目标初期并不会有任何问题，问题可能发生在过程或者结束的时候。因为在每个人的视角来看，可能会觉得别人的目标比自己轻松太多了（不论是主观还是客观），目标和职级不匹配，心生芥蒂，这是危险的种子</li> <li>这我喜欢称之为向上管理的一个例子。其实很多时候完成上级的目标没有问题，问题是你通过什么手段和方式来完成。如果你希望你的团队战斗力很强，那么最好不要草率的对待每个人的目标，尤其这个目标的持续时间比较长的情况下。最好能因人制宜，将目标和个人的意愿或规划做一定程度的匹配，当然这个会消耗管理者较多的时间</li> </ol> <p>我觉得这些问题大多能在前置环节解决，有些在过程中也能调整解决，关键在于能否识别。这里就需要看团队或者公司的文化和氛围是否有对应的机制去接收员工的反馈。不是每个人都会主动对团队或公司的发展出谋划策的，但是要有这样的机制能接收员工的反馈，这样才能知道团队是否出了问题，这有助于某些坏事情在滋生阶段就介入处理的。</p> <p>在目标制定阶段，在确定初版之后，我觉得有一个环节可以有蛮大收益的，让每个人对别人的目标做评价，这样他们可以认真去看别人的目标，这样可以在前置环节就让大家互相知道对方的目标，并且如果可以的话，可以问某个人如果xxx休假了，你可否代替她完成她的目标？一旦这个说法出来之后，这个人对于别人的目标的心态就会有些许变化了，可能就会开始带入自己是主人公的角色去思考，这样有助于大家对于目标制定达成共识。这点其实和敏捷迭代里的点数评估类似，比如某个任务，A需要2D完成，但是B只需要1D完成，这就是能力差异以及目标执行人的可替换性，其实不仅在迭代里可以这样，在目标的制定也是如此，我们不希望某个目标只能由某个人完成，我们其实应该至少保证有2个人以上可以完成某个目标，理想情况下当然是团队内每个人都可以完成任意的目标，但是出于对专业化分工的带来效率最大化的追求，通常是不会这样的，但至少我们可以保证有至少2人能完成某个目标。</p> <p>在目标的制定和规划上，管理人员不能只考虑自己的目标是否能完成，应该充分考虑将团队成员充分发挥起来，整个团队一起完成目标。参与感是一个很重要的东西。这里我想要举个有趣的例子来佐证这个观点：</p> <p>我们在做Scrum迭代的时候，正常是会有一个固定的Scrum master，负责组织站会、规划回顾会之类的敏捷会议。但是我们在实践过程中发现，与其设定一个固定的Scrum Master，不如让人人皆为Scrum Master，也就是轮流制，简单的实践方式是每周（假设迭代冲刺周期是1week）由不同的团队成员来担任Scrum Master。我发现这种方式带来的好处是远远大于前值的，主要集中在这么几点：</p> <ol> <li>每个人都能有机会成长，学会如何转从头到尾主持处理一次完成的敏捷迭代冲刺</li> <li>大家都会以主人公的意识来参与，当轮到别人做Scrum Master的时候你不会在旁边划水或者不怎么爱应答其发出的疑问，因为你知道当Scrum Master的感觉，也知道你提问的时候没人回应的感觉，你也希望下次你做Scrum Master的时候大家能配合你</li> <li>对于团队目标的追踪，你会开始上心，哪怕轮到你一次需要好几周，但是因为你已经开始注意目标的跟进了，你已经锚定了，因此你很容易就会将对应的信息听进去并且评估团队的情况</li> <li>团队内有管理能力的人会慢慢浮出水面，大家都得到了机会，作为管理者你可以很容易的观测到每个人在管理者的角度做事时是怎样的姿态，能帮助管理者更加容易的发现每个人的能力和定位，以及在遇到问题时候要怎样针对性的应对</li> </ol> <p>我并不是倡导一定要走轮流Scrum Master的方式，我只是觉得这种方式值得一试。这个例子说明是想说明如果你希望团队成员都动起来，首先需要让每个人尽可能找到主人翁的意识，这有挺多方法能达到的，我这里仅仅举了个例子。</p> <p>管理中最难的且最重要的永远是人，其次才是产品和利润（来自创业维艰），我觉得前者偏向于因，后两者偏向于果。因此我觉得好的管理是能人尽其才 🫡</p>]]></content><author><name></name></author><category term="opinions"/><category term="thoughts"/><summary type="html"><![CDATA[在做OKR或者目标的制定中，不管是季度还是年度的，本意应是好的，毕竟从企业的角度来看，能让一线的员工也能感知到公司级别的战略或者目标是一件很好的事情。但是在关于目标制定、迭代和最终结果评定以及绩效发放的过程中，有可能会变形。这个问题我思考过几次，现在我稍微有一些想法了。]]></summary></entry><entry><title type="html">在确定性中寻找不确定性 / Seeking uncertainty in certainty</title><link href="https://ifuryst.github.io/blog/2024/seeking-uncertainty-in-certainty/" rel="alternate" type="text/html" title="在确定性中寻找不确定性 / Seeking uncertainty in certainty"/><published>2024-08-30T14:58:27+00:00</published><updated>2024-08-30T14:58:27+00:00</updated><id>https://ifuryst.github.io/blog/2024/seeking-uncertainty-in-certainty</id><content type="html" xml:base="https://ifuryst.github.io/blog/2024/seeking-uncertainty-in-certainty/"><![CDATA[<p>一周前偶然在外图看到一本杨潇的《可能的世界》，起初吸引我的是类似游记的内容，小翻两页觉得内容似乎对味，因此就买了这本书。晚上吃晚饭随手拆看一看，竟是2小时过去了。</p> <p>算是一本在不同国家、地区的生活或经历结合一些自己的三观写出来的东西，我觉得非常引人入胜，其中有很多点非常棒。难免结合自己近一年来的生活进行了一定的印证和思考。</p> <h2 id="不确定性循环">(不)确定性循环</h2> <blockquote> <p>It’s easy to see the beginnings of the things, and harder to see the ends. (From Joan Didion) (Pxii)</p> </blockquote> <p>这是一句很能引起共鸣的话，很多时候我们只能看到事情的开始，看不到结束，这也是我们在这个世界剩余的日子里要不断经历的。</p> <p>昨天和一位同学简朋友聊，也聊到了对应的话。很多人的一生都是在追求一种确定性，这种确定性可以有很多现实的表征，也可以是一种心理上的确定性。但是也有一批人，在追求不确定性，不管她是在确定性中寻找不确定性还是在不确定性中寻找不确定性。</p> <p>怎么理解这个宛如绕口令的东西？无外乎利益。我们的一个共识是，原始动力皆为利益，哪怕亲情友情爱情，在广义上来说也是利益。在这里我认为利益并不是一个贬义词，我觉得更像是一个中性词，虽然很多时候我们很容易在向钱看的世俗意义中把利益当成一个偏向贬义词的词。</p> <p>为什么要寻找那一丝不确定性呢？有人为了机会，有人不喜欢按部就班的生活，有人为了找到更大的确定性。都说人的一生是在走出自己的偏见，在这里我们也可以说成，人的一生就是在确定性和不确定中不断循环，直到生命的终结。有人疲于奔命，有人一个循环都没走完。套用最近火出圈的黑猴，人人都想上个显卡当一回天命人，在黑猴的世界里，也是六道轮回，循环往复。</p> <h2 id="信息过载">信息过载</h2> <p>P48-P49说到一些关于信息过载的内容，比较散，就没有提取出原文了。这一点非常有感触。近一年来我的信息摄入量增加到非常可怕的地步，每天都在“赶进度”，每天都有看不到新闻、文章、paper推送，每天都要把newsletter都清掉，每天的commuting都需要听英文podcast，每天都要关注开源社区的邮件情况，还要把去年底带回来的基本英文书看完。准确来说近半年属于信息超级过载的状态，主要有几个原因：</p> <ol> <li>一定要尽可能接收（我认为的）正确的信息和一手的信息</li> <li>英语能力提升的同时伴随着对信息摄入的变态需求</li> <li>正向反馈，越是收到有价值的信息越激励自己去追求</li> </ol> <p>我觉得信息过载不是长期形态，我觉得最终的形态是会收敛到一个稳定的状态，我记得之前看纪录片Inside Bill’s Brain: Decoding Bill Gates，至今印象深刻的一个点是，Bill Gates会有一个时间，比如几天，开着飞机到某个地方，提了一袋书去闭关，让我震惊的是他阅读书籍的速度，快到不可思议，所以我觉得信息的摄入速度有很大的增长空间，当你的大脑不断重复一些pattern，他就能很快的判断内容，有点想神经网络训练后，很自然的就能知道下一个字符可能是什么…</p> <p>所以我觉得是一个做加法然后做减法的过程，一定要有一个量的积累，我不断在挑战自己的天花板，慢慢增加摄入量，一定要让自己保持在堪堪能catch up今天的信息流的进度，这个过程也不是一层不变，我会不断剔除不适合或不感兴趣的内容</p> <p>总得来说，我得出的结论就是，要让自己痛苦，让自己信息过载。当然方式有很多了，也有人是通过频繁和别人交流、交换思想来达成的，也有人是通过玩游戏、看电影、刷短视频达成的。</p> <p>最后，我觉得最值得一提的一点是，宝贵的信息永远不是免费的，也不能是免费的。我觉得比无法获取珍贵的信息更无法忍受的是获取错误的信息，这也是免费信息里的重灾区，太多的错误、无效信息，这也是我不喜欢短视频的一点，短视频让人很容易即时满足，但是其提供的往往不是我想要的，长视频可能还有一些尚可的内容。另外书籍真的是人类文明很重要的一个发明。还有一点，曾经我是非常不喜欢订阅制付费的人，我会非常稀罕那个费用，但是现在我愿意给任何一个信息、媒体平台一个机会，去订阅内容，如果是我想要的，我可以长期订阅支持，我觉得这是对正确信息的输出最直接的回报，我也希望能长期获得有深度的报道和分析。</p> <h2 id="思辨">思辨</h2> <p>P41, P38</p> <p>我非常喜欢哈佛来信这一章，这一张里讲的各类关于在哈佛大学里的所见所闻所思所想都非常吸引我。我是一个坚定的应试教育厌恶者（或许跟我本身没有那个应试教育的能力有一定关系吧😅），但是我对于知识的渴望是非常高的。</p> <p>文中有聊到一个课叫伦理、生物科学和人类未来，是两位教授迈尔克·桑德尔和道格拉斯·梅尔顿（Douglas A. Melton）一起上的，一人站在一边，然后通过对学生发问以及两位教授之间的辩论来完成的，非常有魅力和有趣，里面聊到关于运动员使用促红素（EPO）的观点，大体是EPO可以提高血液携氧能力，让肌肉工作更长时间，在运动领域这就类似兴奋剂的存在，教授列出总共有8种方法可以提升的，从最基础的锻炼休息，高海拔训练，低氧舱休息，到服用食物，转基因食物，再到注射。然后让学生选择哪个阶段你会投反对票，这也是国际奥委会实际在争论的问题。这个过程很有趣，大家都可以决定自己在哪个级别禁止，两位教授会就这个内容进行辩论。</p> <p>另外有一节聊到《纽伦堡的审判》，关于法庭上的对话也非常有意思。也给我带来了很大的思考。</p> <h2 id="自我她我">自我、她我</h2> <blockquote> <p>究竟是出于记录当下的冲动，还是为了迎合想象中的他者目光。(P46)</p> </blockquote> <p>这点也很有意思，对于发动态这件事情，咱们这个社会氛围之下，自然有两类主要的人，一类是热衷于发布自己的动态，一类是完全不发动态。当然还有其她类别的人，但是我觉得主要就这两类了。</p> <p>在亚洲的社会习俗或者社会观念之下，会有一些无形的东西在控住你的思想，这个讲不清是从小环境还是基因里多少带了一些千年的余韵。确实很多时候有这种考量，有时候只是当下的某些因素促使自己想去发布一个动态，但有些时候想的又是自己的人设问题。文中这句话倒真切的点出了这个。</p> <h2 id="写在最后">写在最后</h2> <p>这本书我还在看，就好像前面那句话一样，我只知道我什么时候开始看，我无法知道我什么时候能看完，如果还有有趣的内容，我还会继续更新一下这篇随笔。</p> <p>Let’s keep going. 🧗🏼‍♂️</p> <p>[*]<em>文中第三人称代指多用女性她，也是最近我学习到的，在某些英文资讯、文章中会以女性代词来代指，用于表明性别不明或不重要，也有避免性别歧视的一层含义，我觉得蛮有意义的。</em></p> <blockquote> <p>A user can choose her favorite serialization method to encode a message.(Forgive me. I forgot where this is from.. I’m retrieved if from ChatGPT’s chat history.)</p> </blockquote>]]></content><author><name></name></author><category term="opinions"/><category term="thoughts"/><summary type="html"><![CDATA[一周前偶然在外图看到一本杨潇的《可能的世界》，起初吸引我的是类似游记的内容，小翻两页觉得内容似乎对味，因此就买了这本书。晚上吃晚饭随手拆看一看，竟是2小时过去了。]]></summary></entry><entry><title type="html">最高级的生活方式：存钱，早起，运动，读书 / Ultimate Adulting Hack: Stashing Cash, Racing the Sunrise, Sweating by Choice, and Pretending You Actually Finished That Book</title><link href="https://ifuryst.github.io/blog/2024/the-secret-to-peak-living/" rel="alternate" type="text/html" title="最高级的生活方式：存钱，早起，运动，读书 / Ultimate Adulting Hack: Stashing Cash, Racing the Sunrise, Sweating by Choice, and Pretending You Actually Finished That Book"/><published>2024-08-30T14:58:27+00:00</published><updated>2024-08-30T14:58:27+00:00</updated><id>https://ifuryst.github.io/blog/2024/the-secret-to-peak-living</id><content type="html" xml:base="https://ifuryst.github.io/blog/2024/the-secret-to-peak-living/"><![CDATA[<p>说实话，这个标题恶心到我了………🤫</p> <p>今天在家庭群里看到一篇分享，是个不到10min的短视频，标题叫《最高级的生活方式：存钱，早起，运动，读书》，刚好我洗完澡在餐桌上看点材料，心血来潮的回复了一段话：</p> <blockquote> <p>感觉能认识到自己想要的和追求的，有理想也有现实，有事业也有家庭，能平衡好自己的生活，自己认为好的生活方式就是最好的。不过这里面很多点，很多人一辈子都没有看明白。怎么说一个人一辈子都是在走出偏见的过程。读书学习，遇人识物，出门旅行，都是不同的方式。</p> </blockquote> <p>人的一生都在追求什么？</p> <p>我觉得很多人都有自己的答案，也有挺多人知道自己有答案，但是不敢或者不想去揭露那个答案，有时候朦胧也是一种美。</p> <p>当然也有一些人可能不知道或者还不知道自己的追求是什么。这其中也有很多原因，如果单独从不知道追求什么就先入为主的认为，可能会有一些相对偏见的结果。</p> <p>从很小我就开始为自己的人生做决定，我不会后悔自己做的事情，习惯性没有这个想法，也不知道是逃避还是真如自己认为的“我永远会对自己的决定负责到底”，这也让我在做每个重要决定之前会想的多一点。姑且认为是后者，我觉得做决定还挺简单的，难的是，你要在有限的选择里做出更好的决定，以及随之而来的伴随你的决定的一切结果。</p> <p>我也同很多人一样，觉得成年人的世界更加复杂。但是我乐爱成年人的世界，因为我有能力也有足够的见识支撑我做出更加重要的决定，这个在比较小的年龄来说，是很难的，因为见识和经历太少，很多时候做出正确的决定也有一定的运气在里面（其实成年人的世界做决定也逃不过这个，只是成分多寡的区别），并且也没有太多物质能力支撑你做更广的选择。从某些层面来看，成年人的选择会更多一些，但是也挺多时候可以发现一样是非常有限的选择，甚至没有选择。</p> <p>回过头来，其实很多时候我知道自己追求的是什么，自己想要的是什么，我对于自己的中期规划会比较擅长，短期会比较倾向于在中期计划里野蛮生长，我喜欢在有限的自由里这样做，就好像小时候最喜欢画自由画一样，我必须要提交一份画，这个是边界，在此基础之上，我可以畅想并画任何我想画的，我觉得这个也是能在一定程度内让自己保持有创造力的表现，在这个空间之下，去跳脱。不过也有另一面（On the flip side），很多事情会混乱起来，我觉得这个事情有一些人很难接受，比如你会让你的桌面很乱，但是其实这是外人眼里的乱，包括在严肃一些的场景之下，可能会被人冠以没有条理性之类的帽子。但是这个乱在我的世界中都有各自的定位，我在里面能随心所欲的实施很多想法，以我刻板和有限的对艺术家或者创作者的想法和认知来看，我认为这个是有一定共性的（欢迎有人随时来打我的脸）。</p> <p>就这样，我会以中期规划做锚点，来指导我的某些短期行为（但是这并不代表我会事事照着这个来，那样可太无趣了）。你可能发现少了一个长期规划或者远期规划，我觉得这是一个很难的事情，就我个人而言。我觉得太远的规划存在的意义值得商榷，我不太喜欢把事情想得那么远，因为有可能落入一些陷阱。</p> <p>比如有的人会说，理想总要有的，万一实现了呢。这种会把长期规划当作一种偏向于比较难实现的东西去想。还有一种是偏向比较可实现的方向去想，这种相对前面那种会好一点，但是我觉得都不是很有意义，我的观点是，太容易随着时间流逝，经历的不同东西，体验到不同的事物而改变了。还有一个点就是，规划某种程度上说可能是给自己设限，因为你期望按照这个方向走，所以也有割伤自己的嫌疑。当然这一切都是基于我的认知所想的，我相信有很多人和我的观点相左，我愿意接受一切和我观点相似或者相反的想法存在，多样性的意义大概如此。</p> <p>口嗨了这么多，其实也只是在口嗨。从一个生活方式的分享视频说到人生追求，再扯到选择和决定，最后再胡诌一下规划，这大抵就是成年人的自由画。我也不太可能在这里把我的生活方式、追求、决定、选择和规划相关的东西都剖析得一干二净，只是希望能给大家，给这个世界带来一点个人观点和想法。That’s enough :)</p>]]></content><author><name></name></author><category term="opinions"/><category term="thoughts"/><summary type="html"><![CDATA[说实话，这个标题恶心到我了………🤫]]></summary></entry><entry><title type="html">Kafka设计理念 / Kafka Design Concept 📝</title><link href="https://ifuryst.github.io/blog/2024/kafka-design-concept/" rel="alternate" type="text/html" title="Kafka设计理念 / Kafka Design Concept 📝"/><published>2024-08-29T14:18:27+00:00</published><updated>2024-08-29T14:18:27+00:00</updated><id>https://ifuryst.github.io/blog/2024/kafka-design-concept</id><content type="html" xml:base="https://ifuryst.github.io/blog/2024/kafka-design-concept/"><![CDATA[<p><a href="https://notes.stephenholiday.com/Kafka.pdf">https://notes.stephenholiday.com/Kafka.pdf</a></p> <p>依然建议点开这个链接，先读一下原始信息，读完后仍然感觉有必要的情况下再来阅读本文，避免被我提供的信息先入为主影响你的思考。 当然你反过来阅读也可以，可以先通俗阅读后去原文里印证一下想法，也是一种方式。Whatever you prefer.</p> <h2 id="背景">背景</h2> <p>Kafka是2011年LinkedIn开源的，后来捐给ASF了，现今到一定规模的企业基本没有不涉及到使用Kafka的可能，这是一个很重要的基础设施。</p> <p>Kafka诞生的初衷是因为传统的日志处理、聚合和消息系统在某些程度上都不满足一些场景下的需求，包括：</p> <ol> <li>过度递送保证了，比如强事务、强ACK等，这个在某种程度上会牺牲能处理的量级，并且在某些场景并不是完完全全关心这个保证，比如某些日志丢失一两条可能并没有什么问题。</li> <li>大多数系统并不是以吞吐量优先的原则进行设计的，比如里面提到的JMS甚至不支持批量发送消息，这会导致每个消息都需要一个完整的网络请求来回时间（Roundtrip）</li> <li>对于分布式支持较弱</li> <li>大多数消息系统都假设下游接近实时消费，堆积量很小。这个在大量堆积的场景会引发很严重的性能问题（某些采用push给下游的，还可能导致更严重的问题）</li> </ol> <p>所以我个人感觉，Kafka其实是技术或者说行业量级发展到一定程度必然会产生的一个产物，因为在数据量级日益增长的情况下，必然需要这样一个基础设施、 中间件、消息队列来持续以高吞吐可靠的处理高量级（High Volume）的数据，并且能有分布式的支持来应对灾难， 其他的就是一些相应的feature了， 比如可靠性、可堆积、可重复消费、PULL代替PUSH等</p> <h2 id="设计理念">设计理念</h2> <p>基于前面的背景，大概也能知道Kafka会是什么样子的，以下是一些基础的概念、术语：</p> <ol> <li>Message：经过的数据都叫消息</li> <li>Topic：特定的消息流被定义在topic里</li> <li>Producer：可以发布消息到topic</li> <li>Broker：实际保存数据的服务器</li> <li>Consumer：可以从一个或多个topic里订阅读取消息（PULL）</li> <li>Partition：基于topic下的逻辑分区</li> </ol> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2024-08-28-kafka-design-concept/kafka_architecture.2024-08-28_13-44-48-480.webp 480w,/assets/img/2024-08-28-kafka-design-concept/kafka_architecture.2024-08-28_13-44-48-800.webp 800w,/assets/img/2024-08-28-kafka-design-concept/kafka_architecture.2024-08-28_13-44-48-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/2024-08-28-kafka-design-concept/kafka_architecture.2024-08-28_13-44-48.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption mt-0"> Git History </div> <h3 id="简单存储">简单存储</h3> <p>日志被分成固定大小的文件（Segment file），比如1G。为了提高性能，每次收到消息后会换存在内存，等到一定消息量或经过一定时间后， 才会被写到（flush）磁盘，只有在写到磁盘后才可以被消费者消费</p> <p>Kafka的消息并没有message id，而是以逻辑偏移（logical offset）来定位。这能避免寻址的开销，如随机访问等。kafka的id是递增的但是不连续， 因为下一个消息的偏移需要用当前的消息id+消息长度</p> <h3 id="传输效率">传输效率</h3> <p>利用了底层操作系统的页缓存（page cache），这样的好处是Kafka自己不需要管理这些内存了，操作系统自己管就行了，没有命中的页再去磁盘load进来， 操作系统自己有一套完备的内存页管理机制；另外就是减少了GC的开销了，不需要对这部分数据的GC头疼了。这种情况下可以支持TB级别的数据消费</p> <p>另外就是利用了系统调用（system cal）来减少数据在内核和用户空间拷贝的开销，这个也是很聪明的一个设计， 按照常规从磁盘读数据通过网络发送的应用来说，大体是这样一个过程：</p> <ol> <li>从磁盘读取数据到操作系统页缓存，此时数据在内核态</li> <li>从内核拷贝数据到用户空间的缓存里</li> <li>然后要通过网络发出去的话，从用户空间的应用缓存里再拷贝到内核缓存空间</li> <li>从内核缓存空间发给socket</li> </ol> <p>前后经过4次数据拷贝，2次系统调用。在这种情况下Kafka通过系统调用（如linux里的sendfile）可以直接把数据从磁盘给到socket， 可以减少步骤2、3的操作了，等于简化到2次数据拷贝，1次系统调用（也有的地方会称为0拷贝，我觉得这个说法应该是针对0次拷贝到用户空间的说法）</p> <h3 id="无状态broker">无状态Broker</h3> <p>broker不知道消费者的任务信息，都有消费者自己管理，因此broker极度简化，但是这也带来一个问题，就是broker不知道什么时候才能删掉消息， 所以Kafka采用了通过以时间为基准的SLA保留策略，比如7d、30d、90d这种，在实际生产环境中是完全可行的，正常下游不会不可用或者lag到这么久， 这个设计的另外一个好处是，消费者可以自主回滚offset或者重新拉取之前的消息，在某些故障场景下， 可以很好的结合一些诸如checkpoint机制来保障下游数据的可靠性。</p> <p>当然这个设计是违背常规队列的设计的。这也是一个很不错的点，就好比人人都和你说队列就应该这样设计，如果你一直遵从这种思维， 你设计的消息队列就有可能先入为主的沿着这个方向去思考，所以有时候能打破旧有的标准，敢于挑战权威是一种勇气也是一种能力</p> <h3 id="分布式协调">分布式协调</h3> <p>抛弃主节点的设计，结合了Zookeeper做Consumer的协调，主要针对topic和partition以及offset，具体涉及了4个注册表（registry）：</p> <ol> <li>Broker Registry(ephemeral)：存放broker注册信息，启动时会注册</li> <li>Consumer Registry(ephemeral)：消费者加入consumer group的时候会创建注册</li> <li>Ownership Registry(ephemeral)：当一个消费者声明自己负责某个partition的时候，会创建表明所有权</li> <li>Offset Registry(Persistent)：存储消费者消费到的偏移量，每个partition一个节点，值表示最新已提交的消息偏移量</li> </ol> <h3 id="递送保证">递送保证</h3> <p>Kafka只支持至少一次，并不支持准确一次。但后面的迭代中还是加入了ACK等机制，只是最初设计是还没有做这个。</p> <h2 id="结论">结论</h2> <p>整体从最初的设计理念可以看出，Kafka对于非常重要的数据的保障并没有做到最好，也就是跟传统的日志服务不同，更注重低时延高吞吐。 比如一开始并没有ACK机制，Broker也不支持数据副本，这些也在后续陆续被支持。Kafka后续也迭代增加了很多Feature，甚至现在都用KRaft取代了ZK， 单看一篇最初始的Paper并不能了解所有，只能窥探最初的设计理念，但是后面演进过程中也有很多的有趣、很棒的设计， 具体可以看相关的<a href="https://cwiki.apache.org/confluence/display/KAFKA/Kafka+Improvement+Proposals">KIP（Kafka Improvement Proposal）</a></p> <p>PULL vs PUSH模型也是一个很有意思的选择，Prometheus和Kafka在他们的场景都采用了PULL，是从一定的出发点、设计理念和背景下做出的这个选择。 进一步可以说明并没有什么银弹，很多时候是在一定的背景和场景之下去选择合适的方案，是一种能力也是一种智慧。</p> <h2 id="appendix-1">Appendix 1</h2> <p>以下内容基于Kafka 2.4.1</p> <table> <thead> <tr> <th>ZK路径</th> <th>内容示例</th> <th>作用</th> </tr> </thead> <tbody> <tr> <td>/admin</td> <td> </td> <td>Kafka管理任务的信息</td> </tr> <tr> <td>/admin/delete_topics</td> <td> </td> <td>删除topic操作信息存在这里</td> </tr> <tr> <td>/brokers</td> <td> </td> <td>broker信息</td> </tr> <tr> <td>/brokers/ids/<broker_id></broker_id></td> <td>{<br/> “listener_security_protocol_map”:<br/> {<br/> “PLAINTEXT”: “PLAINTEXT”<br/> },<br/> “endpoints”:<br/> [<br/> “PLAINTEXT://10.123.123.1:9092”<br/> ],<br/> “jmx_port”: 9989,<br/> “host”: “10.123.123.1”,<br/> “timestamp”: “1722923239941”,<br/> “port”: 9092,<br/> “version”: 4<br/>}</td> <td>具体的broker信息，ID，端口，注册时间等</td> </tr> <tr> <td>/brokers/seqid</td> <td> </td> <td> </td> </tr> <tr> <td>/brokers/topics</td> <td> </td> <td> </td> </tr> <tr> <td>/cluster</td> <td> </td> <td>集群信息</td> </tr> <tr> <td>/cluster/id</td> <td>{<br/> “version”: “1”,<br/> “id”: “tsc3VC-yQeeCkti2jdaX-Q”<br/>}</td> <td> </td> </tr> <tr> <td>/config</td> <td> </td> <td>配置相关，如topic或客户端相关的配置</td> </tr> <tr> <td>/config/brokers/<broker_id></broker_id></td> <td>{<br/> “version”: 1,<br/> “config”: {}<br/>}</td> <td> </td> </tr> <tr> <td>/config/changes/config<em>change</em><nums></nums></td> <td>{<br/> “version”: 2,<br/> “entity_path”: “topics/xxxxxx”<br/>}</td> <td>记录所有配置变更</td> </tr> <tr> <td>/config/clients</td> <td> </td> <td> </td> </tr> <tr> <td>/config/topics/__consumer_offsets</td> <td>{<br/> “version”: 1,<br/> “config”:<br/> {<br/> “segment.bytes”: “104857600”,<br/> “compression.type”: “producer”,<br/> “cleanup.policy”: “compact”<br/> }<br/>}</td> <td> </td> </tr> <tr> <td>/config/topics/<topic_name></topic_name></td> <td>{“version”:1,”config”:{}}</td> <td>topic配置</td> </tr> <tr> <td>/config/users</td> <td> </td> <td> </td> </tr> <tr> <td>/consumers</td> <td> </td> <td>消费组信息</td> </tr> <tr> <td>/controller</td> <td>{<br/> “version”: 1,<br/> “brokerid”: 2,<br/> “timestamp”: “1722923238927”<br/>}</td> <td>集群中controller的信息（特殊的broker，负责协调选举等控制任务）</td> </tr> <tr> <td>/controller_epoch</td> <td>37</td> <td>记录epoch，每次选举后增加</td> </tr> <tr> <td>/isr_change_notification</td> <td> </td> <td>临时节点，用于通知ISR中的变更</td> </tr> <tr> <td>/latest_producer_id_block</td> <td>{<br/> “version”: 1,<br/> “broker”: 1,<br/> “block_start”: “54000”,<br/> “block_end”: “54999”<br/>}</td> <td>存储producer的id范围最新状态</td> </tr> <tr> <td>log_dir_event_notification</td> <td> </td> <td>用于触发和管理日志目录变更的通知机制</td> </tr> </tbody> </table>]]></content><author><name></name></author><category term="distributed-systems"/><category term="distributed-systems"/><summary type="html"><![CDATA[从Kafka Paper中感受其设计思想]]></summary></entry><entry><title type="html">Raft论文阅读小记 / RAFT paper reading notes 📝</title><link href="https://ifuryst.github.io/blog/2024/raft/" rel="alternate" type="text/html" title="Raft论文阅读小记 / RAFT paper reading notes 📝"/><published>2024-08-21T12:51:27+00:00</published><updated>2024-08-21T12:51:27+00:00</updated><id>https://ifuryst.github.io/blog/2024/raft</id><content type="html" xml:base="https://ifuryst.github.io/blog/2024/raft/"><![CDATA[<p><a href="https://raft.github.io/raft.pdf">https://raft.github.io/raft.pdf</a></p> <p>建议读一下原Paper</p> <h2 id="背景">背景</h2> <p><code class="language-plaintext highlighter-rouge">RAFT</code>是一个分布式领域内的共识算法（Consensus Algorithm），目的是为了提供一个更加直观易懂（Understandability）、 更易于实现且不丧失相关的强一致性，可以理解就是<code class="language-plaintext highlighter-rouge">PAXOS</code>的通识版</p> <p>因为此前<code class="language-plaintext highlighter-rouge">PAXOS</code>在这个领域占据主导地位，大量的教科书里都是用<code class="language-plaintext highlighter-rouge">PAXOS</code>来教学，初学者有较大的学习成本，并且工程实践方面也比较困难，表现在2点：</p> <ol> <li>理解的难度，再加上理论和实践的差距</li> <li><code class="language-plaintext highlighter-rouge">PAXOS</code>对于很多细节并没有阐述清晰，导致各方在实现的时候就会根据情况去变形，导致最终大家实现的都是有出入的</li> </ol> <p>Conclusion里的这段我觉得能挺清晰的表达出<code class="language-plaintext highlighter-rouge">RAFT</code>对于易理解的追求：</p> <blockquote> <p>Algorithms are often designed with correctness, efficiency, and/or conciseness as the primary goals. Although these are all worthy goals, we believe that understandability is just as important. None of the other goals can be achieved until developers render the algorithm into a practical implementation, which will inevitably deviate from and expand upon the published form. Unless developers have a deep understanding of the algorithm and can create intuitions about it, it will be difficult for them to retain its desirable properties in their implementation.</p> </blockquote> <p>整体就是说，追求正确、效率和简洁明了通常是设计算法里的首要目的，但是<code class="language-plaintext highlighter-rouge">RAFT</code>的作者认为易于理解同样重要。除非深入的理解， 否则在实现或者在不同形式的传播中，很难一直保持其原有的设计思想或理念，也就是咱们前面说到的，实现中要根据情况、经验和认知去决定实现方式， 不可避免的结果就是会导致很多“版本”的流通</p> <h2 id="设计理念">设计理念</h2> <p><code class="language-plaintext highlighter-rouge">RAFT</code>借鉴了现实社会中的领导选举机制，还挺方便理解。从全局的角度看，整体遵循了这么几个点：</p> <ol> <li>只有三种角色：Leader（主，领导者）、Candidate（候选者）、Follower（跟随者）</li> <li>任期制：确保节点不可用时（尤其Leader）能快速感知和切换</li> <li>所有的操作只能在Leader上进行（需要注意，这种情况下性能层面会有一定问题，因此在某些应用场景还是需要结合一些其他缓存系统来保障高效的读写，这就是架构设计中需要注意的，没有银弹，一切都是取舍Tradeoff，当然要做tradeoff之前你是需要对涉及到的技术、系统的设计理念和应用场景有一定的认知，才能做出正确的判断）</li> <li>追加日志，日志从Leader复制到其他Follower</li> <li>安全性：日志复制需要经过一致性检查，大多数节点确认才可提交</li> </ol> <p>其他的就是基于这些点下沉的一些细节，比如：</p> <ul> <li>怎么选举</li> <li>角色如何切换</li> <li>怎么防止切换时日志被新主覆盖</li> <li>节点故障的具体处理细节</li> <li>如何保持心跳</li> <li>如何处理在相同下标下的不同数据</li> </ul> <h2 id="选举">选举</h2> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2024-08-21-raft-paper-reading-notes/electoral_process.2024-08-21_23-26-19-480.webp 480w,/assets/img/2024-08-21-raft-paper-reading-notes/electoral_process.2024-08-21_23-26-19-800.webp 800w,/assets/img/2024-08-21-raft-paper-reading-notes/electoral_process.2024-08-21_23-26-19-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/2024-08-21-raft-paper-reading-notes/electoral_process.2024-08-21_23-26-19.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <div class="col-sm mt-0 mb-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2024-08-21-raft-paper-reading-notes/requestvote_rpc.2024-08-21_23-26-35-480.webp 480w,/assets/img/2024-08-21-raft-paper-reading-notes/requestvote_rpc.2024-08-21_23-26-35-800.webp 800w,/assets/img/2024-08-21-raft-paper-reading-notes/requestvote_rpc.2024-08-21_23-26-35-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/2024-08-21-raft-paper-reading-notes/requestvote_rpc.2024-08-21_23-26-35.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption mt-0"> Left: Electoral Process, Right: RequestVote RPC </div> <ol> <li>刚启动，所有节点都是Follower（或者Leader没了，剩余的都是Follower）</li> <li>发现没有来自Leader的心跳同步包（Leader发送的心跳是跟着AppendEntriesRPC请求一起的，哪怕没有数据也可以发空payload代表这个请求只用于心跳用途），等待任期超时（每个节点的超时时间都是不同的，随机的，意图是这样能有效避免选票分散在多个同时发起选举的候选人身上）</li> <li>某些节点超时了，触发选举，将自己从Follower提升到Candidate，发送投票请求（RequestVote RPC）给所有节点（会携带上任期号term和最新的日志下标lastLogIndex, lastLogTerm）</li> <li>节点收到投票请求，会和本身的当前任期对比，如果自己所处的任期大于对方的，或者自己的日志比对方更多，拒绝投给对方，否则就投票给对方（同节点可能会收到多个投票请求，也是基于这个逻辑来确认投给谁）</li> <li>最终票数多的成为Leader（也有可能票数一样导致没有Leader产生，就会等下一任期到来再选举一波），开始定期发心跳维持自己的地位（某个节点在超时时间内收到Leader的心跳会重启超时等待，直到没收到就会回到Step 2.开启新的选举），此时其他节点全部退回Follower状态</li> </ol> <h2 id="日志复制">日志复制</h2> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2024-08-21-raft-paper-reading-notes/state.2024-08-21_23-26-51-480.webp 480w,/assets/img/2024-08-21-raft-paper-reading-notes/state.2024-08-21_23-26-51-800.webp 800w,/assets/img/2024-08-21-raft-paper-reading-notes/state.2024-08-21_23-26-51-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/2024-08-21-raft-paper-reading-notes/state.2024-08-21_23-26-51.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <div class="col-sm mt-0 mb-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2024-08-21-raft-paper-reading-notes/appendentries_rpc.2024-08-21_23-27-04-480.webp 480w,/assets/img/2024-08-21-raft-paper-reading-notes/appendentries_rpc.2024-08-21_23-27-04-800.webp 800w,/assets/img/2024-08-21-raft-paper-reading-notes/appendentries_rpc.2024-08-21_23-27-04-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/2024-08-21-raft-paper-reading-notes/appendentries_rpc.2024-08-21_23-27-04.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption mt-0"> Left: State, Right: AppendEntries RPC </div> <p>每个节点自身都维持了一个状态机（State）在内存，代表目前的数据情况，只有被确认提交的数据会进到这里，收到但还没确认的不会</p> <p>日志追加的方式，通过AppendEntriesRPC请求同步给其他的节点，在大多数的节点确认后，会进行提交， 这样能有效确保Leader切换后数据不会丢失（拥有的日志越多的节点约有可能成为下一任Leader）</p> <p>整体流程如下：</p> <ol> <li>收到写数据请求，操作附加到自己的日志中（此时还没提交生效）</li> <li>发送日志给其他节点（发AppendEntriesRPC请求），信息里面会包含一些诸如任期号、LeaderID，日志条目和下标等信息</li> <li>Follower节点收到后，检查自己的日志条目情况，如果匹配就追加最新的，不匹配的话拒绝（Leader给的前面的Log的任期不同之类的情况）</li> <li>Leader收到超过半数节点的成功响应后，确认已经传播到多数节点了，该日志条目被标记为提交（commited），应用条目到自己的状态机中（下一次AppendEntriesRPC就会告知Follower已经提交到这个位置，Follower也可以跟着提交到这个下标位置的Log）</li> <li>Leader响应客户端</li> </ol> <p>在此期间，Step 3.会有个分叉逻辑，就是Leader需要补发Follower缺失的Log， Log下标会往前推直到这个Follower最后的Log位置（此时会借助一些任期号来加快定位到需要补的日志的开头）</p> <h2 id="安全性">安全性</h2> <p><code class="language-plaintext highlighter-rouge">RAFT</code>通过任期号、多数投票选举、日志的一些机制保障了安全性，以下列举几个点：</p> <ul> <li>多数投票选举机制和任期号机制，防止出现脑裂（No Split-Brain）</li> <li>Leader包含所有已提交条目（Leader Completeness Property），统一负责读写，包括线性一致性读（Linearizable reads）</li> <li>只有Follower的日志可以被覆盖，Leader的日志只能不断追加，不可再覆盖旧的</li> <li>多数确认提交，确保多数确认的情况下才会提交</li> </ul> <h2 id="写在最后">写在最后</h2> <p>整体过了一下<code class="language-plaintext highlighter-rouge">RAFT</code>的一些设计理念，从paper里的一些表述中能很明确的感受到作者的意图和想法，尽可能阅读最一手的资料是追求有效信息的好方法， 也可以避免信息传播过程中产生的变形（不过也有利弊，有些人会有更加翔实的分析和剖析，就像这篇文章一样也是二手信息）</p> <p>值得一提的是，在paper里一句带过的Leader租约（Lease）机制，在实际应用中也是一个挺重要的点， 比如Consul和Etcd都实现这个机制，可以增加读的性能（风险取决于节点间的时钟差异程度和可接受的时钟漂移范围）</p>]]></content><author><name></name></author><category term="distributed-systems"/><category term="distributed-systems"/><summary type="html"><![CDATA[从Raft paper中感受其设计思想]]></summary></entry><entry><title type="html">zsh nice 5 🧐</title><link href="https://ifuryst.github.io/blog/2024/zsh-nice-5/" rel="alternate" type="text/html" title="zsh nice 5 🧐"/><published>2024-08-07T12:51:27+00:00</published><updated>2024-08-07T12:51:27+00:00</updated><id>https://ifuryst.github.io/blog/2024/zsh-nice-5</id><content type="html" xml:base="https://ifuryst.github.io/blog/2024/zsh-nice-5/"><![CDATA[<blockquote> <p>The English Version is <a href="https://medium.com/@ifuryst./zsh-nice-5-f520a70d0f90">here</a></p> </blockquote> <p>今天在排查一个服务吞吐量上不去的问题，在做压力测试，期间刚好在观测CPU使用率，系统是32c的。 除了关注进程的CPU消耗情况，我还会关注每个核心的使用率，确保不会出现核心利用率不均衡（之前在NUMA Node时因为大量网卡软中断出现过，所以现在习惯性会关注一下） ， 一开始一切都蛮正常的，类似这样：</p> <div class="row mt-3"> <div class="col-12 col-md-8 col-lg-6 col-xl-6 col-xxl-6 mt-0 mb-0 mx-auto"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2024-08-07-zsh-nice-5/normal_cpu_usage.2024-08-07_17-49-16-480.webp 480w,/assets/img/2024-08-07-zsh-nice-5/normal_cpu_usage.2024-08-07_17-49-16-800.webp 800w,/assets/img/2024-08-07-zsh-nice-5/normal_cpu_usage.2024-08-07_17-49-16-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/2024-08-07-zsh-nice-5/normal_cpu_usage.2024-08-07_17-49-16.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption mt-0"> Normal CPU Usage </div> <p>可以看到，进程使用了28c，约为87%的使用率。整体其实已经跑了挺满的，在单核上也可以观测到us都蛮高且相对均衡（77%~90%）</p> <blockquote> <h5 id="tip">TIP</h5> <p class="block-tip">top里是按照绝对值计算百分比的，因此不是传统的0-100%的认知，比如我32c，实际上最大是跑到3200%</p> </blockquote> <div class="row mt-3"> <div class="col-12 col-md-8 col-lg-6 col-xl-6 col-xxl-6 mt-0 mb-0 mx-auto"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2024-08-07-zsh-nice-5/abnormal_cpu_usage.2024-08-07_17-51-01-480.webp 480w,/assets/img/2024-08-07-zsh-nice-5/abnormal_cpu_usage.2024-08-07_17-51-01-800.webp 800w,/assets/img/2024-08-07-zsh-nice-5/abnormal_cpu_usage.2024-08-07_17-51-01-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/2024-08-07-zsh-nice-5/abnormal_cpu_usage.2024-08-07_17-51-01.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption mt-0"> Abnormal CPU Usage </div> <p>在经过几次调整测试的过程中，突然之间，我留意到单核的us都接近0了，但是进程级别的使用率看起来和之前保持相似的使用率，此时脑子过了好几个想法：</p> <ul> <li>是不是top的显示有问题？</li> <li>top发生某种奇怪的错误统计？</li> </ul> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2024-08-07-zsh-nice-5/grafana_total_cpu_usage.2024-08-07_17-59-21-480.webp 480w,/assets/img/2024-08-07-zsh-nice-5/grafana_total_cpu_usage.2024-08-07_17-59-21-800.webp 800w,/assets/img/2024-08-07-zsh-nice-5/grafana_total_cpu_usage.2024-08-07_17-59-21-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/2024-08-07-zsh-nice-5/grafana_total_cpu_usage.2024-08-07_17-59-21.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <div class="col-sm mt-0 mb-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2024-08-07-zsh-nice-5/grafana_core_cpu_usage.2024-08-07_17-59-48-480.webp 480w,/assets/img/2024-08-07-zsh-nice-5/grafana_core_cpu_usage.2024-08-07_17-59-48-800.webp 800w,/assets/img/2024-08-07-zsh-nice-5/grafana_core_cpu_usage.2024-08-07_17-59-48-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/2024-08-07-zsh-nice-5/grafana_core_cpu_usage.2024-08-07_17-59-48.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption mt-0"> Grafana CPU Usage: Total Left, Core Right </div> <p>然后我马上打开<code class="language-plaintext highlighter-rouge">Grafana</code>查看了机器层面的自监控，在<code class="language-plaintext highlighter-rouge">Grafana</code>上查看总体CPU使用率和分核使用率都是在高位，符合预期，略奇怪（此时仍然不知道自己粗心没留意到ni）</p> <p>结合前面的想法，我找了设备运维大佬，请教了问题，然后他一下指出ni很高，不太对，还指明正常我们的设备不会调整进程的nice。 这个时候我才恍然大悟，哦，确实ni列的值都很高呀，然后我开始从乡村土路开回了高速</p> <p>首先明确一下<a href="https://en.wikipedia.org/wiki/Nice_(Unix)">nice</a>的定义，nice越小优先级越高（范围从-20 ~ 19 or -20 ~ 20） 系统级别的正常-20，用户态进程是0，我看了一下我的进程是5🤔，what’s going on? 直到这里已经能解释清楚，为什么ni那么高了，因为进程的<code class="language-plaintext highlighter-rouge">nice=5</code>， 被认为是较低优先级的进程，同等条件下比0或者-20更加小的机会被CPU调度执行，但是因为我的进程在压测，进程过于强势，吃掉了80+%的CPU时间片， 此时就单核心的ni列代表就是CPU被低优先级的进程占用的百分比，其实这种情况下是符合预期的，也就是我们认为的单核使用率=us+ni，在这种场景下， 没有任何问题。</p> <p>回过头来，问题在于，为什么进程变成了<code class="language-plaintext highlighter-rouge">ni 5</code>？什么时候开始的？为什么？</p> <p>于是开始回溯，开始挖掘，因为压测过程中会调整各类参数，甚至也会调优一下代码，所以还是有比较多的变量，好在我能明确是那次变化出现的， 不过挖掘了半天没再出现，直到某刻突然灵光一闪，不会是<code class="language-plaintext highlighter-rouge">bg job</code>吧？因为要调整启动参数，有时候为了快速切换我会直接kill掉服务然后用类似<code class="language-plaintext highlighter-rouge">commd &amp;</code>的方式直接手动拉一下， 然后我试了一下，bingo，就是你了，然后我就写了一个shell进一步确认了一下</p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c">#!/bin/sh</span>

<span class="nb">sleep </span>333<span class="p">;</span>
</code></pre></div></div> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2024-08-07-zsh-nice-5/bg_job_in_zsh_bash.2024-08-07_18-05-18-480.webp 480w,/assets/img/2024-08-07-zsh-nice-5/bg_job_in_zsh_bash.2024-08-07_18-05-18-800.webp 800w,/assets/img/2024-08-07-zsh-nice-5/bg_job_in_zsh_bash.2024-08-07_18-05-18-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/2024-08-07-zsh-nice-5/bg_job_in_zsh_bash.2024-08-07_18-05-18.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption mt-0"> bg job in zsh &amp; bash </div> <p>确实是，通过这种方式启动的，会导致nice被打成5，然后我就开始在网上找资料，并且也问了ChatGPT，但是并没有任何相关的信息明确表示<code class="language-plaintext highlighter-rouge">bg job</code>会将nice设成<code class="language-plaintext highlighter-rouge">5</code>， 并且有些地方明确表示除非主动设置否则不会改变进程的nice值，此时我灵光一想，从zsh切到bash，测了一下，emmmm，确实不会改变nice，至少在bash下不会， 问题面进一步缩小了，问题出在zsh身上，继续查资料问AI，依然没有明确的结果，我还进一步检查了包括.zshrc在内相关的配置文件里也没有任何nice相关的设置，很疑惑</p> <p>过了一会我放弃在网上搜索结果了，我开始找<a href="https://zsh.sourceforge.io/Arc/git.html">zsh的源码</a>，当我把源码clone下来，我开始翻看源码， C写的，我有两个线索，一个是<code class="language-plaintext highlighter-rouge">nice=5</code>，一个是<code class="language-plaintext highlighter-rouge">bg job(&amp;)</code>，开始围绕这两个去针对性挖掘就好了，在这里我依然还是背靠大山，ChatGPT一下就帮我缩小范围到某几个文件上了，分别是</p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>	•	Src/parse.c：包含 zsh 的语法解析器代码。
	•	Src/exec.c：包含命令执行相关的代码。
	•	Src/jobs.c：处理作业控制和后台进程的代码。
</code></pre></div></div> <p>我在<code class="language-plaintext highlighter-rouge">jobs.c</code>找到了<code class="language-plaintext highlighter-rouge">spawnjob</code>这个函数，但是这个文件没有涉及nice的调整，继续翻看了<code class="language-plaintext highlighter-rouge">exec.c</code>，在<code class="language-plaintext highlighter-rouge">execcmd_fork</code>这个函数内部，看到了目标代码</p> <ul id="execcmd-fork" class="tab" data-tab="2b06a7c8-5aa1-4e8a-b8af-0057d845137f" data-name="execcmd-fork"> <li class="active" id="execcmd-fork-newest-version"> <a href="#">newest version </a> </li> <li id="execcmd-fork-oldest-version"> <a href="#">oldest version </a> </li> </ul> <ul class="tab-content" id="2b06a7c8-5aa1-4e8a-b8af-0057d845137f" data-name="execcmd-fork"> <li class="active"> <div class="language-c highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="cm">/**/</span>
<span class="k">static</span> <span class="kt">int</span>
<span class="nf">execcmd_fork</span><span class="p">(</span><span class="n">Estate</span> <span class="n">state</span><span class="p">,</span> <span class="kt">int</span> <span class="n">how</span><span class="p">,</span> <span class="kt">int</span> <span class="n">type</span><span class="p">,</span> <span class="n">Wordcode</span> <span class="n">varspc</span><span class="p">,</span>
	     <span class="n">LinkList</span> <span class="o">*</span><span class="n">filelistp</span><span class="p">,</span> <span class="kt">char</span> <span class="o">*</span><span class="n">text</span><span class="p">,</span> <span class="kt">int</span> <span class="n">oautocont</span><span class="p">,</span>
	     <span class="kt">int</span> <span class="n">close_if_forked</span><span class="p">)</span>
<span class="p">{</span>
<span class="c1">// ...</span>
<span class="cp">#ifdef HAVE_NICE
</span>    <span class="cm">/* Check if we should run background jobs at a lower priority. */</span>
    <span class="k">if</span> <span class="p">((</span><span class="n">how</span> <span class="o">&amp;</span> <span class="n">Z_ASYNC</span><span class="p">)</span> <span class="o">&amp;&amp;</span> <span class="n">isset</span><span class="p">(</span><span class="n">BGNICE</span><span class="p">))</span> <span class="p">{</span>
	<span class="n">errno</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span>
	<span class="k">if</span> <span class="p">(</span><span class="n">nice</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span> <span class="o">==</span> <span class="o">-</span><span class="mi">1</span> <span class="o">&amp;&amp;</span> <span class="n">errno</span><span class="p">)</span>
	    <span class="n">zwarn</span><span class="p">(</span><span class="s">"nice(5) failed: %e"</span><span class="p">,</span> <span class="n">errno</span><span class="p">);</span>
    <span class="p">}</span>
<span class="cp">#endif </span><span class="cm">/* HAVE_NICE */</span><span class="cp">
</span>
    <span class="k">return</span> <span class="mi">0</span><span class="p">;</span>
<span class="p">}</span>
</code></pre></div></div> </li> <li> <div class="language-c highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="cp">#ifdef HAVE_NICE
</span>	<span class="cm">/* Check if we should run background jobs at a lower priority. */</span>
	<span class="k">if</span> <span class="p">((</span><span class="n">how</span> <span class="o">&amp;</span> <span class="n">Z_ASYNC</span><span class="p">)</span> <span class="o">&amp;&amp;</span> <span class="n">isset</span><span class="p">(</span><span class="n">BGNICE</span><span class="p">))</span>
	    <span class="n">nice</span><span class="p">(</span><span class="mi">5</span><span class="p">);</span>
<span class="cp">#endif </span><span class="cm">/* HAVE_NICE */</span><span class="cp">
</span></code></pre></div></div> </li> </ul> <p>可以看到这个条件编译（即在支持nice的系统上才会调用）内部包含了判断：当是异步作业的时候，并且<code class="language-plaintext highlighter-rouge">BGNICE</code>设置的话，就会把<code class="language-plaintext highlighter-rouge">nice设置5</code>， 翻看了一下git历史，从<code class="language-plaintext highlighter-rouge">1999年4月16日</code>最初的版本就已经带上了这个核心逻辑了，只是后来针对<code class="language-plaintext highlighter-rouge">cmd fork</code>和相关的错误捕获做了几次修订</p> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2024-08-07-zsh-nice-5/git_history.2024-08-07_18-25-28-480.webp 480w,/assets/img/2024-08-07-zsh-nice-5/git_history.2024-08-07_18-25-28-800.webp 800w,/assets/img/2024-08-07-zsh-nice-5/git_history.2024-08-07_18-25-28-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/2024-08-07-zsh-nice-5/git_history.2024-08-07_18-25-28.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption mt-0"> Git History </div> <p>所以我们可以明确从最开始zsh就已经明确后台执行的任务优先级不会比前台的任务高，也就一直遗留至今了，至于历史原因，我是没找到任何相关的资料文献， 我看到最初<code class="language-plaintext highlighter-rouge">Inital reversion</code>是<code class="language-plaintext highlighter-rouge">Tanaka Akira</code>提交的，我写了一封邮件给他，希望能了解一下历史原因和背景。但是可惜的是，他的邮箱已经不再使用了， 被退信了。</p> <p>其实在此基础上其实还可以继续挖一下how, Z_ASYNC, BGNICE的来源，在哪些地方被更改设置了，甚至进一步再回顾一下CPU调度策略，尤其结合优先级来测一下， 但是最近有点忙，社区里还有几个PR需要处理。whatever, casual tech just for casual :)</p> <p>只是好奇心作祟下的一次探索 💀</p>]]></content><author><name></name></author><category term="casual-tech"/><category term="linux"/><summary type="html"><![CDATA[How the nice value disturb the observation for CPU usage]]></summary></entry><entry><title type="html">zsh nice 5 🧐. How the nice value disturb the… | by ifuryst | Aug, 2024 | Medium</title><link href="https://ifuryst.github.io/blog/2024/zsh-nice-5-how-the-nice-value-disturb-the-by-ifuryst-aug-2024-medium/" rel="alternate" type="text/html" title="zsh nice 5 🧐. How the nice value disturb the… | by ifuryst | Aug, 2024 | Medium"/><published>2024-08-07T00:00:00+00:00</published><updated>2024-08-07T00:00:00+00:00</updated><id>https://ifuryst.github.io/blog/2024/zsh-nice-5--how-the-nice-value-disturb-the--by-ifuryst--aug-2024--medium</id><content type="html" xml:base="https://ifuryst.github.io/blog/2024/zsh-nice-5-how-the-nice-value-disturb-the-by-ifuryst-aug-2024-medium/"><![CDATA[]]></content><author><name></name></author><category term="linux"/><category term="casual-tech"/><summary type="html"><![CDATA[Today, I was troubleshooting an issue with a service’s throughput during a stress test. While observing the CPU usage, I paid attention not only to the process’s CPU consumption but also to the usage…]]></summary></entry><entry><title type="html">TCP congestion control. Statement!!! | by ifuryst | Medium</title><link href="https://ifuryst.github.io/blog/2024/tcp-congestion-control-statement-by-ifuryst-medium/" rel="alternate" type="text/html" title="TCP congestion control. Statement!!! | by ifuryst | Medium"/><published>2024-03-12T00:00:00+00:00</published><updated>2024-03-12T00:00:00+00:00</updated><id>https://ifuryst.github.io/blog/2024/tcp-congestion-control-statement--by-ifuryst--medium</id><content type="html" xml:base="https://ifuryst.github.io/blog/2024/tcp-congestion-control-statement-by-ifuryst-medium/"><![CDATA[]]></content><author><name></name></author><category term="TCP"/><category term="networking"/><summary type="html"><![CDATA[I am sharing a draft article from a field I no longer focus on but believe the insights within are too valuable not to share. Please note, this manuscript is presented as-is :) All of these…]]></summary></entry></feed>
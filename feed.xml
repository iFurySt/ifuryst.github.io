<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.3.3">Jekyll</generator><link href="https://ifuryst.github.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://ifuryst.github.io/" rel="alternate" type="text/html" hreflang="en"/><updated>2025-07-07T07:01:21+00:00</updated><id>https://ifuryst.github.io/feed.xml</id><title type="html">ifuryst</title><subtitle>📝 &amp; 💭 </subtitle><entry><title type="html">一文看懂上下文工程（Context Engineering）</title><link href="https://ifuryst.github.io/blog/2025/context-engineering-101-what-it-is-and-why-it-matt/" rel="alternate" type="text/html" title="一文看懂上下文工程（Context Engineering）"/><published>2025-07-07T00:00:00+00:00</published><updated>2025-07-07T00:00:00+00:00</updated><id>https://ifuryst.github.io/blog/2025/context-engineering-101-what-it-is-and-why-it-matt</id><content type="html" xml:base="https://ifuryst.github.io/blog/2025/context-engineering-101-what-it-is-and-why-it-matt/"><![CDATA[<p>为什么最近大家都在聊Context Engineering？</p> <p>这个词似乎突然爆火，但这个概念并不是新的概念，而是从大语言模型诞生并进入应用层之后一直存在。只不过随着AI能力的发展和实际应用需求的提升，它终于被重新放上了聚光灯下，<a href="https://x.com/karpathy/status/1937902205765607626">Andrej Karpathy</a>6月25日的推文助推下，更多人关注了</p> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-07-07-context-engineering-101-what-it-is-and-why-it-matt/1751866810_1-480.webp 480w,/assets/img/2025-07-07-context-engineering-101-what-it-is-and-why-it-matt/1751866810_1-800.webp 800w,/assets/img/2025-07-07-context-engineering-101-what-it-is-and-why-it-matt/1751866810_1-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/2025-07-07-context-engineering-101-what-it-is-and-why-it-matt/1751866810_1.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> </div> </div> <p>本文将带你从提示词工程一路走到上下文工程，梳理清楚它们的关系，并了解为什么上下文工程这么重要</p> <h2 id="tldr">TL;DR</h2> <p>对于不想看全文的，可以直接看摘要：</p> <p>本质来说上下文工程（Context Engineering）和提示词工程（Prompt Engineering）是一个东西，前者是一个更加fancy的叫法，也从狭义的提示词扩大到上下文的维度，涵盖更加广的上下文工程实践</p> <p>用Agent的例子来说明，就是Agent每次执行的时候都需要有合适的上下文（太多太少不够准确的都不行），这些上下文可以是预设的（比如预先写好的系统提示词），也可以是运行时获取的（通过工具调用外部获取），配合一些诸如RAG、Memory、读写、Compact/Compression等手段可以更好的管理上下文，因此上下文工程就是如何将合适的信息填充到有限的上下文里的艺术和科学</p> <h2 id="prompt-vs-context">Prompt vs Context</h2> <p>在与大语言模型（LLM）打交道的过程中，我们其实一直在围绕两类输入工程打转：提示词工程（Prompt Engineering）和上下文工程（Context Engineering）</p> <p><strong>前者更像是在告诉模型它是谁，而后者是喂给模型它需要知道的相关信息</strong></p> <p>其实非常好理解，在基于LLM的应用运行期间，需要一些预设背景信息，且拥有合适的上下文信息，尤其是现在以Agent为主的应用，多轮次交互中每一轮次都需要不同的、合适的且准确的上下文信息，才可以最大化Agent的效果</p> <h2 id="提示词工程prompt-engineering">提示词工程Prompt Engineering</h2> <p>最早底层模型能力还没有被大幅提升的时候，大家都在利用提示词挖掘底层模型的能力，我还记得当时Sam Altman还说过写提示词这个东西有些人很有天份，一下就知道怎么写</p> <p>早期大家都是管理一堆的提示词，用于不同的使用场景，这也衍生出了一些诸如：GPTs，Character.AI、星野等这一些“Cosplay”的AI应用，这类应用本质上就是允许用户去编写提示词来驱动模型以某种形式去回复用户的问题</p> <p>通过提示词控制也是相对符合直觉的一个行为，提示词工程里还有一些更加高阶一点的手段，比如：</p> <ul> <li>少样本提示（Few-shot Prompt）：给出几个类似的示例，引导模型模仿</li> <li>零样本提示（Zero-shot Prompt）：不给任何示例，让模型自主决定输出</li> <li>思维链提示（Chain-of-Thought Prompt）：引导模型一步步说出来的自我思考过程，重点是提示格式而不是答案示例</li> </ul> <p>少样本提示（Few-shot Prompt）:</p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>文本：我太喜欢这部电影了！
情感：正面

文本：这道菜太难吃了。
情感：负面

文本：还行吧，我觉得。
情感：
</code></pre></div></div> <p>零样本提示（Zero-shot Prompt:</p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>文本：还行吧，我觉得。
情感：
</code></pre></div></div> <p>思维链提示（Chain-of-Thought Prompt）：</p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>文本：还行吧，我觉得。
情感分析：我们来分析一下这句话。<span class="s2">"还行吧"</span> 表示中等、不好不坏，<span class="s2">"我觉得"</span> 表示语气不确定或者没有强烈的情绪。整体来看，这句话情绪不强烈，偏向中性。
情感：中性
</code></pre></div></div> <p>因此本质上提示词工程就是在告诉模型开始处理任务之前的一些预设，可以很有效的帮助模型做一个锚定，在此之后就让模型在这个范围内和方向上自我发挥</p> <p>在这个阶段模型没有任何外部知识，也没有记忆等，全部依赖于提示词本身</p> <h2 id="上下文工程-context-engineering">上下文工程 Context Engineering</h2> <p>上下文窗口一直是模型能力的重要衡量指标之一，原因就是<strong>上下文对于模型应用效果非常关键</strong></p> <p>前面提到最早通过较为直觉的方式来写提示词，随着底层模型的发展和模型应用的普及，对于效果的追求也越来越高，从最早的泛娱乐式消费，到生产力提升的需求，上下文是<strong>相对于模型微调来说更加低成本且可操作性更高</strong>的方式来提升整体的效果</p> <p>在上下文工程领域延伸出很多手段：</p> <ul> <li>RAG（Retrieval-Augmented Generation，检索增强生成）：通过语义化响亮搜索，从知识库中检索与用户问题最相关的文档片段，并拼接到上下文，提升回答准确性</li> <li>Memory（记忆）：引入长短期记忆，帮助模型回顾过往记录</li> <li>Tool Calling/MCP（工具调用）：通过结构化提示词告诉模型如何调用预定工具（如数据库查询、API调用等）来获取外部信息，是一种与世界连接的输入增强方式</li> </ul> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-07-07-context-engineering-101-what-it-is-and-why-it-matt/1751866811_2-480.webp 480w,/assets/img/2025-07-07-context-engineering-101-what-it-is-and-why-it-matt/1751866811_2-800.webp 800w,/assets/img/2025-07-07-context-engineering-101-what-it-is-and-why-it-matt/1751866811_2-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/2025-07-07-context-engineering-101-what-it-is-and-why-it-matt/1751866811_2.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> </div> </div> <p>我们是可以参考<a href="https://rlancemartin.github.io/2025/06/23/context_engineering/"><strong>Context Engineering for Agents</strong></a>里所做的分类（主要针对Agent语境下的分类）：</p> <ul> <li>写上下文（Write Context）：上下文窗口限制，需要把过往的上下文存到外部，必要时召回</li> <li>选择上下文（Select Context）：从已经保存的数据中选择合适的部分注入到上下文窗口中，帮助LLMs更好完成任务</li> <li>压缩上下文（Compressing Context）：上下文超出的情况下，对上下文进行合理的压缩保留必要的最小内容</li> <li>隔离上下文（Isolating Context）：拆分并分配不同的上下文给不同的子智能体或子任务，提高效率和清晰度</li> </ul> <p>目前大家都在上下文工程领域持续深耕。简单说，就是<strong>底层模型的性能提升是取决于几家头部模型厂商的，在有限的情况之下，应用层都是在拼上下文处理能力以及和用户交互的UI/UX</strong></p> <p>因此我们其实可以留意到目前AI应用都是围绕这两点展开的，如何帮助模型更好的获取上下文去完成用户的需求+如何用更好的交互方式让用户与模型交互。反观UI/UX已经是一个体系化的学科之后，对于一个AI应用能否足够好用，就取决于上下文工程的能力。这样想我们就能知道为什么上下文工程如此重要且受关注面这么广</p> <p>我们可以看到早期的RAG就是一种相对固定的外部信息获取，一般我们在RAG里做召回会用topk，也就是最匹配的k份材料（chunk）给到模型，本质上就是因为上下文是有限的，如何获取最合适的材料，就是RAG里需要不断去摸索的方向。</p> <p>记忆模块也是一部分，现在也有很多人在这块投入研究，我觉得是一个非常值得投入研究的领域，记忆可分为长时记忆和短期记忆，通过ChatGPT这个APP我们也可以看得到一些实践，现在它可以召回以前的对话（本质上也是向量搜索这类方式），这样就是通过对话来实现记忆recall的一个过程，同时它也会在日常对话中去记录一些关键点到记忆条目里，这样就能建立一个长期记忆（最早记忆是会满的，我觉得没理由让用户去手动删除和管理记忆，现在就没有这个问题了）。</p> <p>前段时间疯狂流行的MCP，也就是和以前的Function Tool，或者Tool Calling一样，就是让模型能调用一些预设的工具，去获取对应的信息来做决策，也是上下文工程的一种，这个方向是对于现有服务和基础设施，甚至是物理世界交互的一个标准接口，所以意义深远</p> <p>总体而言，上下文工程涵盖的就是很简单的东西，给到模型的上下文内容，但是期间涉及的手段有很多值得研究和发展的领域和方向。这个也为未来AGI方向提供了一个必要的基础</p> <h2 id="界限并没有那么清晰">界限并没有那么清晰</h2> <p>通常系统提示词不太会变，这个是有别于上下文的，否则严格意义上来说，提示词也是上下文的一部分，所有模型能看到的内容都统称为上下文。因此实际上现在讨论Context Engineering并不是一个全新的概念呢，而是自大语言模型诞生之初就一直存在的，只不过现在规范化、专业化和学科化</p> <p>现在越来越多人认识到，随着底层模型能力的提升，prompt的需求程度在降低，现在演变出一个更加fancy的叫法，就是上下文工程Context Engineering，从更加广义的角度来定义，上下文工程自此进入人们的视野，也使得越来越多人关注</p> <p>因此可以认为这两个工程都是在同样的目的：<strong>目标很明确，就是通过合理的处理组装上下文，让模型效果最大化</strong></p> <p>举例来说，我们来看看Claude Code的系统提示词（System Prompt）:</p> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-07-07-context-engineering-101-what-it-is-and-why-it-matt/1751866812_3-480.webp 480w,/assets/img/2025-07-07-context-engineering-101-what-it-is-and-why-it-matt/1751866812_3-800.webp 800w,/assets/img/2025-07-07-context-engineering-101-what-it-is-and-why-it-matt/1751866812_3-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/2025-07-07-context-engineering-101-what-it-is-and-why-it-matt/1751866812_3.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> </div> </div> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-07-07-context-engineering-101-what-it-is-and-why-it-matt/1751866812_4-480.webp 480w,/assets/img/2025-07-07-context-engineering-101-what-it-is-and-why-it-matt/1751866812_4-800.webp 800w,/assets/img/2025-07-07-context-engineering-101-what-it-is-and-why-it-matt/1751866812_4-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/2025-07-07-context-engineering-101-what-it-is-and-why-it-matt/1751866812_4.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> </div> </div> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-07-07-context-engineering-101-what-it-is-and-why-it-matt/1751866813_5-480.webp 480w,/assets/img/2025-07-07-context-engineering-101-what-it-is-and-why-it-matt/1751866813_5-800.webp 800w,/assets/img/2025-07-07-context-engineering-101-what-it-is-and-why-it-matt/1751866813_5-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/2025-07-07-context-engineering-101-what-it-is-and-why-it-matt/1751866813_5.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> </div> </div> <p>从Claude Code的System Prompt中可以看出，我们可以看到它融合了<strong>角色设定、少样本提示、工具调用</strong>等手段，同时通过 Tool 使用能力动态扩展上下文，比如支持查看文件、编辑代码、提交 Git、拉取图片等。<strong>这种设计结合了提示词工程与上下文工程，是一种典型的 Prompt + Context 混合型应用，本质上构建出了一个具备自主决策能力的 Agent</strong></p> <h2 id="新学科的出现">新学科的出现</h2> <p>这边有一段在<a href="https://rlancemartin.github.io/2025/06/23/context_engineering/">Context Engineering for Agents</a>这篇文章中的一段话，我觉得描述得很好：</p> <blockquote> <p>As Andrej Karpathy puts it, LLMs are like a <a href="https://www.youtube.com/watch?si=-aKY-x57ILAmWTdw&amp;t=620&amp;v=LCEmiRjPEtQ&amp;feature=youtu.be">new kind of operating system</a>. The LLM is like the CPU and its <a href="https://docs.anthropic.com/en/docs/build-with-claude/context-windows">context window</a> is like the RAM, serving as the model’s working memory. Just like RAM, the LLM context window has limited <a href="https://lilianweng.github.io/posts/2023-06-23-agent/">capacity</a> to handle various sources of context. And just as an operating system curates what fits into a CPU’s RAM, “context engineering” plays a similar role. <a href="https://x.com/karpathy/status/1937902205765607626">Karpathy summarizes this well</a>: [Context engineering is the] ”…delicate art and science of filling the context window with just the right information for the next step.”</p> </blockquote> <p>把LLMs类比成新的操作系统（OS），而上下文窗口（Context Window）则是LLMs的内存，内存是有限的，因此需要用一些辅助手段在磁盘、网络间去置换合适的数据到内存里，上下文窗口也是同理，在运行时需要合适的数据加载到上下文窗口内，才可以让LLMs发挥最大效果</p> <p>随着LLM的流行和应用，未来的会涌现更多不同的学科， 我觉得上下文工程就是其中一个方向，是一个为LLM设计和管理输入上下文的一门新兴技术学科，可以预见，在未来的一段时间内，随着AI工程化的复杂程度提升，LLM与外界交互变多的情况下，上下文工程是一个极其重要的研究方向，可以进一步决定LLM能发挥出多大的潜力和能力</p> <p>从应用到具身智能，都离不开模型对于外界信息的获取和感知，外界信息是无穷多的，如何在有限的上下文内把最有价值的信息提供给模型，决定了这个学科研究的方向</p> <p>在未来，<strong>Context Engineer</strong>也许会成为AI团队中的关键角色之一，就像数据工程师之于机器学习团队那样重要</p> <p>如果说Prompt是语言的编程，那么<strong>Context Engineering就是系统级调度与资源管理，决定了模型能否发挥巨大的潜力</strong></p> <h2 id="上下文工程是ai工程化时代的关键基建">上下文工程，是AI工程化时代的关键基建</h2> <p>随着大语言模型底层能力的不断突破，我们对如何更好地用好模型的关注也正从提示词的微调，逐渐转向对<strong>上下文的理解、管理与动态构建</strong></p> <p>Prompt Engineering是起点，Context Engineering则是让它走得更远的路。我们可以预设提示词来激发模型潜力，但能否持续发挥作用，最终还要看上下文工程能否构建出<strong>精准、动态、可扩展</strong>的输入</p> <p>在未来，无论是智能体（Agent）的构建，复杂任务的编排，还是具身智能（Embodied AI）的落地，<strong>Context Engineering都会是连接模型与现实世界的桥梁</strong>。<strong>它不仅是工程问题，更是产品问题、交互问题、认知问题</strong></p> <p>也许未来我们会看到一个新角色的诞生：<strong>上下文设计师（Context Architect）</strong>，就像数据工程师之于机器学习，它将成为AI团队中不可或缺的一环。</p> <p>这场革命，已经从写好一句提示词进入到了设计一个完整的上下文生态，也就是大行其道的Agent在做的事情和方向</p>]]></content><author><name></name></author><category term="AI"/><category term="AI"/><summary type="html"><![CDATA[为什么最近大家都在聊Context Engineering？]]></summary></entry><entry><title type="html">这个词正在AI创业圈爆发力量：Momentum</title><link href="https://ifuryst.github.io/blog/2025/momentum-for-startups/" rel="alternate" type="text/html" title="这个词正在AI创业圈爆发力量：Momentum"/><published>2025-07-04T00:00:00+00:00</published><updated>2025-07-04T00:00:00+00:00</updated><id>https://ifuryst.github.io/blog/2025/momentum-for-startups</id><content type="html" xml:base="https://ifuryst.github.io/blog/2025/momentum-for-startups/"><![CDATA[<p>这个词我第一次看到并了解其意思的时候，我就非常喜欢，之前我也在其他的文章中表达过，现在这个词来到了今年AI创业投资领域里的一个很重要的地位</p> <h2 id="-一vc的钱花不出去创业者的好机会">💸 一、VC的钱花不出去，创业者的好机会</h2> <p>刚刚进入下半年， 回顾2025年上半年的AI创业生态，我们确实看到了不少应用层的新产品。但它们似乎还没达到我们期待的那种“百花齐放”的程度。</p> <p>有趣的是，我已经不止一次听到别人提起：<strong>现在投资人有钱，却找不到好项目投资</strong>，这个确实是真实发生的</p> <p>现在顶级VC已经拉到太多的钱了，而AI相关的创业项目又不足以消化掉如此多的资金，这些VC也在疯狂的找投资标的。我们今年以来可以看到一个现象就是，资金越来越多流入到一些超级项目（如stargate和AI机房基础设施)</p> <p>这些都是非常巨大的投资，这里面何时有回报，退出机制等都是比较难确定的。但是还是持续有钱涌入AI领域。</p> <p>另外我们也可以看到资金大量流入有“流量”的startup和产品里，这个正是我们打算探讨的方向。现在<strong>VC越来越看重一个项目的Momentum——即公司、产品甚至创始人所具备的上升势头，这对于他们未来退出变现是一个关键信号。</strong></p> <h2 id="-二为什么越来越多ai公司不愿意ipo了">🚫 二、为什么越来越多AI公司不愿意IPO了？</h2> <p>过去，创业成功的终极目标往往是IPO上市。但现在越来越多的AI初创企业并不急于走向公开市场</p> <p>这是因为：</p> <ul> <li><strong>私有市场的钱已经足够多</strong>，可以支持公司发展的多个阶段</li> <li>一旦IPO，会面临复杂的监管和信息披露要求</li> <li>AI作为一个快速演进、监管滞后的领域，本身就存在很多法律与合规的不确定性</li> </ul> <p>这些因素使得AI公司更愿意保持灵活性，在私有领域稳步推进，而不是过早暴露在IPO后的聚光灯和监管压力之下</p> <h2 id="-三技术产品成功动量才是关键">🔊 三、技术≠产品成功，动量才是关键</h2> <p>在AI极大提升生产力之后，我们看到越来越多一人团队（Solopreneur）的爆发和产品的快速诞生</p> <p>但你会发现，很多“跑出来”的项目，<strong>未必是技术最好，也未必是整合最全面的</strong>，它们往往胜在一个词：<strong>声量（Momentum）</strong></p> <p>这听上去像是“营销”，但它其实是让产品产生实际用户反馈和市场涌动的必要步骤。就像我们谈Product-Market Fit（PMF），你得让市场“看到”你的产品，才能知道是不是对的产品</p> <h2 id="️-四solopreneur的可行路径从输入到输出">🛠️ 四、Solopreneur的可行路径：从输入到输出</h2> <p>对于现在的Solopreneur或者AI创业者，我分析解构后，有个相对清晰可实践的路径：</p> <ol> <li><strong>输入</strong>：多摄入前沿资讯和产品信息，持续体验新产品</li> <li><strong>输出</strong>：不只是做产品，也可以写下自己的经历和想法</li> <li><strong>积累声量</strong>：在某个圈子里建立一点知名度，让人们认识你</li> <li><strong>交流反哺</strong>：与人交换观点，不断修正自己的思想和产品定位</li> <li><strong>找到自己的“Own Business”</strong>：把这个过程变成有利可图的盈利项目</li> </ol> <p>这条路径并不神秘，只是如何<strong>“长期保持势能”</strong>这一点。</p> <h2 id="-五momentum的门槛与技巧">🧠 五、Momentum的门槛与技巧</h2> <p>保持Momentum这件事，其实对每个人的难度是不一样的：</p> <ul> <li>有些人善于表达</li> <li>有些人擅长写作</li> <li>有些人懂得如何做出很棒的产品</li> </ul> <p>但问题是，<strong>没有早期正向反馈的时候，很多人会陷入苦苦挣扎的状态</strong></p> <p>我有一个比较实用技巧：<strong>Go in Public！</strong></p> <p>哪怕只是发发开发日志，晒一下产品截图，也可能收获点赞和评论。这些反馈其实就是我们人类所依赖的“生化激励”，别忽视它的力量</p> <p>我们不是非得靠“苦行僧模式”才能成功。<strong>创造 + 分享 + 享受反馈</strong>👍❤️，可以一路直达目的地</p> <p>虽然我自己也是一个Workaholic，但是我其实一直是在做自己喜欢的事情。我不太喜欢长期苦行僧的艰苦岁月，吃苦和坚持不等于成功，轻松愉快的创造和分享也能让你到达心中的远方</p> <h2 id="-六solopreneur--孤军奋战而是找到适合你的平衡">🤝 六、Solopreneur ≠ 孤军奋战，而是找到适合你的平衡</h2> <p>Solopreneur，并不是要你一个人永远闷头搞产品，而是探索<strong>自由创造和外部连结之间的平衡点</strong></p> <p>有人选择自由职业的自由，有人喜欢稳定工作的稳定；有人愿意一个人拼命冲刺，有人喜欢开源协作。这些都可以是Solopreneur的一种表现方式</p> <p>关键在于<strong>找到适合你性格、节奏和价值观的方式，然后持续创造</strong></p> <p>在这个充满熵增的时代，如果你能找到自己的动态平衡点，那么你已经在前行的路上，走过了至关重要的一步</p>]]></content><author><name></name></author><category term="AI"/><category term="AI"/><category term="Tech"/><category term="Insights"/><summary type="html"><![CDATA[这个词我第一次看到并了解其意思的时候，我就非常喜欢，之前我也在其他的文章中表达过，现在这个词来到了今年AI创业投资领域里的一个很重要的地位]]></summary></entry><entry><title type="html">Claude Code实测报告: 当我不再Debug</title><link href="https://ifuryst.github.io/blog/2025/claude-code-experience/" rel="alternate" type="text/html" title="Claude Code实测报告: 当我不再Debug"/><published>2025-07-03T12:30:00+00:00</published><updated>2025-07-03T12:30:00+00:00</updated><id>https://ifuryst.github.io/blog/2025/claude-code-experience</id><content type="html" xml:base="https://ifuryst.github.io/blog/2025/claude-code-experience/"><![CDATA[<p>深度体验了一段时间Claude Code（以下称呼为CC），是时候稍微聊一下</p> <h2 id="cc拔得头筹">🚀 CC拔得头筹</h2> <p>目前得到的反馈和评价基本一致，CC远超Cursor，不管在Cursor中选择什么Model，都无法扳回，唯一能说的就是Cursor在产品化能力上是更胜一筹的，至少就目前的迭代速度和产品交互上来说，Cursor的体验更加优</p> <p>但是终究耐不住效果的差异，就是那句简单的话：<strong>在强大的实力面前，一切锦上添花的东西都显得不重要了</strong></p> <p>言语万千，不如置身一试。下面就简单过一下CC使用方式</p> <h2 id="️使用技巧">⚒️ 使用技巧</h2> <p>通过npm全局安装</p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>npm i <span class="nt">-g</span> @anthropic-ai/claude-code
</code></pre></div></div> <h3 id="默认允许---dangerously-skip-permissions">默认允许 <code class="language-plaintext highlighter-rouge">--dangerously-skip-permissions</code></h3> <p>我通常都是</p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>claude <span class="nt">--dangerously-skip-permissions</span>
</code></pre></div></div> <p>这样启动的，就是允许其执行任何的命令，当然你应该根据你的实际情况来决定，我是MacOS，本身不是root，我的rm也是删到回收站，我认为我的需求都在我的控制范围内</p> <h3 id="恢复会话---continue">恢复会话 <code class="language-plaintext highlighter-rouge">--continue</code></h3> <p>如果你在一个session里不小心退掉了，可以通过这个命令回到之前的任务，会保留当时的相关的context，很适合用于继续之前的工作，或者之前的上下文对于后续的任务比较重要的话，可以持续使用</p> <h3 id="单次任务执行--p">单次任务执行 <code class="language-plaintext highlighter-rouge">-p</code></h3> <p>可以单次执行某个任务来利用claude去处理，可以是基于repo来做一些动作，比如：</p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>claude <span class="nt">-p</span> <span class="s2">"看看哪里用到users.gender"</span>
git commit <span class="nt">-m</span> <span class="s2">"</span><span class="si">$(</span>claude <span class="nt">-p</span> <span class="s2">"查看暂存的 git 更改并创建一个总结性的 git commit 标题。只回复标题，不要确认。"</span><span class="si">)</span><span class="s2">"</span>
</code></pre></div></div> <p>可以分析代码，可以生成git commit，也能不依托repo直接使用的</p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>claude <span class="nt">-p</span> <span class="s2">"glucose 中文意思"</span>
</code></pre></div></div> <p>我觉得这点比ChatGPT的订阅好，平时可以在某些地方直接集成使用，很方便</p> <h3 id="登录-login">登录 <code class="language-plaintext highlighter-rouge">/login</code></h3> <p>有时候凭证过期了，可以通过这个方式再去浏览器授权后refresh token，持续使用</p> <h3 id="上下文压缩-compact">上下文压缩 <code class="language-plaintext highlighter-rouge">/compact</code></h3> <p>通常我们很容易遇到上下文超过的情况，CC会在右下角提醒，出现百分比的时候就是快到上下限制，到0%就会自动去compact上下文，会丢失掉一些内容，但是依然保持了一些相关的上下文</p> <p>有时候我会主动去compact，我个人的观点是，在连续或者相关联的任务场景下，compact后的上下文，依然比没有上下文来得更好，更加有助于实现</p> <p>不过依然可能存在关键信息compact后丢失，根据情况自我取舍</p> <h3 id="清空会话-clear">清空会话 <code class="language-plaintext highlighter-rouge">/clear</code></h3> <p>和直接Ctrl+C后再重开一个全新的会话是相同的，只不过可以快速清理，适合准备开启一个全新无依赖的任务，可以有效降低token消耗和无关上下文的干扰</p> <h3 id="多repo结合">多Repo结合</h3> <p>除了上面之外，还有一个比较重要的技巧，就是善用多repo结合，有些人会使用git worktree来把多个项目集中到同一个目录，这样方便claude可以同时在多个项目里工作，某些场景下很适合，比如前后端分离仓库的时候。</p> <p>不过我自己的实践是喜欢使用软链，比如：</p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">cd</span> /path/to/project1
<span class="nb">mkdir</span> <span class="nt">-p</span> temp
<span class="nb">ln</span> <span class="nt">-s</span> /path/to/project2 temp
</code></pre></div></div> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-07-03-claude-code-experience/1-480.webp 480w,/assets/img/2025-07-03-claude-code-experience/1-800.webp 800w,/assets/img/2025-07-03-claude-code-experience/1-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/2025-07-03-claude-code-experience/1.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <p>好处是，我自己有一个projects的管理机制，并且有可能是不相关的项目，各自有自己的工作目录，最好的方式就是通过这样共享一份代码，我还会在temp里放大量给CC参考的东西，比如我在做页面开发的时候，我希望样式能参考某些站点的时候，我就会放置对应的html之类的文件</p> <p>我觉得还挺重要的，包括有时候可以丢一些日志或者辅助文件，CC自己读取，会比自己贴到问题里好一些，哪怕很长的上下文也不会有问题</p> <h2 id="关于limit--token"><strong>📉</strong> 关于Limit &amp; Token</h2> <p>我订阅的是Pro，基本每天都会遇到3次limit，比如中午12点，下午6点，晚上12点这种</p> <p>关于CC的Token计算，始终不知道限制的Token数量是多少，网上流行的<a href="https://github.com/Maciek-roboblog/Claude-Code-Usage-Monitor">Claude-Code-Usage-Monitor</a> 是从<code class="language-plaintext highlighter-rouge">~/.claude/projects</code>里去统计对应的josnl文件里的，相当不准确，就我个人抓包分析和观测来看，这里面没有包含完整的token消耗情况</p> <p>改了一下cli.js里的，在这个session里输出了一下cost，大概如图所示</p> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-07-03-claude-code-experience/2-480.webp 480w,/assets/img/2025-07-03-claude-code-experience/2-800.webp 800w,/assets/img/2025-07-03-claude-code-experience/2-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/2025-07-03-claude-code-experience/2.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <p>可以看到一开始问题走了sonnet，所以input不大，output特别大，后来降到haiku。</p> <p>另外其中包含大量的命中缓存，这些都是LLM厂商在推理过程中做的一些优化，有KV之类的缓存减少推理成本提高速度</p> <h2 id="system-prompt"><strong>📄</strong> System Prompt</h2> <p>我们其实也可以自己指定System Prompt，我在抓包的时候也看到，一个简单的问题背后，产生了3次请求：</p> <ol> <li>先请求quota</li> <li>对本次任务生成一个标题</li> <li>开始实际的问答completion</li> </ol> <div class="row mt-3"> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-07-03-claude-code-experience/3-480.webp 480w,/assets/img/2025-07-03-claude-code-experience/3-800.webp 800w,/assets/img/2025-07-03-claude-code-experience/3-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/2025-07-03-claude-code-experience/3.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <div class="col-sm mt-0 mb-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-07-03-claude-code-experience/4-480.webp 480w,/assets/img/2025-07-03-claude-code-experience/4-800.webp 800w,/assets/img/2025-07-03-claude-code-experience/4-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/2025-07-03-claude-code-experience/4.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-07-03-claude-code-experience/6-480.webp 480w,/assets/img/2025-07-03-claude-code-experience/6-800.webp 800w,/assets/img/2025-07-03-claude-code-experience/6-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/2025-07-03-claude-code-experience/6.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <div class="col-sm mt-0 mb-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-07-03-claude-code-experience/7-480.webp 480w,/assets/img/2025-07-03-claude-code-experience/7-800.webp 800w,/assets/img/2025-07-03-claude-code-experience/7-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/2025-07-03-claude-code-experience/7.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> </div> <p>这期间还会配套一些监控统计的采集。我觉得要做到监控准确，可以开发一个服务做代理，代理CC的请求，期间通过里面的数据去做统计是最准确的</p> <h2 id="实际项目">💼 实际项目</h2> <h3 id="信息hub-tididi">信息Hub: Tididi</h3> <p>https://tididi.amoylab.com/</p> <p>这个项目会演变成一个信息Hub的平台，目前主要还是服务于自己和身边几个比较好的朋友，我希望能提高自己对有效有价值信息的高效摄入，不借助LLMs去做信息聚合是不太可能的。目前期望借助LLMs从一些确定价值的信息渠道去聚合，可以有效排除网上的一些噪声。有兴趣的朋友可以试试，目前免费使用，有想找我交流的可以公众号留言</p> <p>目前是一个闭源的项目，未来有可能会开源一个个人版，这个项目全部是用CC写的，我介入的情况不多，只有一点点，接近100%代码是CC写的</p> <div class="row mt-3"> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-07-03-claude-code-experience/10-480.webp 480w,/assets/img/2025-07-03-claude-code-experience/10-800.webp 800w,/assets/img/2025-07-03-claude-code-experience/10-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/2025-07-03-claude-code-experience/10.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-07-03-claude-code-experience/11-480.webp 480w,/assets/img/2025-07-03-claude-code-experience/11-800.webp 800w,/assets/img/2025-07-03-claude-code-experience/11-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/2025-07-03-claude-code-experience/11.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-07-03-claude-code-experience/12-480.webp 480w,/assets/img/2025-07-03-claude-code-experience/12-800.webp 800w,/assets/img/2025-07-03-claude-code-experience/12-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/2025-07-03-claude-code-experience/12.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> </div> <h3 id="内容集中分发-ripple">内容集中分发: Ripple</h3> <p>https://github.com/iFurySt/Ripple</p> <p>我不想要再浪费大量时间在不同的平台和分发渠道去重复性的编辑自己写的文章，但是依然希望能保持一定的风格和格式去分发，所以有了这个内容分发的项目。</p> <p>这个项目我相信我可以长期保持95%以上的代码交给AI来写，目前主要还是CC在驱动</p> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-07-03-claude-code-experience/13-480.webp 480w,/assets/img/2025-07-03-claude-code-experience/13-800.webp 800w,/assets/img/2025-07-03-claude-code-experience/13-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/2025-07-03-claude-code-experience/13.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <h3 id="mcp网关服务-unla">MCP网关服务: Unla</h3> <p>https://github.com/AmoyLab/Unla</p> <p>通过配置就可以将一些诸如HTTP的存量服务直接转成MCP Server，类似MCP时代的Nginx，也可以平行代理MCP Servers。企业级性能和特性。在开源社区这已经是一个很流行的项目了，目前已经有1.4K的Stars✨了，包括字节在内的多家企业和大量的个人用户都采用了Unla</p> <p>不过这个项目最开始是用Cursor启动的，前些日子才开始用CC，但是依然是一个大量代码由AI产生的一个项目</p> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-07-03-claude-code-experience/14-480.webp 480w,/assets/img/2025-07-03-claude-code-experience/14-800.webp 800w,/assets/img/2025-07-03-claude-code-experience/14-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/2025-07-03-claude-code-experience/14.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <h2 id="背后的意义">🤔 背后的意义</h2> <p>使用CC我觉得有点动手能力的在AI Era基本自己都能捣鼓会了，我其实更想聊的是延伸产生的一些思考</p> <div class="row mt-3"> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-07-03-claude-code-experience/8-480.webp 480w,/assets/img/2025-07-03-claude-code-experience/8-800.webp 800w,/assets/img/2025-07-03-claude-code-experience/8-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/2025-07-03-claude-code-experience/8.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-07-03-claude-code-experience/9-480.webp 480w,/assets/img/2025-07-03-claude-code-experience/9-800.webp 800w,/assets/img/2025-07-03-claude-code-experience/9-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/2025-07-03-claude-code-experience/9.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> </div> <p>最近连续的几个项目，我看代码的实际越来越少，自己动手的机会更是越来越少，有些新项目直接是“0参与”</p> <p>我提出需求，设计结构，选好主要三方库，验收需求。除此之外，代码细节我是一点不知道，或许可以说为“0参与”</p> <p>我节省了非常多的时间，明白了为什么之前有个人说他们在公司开始放更多书、吉他和其他消遣的东西，猫被撸得更多了</p> <p>现在的我要么是同时并发在2、3个项目中，要么是1个任务在跑，我在看文章、看newsletter或社交中</p> <p>但是这带来的是什么呢？我们真的有这么多需求做么？我觉得大部分在岗位上的打工人，并没有这么多需求，只要你会合理管理需求，我觉得现在的你在需求上的工作效率是X倍于2年前的自己</p> <p>不过自己喜欢捣鼓或者有Solopreneur的想法的人，或许可以无限放大自己的能力。以前我想过如果可以把自己劈成2个自己该多好，或许现在在某种意义上，已经实现了那个妄想</p> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-07-03-claude-code-experience/7-480.webp 480w,/assets/img/2025-07-03-claude-code-experience/7-800.webp 800w,/assets/img/2025-07-03-claude-code-experience/7-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/2025-07-03-claude-code-experience/7.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <p>这个是我和一个朋友的聊天记录，这边玩的是CC，我们有时候会交流一下这些东西的使用感想。我这两天确实有点索然无味的感觉。</p> <p>非常奇怪的感觉，明明我递送的东西比以往多得多，我的效率和产出都在持续上升中，但是就是难免有这种感觉。我很庆幸我的职业和我喜欢的是重叠的，<strong>但是现在的AI似乎在剥夺走一部分我热爱的东西</strong></p> <p>有时候Hit Limit之后，感觉自己什么都做不了了，或许最近看到的Brain-Rot从某种角度来说可以描述这个现象</p> <p>细想一下，<strong>有时候并不是想要那个结果，而是喜欢过程中的感觉</strong>。那种Debug2天终于解决一个问题的成就感也变淡了，现在是再让CC多跑一次吧</p> <p>这是否意味着我们要重新思考真正有价值或有意义的东西？</p> <h2 id="️人才争夺战">🤼‍♂️ 人才争夺战</h2> <p>昨天早上我还发了一条推：</p> <blockquote> <p>今天看到Cursor从anthropic挖了两个人，结合最近Meta疯狂挖AI人才；再反观big tech大量收缩人员招聘，尤其针对校招或者junior。</p> <p><strong>顶尖人才每个时代都是稀缺的，其余的随着时代剧烈变革，皆是阵痛</strong></p> </blockquote> <p>最近看得到的新闻就是这样，其实从前年和去年就已经开始的趋势了，只不过最近在硅谷以Meta大肆挖人开始持续发酵</p> <p>最近越来越多用户从Cursor转投CC，我相信也给Cursor带来了很大的压力，也不奇怪今天看到这样的新闻，Cursor把对方2名Leader挖走了</p> <p>这也是我在推文里提到的，<strong>顶尖的AI人才的薪酬待遇是持续增长的</strong>，企业间的持续挖角行为，势必会持续助长这个趋势的，因为人才的供给是有一定的滞后性的，虽然美国顶尖的高校在持续加大投入AI人才的培养，但是依然有一定的空窗期，大部分都是半路出家转投神经网络、GenAI为主的AI领域。</p> <p>加上AI时代的快和互联网时代的快已经不再是一个级别了，因此对于大企业或者明星初创企业，几个月一年这种时间跨度的落后是非常致命的，有可能导致远远被竞争对手抛下的后果</p> <p>因此面对这种困境，企业间不惜血本的挖人挖团队收购的行为也更加可以理解了。但是这也造就了现在非常两极化的一个现象：</p> <ul> <li>一边是大量裁员与就业难</li> <li>一边是顶尖 AI 人才年薪上千万美元</li> </ul> <p>微软今天开始规模9千人的裁员了，这次主要集中在销售，4月份刚刚裁员6千人。现在Big Tech也在大量的缩招，HC大量减少，没有裁员也不怎么新增，这个就是现状，也预示着未来</p> <blockquote> <p>He was talking about three of his friends who are machine-learning engineers or AI researchers — Das said they’ve all been offered between <a href="https://l.businessinsider.com/a/click?_t=c8e10479a20f45bba5aad6c5f6fbb009&amp;_m=308bd1001ee34ff396ec743067adb914&amp;_e=eOj6rjcChDrrSW3-BW1tuG3O79vxpjzoJnmJKWbtAMwRcVgvvMyzSdNG97a3kzQJqhnPoi6PWFipRM1ThV8ivKE5l25YspPFUGMmjBY9yWUOHhMzreBzJjl2ijHwCwOF536whefpVEXxAvc1ZlYckx6-ldnUzb79NTT3QVE27Q6tV383oUB-ckcQyWQhcQD6riSySAN34T-PPsTdmgN5AxK0LfKwVJnfrx_fK6Ld4jgadsdKsIbzTYk6sohiLTle49YK62Hn7dAwGKWTNVVhYxrrT3OSIDdJ6a8UmBkMzo2xcOSIVYwlzieERP1z6HrRRFnk7Cqtah1rvkPMPaWvQ7s9KTIsVtEb1XkefZ3WX3O0i_5U1YlaXjkxN7EOdzN6DhS3_N3fSDJj6fkZhJij_wGkbWMP2saFFk3PmQ1EpEKEtabKPEGn6wrVhUyfMhdB">$8 and $20 million in total compensation</a> a year to join Meta. “It’s honestly hard to digest.”</p> </blockquote> <p>BI报道里的这段也表明了，现在Big Tech对于AI Talent的追求到达多么可怕的地步</p> <p>这些都令人难以消化，也预示着未来：<strong>AI人才的价值，将会被这个时代重新定价</strong></p> <h2 id="尾声"><strong>🧩</strong> 尾声</h2> <p>与其探究我们是否会被AI替代，不如思考我们还能在人类的独特性中，创造出什么AI无法替代的东西？</p> <p><strong>也许真正值得我们热爱的不是工作本身，而是那个在工作中持续试错、表达、创造的自己</strong></p> <p>我们正处于一个被技术重塑的时代，效率爆炸了，边界也模糊了。<strong>也许我们无法再用旧世界的逻辑，来定义新世界的自我</strong></p>]]></content><author><name></name></author><category term="AI"/><category term="Thoughts"/><category term="Tech"/><category term="AI"/><category term="Thoughts"/><category term="Tech"/><summary type="html"><![CDATA[深度体验了一段时间Claude Code（以下称呼为CC），是时候稍微聊一下]]></summary></entry><entry><title type="html">历史刚被创造出来，而世界上只有少数人知道</title><link href="https://ifuryst.github.io/blog/2025/a-new-history-begins-known-only-to-a-few-copy/" rel="alternate" type="text/html" title="历史刚被创造出来，而世界上只有少数人知道"/><published>2025-07-02T14:30:00+00:00</published><updated>2025-07-02T14:30:00+00:00</updated><id>https://ifuryst.github.io/blog/2025/a-new-history-begins-known-only-to-a-few%20copy</id><content type="html" xml:base="https://ifuryst.github.io/blog/2025/a-new-history-begins-known-only-to-a-few-copy/"><![CDATA[<blockquote> <p><strong>历史刚被创造出来，而世界上只有少数人知道</strong></p> </blockquote> <p>这个命题还挺大的，很适合自媒体的引流标题。但是我其实还挺喜欢这个标题，有一种史诗感和不知道从哪里来的一丝悲壮感？？</p> <p>这个是今天我在朋友圈看到的Cursor北京线下meetup里某位朋友发在小红书的笔记标题。无疑，探讨的内容就是这一次以生成式AI为首的AI新浪潮，一个新的时代。</p> <h2 id="software-30一个新时代的开端"><strong>📜</strong> Software 3.0：一个新时代的开端</h2> <p>Andrej Karpathy最近在YC AI Startup School里的演讲<a href="https://www.youtube.com/watch?v=LCEmiRjPEtQ">Software Is Changing(Again)</a>中提到现在进入了Software 3.0时代的概念：<strong>Prompt（提示词）是新的编程语言</strong>，即将替代传统的手写代码（Software 1.0/2.0）。许多软件系统将被重写，以利用LLMs解析提示并生成行为</p> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-07-02-a-new-history-begins-known-only-to-a-few/software3.0-480.webp 480w,/assets/img/2025-07-02-a-new-history-begins-known-only-to-a-few/software3.0-800.webp 800w,/assets/img/2025-07-02-a-new-history-begins-known-only-to-a-few/software3.0-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/2025-07-02-a-new-history-begins-known-only-to-a-few/software3.0.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption mt-0"> Software 3.0 </div> <p>在我看来，这是很有远见又相对合理又具前瞻性的判断。并且如果你还记得的话，之前就是他在今年2月份的时候提出的<a href="https://x.com/karpathy/status/1886192184808149383?lang=en">Vibe Coding</a>的概念</p> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-07-02-a-new-history-begins-known-only-to-a-few/vibecoding-480.webp 480w,/assets/img/2025-07-02-a-new-history-begins-known-only-to-a-few/vibecoding-800.webp 800w,/assets/img/2025-07-02-a-new-history-begins-known-only-to-a-few/vibecoding-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/2025-07-02-a-new-history-begins-known-only-to-a-few/vibecoding.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption mt-0"> Vibe Coding </div> <h2 id="-claude-codejunior--senior-都能被替代">💻 Claude Code：Junior &amp; Senior 都能被替代？</h2> <p>最近我深度使用了Claude Code（以下就称为cc），我和身边的朋友反复表达了我的想法：Cursor及之前基于LLMs的产品可以抬走Junior工程师，<strong>而CC可以抬走Senior了，一点也不夸张</strong></p> <p>我是一名多年的从业者，从上层CURD、底层系统、网络、微服务、容器化、分布式等等均有涉猎，虽然不敢说专家，但至少有自己的一些认知，我能从中窥探出这背后带来的多牛逼和可怕的效应。CC已经达到了高级工程师的水平了</p> <p>更重要的，我已经很长时间没有进行完整的coding工作了，现在用了CC之后，我看代码的时间都大幅度下降，从最开始命令行操作界面吐槽不能像cursor一样reset，到最后已经习惯全盘接受后，只做端到端的需求验收，但是CC不断表明他自己就能做端到端的验收了。</p> <p>关于CC，我会找机会单独展开说说。<strong>CC真的让我感觉到世界的规则正在被重写</strong>，创造它的人先把自己革命了</p> <h2 id="温水煮青蛙变革往往发生在不知不觉中">🔁 温水煮青蛙：变革往往发生在不知不觉中</h2> <p>如果你有深入地应用或者积极跟进前沿的发展，一定对于这个software3.0的提出表示认可，我们可以看到行业的发展其实就是一个又一个的更新的推进c</p> <p>我们可能经常觉得新推出的LLMs好像也没什么亮点，都是一直在唱的那些东西，这个时候其实正是危险的时候，<strong>很多行业的变革就是在这样一次又一次平凡的更新中，达到临界点突破了</strong></p> <p>一定要让自己对新技术的敏感度提升，才能保持前沿的认知。</p> <h2 id="人人皆可成为创造者">🧑‍💻人人皆可成为创造者</h2> <p>我们其实已经可以看到越来越多的非从业者进入这个领域了，他们可能没有技术背景，但有想法、有品位。他们可以借助AI去build出一个真正有吸引力的产品或服务，这个趋势无人能挡。</p> <p>我们回归最初，计算机、互联网还有各种APP，给人类带来的是什么呢？最本质的就是拥有比人类更加复杂高效的算术能力，上到天文下到地理，这个是最原始的需求。</p> <p>包括提升信息的流通速度，这个也是互联网最大的威力，让人类对于信息的产生、吸收和积累都达到了人类历史的巅峰，造就也占据了现代文明很重要的一部分。后来才陆续衍生出满足人类精神需求的东西，比如现在很多APP上的信息可能本质上是没有实际价值的，但是因为能满足人们的各种精神需求而产生了价值，也催生了新的职业。</p> <p>未来，同样可能在LLM之上诞生出新的职业，新的物种</p> <hr/> <h2 id="️从-medicine-30-到-software-30认知觉醒的重要性">⚕️从 Medicine 3.0 到 Software 3.0：认知觉醒的重要性</h2> <p>我最近在看的一本书叫《Outlive》，是一本讲医学和认知的，里面提到了Medicine3.0，大体就是Medicine2.0是用现代医学的各类手段去处理疾病，但是对于慢性病来说，已经不太适用了，因为被诊断出来之前是有一段很长的潜伏发展期</p> <p>这段时间其实如果能进入干预，那么可以很大程度避免未来的悲剧，在慢性病（包括癌症这些）在2.0时代都是跟时间在做斗争，所以作者认为我们应该要进入3.0时代</p> <p>积极去在较早的时间节点去发现和提前干预。这里面提到了观念或者意识问题我觉得很对，也很适用于套用在我们在聊的AI时代上。我觉得现在影响很多人前进的正是他们的思想观念</p> <h2 id="-思想的壁垒才是最大的限制">🧱 思想的壁垒，才是最大的限制</h2> <p>从历史上各类变革来看，思想建设和教育需要经常很长的时间，这边也是为什么我觉得标题是挺好的一个标题的原因。</p> <p>我们每个人都可能被经验绑架，尤其是在某个行业或领域工作久了之后。<strong>经验可能不再是财富，而是无形的枷锁</strong>。尤其是<strong>在急速变革的时代，适应力才是最需要的</strong>。</p> <p>很多人会因为固有的观念和想法，对于新的技术和趋势存在一定的偏见或者视而不见，这个在不同的国家、不同地区、不同的行业或领域都是存在的。因为过去的经历，在某个行业里的经验沉淀，极有可能成为阻止我们思维前进的枷锁</p> <p>最近我看的Sal Khan（可汗学院创始人）的书《Brave New Words》（中文是《教育新语》），郝景芳在推荐中的《让孩子具备与人工智能共舞的能力》一文里有这么一段话：</p> <blockquote> <p>英国科幻作家道格拉斯·亚当斯说过：“任何在我出生时已经有的科技，都是稀松平常的；是世界本来秩序的一部分。”</p> <p>我们之所以对 AI 技术反应强烈，要么是因为我们正处于一个事业的高峰期，想要抓住这波变革大赚一把，因此大肆吹嘘其伟大之处，要么是因为我们已经老了，对跟上奇幻变革的技术没有信心，就一直在说这波技术会让人类毁灭。但对于孩子来说不是这样的。让我们惊呼的AGI（通用人工智能）技术，他们只觉得天然而如此。</p> <p>孩子们生下来就生存在他们所处时代的技术之上。他们打开电子产品就会使用，而不会惊叹智能手机颠覆世界。他们接触 AI 大模型，也不会说什么“机器人要取代人类了”，而只会跟 AI 聊一会儿，然后就一如往常地做自己的事情了。对孩子们而言，AI 就是这么平凡。</p> </blockquote> <p>他们生来就活在 AI 之中，或者叫<strong>AI Native</strong>，他们已经司空见惯这些新技术了，他们的学习和成长以及未来的商业都绕不开这些生活中的基础构成，就好像互联网之余我们</p> <p>我们这一代人很难做到真正“空杯”。我们已经太习惯上一轮技术周期的逻辑了。只能通过后天人为的刻意，去保持童心，保持好奇心，保持学习和拥抱一切新事物的心态，才有可能对冲掉一切固有的认知。</p> <h2 id="-投资前沿技术就是投资机会本身">💸 投资前沿技术，就是投资机会本身</h2> <p>为什么一个月要花费那么多时间精力和成本去跟进最新的技术呢？</p> <ul> <li>是在为自己创造一个前沿实验的突然</li> <li>是为了抢占熟悉工具的早期红利</li> <li>是想打开新的认知边界</li> <li>Just For Fun</li> <li>当然，也有一点点FOMO</li> </ul> <p>这就像90年代，能早早接触计算机的孩子，往往比同龄人视野更加开阔</p> <h2 id="-写在最后你可以不fomo但别闭上眼睛">📍 写在最后：你可以不FOMO，但别闭上眼睛</h2> <p>说了很多，也许有点杂，但是我还是想写下这些思考。</p> <p>我觉得这可能是一个全新的时代，你<strong>可以不FOMO，但别选择闭上眼睛</strong>。如果你想要尝试去理解和拥抱的话，也许这篇文章可以提供一些启发</p> <p>现在的状态就好像一条长长的鞭子打过来，不多的人已经看到鞭了影，但是真正等鞭尾打到身上还需要一段时间，在这期间，你想做什么都是可以的，至少<strong>目前我们每个人都有这个选择的权利</strong></p>]]></content><author><name></name></author><category term="AI"/><category term="Thoughts"/><category term="Insights"/><category term="AI"/><category term="Thoughts"/><category term="Insights"/><summary type="html"><![CDATA[历史刚被创造出来，而世界上只有少数人知道]]></summary></entry><entry><title type="html">33号远征队</title><link href="https://ifuryst.github.io/blog/2025/expedition-33/" rel="alternate" type="text/html" title="33号远征队"/><published>2025-06-22T12:30:00+00:00</published><updated>2025-06-22T12:30:00+00:00</updated><id>https://ifuryst.github.io/blog/2025/expedition-33</id><content type="html" xml:base="https://ifuryst.github.io/blog/2025/expedition-33/"><![CDATA[<div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-06-22-expedition-33/expedition33-480.webp 480w,/assets/img/2025-06-22-expedition-33/expedition33-800.webp 800w,/assets/img/2025-06-22-expedition-33/expedition33-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/2025-06-22-expedition-33/expedition33.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption mt-0"> Expedition 33 </div> <p>一场奇妙的旅程，引发挺多的思考和感想。现在我希望打开PS5, Xbox或Switch玩一些单机游戏，拿着手柄躺在沙发里，对着85寸的电视，非常cozy，很适合某些夜晚或者周末时光去放松（或者从另一个角度来说是上瘾），从小时候接触电子游戏开始，对于游戏有着一种莫名的感情，在那个物质匮乏、资讯闭塞的小地方，游戏成了我通往外部世界为数不多的窗口之一，算是以前思想启蒙教育中不可或缺的一环。从最早的不可得而想的着迷年代，到后来慢慢懂得为什么游戏叫做第九艺术，再到现在，我喜欢到体验一段旅程，想看看创作人或创作团队希望展示给用户的世界。</p> <p>虽然我喜欢玩，但是我其实很少关注游戏行业的新闻，几乎不关注，我对于新游戏的发掘也是比较佛系的情况，第一次看到33号远征队的消息还是在互联网上大家热议后，偶然看到宣传片，每一年都在减少的数字代表了人们可以存活的年龄，这个设定一下戳中了，我就去下单了一张光盘。低头看了一下订单2025-05-10，到今天差不多1个半月的时间，陆陆续续在空余的时间走完了整个旅程。</p> <p>我很喜欢这个设定，单单这个设定可以让人想到很多东西，33这个数字，对于我来说意味着如果我活在这样的一个世界里，只剩下最后2年了，假如我生活在这样的世界里，我会选择去做什么呢？有些人逃避现实，有些人勇敢追求热爱，我觉得每个人都有权利去做出选择或者不做选择。我们有些人会和我一样，总是觉得未来还很长，或许这个游戏可以提供另一种不同的视角来思考。</p> <p>很喜欢里面的音乐和美术风格，很有艺术性，每个人物刻画的也很立体，很饱满，虽然日常生活中的大部分人都是平凡的人，很难有这么强的人物塑造出现，这或许也是平凡的世界里的我们对冲平凡的生活的一种方式和情趣吧？我们喜欢代入到各种载体的作品里的人物，去体验不同的生活，感受不一样的旅程，或许在一成不变的日常生活中，绝大部分的我们都有着寻找诗和远方的那部分自我，只不过大家的表现形式体现有所不同，有的人看书，有的人听音乐，有的人刷短视频，有的人开talkshow，有的人旅行，有的人transfer到另一个城市，有的人发展职业，有的人寻求创业…</p> <p>最后是关于临近尾声的一个探讨，我觉得应该是一个挺有争议的议题，就像一位身体受限的人，在虚拟世界中找到了完整的自我与存在的意义，或者是积极面对一切勇敢面对现实。我觉得还挺难选的，我觉得很多人可以草率的选择或者断言，那是因为言语是轻松的，要设身处地的在那个境地之中，或许就没那么容易做出选择了，并且我觉得2个选择都是可取的，在哲学的角度上这个问题很难争辩出一个结果，我觉得可以给每个人自由选择的权利，或许是一个更好的选择。就我个人而言，我认可在虚拟世界中也能找到意义，也可以体验一切的美好。人类是寻求物理感知的生物么？我们能轻松的分辨出自己是否真实存在于物理世界之中么？我想随着科技的发展，这个答案的肯定性在持续的动摇，人类作为一个个体，一个群体中的一部分，我们应该怎样面对未来世界的可能？科幻小说、电影已经给我们在很多方向上的可能做了探索，但是最终人类会走向何方，都未可知，但愿每个人都能有选择的权利和勇气。前者是客观因素制约，后者或许更多的是主观因素驱动，你是否有选择的勇气？</p> <p>最后的最后，无论你选择现实，还是沉浸于虚拟，游戏给你的只是创作者设定的世界，但你依然可以在人生中做出真正属于自己的决定。无论是奔赴远方，还是栖居当下，重要的不是去哪里，而是那是否是你内心认定的方向。愿你始终拥有选择的权利，也拥有选择的勇气。</p>]]></content><author><name></name></author><category term="Game"/><category term="Game"/><summary type="html"><![CDATA[Expedition 33]]></summary></entry><entry><title type="html">从互联网的历史思考AI时代</title><link href="https://ifuryst.github.io/blog/2025/echoes-of-the-internet-in-the-ai-era/" rel="alternate" type="text/html" title="从互联网的历史思考AI时代"/><published>2025-06-06T05:47:00+00:00</published><updated>2025-06-06T05:47:00+00:00</updated><id>https://ifuryst.github.io/blog/2025/echoes-of-the-internet-in-the-ai-era</id><content type="html" xml:base="https://ifuryst.github.io/blog/2025/echoes-of-the-internet-in-the-ai-era/"><![CDATA[<p>上周参加完Google I/O migle后，加上前一周在美国结束的Google I/O 2025，结合近几个月Google在LLMs上持续的发力。有一些想法</p> <p>我们喜欢从历史里学习到一些范式可以应用到预测未来的时候做佐证，我们可以把以前互联网时代的一些案例映射到AI时代来做一个类比和思考。我们知道思科随着互联网爆发式增长，成为全球最大的网络设备供应商，但是后来的故事我们都知道了，随着互联网的发展，最终硬件或者基础设施本身并不是最大的价值所在，最有价值的是上层的应用，我们可以看到目前顶尖的Big Tech大部分是在应用层拥有拳头产品。这个也是互联网时代可以告诉我们的，一开始硬件或者基础设施层面是巨大的价值所在，但是随着时间推进，应用层价值占比会不断提升，硬件成本则会持续的下降到一个阈值后趋于稳定。</p> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-06-06-echoes-of-the-internet-in-the-ai-era/MarketCap-480.webp 480w,/assets/img/2025-06-06-echoes-of-the-internet-in-the-ai-era/MarketCap-800.webp 800w,/assets/img/2025-06-06-echoes-of-the-internet-in-the-ai-era/MarketCap-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/2025-06-06-echoes-of-the-internet-in-the-ai-era/MarketCap.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption mt-0"> Top 10 Tech Companies by Market Capitalization (June 2025) </div> <p>回到现在，我们看看目前市值排行情况，NVIDIA在这里是尤其的“异类”，NVIDIA目前市值在3.352万亿美元的规模，几乎要问鼎Top1了，对比思科的例子来看，似乎有一点相似的味道。这个就是我们前面说到的历史过往可以印证思考现在及未来。但是我们需要分清楚过往不代表未来，趋势不代表公司命运。未来GPU或者说支持AI训练和推理运算的硬件成本是会持续下降的，会使得这一部分的市场规模在模型层或者应用层的规模占比来看小很多。不过我们可以看到NVIDIA目前其实出来在硬件基建层的持续供应以外，还在上层也开始推进，也就是上探到应用层，这个能在一定程度上对冲掉底层基建市场规模占比缩小的风险。</p> <p>反观一下Google（Alphabet）的市值只有2.067万亿美元，这个是我想探讨的一个点。我觉得Google的市值被严重低估了。我们知道在OpenAI（截至202506的市场估值3千亿美元，仅次于SpaceX的3.5千亿美元，和字节差不多）出来之前，Google在AI领域基本是Top1的，有人有钱有技术。开头也提到，随着这一两年Google在AI领域持续发展（Google CEO Sundar Pichai在Google I/O 2017的时候提出AI First），已经能感受到Google慢慢回到了它以前在的位置了，今年也是AI在B端和应用层大爆发的一年，我们或许可以叫做应用层元年，AI时代的发展阶段被大大缩短和加速了。可以预见未来在模型层和应用层还会有大量的爆发式增长。</p> <p>当然Google现在也有它的问题，包括被两起主要的反垄断诉讼（搜索引擎市场垄断和数字广告技术垄断）都是投资者慎重的重要原因，包括Google成为大公司后自然衍生出的一些所谓的“大公司病”。因此就如前面说的，过去不代表未来，只不过如果Google可以延续过往在AI领域的人才储备和科研投入，那么Google依然有可能在未来的AI领域持续增长</p> <p><strong>不构成投资建议，就是记录一下想法</strong></p>]]></content><author><name></name></author><category term="Thoughts"/><category term="Thoughts"/><summary type="html"><![CDATA[上周参加完Google I/O migle后，加上前一周在美国结束的Google I/O 2025，结合近几个月Google在LLMs上持续的发力。有一些想法]]></summary></entry><entry><title type="html">Google IO开发者小会</title><link href="https://ifuryst.github.io/blog/2025/google-io/" rel="alternate" type="text/html" title="Google IO开发者小会"/><published>2025-05-30T20:00:00+00:00</published><updated>2025-05-30T20:00:00+00:00</updated><id>https://ifuryst.github.io/blog/2025/google-io</id><content type="html" xml:base="https://ifuryst.github.io/blog/2025/google-io/"><![CDATA[<p>今天受小红书邀请，作为30位独立开发者之一参与了Google IO，突然的行程，受益颇丰。</p> <div class="row mt-3"> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-05-31-google-io/p1-480.webp 480w,/assets/img/2025-05-31-google-io/p1-800.webp 800w,/assets/img/2025-05-31-google-io/p1-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/2025-05-31-google-io/p1.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <div class="col-sm mt-0 mb-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-05-31-google-io/p2-480.webp 480w,/assets/img/2025-05-31-google-io/p2-800.webp 800w,/assets/img/2025-05-31-google-io/p2-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/2025-05-31-google-io/p2.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-05-31-google-io/1-480.webp 480w,/assets/img/2025-05-31-google-io/1-800.webp 800w,/assets/img/2025-05-31-google-io/1-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/2025-05-31-google-io/1.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <div class="col-sm mt-0 mb-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-05-31-google-io/2-480.webp 480w,/assets/img/2025-05-31-google-io/2-800.webp 800w,/assets/img/2025-05-31-google-io/2-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/2025-05-31-google-io/2.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-05-31-google-io/3-480.webp 480w,/assets/img/2025-05-31-google-io/3-800.webp 800w,/assets/img/2025-05-31-google-io/3-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/2025-05-31-google-io/3.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <div class="col-sm mt-0 mb-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-05-31-google-io/4-480.webp 480w,/assets/img/2025-05-31-google-io/4-800.webp 800w,/assets/img/2025-05-31-google-io/4-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/2025-05-31-google-io/4.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> </div> <div class="caption mt-0"> Google IO 2025 in Beijing </div> <h2 id="googleai">Google+AI</h2> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-05-31-google-io/5-480.webp 480w,/assets/img/2025-05-31-google-io/5-800.webp 800w,/assets/img/2025-05-31-google-io/5-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/2025-05-31-google-io/5.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <p>首先第一趴来自Google侧的分享（包含一些他们回答问题时的想法和见解），结合这几个月来Google的动作，可以很明显的感受到Google在AI领域慢慢追上来了，有钱有人有技术的屠龙少年（虽然现在被诟病屠龙后自己也逐渐成为恶龙）开始继续在技术力上发挥了（虽然Google一直在产品力上比不上其他几家big tech，但是技术力是很顶的）。对于开发者或者用户来说，我和很多人一样是喜闻乐见的，我非常期待底层模型效果持续增加，费用持续降低的道路上持续下去，这样可以让应用层的风吹到世界每个角落。就好像去年到今年AI Agent和Agenic AI持续发展却不够杀手不够普遍（简单问一句几个人用个Devin、Manus这类产品呢？），其中原因就是费用问题，而不是效果和门槛。最近Devin开的credit 3个PR就烧没了，同等情况下cursor这类产品也可以做到，多喝两口茶的事情，这就限制了Agent的流行。我坚信费用持续下探到一个水平的时候，会迎来一波在各个领域的Agent爆发，现在这个阶段很多人其实是在抢滩，都希望大风来了自己是风口上的🐷。我也是其中的一只想成为🐷的人</p> <p>和与会的一些人的观点一样，我对于Gemini最看好的就是多模态能力，有人（坐在我后面的，但是我不知道叫什么名字😨）表示是SOTA级别的，我认可，我觉得这个也是大语言模型未来一个必然的方向，我们可以有垂类区分的LLMs，但是一定不会缺少全能的LLMs，这点我觉得也是头部AI企业会持续深耕的方向。</p> <p>Gemini的上下文长度确实是很重要的一点，有位Google某个事业部的研发负责人分享的客户案例我觉得有点启发性，在上下文足够大的情况下，可以直接把整部电影丢进去，然后做一些解说、去水、压缩等动作的时候就可以非常的方便，这和切片后处理的效果完全不同。我觉得这个也是很多垂直行业可以探索的，大公司的市场是给各个行业赋能，这个是他们的能力和价值体现，作为独立开发者，我们能做的面很广，但是能做的事情却很少，我们能做的只有我们熟知的部分行业，我发现现场的大部分人都是从自身或者周边的需求开始以点到面再到一个实际的产品，坚持落地才成就了自己。所以不同的行业机会都特别多，别顾着FOMO，别顾着跟进趋势，一定要持续保持发现，持续去执行，你能找到你的赛道</p> <p>另外关于LLMs的智能水平，之前的Scale Law其实大家还在持续的探索，毕竟就文本而言，互联网的语料已经被大家吃的差不多了，音视频的切片转化也在做，目前最前沿的模型几十万张卡训练出来的，如果未来可以上升到百万张卡的级别，可能会将智能程度往前推一个级别</p> <p>目前AI和人类的关系很暧昧也很模糊，这个导致人类认为界定的一些职业或者角色也在模糊化，比如现在产品和研发的边界已经逐渐模糊了，产品可以借助AI达到一部分研发的职能，而研发也可以借助AI放大自己的产品能力和思维。所以不要被天然的职业规划限制了你的想法，回到文艺复兴时代，达芬奇就是一位全才（<strong>Polymath</strong>），他不仅在艺术领域有极高的造诣，在科学、工程、解剖、建筑等多个学科也有深入探索，是通才或者博学的典范。我觉得现代人为的划定学科是为了应对现代社会的分工，让每个人可以更加专精于自己的学科领域，这样可以出现高精尖人才，但是这也天然的给后来者上了精神枷锁，先入为主的被学科和职业所限制，少数人会意识到这个问题，主动被动的去弱化或对抗这个观念，我觉得创业者需要这方面的探索，会很有助力。（我觉得一些T型、π型之类的人才定义，其实就是有了这方面的意识后才去提出这样的概念，对冲固有的界定）</p> <h3 id="model-is-agent">model is agent</h3> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-05-31-google-io/6-480.webp 480w,/assets/img/2025-05-31-google-io/6-800.webp 800w,/assets/img/2025-05-31-google-io/6-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/2025-05-31-google-io/6.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <p>这个是一个Google解决方案的老师提出来的，我觉得也合理，和另外一位朋友提出来的有一些匹配：水漫金山还是水涨船高（林神龙老师在他朋友圈看到的，分享的）。大体就是说随着LLMs的能力提升，他的杀伤区内的应用都会被干死，一个简单的例子，我们可以看到之前存在很多GPTs，现在其实没多少人再用了，因为ChatGPT自身的能力不断提升，已经完全吃掉那些基于Prompt调整的GPTs了，一个道理，现在大家在持续推进Agent，当模型能力达到一定程度的时候，模型本身就可以是Agent，其实我们对于Agent的概念由来以久了，对于浏览器有关注的人应该知道浏览器本身就是一个Agent，我们可以在HTTP请求头里看到一个字段叫做User-Agent，就是用来代表代表用户的Agent是什么，可以是浏览器，可以是一个Python写的程序，也可以是curl之类命令行。现在大家说Agent只会联想到AI Agent，这个就是大背景下大家都在唱这个东西，但是本身就是代理的不断演进，从计算机远古时代就持续存在的理念，我们有理由相信大模型是有成为Agent的那一天的。</p> <h3 id="通用-or-垂直">通用 or 垂直？</h3> <p>这个问题和以前我聊芯片时候的想法有点类似，现在其实大家在追求的通用的还是垂直/专用的LLMs？我觉得是都有的，就像其他人提出的，还是要以问题为导向，以客户为导向，专注于交付，不然就是本末倒置了。这其实也是一个很简单的道理，你打造了一把贼风里的刀，你看到什么都想砍两下，你觉得要找到东西砍一砍才能发挥他的威力，但是如果你本身没有切西瓜的需求，你拿一把西瓜刀也没什么用。所以哪怕有把贼牛的刀，你要剪指甲的时候还是需要指甲刀，而不是用那把贼牛逼的刀。</p> <h2 id="创业者">创业者</h2> <p>第二批是几位创业者的分享，这一趴我太喜欢了，是我收获最大的，我觉得很多时候最棒的东西是来源于走在同一条道路上的同行人，因为大家很有可能面临一样的困难，收获类似的喜悦，吃过成吨的苦。</p> <p>不得不说大家的嘴炮能力是真的厉害，每个人都是张嘴成河，还讲得贼好的那种，这个或许也是成功的一部分因素，能推销自己的观念和主张在很多场合是正向收益的。</p> <p>我认真在听大家的分享，随手就写了我觉得比较有共鸣的点到笔记里，我稍微沿着我的记录的笔记去展开结合一下我自己的想法聊聊。不过这里我忘记记录是谁发言的，加上我是第一次见大家，我已经不记得哪句话是哪位讲的了，不能标注出处，还请见谅（但是范围很小，大部分来源于下面这6位朋友的分享内容，加上一些Google或者小红书侧的一些发言）</p> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-05-31-google-io/7-480.webp 480w,/assets/img/2025-05-31-google-io/7-800.webp 800w,/assets/img/2025-05-31-google-io/7-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/2025-05-31-google-io/7.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <h3 id="赚钱这回事">赚钱这回事</h3> <p>做产品的第一要务是赚钱，哈哈，很现实，但是我很喜欢。包括我自己，我觉得有很多人很容易走进误区，一定要直面自己的问题，努力去调整。就像今天有人分享的：产品不是表达自己，而是服务用户。我觉得一开始你可以有很好的Idea或者个性去表达自己，很容易收到有共感的用户，在此之后，应该聚焦于服务用户，你的受众才是你的产品持续发光发热的源头。包括那句：匠人精神到商人精神的转变，是个很棒的概括。</p> <p>订阅制对于独立开发者的重要性，这个确实是能长期支持独立开发者或小团队的一个持续源动力，所以围绕着这个展开的就是我们如何让用户接受订阅？可以是好产品，也可以有其他的手段</p> <h3 id="创业思维">创业思维</h3> <div class="row mt-3"> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-05-31-google-io/8-480.webp 480w,/assets/img/2025-05-31-google-io/8-800.webp 800w,/assets/img/2025-05-31-google-io/8-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/2025-05-31-google-io/8.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <div class="col-sm mt-0 mb-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-05-31-google-io/9-480.webp 480w,/assets/img/2025-05-31-google-io/9-800.webp 800w,/assets/img/2025-05-31-google-io/9-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/2025-05-31-google-io/9.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> </div> <ol> <li>提升自身信息敏感度</li> <li>自身技术涉猎范围</li> <li>体验产品广度</li> </ol> <p>上面这三个点是我非常认可的。</p> <p>信息敏感度这点是十分重要的，我们时刻要保持敏锐的嗅觉，去思考某个需求是否可以转化成产品，甚至是在和别人的交流中都能产生出很棒的点子，这个也是social的意义之一。</p> <p>第二点和前面我说的通才那边的观点一直，尤其是AI时代，去年的技术你敢说不旧么？小时候那个词：日新月异，现在真的是感受到了，比互联网时代更加真实的感受。</p> <p>第三点之前我也和别人说过类似的观点，简单说就是dirt your hands，一定要自己去尝试！千万不要以为简单看一下新闻、自媒体的评测和言论就以为了解这个东西了，很多东西你真实去感受有可能得到的完全不一样的结论和收获</p> <div class="row mt-3"> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-05-31-google-io/10-480.webp 480w,/assets/img/2025-05-31-google-io/10-800.webp 800w,/assets/img/2025-05-31-google-io/10-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/2025-05-31-google-io/10.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <div class="col-sm mt-0 mb-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-05-31-google-io/11-480.webp 480w,/assets/img/2025-05-31-google-io/11-800.webp 800w,/assets/img/2025-05-31-google-io/11-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/2025-05-31-google-io/11.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> </div> <p>有一些对于当代社会的认知我觉得特别棒， 尤其是对于感受力经济的洞察，社会发展至今，现代化进程都走得七七八八了，现在新世代群体对于基础的温饱需求已经不是问题了，他（她）们更多会追求一些精神层次的东西，其中感受是一个很重要的组成部分，也就是前面说到的感受力经济。提到这个我想展开说一下，今天我观察了几位分享的产品，我觉得有一个很大占比是情感类的（很笼统，大体是这个意思，但是其实细化还有一些心理、感受、情绪之类的），女性群体是一个巨大的受众群体，这点其实是我之前了解但是却没有重视过的（像星野这个产品，我第一次在杂志上看到的时候也蛮惊讶的），这个也是一个很大的收获，虽然我没有toC的产品直接面向这类受众群体，但是我相信我已经在重视这个群体了。</p> <p>所以其实现代社会，人均教育水平和生活水平的提高，很多人都是斜杠青年了，每个人都是多面人，在生活中扮演了不同的角色，所以我们不应该用刻板的印象去面对用户，比如简单定义这个是18-28的男性用户群体，而是应该更加细化的去服务好不同的群体，我相信这个也是AI时代会带来改变的一个方面，哪怕再小众的群体，也有机会且值得被好的产品所感动</p> <p>互联网发展至今，很多基建都做得差不多了，现在很多平台都在寻找增量空间，而AI就是一个很大的方向。现在做项目出门融资，不和AI沾点边，估计还不太行</p> <h3 id="节奏">节奏</h3> <p>对于独立开发者而言，节奏比方向更重要。在一定程度上我是很认可的，不过我是觉得方向也挺重要的，或者换句话说，选对赛道很重要，这个一定是在对需求的深刻洞察和对于自我拥有的一切可调动资源的合理感知之下走进适合你的赛道，然后就是节奏。我和大多数人一样，不可免俗的对快速变化的世界，不断消逝的机会有一些FOMO的心态，我觉得这是一把双刃剑，看你怎么舞动他，就好像欲望一样，可以驱使人们做出很恐怖的事情，也可以做出“很恐怖”的事情。</p> <h3 id="ai人">AI&amp;人</h3> <p>以前是AI辅助人类变成，现在是人类辅助AI变成，未来可能是AI编程。我觉得很有道理，如果还没有意识到这个阶段的变化，那么你很有可能已经错过了第一波AI浪头，停下来仔细想一下吧，真实去使用去感受一下。</p> <div class="row mt-3"> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-05-31-google-io/12-480.webp 480w,/assets/img/2025-05-31-google-io/12-800.webp 800w,/assets/img/2025-05-31-google-io/12-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/2025-05-31-google-io/12.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <div class="col-sm mt-0 mb-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-05-31-google-io/13-480.webp 480w,/assets/img/2025-05-31-google-io/13-800.webp 800w,/assets/img/2025-05-31-google-io/13-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/2025-05-31-google-io/13.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> </div> <p>关于这点我之前也说过很多类似的言论，今天听到依然觉得很棒，就是心光的禹效分享的逆学习Unlearning这个概念：忘掉你之前掌握的东西！</p> <p>空杯心态非常适合应用到这里：技术特别好的人用AI用的少，反而是那种什么都不懂的人用的多。我太认可这个点了，身边对于AI的态度基本上就是2派，超级认可和超级不认可，如果你至今还觉得AI做得还不如自己做得快做得好，那你很有可能已经out了，需要alarm了。有个Google的高管提到一点，就是你好像是老板，AI好像是员工，没有理由AI写的代码你需要去看去改，你要做的只是不断提需求，验收需求即可。随着LLMs的效果不断提升，这个场景是必然到来的，到时候你会怎么选择呢？</p> <p>关于有时候大骂AI太垃圾，有时候夸到天上去了的这件事，也很有意思，就是对于结果是否Align我们脑子里想的，真的就是这么回事，和前面一个道理，对于有一定研发背景的人来说，很可能描述给AI到最后做出来的，有一个巨大的差距，就会开始觉得AI不行，适应性强的人会重新roll一遍，就好像抽卡一样，适应性不行的人就会骂骂咧咧自己修改。期间的味道大家自行品味</p> <p>所以一定要始终保持空杯心态，这个时代只要你下决心想学，人类已有的旧知识体系里的知识，没有你学不会的，所以千万不要限制自己的心态，保持成长心态，保持成长。理论上老年人的学习能力应该可以很强的，因为他（她）们已经看遍世间百态，了解了特别的东西，是活化石了，但是为什么事实是反过来的呢？依然是双刃剑，知识和阅历是把双刃剑，可以给你很高的视野和认知，也可以把你限制在这座高峰之上，但是你不知道的是，当你下山后，走过一段平路，越过你看不到的地平线的那边，有一座更高的山峰正在拔地而起，你是选择在这座山峰洋洋自得，还是选择去远方看看不同的风景？放下或许是一种智慧</p> <p>另外关于前面提到的职业划分，换到行业和专业也是一个道理，这些都是现代社会人为根据经验进行划分的。在LLMs的眼里，并没有行业和专业的区分，在LLMs的眼里一视同仁，这些限制仅仅是对于人来说的，因为人的能力范围是有限的，反过来这个也限制了我们能与AI交互的边界范围。所以我认为目前其实我们没办法完全释放LLMs的能力，我们只是在LLMs的一个子集范围内去与其交互，有打算在超级个体方向持续深耕的朋友或许该思考的是，我们该如何以个体的角度去最大化释放LLMs的能力。我有一个很sci-fi的想法，一群人从不同的领域组成一个超级个体（或超级群体？），然后这个超级个体去与LLMs交互，这样可以最大限度释放LLMs的能力。</p> <h2 id="总结">总结</h2> <p>最后引用一句忘记是谁说的了：技术快速变化，有些人抓住变化，有些人引领变化。</p> <p>今天在场几十个人，只是这个新时代之际的一小撮人，还有无数分布在全球的这样的人，对于未来充满了希望和信心，也感叹自己生活在一个能经历历史变迁的时代（高晓松近段时间分享过这个观点），何其有幸！我们需要做的就是做好长战线的学习、敏捷迭代并持续执行落地，做好付出没有任何回报的心理准备，除此之外，干就完事了。你能决定的只有你自己❤️</p> <p><em>今天早上起来一天都忙没停，Google开完会和老同事喝了两杯精酿后回酒店还和人谈了一个项目，又开了电脑卷了一下新项目后又去机场接人，回来就马不停蹄地写下今天的经历和收获，我也懒得勘误和排版了，随性一点，大家也就随性看看，有收获自然是好的，没有收获就当一厕所读物吧。明天去颐和园放空一下心灵，为下半年的腥风血雨做个准备</em></p> <p><em>最后还是对与会分享的人道个歉，我觉得国内的教育和环境并没有教会我们在引用别人说的话适合应该标注出处，我是非常乐意告诉大家这句话是谁说的，但是当时我确实没有这个意识要记下来，全身心的专注在内容本身了，如果有需要可以告诉我哪些话是你说的，我可以再次标注</em></p>]]></content><author><name></name></author><category term="Events"/><category term="Events"/><summary type="html"><![CDATA[今天受小红书邀请，作为30位独立开发者之一参与了Google IO，突然的行程，受益颇丰。]]></summary></entry><entry><title type="html">Duolingo w/ AI</title><link href="https://ifuryst.github.io/blog/2025/duolingo-with-ai/" rel="alternate" type="text/html" title="Duolingo w/ AI"/><published>2025-05-28T14:51:00+00:00</published><updated>2025-05-28T14:51:00+00:00</updated><id>https://ifuryst.github.io/blog/2025/duolingo-with-ai</id><content type="html" xml:base="https://ifuryst.github.io/blog/2025/duolingo-with-ai/"><![CDATA[<div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-05-28-duolingo-with-ai/ChatHistory-480.webp 480w,/assets/img/2025-05-28-duolingo-with-ai/ChatHistory-800.webp 800w,/assets/img/2025-05-28-duolingo-with-ai/ChatHistory-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/2025-05-28-duolingo-with-ai/ChatHistory.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <p>上面这张图是之前看到新闻时分享给别人的聊天记录，今天就看到了Duolingo的CEO发布声明开始”撤回”之前的声明了。我觉得这个事件还挺有趣的，反应了AI时代的个体和企业的决策和行为</p> <p>背景概览大体是</p> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-05-28-duolingo-with-ai/DuolingoPost1-480.webp 480w,/assets/img/2025-05-28-duolingo-with-ai/DuolingoPost1-800.webp 800w,/assets/img/2025-05-28-duolingo-with-ai/DuolingoPost1-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/2025-05-28-duolingo-with-ai/DuolingoPost1.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <div class="col-sm mt-0 mb-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-05-28-duolingo-with-ai/DuolingoPost2-480.webp 480w,/assets/img/2025-05-28-duolingo-with-ai/DuolingoPost2-800.webp 800w,/assets/img/2025-05-28-duolingo-with-ai/DuolingoPost2-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/2025-05-28-duolingo-with-ai/DuolingoPost2.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <p>2025年4月底的时候就是Duolingo账号在LinkedIn发了CEO Luis von Ahn的全员信说要公司要逐步用AI替代外包，AI优先的战略</p> <blockquote> <p>Duolingo is going to be Al-first.</p> </blockquote> <p>然后在几天前，也就是一个月后的5月底，CEO自己出来发了Post，试图挽回….</p> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-05-28-duolingo-with-ai/DuolingoPost3-480.webp 480w,/assets/img/2025-05-28-duolingo-with-ai/DuolingoPost3-800.webp 800w,/assets/img/2025-05-28-duolingo-with-ai/DuolingoPost3-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/2025-05-28-duolingo-with-ai/DuolingoPost3.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <div class="col-sm mt-0 mb-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-05-28-duolingo-with-ai/DuolingoPost4-480.webp 480w,/assets/img/2025-05-28-duolingo-with-ai/DuolingoPost4-800.webp 800w,/assets/img/2025-05-28-duolingo-with-ai/DuolingoPost4-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/2025-05-28-duolingo-with-ai/DuolingoPost4.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <p>原文我都截图了，顺带随手截了一下评论区，大家可以自行感受一般</p> <p>大体上就是声明AI取代人，然后被喷飞，甚至大量取消订阅，总而言之就是引起品牌的负面影响，然后CEO跳出来试图挽回</p> <p>Duolingo本质上是一个toC的产品，受众是普罗大众，我觉得用AI取代人这种话对这个群体的杀伤力是非常大的。从另外一方面讲，语言这个东西多少和文艺搭边，这种情况下会让相关从业者极度反感用AI取代人的这种趋势。</p> <p>反观硅谷，很过公司不是直接toC的，目前阶段很多其实只到toD之类的层面，更多还是提效的，而不是直接取代什么。并且更多startup还是面向投资人的，所以引发负面情绪小一点。</p> <p>我们可以看到之前好莱坞大量编剧和演员罢工本质上也是反应了科技发展和现存就业者的客观现实冲突。历史上在工业革命时期也出现过卢德派（Luddites），机械化导致大量工人失业，Luddites就在夜间潜入工厂砸毁机械。</p> <p>我觉得这个话题本身就是非常两面的，我觉得两边都很容易找人站台支持，科技发展，旧职业消失，新的职业出现，这前后是否存在数量差异，更迭速度如何，是否会牺牲一代人成就另一代人，个体在里面似乎微不足道，人类社会取得成就可能是构筑在大量个体悲惨命运之上？我觉得这些很难给出一个统一的答案，很多答案或多或少都带了一定的主观意识。世界的运作本就不是做题，没有唯一的答案，未来技术的发展也是一样，我们起于无知，面向未知。</p> <p>最近MCP Gateway也达到了第一个milestone（达到1k stars），我也在着手成立Lab，目前是一个SoloLab，有一句Slogan就是</p> <p>Born to Hack the Future</p> <p>我觉得个体很难抵抗时代发展的车轮，能碾碎无数个体甚至国家，我们唯一能做的就是让自己不断强大，更加敏捷，才能应对快速变化的未来</p> <h2 id="references">References</h2> <ul> <li>https://htxt.co.za/2025/05/duolingo-ceo-tries-to-walk-back-ai-first-comments-fails/</li> <li>https://www.linkedin.com/feed/update/urn:li:activity:7322560534824865792/</li> <li>https://www.linkedin.com/posts/luis-von-ahn-duolingo_one-of-the-most-important-things-leaders-activity-7331386411670982658-jpfX/</li> </ul>]]></content><author><name></name></author><category term="Insights"/><category term="Insights"/><summary type="html"><![CDATA[]]></summary></entry><entry><title type="html">关于转向灯的思考</title><link href="https://ifuryst.github.io/blog/2025/signals-we-miss/" rel="alternate" type="text/html" title="关于转向灯的思考"/><published>2025-05-22T14:51:00+00:00</published><updated>2025-05-22T14:51:00+00:00</updated><id>https://ifuryst.github.io/blog/2025/signals-we-miss</id><content type="html" xml:base="https://ifuryst.github.io/blog/2025/signals-we-miss/"><![CDATA[<p>反正我觉得这是一个挺奇怪的标题，但是今天中午游泳的时候，我确实在思考这个问题。</p> <p>这个思考的由来是今年1月底我去美国旅行的感悟，这次去美国在美西十来天就开着一辆在SFO租来的迈锐宝在几个城市和国家公园来回穿梭，不得不提这个在美国开车之爽，和在国内开车是2个体验。</p> <p>在那边基本上你就认着一条路无脑踩油门直开就行了，大部分情况下是不会有人别车的，拥有路权意识的国家开车就是这么爽，也因此经过了开始的小心翼翼阶段后，开始肆无忌惮的飙车了，刚好2个人，路上经常可以进到Carpool的道路开（在美国尤其以SF和LA这种城市周边的高速公路有专门给一辆车超过2个或者3个人以上的车辆，或者交了钱的车跑的快速车道，本质上是鼓励更多人共乘提高车载率，跟环保什么的多少也有关系），开得更快了。</p> <p>那天晚上我们从海豹观景点一路沿着1号公路南下，准备去LA市区过夜，当晚住宿其实没有提前定，本来是打算在Solvang或者圣巴巴拉停留的，后来因为发现通行速度实在是快，并且第二天打算在LA多逛逛，所以在Solvang逛完这个欧洲风情的小城镇后就一路要杀到LA了，路上下了山到圣巴巴拉的时候就想起来打算拐去Gelson’s买点吃的，然后就是在我到了Gelson’s外面路上的时候，我发现到了，就直接右拐进去了，此时右后方就发出一阵奇怪的声响，然后一个小哥骑着自行车上来马上质问我说他没有看到任何转向灯。重复了好几次，我愣了一下后确认下车确认他有没有问题，当时是他及时刹停了，我连忙和他say sorry，然后他一转刚才质问的态度，马上跟我说兄弟没事了，然后跟我解释，他说他是一个很棒的自行车骑手，他很快反应过来了，说他没有事情，我们就交流一下他就走了。</p> <p>这件事事后我自己得出了几个结论：</p> <ol> <li>转向灯在美国路上尤其的重要，因为大家的车速尤其的快，且路权意识特别强，你不打灯直接转很容易出事故。这点和在国内开车天壤地别，在国内大部分老司机变道过湾几乎不会打灯的，我记得我刚买车那会，我的车还有变道辅助系统，也就是你变道你不打灯方向盘会在你强行变道的时候把你拉回来一点，就是给施加一点阻力告诉你要打灯才能变道。我还记得当时我朋友问我为什么变道要一直打灯。现在想想转向灯在国内的用武之地小太多了，很多时候我们是通过对方车速、车身姿态来确认他要变道，有一种车身姿态语言的无声交流。毕竟车这个东西原产于西方国家，基于他们社会和大家的习惯下产生的自然需要转向灯告诉大家我要变道转向了。我觉得当时我能打灯无论如何能让小哥提前知道并提前规避</li> <li>后视镜的重要性，其实打灯我觉得不是根本原因，是直接原因。根本原因是因为这个后视镜视野太早了，这辆车左右后视镜放大倍数太大，导致两侧存在很大的死角空间，经常要探头缩头的看，这点真的是教训啊，后面从LAS去布莱斯国家公园的高速路上我也是因为这个连变2道以为没车的情况下差点撞上后方来车，那位女司机反应不可谓不快，马上急转打到左侧应急车道上去再回来，一路烧胎，颇有点速度与激情的feeling了，她马上油门一带就走了，留我在那后怕</li> <li>南加州人的热情，以前高晓松在晓说里有提到这点，真该庆幸自己是在南加州遇到这档事，要是在Texas之类的州，有可能没啥好果子吃，南加州在城市里的人确实非常的热情，和纽约完全是两个样子，至于乡下道Utah之类的地方也都蛮好的，当然那可能跟去的地方在旅游景点范畴有点关系。总而言之LA的人感觉都挺友善的，在SF我们出去City Walk了一天，一路上遇到的人，不管是晨跑、遛狗之类的，都挺热情的Say Hi</li> </ol> <p>总而言之，很多东西它不是换个地区或国家就能适用的。就好比以前我从澳洲回来后我就一直觉得为什么我们在一些行人较少的路段的人行道不能做那种行人按一下一会就可以通过的那种机制，而是固定死的周期红绿灯，我觉得在一些路段这样设置是合理的，但是在大部分路段不行，因为我们的行人数量足够多，这个本身也是国情或者社会形式不同，所以很难把一个东西硬套，很容易水土不服。</p> <p>这或许也是旅行的意义，开阔眼界，带来更多的思考方式和方向，本来打算分享一些相关的照片的，但是数据线被拿走了，改天我整理出来，写一些关于去美国旅行的一些感悟，我觉得我再不写，很多东西就要忘记了</p>]]></content><author><name></name></author><category term="Thoughts"/><category term="Thoughts"/><summary type="html"><![CDATA[反正我觉得这是一个挺奇怪的标题，但是今天中午游泳的时候，我确实在思考这个问题。]]></summary></entry><entry><title type="html">MCP鉴权</title><link href="https://ifuryst.github.io/blog/2025/mcp-authorization/" rel="alternate" type="text/html" title="MCP鉴权"/><published>2025-05-12T05:30:00+00:00</published><updated>2025-05-12T05:30:00+00:00</updated><id>https://ifuryst.github.io/blog/2025/mcp-authorization</id><content type="html" xml:base="https://ifuryst.github.io/blog/2025/mcp-authorization/"><![CDATA[<p>官方新的<a href="https://modelcontextprotocol.io/specification/2025-03-26/basic/authorization#2-3-1-server-metadata-discovery-headers">修订版本</a>支持了OAuth2的鉴权方式，我们一起来看看</p> <p>首先是协议要求：</p> <ul> <li>STDIO不支持，STDIO只支持通过env传入</li> <li>SSE/Streamable HTTP应该支持（非强制性）</li> </ul> <p>MCP遵循了OAuth2的标准，主要涉及：</p> <ul> <li><a href="https://datatracker.ietf.org/doc/html/draft-ietf-oauth-v2-1-12"><strong>OAuth 2.1 IETF DRAFT</strong></a></li> <li>OAuth 2.0 Authorization Server Metadata (<a href="https://datatracker.ietf.org/doc/html/rfc8414"><strong>RFC8414</strong></a>)</li> <li>OAuth 2.0 Dynamic Client Registration Protocol (<a href="https://datatracker.ietf.org/doc/html/rfc7591"><strong>RFC7591</strong></a>)</li> </ul> <p>其中OAuth2.1还在草案阶段，还没成为正式的RFC标准。这边我们简单汇总一下OAuth相关的RFC</p> <table> <thead> <tr> <th>标准/草案</th> <th>类型</th> <th>状态</th> <th>是否核心</th> <th>简介</th> </tr> </thead> <tbody> <tr> <td>RFC 6749</td> <td>OAuth 2.0 框架</td> <td>✅ 已发布</td> <td>✅ 是</td> <td>定义了授权流程（授权码、隐式、密码、客户端凭证）和四大角色（客户端、资源拥有者、授权服务器、资源服务器）</td> </tr> <tr> <td>RFC 6750</td> <td>Bearer Token 使用</td> <td>✅ 已发布</td> <td>✅ 是</td> <td>描述如何在 HTTP 中安全使用访问令牌（Bearer Token）</td> </tr> <tr> <td>RFC 7591</td> <td>动态客户端注册</td> <td>✅ 已发布</td> <td>❌ 扩展</td> <td>允许客户端通过 API 动态注册到授权服务器</td> </tr> <tr> <td>RFC 8414</td> <td>授权服务器元数据</td> <td>✅ 已发布</td> <td>❌ 扩展</td> <td>提供 .well-known 端点用于公开服务器配置信息，支持自动发现</td> </tr> <tr> <td>draft-ietf-oauth-v2-1</td> <td>OAuth 2.1 草案</td> <td>⏳ 草案中</td> <td>✅ 拟核心</td> <td>汇总和更新 OAuth 2.0 核心内容，合并并替代 RFC 6749 和 RFC 6750，剔除不安全授权方式（如隐式授权）并强制使用 PKCE</td> </tr> </tbody> </table> <h2 id="oauth-20--21">OAuth 2.0 &amp; 2.1</h2> <h3 id="oauth-20---rfc-6749--rfc-6750">OAuth 2.0 - RFC 6749 &amp; RFC 6750</h3> <p>这边简单过一下OAuth的内容，RFC 6749，涉及了OAuth2.0的定义，我们就关注重要的</p> <ol> <li>注册Client，获得ClientID和ClientSecret</li> <li> <p>配置在Client上，需要授权的时候，Client（通常是浏览器）跳转/authorize要求用户授权</p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>GET /authorize?
  <span class="nv">response_type</span><span class="o">=</span>code&amp;
  <span class="nv">client_id</span><span class="o">=</span>abc123&amp;
  <span class="nv">redirect_uri</span><span class="o">=</span>https://client.com/callback&amp;
  <span class="nv">scope</span><span class="o">=</span><span class="nb">read </span>write&amp;
  <span class="nv">state</span><span class="o">=</span>xyz123
</code></pre></div> </div> </li> <li> <p>授权服务器重定向并带回code</p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>HTTP/1.1 302 Found
Location: https://client.com/callback?code<span class="o">=</span>SplxlOBeZQQYbYS6WxSbIA&amp;state<span class="o">=</span>xyz123
</code></pre></div> </div> </li> <li> <p>Client或者Server用授权吗code去换AccessToken和RefreshToken</p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>POST /token
Content-Type: application/x-www-form-urlencoded

<span class="nv">grant_type</span><span class="o">=</span>authorization_code&amp;
<span class="nv">code</span><span class="o">=</span>SplxlOBeZQQYbYS6WxSbIA&amp;
<span class="nv">redirect_uri</span><span class="o">=</span>https%3A%2F%2Fclient.com%2Fcallback&amp;
<span class="nv">client_id</span><span class="o">=</span>abc123&amp;
<span class="nv">client_secret</span><span class="o">=</span>secret456
</code></pre></div> </div> </li> <li> <p>使用token就可以去请求对应的资源了（根据scope决定资源范围）</p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">{</span>
  <span class="s2">"access_token"</span>: <span class="s2">"2YotnFZFEjr1zCsicMWpAA"</span>,
  <span class="s2">"token_type"</span>: <span class="s2">"Bearer"</span>,
  <span class="s2">"expires_in"</span>: 3600,
  <span class="s2">"refresh_token"</span>: <span class="s2">"tGzv3JOkF0XG5Qx2TlKWIA"</span>
<span class="o">}</span>
</code></pre></div> </div> </li> </ol> <p>RFC 6750基本就是对OAuth 2.0进行补充了，主要就是AccessToken用Bearer Token来表示（Authorization: Bearer <token>）。这里需要注意的是，不一定是JWT，很多地方用了JWT但是Bearer Token不等价于JWT，可能是JWT也可能是一串随机的字符串</token></p> <h3 id="oauth-20-authorization-server-metadata---rfc-8414">OAuth 2.0 Authorization Server Metadata - RFC 8414</h3> <p>前面提到的/authorize /token 这类端点都是固定的，或者提前约定配置好的，有些场景就不方便，因此这份RFC提供了一个自动发现的机制，有点类似OIDC中的openid-configuration</p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>GET https://auth.example.com/.well-known/oauth-authorization-server

<span class="c"># 多租户</span>
GET https://auth.example.com/.well-known/oauth-authorization-server?issuer<span class="o">=</span>https://issuer.example.com
</code></pre></div></div> <p>就是增加这个端点（就是Discovery Endpoint，.well-known/oauth-authorization-server），用于发现相关的配置，配置（就是Metadata Document，JSON格式的授权服务器元数据）可能如下：</p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">{</span>
  <span class="s2">"issuer"</span>: <span class="s2">"https://mcp-github-oauth.ifuryst.workers.dev"</span>,
  <span class="s2">"authorization_endpoint"</span>: <span class="s2">"https://mcp-github-oauth.ifuryst.workers.dev/authorize"</span>,
  <span class="s2">"token_endpoint"</span>: <span class="s2">"https://mcp-github-oauth.ifuryst.workers.dev/token"</span>,
  <span class="s2">"registration_endpoint"</span>: <span class="s2">"https://mcp-github-oauth.ifuryst.workers.dev/register"</span>,
  <span class="s2">"response_types_supported"</span>: <span class="o">[</span>
    <span class="s2">"code"</span>
  <span class="o">]</span>,
  <span class="s2">"response_modes_supported"</span>: <span class="o">[</span>
    <span class="s2">"query"</span>
  <span class="o">]</span>,
  <span class="s2">"grant_types_supported"</span>: <span class="o">[</span>
    <span class="s2">"authorization_code"</span>,
    <span class="s2">"refresh_token"</span>
  <span class="o">]</span>,
  <span class="s2">"token_endpoint_auth_methods_supported"</span>: <span class="o">[</span>
    <span class="s2">"client_secret_basic"</span>,
    <span class="s2">"client_secret_post"</span>,
    <span class="s2">"none"</span>
  <span class="o">]</span>,
  <span class="s2">"revocation_endpoint"</span>: <span class="s2">"https://mcp-github-oauth.ifuryst.workers.dev/token"</span>,
  <span class="s2">"code_challenge_methods_supported"</span>: <span class="o">[</span>
    <span class="s2">"plain"</span>,
    <span class="s2">"S256"</span>
  <span class="o">]</span>
<span class="o">}</span>
</code></pre></div></div> <table> <thead> <tr> <th>字段名</th> <th>是否必需</th> <th>类型</th> <th>说明</th> </tr> </thead> <tbody> <tr> <td>issuer</td> <td>✅ 是</td> <td>string</td> <td>授权服务器的唯一标识符（URL），必须是 https，不能带参数或 fragment</td> </tr> <tr> <td>authorization_endpoint</td> <td>✅ 是（除非不支持基于授权码的 flow）</td> <td>string</td> <td>OAuth 授权端点地址，用于获取用户授权</td> </tr> <tr> <td>token_endpoint</td> <td>✅ 是（除非只支持 implicit）</td> <td>string</td> <td>Token 端点，客户端在此获取 access token</td> </tr> <tr> <td>jwks_uri</td> <td>⛔ 可选</td> <td>string</td> <td>JWK Set 的地址，包含公钥供客户端验证 JWT 签名</td> </tr> <tr> <td>registration_endpoint</td> <td>⛔ 可选</td> <td>string</td> <td>支持动态客户端注册时用于注册客户端的端点</td> </tr> <tr> <td>scopes_supported</td> <td>⛔ 推荐</td> <td>array</td> <td>支持的 scope 列表</td> </tr> <tr> <td>response_types_supported</td> <td>✅ 是</td> <td>array</td> <td>支持的响应类型，如 code、token</td> </tr> <tr> <td>response_modes_supported</td> <td>⛔ 可选</td> <td>array</td> <td>支持的 response mode，如 query、fragment、form_post</td> </tr> <tr> <td>grant_types_supported</td> <td>⛔ 可选</td> <td>array</td> <td>支持的授权类型，如 authorization_code、client_credentials</td> </tr> <tr> <td>token_endpoint_auth_methods_supported</td> <td>⛔ 可选</td> <td>array</td> <td>token endpoint 支持的客户端认证方式，如 client_secret_basic</td> </tr> <tr> <td>token_endpoint_auth_signing_alg_values_supported</td> <td>⛔ 可选</td> <td>array</td> <td>token endpoint 使用 JWT 认证时支持的签名算法，如 RS256</td> </tr> <tr> <td>service_documentation</td> <td>⛔ 可选</td> <td>string</td> <td>开发者文档地址</td> </tr> <tr> <td>ui_locales_supported</td> <td>⛔ 可选</td> <td>array</td> <td>UI 支持的语言列表（如 zh-CN）</td> </tr> <tr> <td>op_policy_uri</td> <td>⛔ 可选</td> <td>string</td> <td>授权服务器对客户端使用数据的策略说明 URL</td> </tr> <tr> <td>op_tos_uri</td> <td>⛔ 可选</td> <td>string</td> <td>服务条款 URL</td> </tr> <tr> <td>revocation_endpoint</td> <td>⛔ 可选</td> <td>string</td> <td>token 撤销端点（见 RFC 7009）</td> </tr> <tr> <td>revocation_endpoint_auth_methods_supported</td> <td>⛔ 可选</td> <td>array</td> <td>revocation endpoint 支持的认证方式</td> </tr> <tr> <td>revocation_endpoint_auth_signing_alg_values_supported</td> <td>⛔ 可选</td> <td>array</td> <td>revocation endpoint 支持的 JWT 签名算法</td> </tr> <tr> <td>introspection_endpoint</td> <td>⛔ 可选</td> <td>string</td> <td>token 状态检查端点（见 RFC 7662）</td> </tr> <tr> <td>introspection_endpoint_auth_methods_supported</td> <td>⛔ 可选</td> <td>array</td> <td>introspection endpoint 支持的认证方式</td> </tr> <tr> <td>introspection_endpoint_auth_signing_alg_values_supported</td> <td>⛔ 可选</td> <td>array</td> <td>introspection endpoint 支持的 JWT 签名算法</td> </tr> <tr> <td>code_challenge_methods_supported</td> <td>⛔ 可选</td> <td>array</td> <td>支持的 PKCE code_challenge_method（如 S256）</td> </tr> </tbody> </table> <p>另外服务商还可以增加自定义字段</p> <h3 id="oauth-20-dynamic-client-registration-protocol---rfc-7591">OAuth 2.0 Dynamic Client Registration Protocol - RFC 7591</h3> <p>之前注册获得ClientID的步骤是手动的，这个RFC本质上就是让客户端可以自动注册自身拿到ClientID和ClientSecret，而不需要人为提前注册</p> <p>注册示例</p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>POST /register HTTP/1.1
Host: server.example.com
Content-Type: application/json

<span class="o">{</span>
  <span class="s2">"client_name"</span>: <span class="s2">"AwesomeApp"</span>,
  <span class="s2">"redirect_uris"</span>: <span class="o">[</span>
    <span class="s2">"https://awesome.example.com/oauth/callback"</span>
  <span class="o">]</span>,
  <span class="s2">"grant_types"</span>: <span class="o">[</span><span class="s2">"authorization_code"</span>, <span class="s2">"refresh_token"</span><span class="o">]</span>,
  <span class="s2">"response_types"</span>: <span class="o">[</span><span class="s2">"code"</span><span class="o">]</span>,
  <span class="s2">"scope"</span>: <span class="s2">"read write"</span>,
  <span class="s2">"token_endpoint_auth_method"</span>: <span class="s2">"client_secret_basic"</span>
<span class="o">}</span>
</code></pre></div></div> <p>可能会返回</p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">{</span>
  <span class="s2">"client_id"</span>: <span class="s2">"s6BhdRkqt3"</span>,
  <span class="s2">"client_secret"</span>: <span class="s2">"7Fjfp0ZBr1KtDRbnfVdmIw"</span>,
  <span class="s2">"registration_access_token"</span>: <span class="s2">"access-token-123"</span>,
  <span class="s2">"registration_client_uri"</span>: <span class="s2">"https://server.example.com/register/s6BhdRkqt3"</span>,
  <span class="s2">"client_id_issued_at"</span>: 1599389946,
  <span class="s2">"client_secret_expires_at"</span>: 0
<span class="o">}</span>
</code></pre></div></div> <h3 id="oauth-21">OAuth 2.1</h3> <p>对OAuth 2.0进行修订，而不是完全重写，主要差异：</p> <ul> <li>Implicit和Resource Owner Password Credentials方式因不安全被移除了</li> <li>强制所有客户端都需要使用PKCE</li> <li>推荐refresh token启用rotation（也就是刷新时会废弃旧的）</li> </ul> <p>我觉得这里最重要的明显差异就是强制使用PKCE(Proof Key for Code Exchange)，为了防止授权码被拦截重放而设计的机制，大体是:</p> <ol> <li>客户端随机生成一串字符串，这串字符串就是code_verifier</li> <li>将code_verifier进行SHA256哈希后Base64编码，就可以得到另外一串随机字符串，就是code_challenge</li> <li>客户端请求的时候就可以发送code_challenge和对应的哈希算法code_challenge_method=S256</li> <li>用户同意授权后，服务端记录code_challenge</li> <li>客户端用authorization_code换token的时候，要带上原始的code_verifier</li> <li>授权服务会对code_verifier哈希后对比，以确认是否接受请求</li> </ol> <p>通过代码看看</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">secrets</span>
<span class="kn">import</span> <span class="n">hashlib</span>
<span class="kn">import</span> <span class="n">base64</span>

<span class="k">def</span> <span class="nf">generate_code_verifier</span><span class="p">(</span><span class="n">length</span><span class="o">=</span><span class="mi">64</span><span class="p">):</span>
    <span class="c1"># PKCE 规范推荐长度在 43～128 字符之间
</span>    <span class="k">return</span> <span class="n">base64</span><span class="p">.</span><span class="nf">urlsafe_b64encode</span><span class="p">(</span><span class="n">secrets</span><span class="p">.</span><span class="nf">token_bytes</span><span class="p">(</span><span class="n">length</span><span class="p">)).</span><span class="nf">rstrip</span><span class="p">(</span><span class="sa">b</span><span class="sh">'</span><span class="s">=</span><span class="sh">'</span><span class="p">).</span><span class="nf">decode</span><span class="p">(</span><span class="sh">'</span><span class="s">utf-8</span><span class="sh">'</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">generate_code_challenge</span><span class="p">(</span><span class="n">code_verifier</span><span class="p">):</span>
    <span class="n">code_verifier_bytes</span> <span class="o">=</span> <span class="n">code_verifier</span><span class="p">.</span><span class="nf">encode</span><span class="p">(</span><span class="sh">'</span><span class="s">utf-8</span><span class="sh">'</span><span class="p">)</span>
    <span class="n">sha256_digest</span> <span class="o">=</span> <span class="n">hashlib</span><span class="p">.</span><span class="nf">sha256</span><span class="p">(</span><span class="n">code_verifier_bytes</span><span class="p">).</span><span class="nf">digest</span><span class="p">()</span>
    <span class="n">code_challenge</span> <span class="o">=</span> <span class="n">base64</span><span class="p">.</span><span class="nf">urlsafe_b64encode</span><span class="p">(</span><span class="n">sha256_digest</span><span class="p">).</span><span class="nf">rstrip</span><span class="p">(</span><span class="sa">b</span><span class="sh">'</span><span class="s">=</span><span class="sh">'</span><span class="p">).</span><span class="nf">decode</span><span class="p">(</span><span class="sh">'</span><span class="s">utf-8</span><span class="sh">'</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">code_challenge</span>

<span class="c1"># 示例
</span><span class="n">code_verifier</span> <span class="o">=</span> <span class="nf">generate_code_verifier</span><span class="p">()</span>
<span class="n">code_challenge</span> <span class="o">=</span> <span class="nf">generate_code_challenge</span><span class="p">(</span><span class="n">code_verifier</span><span class="p">)</span>

<span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">code_verifier:</span><span class="sh">"</span><span class="p">,</span> <span class="n">code_verifier</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">code_challenge:</span><span class="sh">"</span><span class="p">,</span> <span class="n">code_challenge</span><span class="p">)</span>
<span class="c1"># code_verifier: 92Foogx4d9Q5cbDbmLrz7eCHfAxX06q-6FHhmyKQ0OMcGpRbu6CWzknxCUSuvJ6b5-D_dIaJB5mHfAIfk_Qu1A
# code_challenge: GFc8vy-W93jTehp7I3Fvzma2DH5JNjnRAoktZuHtywA
</span></code></pre></div></div> <p>所以类似的请求是</p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># 发起是授权请求</span>
GET /authorize?
  <span class="nv">response_type</span><span class="o">=</span>code&amp;
  <span class="nv">client_id</span><span class="o">=</span>abc123&amp;
  <span class="nv">redirect_uri</span><span class="o">=</span>https://client.example.com/cb&amp;
  <span class="nv">code_challenge</span><span class="o">=</span>E9Melhoa2OwvFrEMTJguCHaoeK1t8URWbuGJSstw-cM&amp;
  <span class="nv">code_challenge_method</span><span class="o">=</span>S256&amp;
  <span class="nv">state</span><span class="o">=</span>xyz

<span class="c"># 换取token</span>
POST /token
Content-Type: application/x-www-form-urlencoded

<span class="nv">grant_type</span><span class="o">=</span>authorization_code&amp;
<span class="nv">code</span><span class="o">=</span>SplxlOBeZQQYbYS6WxSbIA&amp;
<span class="nv">redirect_uri</span><span class="o">=</span>https://client.example.com/cb&amp;
<span class="nv">client_id</span><span class="o">=</span>abc123&amp;
<span class="nv">code_verifier</span><span class="o">=</span>dBjftJeZ4CVP-mB92K27uhbUJU1p1r_wW1gFWFOEjXk
</code></pre></div></div> <h2 id="实操案例">实操案例</h2> <h3 id="github配置oauth-app">GitHub配置OAuth APP</h3> <div class="row mt-3"> <div class="col-sm mt-3"> <div class="col-sm mt-0 mb-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-05-12-mcp-authorization/GitHubOAuth1-480.webp 480w,/assets/img/2025-05-12-mcp-authorization/GitHubOAuth1-800.webp 800w,/assets/img/2025-05-12-mcp-authorization/GitHubOAuth1-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/2025-05-12-mcp-authorization/GitHubOAuth1.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="col-sm mt-3"> <div class="col-sm mt-0 mb-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-05-12-mcp-authorization/GitHubOAuth2-480.webp 480w,/assets/img/2025-05-12-mcp-authorization/GitHubOAuth2-800.webp 800w,/assets/img/2025-05-12-mcp-authorization/GitHubOAuth2-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/2025-05-12-mcp-authorization/GitHubOAuth2.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <div class="col-sm mt-0 mb-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-05-12-mcp-authorization/GitHubOAuth3-480.webp 480w,/assets/img/2025-05-12-mcp-authorization/GitHubOAuth3-800.webp 800w,/assets/img/2025-05-12-mcp-authorization/GitHubOAuth3-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/2025-05-12-mcp-authorization/GitHubOAuth3.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <div class="col-sm mt-0 mb-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-05-12-mcp-authorization/GitHubOAuth4-480.webp 480w,/assets/img/2025-05-12-mcp-authorization/GitHubOAuth4-800.webp 800w,/assets/img/2025-05-12-mcp-authorization/GitHubOAuth4-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/2025-05-12-mcp-authorization/GitHubOAuth4.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> </div> <p>按照上面截图方式配置，最后得到对应的Client ID和Client Secret</p> <h3 id="cf-worker部署">CF Worker部署</h3> <p>参考这里https://github.com/cloudflare/ai/tree/main/demos/remote-mcp-github-oauth</p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># 1. 初始化项目，前两步yes，最后no，因为还没配置也deploy不上去</span>
npm create cloudflare@latest <span class="nt">--</span> mcp-github-oauth <span class="nt">--template</span><span class="o">=</span>cloudflare/ai/demos/remote-mcp-github-oauth
<span class="c"># 2. 安装wrangler</span>
npm <span class="nb">install</span> <span class="nt">-g</span> wrangler
<span class="c"># 3. 配置client id 和 client secret</span>
<span class="nb">cd </span>mcp-github-oauth
wrangler secret put GITHUB_CLIENT_ID
<span class="c"># 输入GitHub Client ID，然后y</span>
wrangler secret put GITHUB_CLIENT_SECRET
<span class="c"># 输入GitHub Client Secret</span>
wrangler secret put COOKIE_ENCRYPTION_KEY
<span class="c"># 输入随机字符串，可以用openssl rand -hex 32</span>
<span class="c"># 4. 设置KV命名空间</span>
wrangler kv:namespace create <span class="s2">"OAUTH_KV"</span>
<span class="c"># 会生成对应的id，拷贝写到wrangler.jsonrc文件里的</span>
	<span class="s2">"kv_namespaces"</span>: <span class="o">[</span>
		<span class="o">{</span>
			<span class="s2">"binding"</span>: <span class="s2">"OAUTH_KV"</span>,
			<span class="s2">"id"</span>: <span class="s2">"abc123"</span>
		<span class="o">}</span>
	<span class="o">]</span>,
<span class="c"># 5. 部署到Wroker，这里会跳到浏览器登录之类的操作，最后选择好用户就可以上传</span>
npm run deploy
</code></pre></div></div> <p>相关操作截图如下</p> <div class="row mt-3"> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-05-12-mcp-authorization/MCPGitHubOAuth1-480.webp 480w,/assets/img/2025-05-12-mcp-authorization/MCPGitHubOAuth1-800.webp 800w,/assets/img/2025-05-12-mcp-authorization/MCPGitHubOAuth1-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/2025-05-12-mcp-authorization/MCPGitHubOAuth1.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <div class="col-sm mt-0 mb-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-05-12-mcp-authorization/MCPGitHubOAuth2-480.webp 480w,/assets/img/2025-05-12-mcp-authorization/MCPGitHubOAuth2-800.webp 800w,/assets/img/2025-05-12-mcp-authorization/MCPGitHubOAuth2-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/2025-05-12-mcp-authorization/MCPGitHubOAuth2.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-05-12-mcp-authorization/MCPGitHubOAuth3-480.webp 480w,/assets/img/2025-05-12-mcp-authorization/MCPGitHubOAuth3-800.webp 800w,/assets/img/2025-05-12-mcp-authorization/MCPGitHubOAuth3-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/2025-05-12-mcp-authorization/MCPGitHubOAuth3.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <div class="col-sm mt-0 mb-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-05-12-mcp-authorization/MCPGitHubOAuth4-480.webp 480w,/assets/img/2025-05-12-mcp-authorization/MCPGitHubOAuth4-800.webp 800w,/assets/img/2025-05-12-mcp-authorization/MCPGitHubOAuth4-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/2025-05-12-mcp-authorization/MCPGitHubOAuth4.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> </div> <h3 id="测试">测试</h3> <p>现在支持MCP认证的客户端比较少，cursor目前也没计划支持，我们用官方的inspector来测试</p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>npx @modelcontextprotocol/inspector@latest
</code></pre></div></div> <p>通过SSE来连接，比如 <code class="language-plaintext highlighter-rouge">https://mcp-github-oauth.ifuryst.workers.dev/sse</code>（注意：这是一个演示链接，可能已经失效）</p> <p>大体流程是：连接后因为没有认证授权所以会返回401，这个时候MCP Client会根据MCP Servers暴露的Server Metadata Discovery（在 <code class="language-plaintext highlighter-rouge">https://mcp-github-oauth.ifuryst.workers.dev/.well-known/oauth-authorization-server</code>，演示链接可能已失效）去发现认证的信息，然后跳转到对应的地址去做认证。这里会先到CF Worker上部署的这个服务的页面，然后点击确认后会跳到GitHub做实际的认证，最后跳回MCP Client的callback接口，通常是 <code class="language-plaintext highlighter-rouge">/oauth/callback</code>，比如Inspector这里是 <code class="language-plaintext highlighter-rouge">http://127.0.0.1:6274/oauth/callback</code></p> <div class="row mt-3"> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-05-12-mcp-authorization/MCPGitHubOAuth5-480.webp 480w,/assets/img/2025-05-12-mcp-authorization/MCPGitHubOAuth5-800.webp 800w,/assets/img/2025-05-12-mcp-authorization/MCPGitHubOAuth5-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/2025-05-12-mcp-authorization/MCPGitHubOAuth5.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <div class="col-sm mt-0 mb-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-05-12-mcp-authorization/MCPGitHubOAuth6-480.webp 480w,/assets/img/2025-05-12-mcp-authorization/MCPGitHubOAuth6-800.webp 800w,/assets/img/2025-05-12-mcp-authorization/MCPGitHubOAuth6-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/2025-05-12-mcp-authorization/MCPGitHubOAuth6.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-05-12-mcp-authorization/MCPGitHubOAuth7-480.webp 480w,/assets/img/2025-05-12-mcp-authorization/MCPGitHubOAuth7-800.webp 800w,/assets/img/2025-05-12-mcp-authorization/MCPGitHubOAuth7-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/2025-05-12-mcp-authorization/MCPGitHubOAuth7.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <div class="col-sm mt-0 mb-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-05-12-mcp-authorization/MCPGitHubOAuth8-480.webp 480w,/assets/img/2025-05-12-mcp-authorization/MCPGitHubOAuth8-800.webp 800w,/assets/img/2025-05-12-mcp-authorization/MCPGitHubOAuth8-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/2025-05-12-mcp-authorization/MCPGitHubOAuth8.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-05-12-mcp-authorization/MCPGitHubOAuth9-480.webp 480w,/assets/img/2025-05-12-mcp-authorization/MCPGitHubOAuth9-800.webp 800w,/assets/img/2025-05-12-mcp-authorization/MCPGitHubOAuth9-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/2025-05-12-mcp-authorization/MCPGitHubOAuth9.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> </div> <p>在浏览器整个流程相对丝滑，如果是客户端的MCP Client，通常是跳转浏览器做登录或者应用内打开外部网页做登录，这里涉及到应用本身也需要监听，因为需要对callback做处理</p> <h2 id="结论">结论</h2> <p>MCP是个年轻的协议，提出大半年，鉴权方案也是3月份新的修订才有的，这里其实存在一定的争议，有人认为这不是最佳实践，我们可以看<a href="https://github.com/modelcontextprotocol/modelcontextprotocol/issues/205">这里的讨论</a>。也就是现在其实更多是把MCP Server当作OAuth授权服务器，这样对于MCP Server的提供者是一个负担，大部分MCP Server更偏向于一个轻量的或者微服务形态的，还需要他们去集成对应的鉴权，无疑是巨大的Effort。</p> <p>基于这个，目前MCP Gateway正在开发面向端侧的鉴权体系，这样可以让MCP Gateway适应更多的场景，各类服务也可以接入MCP Gateway快速适配认证场景。</p> <p>如果你感兴趣我的开源项目，欢迎使用、反馈和任何的贡献参与</p> <p>https://github.com/mcp-ecosystem/mcp-gateway</p>]]></content><author><name></name></author><category term="AI"/><category term="AI"/><summary type="html"><![CDATA[官方新的修订版本支持了OAuth2的鉴权方式，我们一起来看看]]></summary></entry></feed>
<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.3.3">Jekyll</generator><link href="https://ifuryst.github.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://ifuryst.github.io/" rel="alternate" type="text/html" hreflang="en"/><updated>2025-10-12T03:46:08+00:00</updated><id>https://ifuryst.github.io/feed.xml</id><title type="html">ifuryst</title><subtitle>📝 &amp; 💭 </subtitle><entry><title type="html">LeoTalk · Hacker News Daily · 2025.10.12</title><link href="https://ifuryst.github.io/blog/2025/leotalk-hacker-news-daily-october-12-2025/" rel="alternate" type="text/html" title="LeoTalk · Hacker News Daily · 2025.10.12"/><published>2025-10-12T00:00:00+00:00</published><updated>2025-10-12T00:00:00+00:00</updated><id>https://ifuryst.github.io/blog/2025/leotalk-hacker-news-daily-october-12-2025</id><content type="html" xml:base="https://ifuryst.github.io/blog/2025/leotalk-hacker-news-daily-october-12-2025/"><![CDATA[<h2 id="-今日重点top-picks">🔥 今日重点（Top Picks）</h2> <ul> <li><strong>科技巨头市值蒸发7700亿美金</strong>：纳斯达克经历4月以来最大跌幅，头部科技公司遭受重创。<a href="https://www.cnbc.com/2025/10/10/tech-megacaps-market-cap-mag-7.html">CNBC</a></li> <li><strong>诺贝尔奖得主丹尼尔·卡尼曼选择辅助自杀</strong>：这位著名心理学家和经济学家在瑞士做出了这一决定。<a href="https://www.bluewin.ch/en/entertainment/nobel-prize-winner-opts-for-suicide-in-switzerland-2619460.html">Bluewin</a></li> <li><strong>微软OneDrive AI照片扫描：每年仅限3次退出</strong>：用户隐私设置受限，AI面部识别引发担忧。<a href="https://hardware.slashdot.org/story/25/10/11/0238213/microsofts-onedrive-begins-testing-face-recognizing-ai-for-photos-for-some-preview-users">Slashdot</a></li> <li><strong>澳洲航空Qantas数据泄露，500万客户受影响</strong>：黑客在赎金期限过后公布了客户敏感数据。<a href="https://www.theguardian.com/business/2025/oct/11/hackers-leak-qantas-data-containing-5-million-customer-records-after-ransom-deadline-passes">The Guardian</a></li> <li><strong>AMD与索尼为PS6重构图形管线</strong>：预示PlayStation 6将采用全新的芯片架构设计，革新游戏体验。<a href="https://arstechnica.com/gaming/2025/10/amd-and-sony-tease-new-chip-architecture-ahead-of-playstation-6/">Ars Technica</a></li> </ul> <h2 id="-ai--开发工具">📦 AI &amp; 开发工具</h2> <ul> <li><strong>如何使用编码Agent</strong>：一篇关于在2025年10月如何利用AI编码Agent的实践文章，分享了作者的经验。<a href="https://blog.fsck.com/2025/10/09/superpowers/">fsck.com</a></li> <li><strong>Windows Subsystem for FreeBSD (WSL-For-FreeBSD)</strong>：一个允许在Windows上运行FreeBSD的子系统项目，为开发者提供更多选择。<a href="https://github.com/BalajeS/WSL-For-FreeBSD">GitHub</a></li> <li><strong>Microsoft Amplifier</strong>：微软发布的一个新项目或工具，其详情和用途可在GitHub上探索。<a href="https://github.com/microsoft/amplifier">GitHub</a></li> <li><strong>AV2视频编码器</strong>：AV2视频编码器在性能上超越AV1，能降低30%的比特率，最终规范预计2025年底发布。<a href="https://videocardz.com/newz/av2-video-codec-delivers-30-lower-bitrate-than-av1-final-spec-due-in-late-2025">VideoCardz</a></li> </ul> <h2 id="-思维激荡mind-food">🧠 思维激荡（Mind Food）</h2> <ul> <li><strong>OpenAI没钱了？</strong>：一篇质疑OpenAI财务状况和商业模式的分析文章，探讨其未来的可持续性。<a href="https://platformonomics.com/2025/10/they-dont-have-the-money-openai-edition/">Platformonomics</a></li> <li><strong>Peter Thiel的“反基督”讲座</strong>：一篇解读这位科技巨头思想深层含义的文章，深入探讨其哲学与对社会的影响。<a href="https://www.theguardian.com/technology/ng-interactive/2025/oct/10/peter-thiel-antichrist-lectures">The Guardian</a></li> <li><strong>“贪婪的开发者”指控回应</strong>：DataStar团队对社区关于“贪婪开发者”指控的回应与反思。<a href="https://data-star.dev/essays/greedy_developer">data-star.dev</a></li> <li><strong>为什么Firefox是最佳移动浏览器</strong>：一篇论证Firefox在移动端优势的博客文章，探讨其隐私、定制化和性能特点。<a href="https://kelvinjps.com/blog/firefox-best-mobile-browser/">kelvinjps.com</a></li> </ul> <h2 id="-科技与社会趋势">🌐 科技与社会趋势</h2> <ul> <li><strong>美国数据中心转向燃煤发电</strong>：气候目标面临挑战，数据中心能耗问题日益突出，引发环保担忧。<a href="https://www.theregister.com/2025/10/10/datacenter_coal_power/">The Register</a></li> <li><strong>Discord漏洞暴露在线年龄验证风险</strong>：凸显互联网监管和青少年保护的挑战，呼吁更安全的验证机制。<a href="https://news.sky.com/story/discord-hack-shows-dangers-of-online-age-checks-as-internet-policing-hopes-put-to-the-test-13447618">Sky News</a></li> <li><strong>TikTok因“TikTok乐趣”移除帖子</strong>：平台内容审核标准引发争议，用户对“乐趣”的定义存在疑问。<a href="https://twitter.com/prem_thakker/status/1976786912154386828/">Twitter</a></li> <li><strong>亚马逊智能显示器广告泛滥，用户后悔购买</strong>：智能家居设备商业化过度引发消费者不满和反思。<a href="https://arstechnica.com/gadgets/2025/10/people-regret-buying-amazon-smart-displays-after-being-bombarded-with-ads/">Ars Technica</a></li> <li><strong>田纳西州男子因发布梗图被捕</strong>：涉嫌威胁枪击，保释金高达200万美元，引发言论自由与公共安全边界的争议。<a href="https://reason.com/2025/10/10/tennessee-man-arrested-gets-2-million-bond-for-posting-facebook-meme/">Reason</a></li> </ul> <h2 id="-新奇项目--show-hn">📱 新奇项目 / Show HN</h2> <ul> <li>🏥 <strong>GNU Health</strong>：一个自由和开源的健康和医院信息系统，旨在改善全球医疗服务。<a href="https://www.gnuhealth.org/about-us.html">gnuhealth.org</a></li> </ul> <h2 id="-快速浏览">🎯 快速浏览</h2> <ul> <li>🌡️ <strong>如何用物理方式烹饪鸡肉？(2020)</strong>：一篇有趣地探讨“打鸡烹饪”所需能量的旧文，充满好奇心和科学精神。<a href="https://james-simon.github.io/blog/chicken-cooking/">james-simon.github.io</a></li> <li>📺 <strong>学习Turbo Pascal VHS视频系列</strong>：一套最初以VHS形式发布的经典编程教程，带你重温早期编程时代。<a href="https://www.youtube.com/watch?v=UOtonwG3DXM">YouTube</a></li> </ul> <h2 id="-dev-tricks">🧰 Dev Tricks</h2> <ul> <li><strong>HTML <code class="language-plaintext highlighter-rouge">&lt;output&gt;</code> 标签</strong>：一个被低估的HTML标签及其在表单计算结果显示中的潜在用途。<a href="https://denodell.com/blog/html-best-kept-secret-output-tag">denodell.com</a></li> <li><strong>“Vibing”非微不足道的Ghostty功能</strong>：一篇关于软件开发中如何直观地感知并实现复杂功能的心得分享。<a href="https://mitchellh.com/writing/non-trivial-vibing">mitchellh.com</a></li> <li><strong>Java 26年变化评级</strong>：一篇回顾Java语言26年来演变的文章，评级了各种重要更新和改变。<a href="https://neilmadden.blog/2025/09/12/rating-26-years-of-java-changes/">neilmadden.blog</a></li> </ul>]]></content><author><name></name></author><category term="HNDailyReport"/><category term="HNDailyReport"/><summary type="html"><![CDATA[🔥 今日重点（Top Picks）]]></summary></entry><entry><title type="html">LeoTalk · Hacker News Daily · 2025.10.09</title><link href="https://ifuryst.github.io/blog/2025/leotalk-hacker-news-daily-october-9-2025/" rel="alternate" type="text/html" title="LeoTalk · Hacker News Daily · 2025.10.09"/><published>2025-10-09T00:00:00+00:00</published><updated>2025-10-09T00:00:00+00:00</updated><id>https://ifuryst.github.io/blog/2025/leotalk-hacker-news-daily-october-9-2025</id><content type="html" xml:base="https://ifuryst.github.io/blog/2025/leotalk-hacker-news-daily-october-9-2025/"><![CDATA[<h2 id="-今日重点top-picks">🔥 今日重点（Top Picks）</h2> <ul> <li><strong>Synology撤销第三方硬盘禁令</strong>：在NAS销售大幅下滑后，Synology反转了此前限制使用第三方硬盘的政策，回应市场呼声。<a href="https://www.guru3d.com/story/synology-reverses-policy-banning-third-party-hdds-after-nas-sales-plummet/">Guru3D</a></li> <li><strong>一人之力阻碍欧盟“聊天控制”法案</strong>：一位活动家通过邮件运动，有效阻滞了欧盟有争议的“聊天控制”法案的通过，凸显公民行动力量。<a href="https://www.politico.eu/article/one-man-spam-campaign-ravages-eu-chat-control-bill-fight-chat-control/">Politico.eu</a></li> <li><strong>数据中心支撑GDP增长</strong>：哈佛经济学家指出，若不计数据中心的贡献，2025年上半年GDP增长仅为0.1%，凸显其对经济的巨大影响。<a href="https://fortune.com/2025/10/07/data-centers-gdp-growth-zero-first-half-2025-jason-furman-harvard-economist/">Fortune</a></li> <li><strong>英格兰银行警示AI科技股泡沫</strong>：英格兰银行发出警告，称AI热潮推动的科技股存在“突然修正”的风险，可能引发市场动荡。<a href="https://www.ft.com/content/fe474cff-564c-41d2-aaf7-313636a83e5b">FT</a></li> <li><strong>百万年头骨揭示人类更早起源</strong>：一项对一百万年前头骨的研究表明，现代人类的起源可能比此前认为的更早，改写人类历史。<a href="https://www.theguardian.com/science/2025/sep/25/study-of-1m-year-old-skull-points-to-earlier-origins-of-modern-humans/">The Guardian</a></li> </ul> <h2 id="-ai--开发工具">📦 AI &amp; 开发工具</h2> <ul> <li><strong>MAME破解Hyper Neo Geo 64</strong>：经过20年努力，MAME终于实现Hyper Neo Geo 64游戏机的完整模拟，包括声音仿真。<a href="https://www.readonlymemo.com/mame-hyper-neo-geo-support-sound-emulation/">ReadOnlyMemo</a></li> <li><strong>RSS阅读器生态洞察</strong>：深入探讨当前RSS阅读器的格局，分析其发展和各类工具的现状。<a href="https://lighthouseapp.io/blog/feed-reader-deep-dive">Lighthouseapp.io</a></li> <li><strong>Julia 1.12 发布亮点</strong>：Julia 1.12 版本在性能、功能和用户体验方面带来了多项重要改进。<a href="https://julialang.org/blog/2025/10/julia-1.12-highlights/">JuliaLang</a></li> <li><strong>Gemini CLI 扩展功能上线</strong>：Google Gemini CLI 现已支持扩展，允许开发者构建和集成自定义工具，提升开发灵活性。<a href="https://blog.google/technology/developers/gemini-cli-extensions/">Google Blog</a></li> </ul> <h2 id="-思维激荡mind-food">🧠 思维激荡（Mind Food）</h2> <ul> <li><strong>他们不该读的那封邮件</strong>：一篇关于意外读取他人邮件带来的道德困境和隐私思考的个人文章。<a href="https://it-notes.dragas.net/2025/10/08/the-email-they-shouldnt-have-read/">IT-Notes</a></li> <li><strong>Ortega假说</strong>：解释了科学进步如何依赖于大量普通科学家，而非少数天才贡献的“Ortega 假说”。<a href="https://en.wikipedia.org/wiki/Ortega_hypothesis">Wikipedia</a></li> <li><strong>Kurt Got Got</strong>：Fly.io 文章反思在一次系统故障中“Kurt”的被捕获过程，并从中吸取经验教训。<a href="https://fly.io/blog/kurt-got-got/">Fly.io</a></li> </ul> <h2 id="-科技与社会趋势">🌐 科技与社会趋势</h2> <ul> <li><strong>Cory Doctorow：科技巨头利用App规避法律</strong>：作家Cory Doctorow指出美国科技卡特尔如何利用应用程序规避法律并形成垄断。<a href="https://lithub.com/how-american-tech-cartels-use-apps-to-break-the-law/">Lithub</a></li> <li><strong>法治国家不应有无根据的“聊天控制”</strong>：欧洲议会议员指出，未经怀疑的“聊天控制”在法治国家中是不可接受的禁忌。<a href="https://digitalcourage.social/@echo_pbreyer/115337976340299372">Digitalcourage.social</a></li> <li><strong>旅行黑名单的武器化</strong>：探讨旅行黑名单如何被用作政治工具，并对其对个人自由和国际关系的影响。<a href="https://papersplease.org/wp/2025/10/06/the-weaponization-of-travel-blacklists/">Papers Please</a></li> <li><strong>TiVo退出传统DVR业务</strong>：TiVo宣布将退出其传统的DVR业务，标志着流媒体时代下行业的一次重要转型。<a href="https://www.mediaplaynews.com/tivo-exiting-legacy-dvr-business/">Mediaplaynews</a></li> <li><strong>军民危机已然到来</strong>：《大西洋月刊》文章深入探讨了美国日益严重的军民关系危机及其潜在的社会和政治影响。<a href="https://www.theatlantic.com/newsletters/archive/2025/10/civil-military-crisis-trump-hegseth/684486/">The Atlantic</a></li> </ul> <h2 id="-新奇项目--show-hn">📱 新奇项目 / Show HN</h2> <ul> <li>⚙️ <a href="https://www.npmjs.com/package/@joseairosa/recall">Recall</a>：利用 Redis 为 Claude AI 提供记忆能力的工具，实现持久上下文。</li> <li>🖥️ <a href="https://www.winboat.app/">WinBoat</a>：一个允许在 Linux 上无缝运行 Windows 应用程序，提供更好集成体验的项目。</li> <li>👨‍👩‍👦 <a href="https://ohyahapp.com/">Oh Yah</a>：一款由父亲为儿子们开发的日常习惯管理应用。</li> </ul> <h2 id="-科学与健康">🔬 科学与健康</h2> <ul> <li><strong>2025年诺贝尔化学奖揭晓</strong>：提供2025年诺贝尔化学奖的获奖信息及相关科学背景的通俗介绍。<a href="https://www.nobelprize.org/prizes/chemistry/2025/popular-information/">Nobel Prize</a></li> </ul> <h2 id="-快速浏览">🎯 快速浏览</h2> <ul> <li>💰 <strong>Bob Ross画作拍卖资助公共广播</strong>：知名画家Bob Ross的画作将进行拍卖，所得款项用于资助美国公共广播事业。<a href="https://www.bbc.com/news/articles/cly10275v5zo">BBC</a></li> <li>🚗 <strong>偷我的保时捷914前必知事项</strong>：一篇幽默的文章，作者分享了偷他保时捷914之前需要了解的几件事。<a href="https://www.hagerty.com/media/advice/a-few-things-to-know-before-you-steal-my-914/">Hagerty</a></li> </ul> <h2 id="-dev-tricks">🧰 Dev Tricks</h2> <ul> <li>🐛 <strong>Go语言ARM64编译器发现Bug</strong>：Cloudflare 团队详细介绍了他们如何在Go语言ARM64编译器中发现并解决一个bug的过程。<a href="https://blog.cloudflare.com/how-we-found-a-bug-in-gos-arm64-compiler/">Cloudflare Blog</a></li> <li>⚡ <strong>Svelte为何如此之快</strong>：一篇学术论文，从技术层面深入分析并解释了Svelte框架为何能实现如此高效和快速的性能。<a href="https://chuniversiteit.nl/papers/svelte-is-fast">Chuniversiteit.nl</a></li> </ul>]]></content><author><name></name></author><category term="HNDailyReport"/><category term="HNDailyReport"/><summary type="html"><![CDATA[🔥 今日重点（Top Picks）]]></summary></entry><entry><title type="html">LeoTalk · Hacker News Daily · 2025.10.08</title><link href="https://ifuryst.github.io/blog/2025/leotalk-hacker-news-daily-october-8-2025/" rel="alternate" type="text/html" title="LeoTalk · Hacker News Daily · 2025.10.08"/><published>2025-10-08T00:00:00+00:00</published><updated>2025-10-08T00:00:00+00:00</updated><id>https://ifuryst.github.io/blog/2025/leotalk-hacker-news-daily-october-8-2025</id><content type="html" xml:base="https://ifuryst.github.io/blog/2025/leotalk-hacker-news-daily-october-8-2025/"><![CDATA[<h2 id="-今日重点top-picks">🔥 今日重点（Top Picks）</h2> <ul> <li><strong>Qualcomm收购Arduino</strong>：Qualcomm宣布收购开源硬件平台Arduino，旨在加速开发者在物联网领域的创新。<a href="https://www.qualcomm.com/news/releases/2025/10/qualcomm-to-acquire-arduino-accelerating-developers--access-to-i">Qualcomm</a></li> <li><strong>Deloitte因AI报告退款</strong>：德勤因在为澳大利亚政府撰写的44万美元报告中不当使用AI工具而被迫退款。<a href="https://www.theguardian.com/australia-news/2025/oct/06/deloitte-to-pay-money-back-to-albanese-government-after-using-ai-in-440000-report">The Guardian</a></li> <li><strong>太阳能成最便宜电力来源</strong>：一项新研究表明，太阳能已成为全球范围内最经济实惠的电力来源。<a href="https://www.surrey.ac.uk/news/solar-energy-now-worlds-cheapest-source-power-surrey-study-finds">University of Surrey</a></li> <li><strong>黄金价格首次突破4000美元</strong>：国际黄金市场创下历史新高，金价首次突破每盎司4000美元大关。<a href="https://www.wsj.com/finance/commodities-futures/gold-prices-top-4-000-for-first-time-d63ab2bd">WSJ</a></li> <li><strong>德国政府反对“聊天控制”</strong>：德国政府明确表态反对欧盟提出的“聊天控制”法案，认为其侵犯隐私。<a href="https://xcancel.com/paddi_hansen/status/1975595307800142205">Paddi Hansen</a></li> </ul> <h2 id="-ai--开发工具">📦 AI &amp; 开发工具</h2> <ul> <li><strong>Gemini 2.5计算机使用模型</strong>：Google DeepMind发布Gemini 2.5新模型，增强了AI与计算机的交互和任务执行能力。<a href="https://blog.google/technology/google-deepmind/gemini-computer-use-model/">Google DeepMind</a></li> <li><strong>Devpush：开源部署替代方案</strong>：一款开源、可自托管的部署平台，提供Vercel、Render、Netlify的替代方案。<a href="https://github.com/hunvreus/devpush">GitHub</a></li> <li><strong>Erlang ARM32 JIT编译器诞生</strong>：Erlang/OTP社区发布了针对ARM32架构的JIT编译器，提升性能。<a href="https://www.grisp.org/blog/posts/2025-10-07-jit-arm32.3">Grisp</a></li> <li><strong>Pdoc：Python项目文档生成器</strong>：一款用于自动生成Python项目API文档的工具，简化开发流程。<a href="https://pdoc.dev/">pdoc.dev</a></li> </ul> <h2 id="-思维激荡mind-food">🧠 思维激荡（Mind Food）</h2> <ul> <li><strong>Bluesky去中心化的现实</strong>：用户封禁争议揭示了Bluesky去中心化愿景与实际运作的差距。<a href="https://plus.flux.community/p/banning-controversy-reveals-blueskys">Flux Community</a></li> <li><strong>美国对AI的巨大押注</strong>：分析指出，美国经济正在将大量未来增长和发展押注于AI技术领域。<a href="https://www.ft.com/content/6cc87bd9-cb2f-4f82-99c5-c38748986a2e">FT</a></li> <li><strong>“少即是多”的递归推理</strong>：一篇探讨如何使用小型网络通过递归推理实现高效AI学习的文章。<a href="https://alexiajm.github.io/2025/09/29/tiny_recursive_models.html">AlexiaJM</a></li> </ul> <h2 id="-科技与社会趋势">🌐 科技与社会趋势</h2> <ul> <li><strong>Windows 11将强制微软账户</strong>：微软再次收紧政策，未来Windows 11可能不再支持无网络或本地账户安装。<a href="https://www.theregister.com/2025/10/07/windows_11_local_account_loophole/">The Register</a></li> <li><strong>加州强制流媒体降低广告音量</strong>：一项新法案要求Netflix和Hulu等平台降低广告音量，以改善用户体验。<a href="https://www.politico.com/news/2025/10/06/dial-it-down-california-forces-netflix-hulu-to-lower-ad-volume-00595663">Politico</a></li> <li><strong>警方监控堕胎女性引争议</strong>：法庭记录显示警方以“安全”为由监控堕胎女性，并曾考虑起诉。<a href="https://www.404media.co/police-said-they-surveilled-woman-who-had-an-abortion-for-her-safety-court-records-show-they-considered-charging-her-with-a-crime/">404 Media</a></li> <li><strong>ICE购伪基站车辆监控手机</strong>：美国移民及海关执法局（ICE）被曝购买配备伪基站的车辆，用于秘密监控手机。<a href="https://techcrunch.com/2025/10/07/ice-bought-vehicles-equipped-with-fake-cell-towers-to-spy-on-phones/">TechCrunch</a></li> <li><strong>罗宾·威廉姆斯女儿呼吁停止AI视频</strong>：罗宾·威廉姆斯的女儿请求公众停止传播其父的AI生成视频，引发AI伦理讨论。<a href="https://www.bbc.co.uk/news/articles/c0r0erqk18jo">BBC</a></li> <li><strong>加拿大法案或剥夺公民互联网访问权</strong>：一项加拿大法案可能在无搜查令的情况下，剥夺“特定人士”的互联网访问权。<a href="https://nationalpost.com/opinion/canadian-bill-would-strip-internet-access-from-specified-persons">National Post</a></li> <li><strong>Google政策威胁F-Droid开源应用商店</strong>：谷歌要求所有Android开发者验证身份的政策，可能导致开源应用商店F-Droid关闭。<a href="https://www.techdirt.com/2025/10/07/googles-requirement-for-all-android-developers-to-register-and-be-verified-threatens-to-close-down-open-source-app-store-f-droid/">Techdirt</a></li> <li><strong>3M或摆脱PFAS毒物遗产</strong>：3M公司可能正寻求摆脱其有毒化学品PFAS制造带来的负面遗产和法律纠纷。<a href="https://www.bloomberg.com/features/2025-3m-pfas-toxic-legacy-turnaround/">Bloomberg</a></li> </ul> <h2 id="-新奇项目--show-hn">📱 新奇项目 / Show HN</h2> <ul> <li><strong>Timelinize</strong>：一个本地化的数据组织工具，帮助用户私密管理来自各处的数据。<a href="https://timelinize.com/">timelinize.com</a></li> </ul> <h2 id="-科学与健康">🔬 科学与健康</h2> <ul> <li><strong>2025年诺贝尔物理学奖揭晓</strong>：<a href="https://www.nobelprize.org/prizes/physics/2025/popular-information/">Nobel Prize</a></li> <li><strong>瑞士冰川十年缩减四分之一</strong>：研究显示，自2015年以来，瑞士冰川的体积已缩减了四分之一。<a href="https://www.france24.com/en/live-news/20251001-swiss-glaciers-shrank-by-a-quarter-in-past-decade-study">France 24</a></li> </ul> <h2 id="-快速浏览">🎯 快速浏览</h2> <ul> <li>📦 <a href="https://ikeamuseum.com/en/explore/ikea-catalogue/">IKEA目录1951-2021年档案</a></li> <li>🚗 <a href="https://www.motor1.com/news/774805/ford-ceo-complains-shortage-mechanics/">机械师为何解释行业招工难</a></li> <li>💻 <a href="https://wiki.tcl-lang.org/page/Showcase">Tcl编程语言的官方案例展示</a></li> </ul> <h2 id="-dev-tricks">🧰 Dev Tricks</h2> <ul> <li>📈 <strong>“错误地”使用Rails</strong>：一篇关于如何避免Rails开发中常见误区的批判性文章。<a href="https://www.bananacurvingmachine.com/articles/you-re-doing-rails-wrong">Banana Curving Machine</a></li> <li>📜 <strong>Lua语言演进史</strong>：一份深入探讨Lua编程语言持续演进的PDF文档。<a href="https://www.lua.org/doc/cola.pdf">lua.org</a></li> <li>🔒 <strong>如何让你的邮件账户更难被封</strong>：一篇提供实用技巧，增强电子邮件账户抗封禁能力的文章。<a href="https://karboosx.net/post/PJOveGVa/become-unbannable-from-your-emailgmail">karboosx.net</a></li> </ul>]]></content><author><name></name></author><category term="HNDailyReport"/><category term="HNDailyReport"/><summary type="html"><![CDATA[🔥 今日重点（Top Picks）]]></summary></entry><entry><title type="html">LeoTalk AI周知 3: 追求差异化的最后一公里</title><link href="https://ifuryst.github.io/blog/2025/leotalk-ai-weekly-3-beyond-the-model-race-toward-t/" rel="alternate" type="text/html" title="LeoTalk AI周知 3: 追求差异化的最后一公里"/><published>2025-10-07T01:00:00+00:00</published><updated>2025-10-07T01:00:00+00:00</updated><id>https://ifuryst.github.io/blog/2025/leotalk-ai-weekly-3-beyond-the-model-race-toward-t</id><content type="html" xml:base="https://ifuryst.github.io/blog/2025/leotalk-ai-weekly-3-beyond-the-model-race-toward-t/"><![CDATA[<p>小公司不必一直追模型，而是做好差异化的最后一公里。</p> <p>目前LLM不管是闭源还是开源都已经到达了一个效果很不错的水平了，在很多Benchmark和实际应用都得到了证明。随着目前SOTA大模型Scaling Law得到的收益趋缓，AI应用升级到最新的大模型的边际收益也会变小。在实际生产中应该着重关注最后一公里的价值体现。</p> <p>这里面可以有多种价值体现方式。最常见的是结合行业或者垂直领域的知识进行应用，通过AI Agent结合后阶段（如RL）做微调，可以最大化模型能力，在应用层结合一些实际的workflow来设计和构建，可以实现真正有价值的AI应用或工作流。</p> <p>VLM也是现在备受关注的方向，甚至在Switcher/Router层面，不一定需要LLM来做，VLM可以运用的场景有很多</p> <p>如何能最大化利用现有模型能力去创造价值或者赋能业务，是企业更应该关心的。也是初创企业的机会所在，保持敏感性，用AI思维去思考每一个已经习以为常的场景。</p> <p>最后一公里是一个泛指的定义，但是确实价值最大化，性价比最高的阶段。</p> <h1 id="技术研究技术突破">技术研究/技术突破</h1> <h2 id="a16z发布人工智能消费报告">a16z发布人工智能消费报告</h2> <p>a16z发布<a href="https://a16z.com/the-ai-application-spending-report-where-startup-dollars-really-go/"><strong>The AI Application Spending Report: Where Startup Dollars Really Go</strong></a>。a16z分析了2025年6-8月间超过20万家初创公司的支出数据，从中识别出前50家AI原生应用公司（AI-native application companies）</p> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-10-07-leotalk-ai-weekly-3-beyond-the-model-race-toward-t/1759769058_1-480.webp 480w,/assets/img/2025-10-07-leotalk-ai-weekly-3-beyond-the-model-race-toward-t/1759769058_1-800.webp 800w,/assets/img/2025-10-07-leotalk-ai-weekly-3-beyond-the-model-race-toward-t/1759769058_1-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/2025-10-07-leotalk-ai-weekly-3-beyond-the-model-race-toward-t/1759769058_1.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> </div> </div> <p>榜单揭示了哪些在花钱、购买什么样的AI应用。</p> <ol> <li>横向应用（Horizontal Apps）占多数：60%横向应用，40%垂直应用： <ul> <li>通用LLM助手：OpenAI、Anthropic、Perplexity、Merlin AI</li> <li>工作区类别工具：Notion、Manus</li> <li>会议类工具：Fyxer、Happyscribe、Plaude、Otter AI、Read AI</li> <li>创意类工具（最大单一类别）：Freepik、ElevenLabs、Canva、Photoroom、Midjourney、Descript、Opus Clip、Capcut、Arcads、Tavus</li> </ul> </li> <li>垂直应用（Vertical Apps）：增强人类vs替代人类： <ul> <li>增强类（12家）：帮助员工减少重复工作，如客服、销售、HR工具等</li> <li>替代类（5家）：AI完成整个业务流程，如AI律师、AI工程师等</li> </ul> </li> <li>Vibe Coding已经进入企业级 <ul> <li>以Replit、Cursor、Lovable、Emergent为主，使得Vibe Coding从消费者端转向了企业端</li> </ul> </li> <li>从Consumer→Prosumer→Enterprise的演化路径 <ul> <li>约70%产品可以个人直接消费</li> <li>很多AI产品短时间内完成了从C端切入到企业应用</li> <li>AI产品模糊了个人工具和企业软件的界限</li> </ul> </li> </ol> <p><em>Opinion：今年应用层的增速是很大的，模型层热转向了应用层热。企业更有意愿也有更多预算投入到AI。这个趋势在2026年会持续加深，2025H2可以明显感觉到B端对于AI Agent的狂热追求，应用也进一步往垂类和私域渗透。</em></p> <h1 id="产品模型发布">产品&amp;模型发布</h1> <ul> <li><a href="https://openai.com/index/buy-it-in-chatgpt/">OpenAI推出Agentic Commerce Protocol</a>：更像是和Google的<a href="https://github.com/google-agentic-commerce/AP2">AP2</a>竞争</li> <li>DeepSeek<a href="https://api-docs.deepseek.com/news/news250929">推出</a><strong>DeepSeek-V3.2-Exp</strong>，相关<a href="https://github.com/deepseek-ai/DeepSeek-V3.2-Exp/blob/main/DeepSeek_V3_2.pdf">技术报告</a></li> <li>Thinking Machines Lab<a href="https://thinkingmachines.ai/blog/announcing-tinker/">推出</a><a href="https://thinkingmachines.ai/tinker/"><strong>Tinker</strong></a>：一个用于微调大语言模型的灵活API平台，研究者和开发者能自行控制算法与数据，系统负责分布式训练与资源管理</li> <li>Anthropic<a href="https://www.anthropic.com/engineering/building-agents-with-the-claude-agent-sdk">推出</a><strong>Claude Agent SDK</strong></li> <li>智谱AI<a href="https://z.ai/blog/glm-4.6">发布</a><a href="https://docs.z.ai/guides/llm/glm-4.6"><strong>GLM-4.6</strong></a></li> <li>Opera<a href="https://www.operaneon.com/">发布</a>Neon（AI浏览器）</li> <li>Hume AI<a href="https://www.hume.ai/blog/octave-2-launch">发布</a>多模态TTS模型Octave-2</li> </ul> <h2 id="anthropic发布claude-sonnet-45">Anthropic发布Claude Sonnet 4.5</h2> <p>Anthropic<a href="https://www.anthropic.com/news/claude-sonnet-4-5">推出</a><strong>Claude Sonnet 4.5</strong></p> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-10-07-leotalk-ai-weekly-3-beyond-the-model-race-toward-t/1759769058_2.webp-480.webp 480w,/assets/img/2025-10-07-leotalk-ai-weekly-3-beyond-the-model-race-toward-t/1759769058_2.webp-800.webp 800w,/assets/img/2025-10-07-leotalk-ai-weekly-3-beyond-the-model-race-toward-t/1759769058_2.webp-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/2025-10-07-leotalk-ai-weekly-3-beyond-the-model-race-toward-t/1759769058_2.webp" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> </div> </div> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-10-07-leotalk-ai-weekly-3-beyond-the-model-race-toward-t/1759769058_3.webp-480.webp 480w,/assets/img/2025-10-07-leotalk-ai-weekly-3-beyond-the-model-race-toward-t/1759769058_3.webp-800.webp 800w,/assets/img/2025-10-07-leotalk-ai-weekly-3-beyond-the-model-race-toward-t/1759769058_3.webp-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/2025-10-07-leotalk-ai-weekly-3-beyond-the-model-race-toward-t/1759769058_3.webp" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> </div> </div> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-10-07-leotalk-ai-weekly-3-beyond-the-model-race-toward-t/1759769059_4.webp-480.webp 480w,/assets/img/2025-10-07-leotalk-ai-weekly-3-beyond-the-model-race-toward-t/1759769059_4.webp-800.webp 800w,/assets/img/2025-10-07-leotalk-ai-weekly-3-beyond-the-model-race-toward-t/1759769059_4.webp-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/2025-10-07-leotalk-ai-weekly-3-beyond-the-model-race-toward-t/1759769059_4.webp" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> </div> </div> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-10-07-leotalk-ai-weekly-3-beyond-the-model-race-toward-t/1759769059_5.webp-480.webp 480w,/assets/img/2025-10-07-leotalk-ai-weekly-3-beyond-the-model-race-toward-t/1759769059_5.webp-800.webp 800w,/assets/img/2025-10-07-leotalk-ai-weekly-3-beyond-the-model-race-toward-t/1759769059_5.webp-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/2025-10-07-leotalk-ai-weekly-3-beyond-the-model-race-toward-t/1759769059_5.webp" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> </div> </div> <p><em>Opinion：看着是为了应对GPT-5发布会后强劲的势头。现在cc默认也是走4.5了。可以发现现在Coding模型会开始着重一个指标，最长可自主运行时间，这点上Sonnet4.5标榜了30小时。</em></p> <h2 id="openai发布sora2">OpenAI发布Sora2</h2> <p>OpenAI<a href="https://openai.com/index/sora-2/">发布</a>Sora2。同时发布了Sora APP，可以理解为AI生成视频领域的TikTok。另外这次Sora2采用了邀请制。</p> <p><em>Opinion：发布后几天内，Sora2席卷全球，自媒体狂欢，邀请码机制更是增加了FOMO心理，助推了裂变。感觉现在邀请机制属于AI产品的常用套路了，用得好确实是有助理的。Sora APP也连续登顶App Store。大家也在持续讨论Sora2是否是可行的路径，Sam也在4号在他的Blog里发了一篇文章表示OAI打算开始和IP方合作分成，进一步探索商业化路径。目前一些知名IP已经无法简单的Gen出来了。另外国内目前针对Sora和邀请码的关键词进行了全网屏蔽，原因未知。回到Sora 2的狂欢本身，很难非黑即白的去评价，不要过度狂欢，也不要视而不见，积极探索发现其背后的商业价值。</em></p> <h1 id="微软推出office-agent">微软推出Office Agent</h1> <p>微软<a href="https://www.microsoft.com/en-us/microsoft-365/blog/2025/09/29/vibe-working-introducing-agent-mode-and-office-agent-in-microsoft-365-copilot/">推出</a>Office Agent，在Word，Excel中可以有Agent模式了（这是一个其他AI Agent产品很早就实现的功能）</p> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-10-07-leotalk-ai-weekly-3-beyond-the-model-race-toward-t/1759769059_6.webp-480.webp 480w,/assets/img/2025-10-07-leotalk-ai-weekly-3-beyond-the-model-race-toward-t/1759769059_6.webp-800.webp 800w,/assets/img/2025-10-07-leotalk-ai-weekly-3-beyond-the-model-race-toward-t/1759769059_6.webp-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/2025-10-07-leotalk-ai-weekly-3-beyond-the-model-race-toward-t/1759769059_6.webp" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> </div> </div> <p>另外Nadlla也宣布自己会将一些对外的事务转移由CCO负责，自己专注于重视内部的RD。MC在Office上的竞争日益激烈，在数据中心层面也面临了越来越激烈的竞争，甚至合作伙伴OAI都要自己建数据中心了</p> <p><em>Opinion：微软的AI进度和成功在MAG7里不是很好，更多还是在数据中心和云服务（包括AI推理）层面的收入，Office结合AI包括定价策略的调整和最终结果都表明用户不太买账。微软还需要在AI上持续投入和发力。相比之下Google现在已经慢慢跟上来并在多个方面实现反超了。</em></p> <h2 id="comet免费使用">Comet免费使用</h2> <p>Perplexity<a href="https://x.com/perplexity_ai/status/1973795224960032857">宣布</a>Comet（AI浏览器）可免费使用了，原来只能付费用户使用</p> <p><em>Opinion：Chrome已经在US开始试点侧边栏AI功能了，标志着AI浏览器下半场开始了。AI浏览器是未来很重要的一个流量入口，期待各家持续竞争下能产出一些对普通用户有价值的产品或者新的交互形态</em></p> <h1 id="热点论文">热点论文</h1> <ul> <li><a href="https://arxiv.org/abs/2510.02250"><strong>The Unreasonable Effectiveness of Scaling Agents for Computer Use</strong></a></li> <li><a href="https://arxiv.org/abs/2510.00510"><strong>JoyAgent-JDGenie: Technical Report on the GAIA</strong></a></li> <li><a href="https://arxiv.org/abs/2510.02283"><strong>Self-Forcing++: Towards Minute-Scale High-Quality Video Generation</strong></a></li> </ul> <h1 id="其他阅读">其他阅读</h1> <ul> <li><a href="https://www.anthropic.com/engineering/effective-context-engineering-for-ai-agents">https://www.anthropic.com/engineering/effective-context-engineering-for-ai-agents</a></li> <li><a href="https://thinkingmachines.ai/blog/modular-manifolds/"><strong>Modular Manifolds</strong></a>：探讨了如何用流形（manifold）约束和几何优化的视角来重新思考神经网络训练</li> <li><a href="https://thinkingmachines.ai/blog/lora/"><strong>LoRA Without Regret</strong></a>：探讨了LoRA的实际权衡与取舍，并提供了关于超参数选择、秩（rank）设定以及与其他技术结合使用的实用指导</li> <li><a href="https://github.com/PicoTrex/Awesome-Nano-Banana-images"><strong>Awesome-Nano-Banana-images</strong></a>：很多Nano-banana的使用方式展示</li> <li><a href="/273da74ef0458051bf22e86a1a0a5c7d"><strong>Building with Cursor (public)</strong></a>：Cursor内部针对非工程的新人Onboarding的指导</li> <li>微软<a href="https://azure.microsoft.com/en-us/blog/introducing-microsoft-agent-framework/">推出</a><a href="https://github.com/microsoft/agent-framework"><strong>Agent Framework</strong></a>：A framework for building, orchestrating and deploying AI agents and multi-agent workflows with support for Python and .NET.</li> <li><a href="https://hbr.org/2025/09/ai-generated-workslop-is-destroying-productivity">AI-Generated “Workslop” Is Destroying Productivity</a></li> <li><a href="https://www.theinformation.com/articles/openais-first-half-results-4-3-billion-sales-2-5-billion-cash-burn">OpenAI上半年43亿美元营收，在RD上投入了25亿美元</a></li> </ul>]]></content><author><name></name></author><category term="AI"/><category term="AI"/><category term="Tech"/><category term="LeoTalkAIWeekly"/><summary type="html"><![CDATA[小公司不必一直追模型，而是做好差异化的最后一公里。]]></summary></entry><entry><title type="html">LeoTalk · Hacker News Daily · 2025.10.04</title><link href="https://ifuryst.github.io/blog/2025/leotalk-hacker-news-daily-october-4-2025/" rel="alternate" type="text/html" title="LeoTalk · Hacker News Daily · 2025.10.04"/><published>2025-10-04T00:00:00+00:00</published><updated>2025-10-04T00:00:00+00:00</updated><id>https://ifuryst.github.io/blog/2025/leotalk-hacker-news-daily-october-4-2025</id><content type="html" xml:base="https://ifuryst.github.io/blog/2025/leotalk-hacker-news-daily-october-4-2025/"><![CDATA[<h2 id="-今日重点top-picks">🔥 今日重点（Top Picks）</h2> <ul> <li><strong>Apple下架ICE追踪应用</strong>：在美国司法部压力下，Apple从App Store移除ICEBlock等移民追踪应用，引发隐私讨论。(<a href="https://www.foxbusiness.com/politics/apple-takes-down-ice-tracking-app-after-pressure-from-ag-bondi">Fox Business</a>、<a href="https://techcrunch.com/2025/10/03/apple-removes-iceblock-and-similar-tracking-apps-from-the-app-store/">TechCrunch</a>)</li> <li><strong>微软拟用自研芯片替代AMD/Nvidia GPU</strong>：微软CTO表示，未来大部分AI芯片将转向内部自研，以减少对外部供应商的依赖。(<a href="https://www.cnbc.com/2025/10/01/microsoft-wants-to-mainly-use-its-own-ai-chips-in-the-future.html">CNBC</a>)</li> <li><strong>AI泡沫迹象：企业债务攀升</strong>：有迹象表明AI领域的投资泡沫可能正在形成，企业负债水平显著增加。(<a href="https://www.axios.com/2025/10/03/ai-bubble-meta-oracle-microsoft">Axios</a>)</li> </ul> <h2 id="-ai--开发工具">📦 AI &amp; 开发工具</h2> <ul> <li><strong>Python PEP 810 – 显式惰性导入</strong>：新的Python增强提案，旨在规范和优化模块的惰性加载。(<a href="https://pep-previews--4622.org.readthedocs.build/pep-0810/">PEP-previews</a>)</li> <li><strong>Blender 4.5 LTS 发布</strong>：广受欢迎的开源3D创作套件发布长期支持版本，带来多项性能与功能改进。(<a href="https://lwn.net/Articles/1036262/">LWN.net</a>)</li> <li><strong>Gmail支持端到端加密邮件</strong>：Google Workspace更新，允许用户向任意邮箱发送端到端加密邮件。(<a href="https://workspaceupdates.googleblog.com/2025/10/send-gmail-end-to-end-encrypted-emails-in-gmail.html">Google Workspace Updates</a>)</li> </ul> <h2 id="-思维激荡mind-food">🧠 思维激荡（Mind Food）</h2> <ul> <li><strong>社恐并非只是渴望被喜欢</strong>：探讨社交焦虑的深层原因，超越简单的被认可需求。(<a href="https://chrislakin.blog/p/social-anxiety">chrislakin.blog</a>)</li> <li><strong>赞美RSS与受控信息流</strong>：文章呼吁回归RSS等受控信息订阅方式，以对抗算法推荐的信息过载。(<a href="https://blog.burkert.me/posts/in_praise_of_syndication/">blog.burkert.me</a>)</li> <li><strong>OpenAI只是又一家无聊绝望的AI初创公司？</strong>：一篇对OpenAI及其未来发展持批判态度的评论文章。(<a href="https://www.wheresyoured.at/sora2-openai/">wheresyoured.at</a>)</li> <li><strong>数字身份：资本主义监控的新枷锁</strong>：批判性探讨数字身份系统可能带来的隐私与自由问题。(<a href="https://theslowburningfuse.wordpress.com/2025/09/26/digital-id-the-new-chains-of-capitalist-surveillance/">The Slow Burning Fuse</a>)</li> <li><strong>你应当保持担忧</strong>：一篇警示人们对当前某些趋势保持警惕的思考文章。(<a href="https://dlo.me/archives/2025/10/03/you-should-be-worried/">dlo.me</a>)</li> <li><strong>我们应接受有瑕疵的技术</strong>：思考技术发展中“完美”的悖论，并倡导接受技术固有的不完美。(<a href="https://entropicthoughts.com/you-want-technology-with-warts">entropicthoughts.com</a>)</li> <li><strong>教老年人使用iPhone的痛苦经历</strong>：一位用户分享了教老年人使用智能手机的挑战与思考。(<a href="https://forums.macrumors.com/threads/i-spent-the-day-trying-to-teach-seniors-how-to-use-an-iphone-and-it-was-a-nightmare.2468117/">MacRumors Forums</a>)</li> </ul> <h2 id="-科技与社会趋势">🌐 科技与社会趋势</h2> <ul> <li><strong>德国必须坚决反对聊天控制中的客户端扫描</strong>：Signal呼吁德国政府抵制欧盟提案中对加密通信进行客户端扫描的要求，以保护用户隐私。(<a href="https://signal.org/blog/pdfs/germany-chat-control.pdf">Signal.org</a>)</li> <li><strong>Anduril与Palantir战场通信系统存在缺陷</strong>：一份陆军备忘录指出Anduril和Palantir联合开发的下一代指挥控制系统存在严重缺陷。(<a href="https://www.cnbc.com/2025/10/03/anduril-palantir-ngc2-deep-flaws-army.html">CNBC</a>)</li> <li><strong>瑞典要求2026年前实现离线银行卡支付</strong>：瑞典央行发布通知，要求银行和支付服务提供商在特定日期前确保离线卡支付能力。(<a href="https://www.riksbank.se/en-gb/press-and-published/notices-and-press-releases/press-releases/2025/offline-card-payments-should-be-possible-no-later-than-1-july-2026/">Riksbank.se</a>)</li> <li><strong>ICE计划建立24/7社交媒体监控团队</strong>：美国移民及海关执法局（ICE）寻求合同建立全天候社交媒体监控能力。(<a href="https://www.wired.com/story/ice-social-media-surveillance-24-7-contract/">Wired</a>)</li> <li><strong>经济学博士就业市场崩溃</strong>：分析文章指出经济学博士就业市场面临严峻挑战。(<a href="https://www.chrisbrunet.com/p/the-collapse-of-the-econ-phd-job">chrisbrunet.com</a>)</li> <li><strong>欧洲不能再忽视俄罗斯的攻击</strong>：一篇评论文章指出欧洲正遭受俄罗斯的混合战争攻击，且不应再对此视而不见。(<a href="https://www.worldpoliticsreview.com/europe-russia-drones-hybrid-war/">World Politics Review</a>)</li> </ul> <h2 id="-新奇项目--show-hn">📱 新奇项目 / Show HN</h2> <ul> <li>🖼️ <strong>Niri – 一个可滚动的平铺Wayland合成器</strong>：一个新的开源项目，为Wayland桌面环境带来独特的平铺窗口管理体验。(<a href="https://github.com/YaLTeR/niri">GitHub</a>)</li> <li>🖥️ <strong>FyneDesk: 用Go语言编写的Linux桌面环境</strong>：一个用Fyne GUI库开发的轻量级、完整的Linux桌面环境项目。(<a href="https://github.com/FyshOS/fynedesk">GitHub</a>)</li> <li>🎮 <strong>将乐高Game Boy变成可玩设备</strong>：一位创作者成功将乐高Game Boy模型改造为实际可运行的游戏机。(<a href="https://blog.nataliethenerd.com/i-turned-the-lego-game-boy-into-a-working-game-boy-part-1/">blog.nataliethenerd.com</a>)</li> <li>🌐 <strong>Webbol: 用COBOL编写的极简静态Web服务器</strong>：一个新颖的开源项目，用古老的COBOL语言实现了一个简单的Web服务器。(<a href="https://github.com/jmsdnns/webbol">GitHub</a>)</li> </ul> <h2 id="-科学与健康">🔬 科学与健康</h2> <ul> <li>🐜 <strong>苏联核掩体中被困蚂蚁生存数年</strong>：研究发现，在极端环境下，一群被困在核掩体中的蚂蚁通过特殊方式存活了多年。(<a href="https://www.sciencealert.com/ants-trapped-in-an-old-soviet-nuclear-bunker-survived-for-years-by-turning-on-their-own">ScienceAlert</a>)</li> </ul> <h2 id="-快速浏览">🎯 快速浏览</h2> <ul> <li>🗺️ <strong>法罗群岛摄影集</strong>：一系列令人惊叹的法罗群岛风光照片。(<a href="https://photoblog.nk412.com/Faroe2025/Faroes/n-cPCNFr">photoblog.nk412.com</a>)</li> </ul> <h2 id="-dev-tricks">🧰 Dev Tricks</h2> <ul> <li>🚀 <strong>Fp8性能提升100 TFLOPS</strong>：在Triton中，FP8模型当内核名称包含”cutlass”时，运行速度可提升约100 TFLOPS。(<a href="https://github.com/triton-lang/triton/pull/7298">GitHub/Triton</a>)</li> <li>❌ <strong>取消异步Rust任务</strong>：深入探讨在Rust异步编程中如何有效取消正在运行的任务。(<a href="https://sunshowers.io/posts/cancelling-async-rust/">sunshowers.io</a>)</li> <li>📚 <strong>Stdlib: 技术领导力框架、模板与指南库</strong>：为技术领导者提供的实用资源集合，涵盖框架、模板和指导。(<a href="https://debuggingleadership.com/stdlib">debuggingleadership.com</a>)</li> </ul>]]></content><author><name></name></author><category term="HNDailyReport"/><category term="HNDailyReport"/><summary type="html"><![CDATA[🔥 今日重点（Top Picks）]]></summary></entry><entry><title type="html">大模型上下文工程实践指南-第5章：检索增强生成</title><link href="https://ifuryst.github.io/blog/2025/ce101-5-rag/" rel="alternate" type="text/html" title="大模型上下文工程实践指南-第5章：检索增强生成"/><published>2025-10-01T00:00:00+00:00</published><updated>2025-10-01T00:00:00+00:00</updated><id>https://ifuryst.github.io/blog/2025/ce101-5-rag</id><content type="html" xml:base="https://ifuryst.github.io/blog/2025/ce101-5-rag/"><![CDATA[<h1 id="51-rag基础与原理">5.1 RAG基础与原理</h1> <h2 id="511-rag基础概念">5.1.1 RAG基础概念</h2> <p>检索增强生成（RAG，Retrieval-Augmented Generation）是由Facebook（现Meta） AI Research在2020年的一篇<a href="https://arxiv.org/abs/2005.11401">论文</a>中出的一个技术，提出的原因是大语言模型（LLM）虽然在各种任务上表现优异，但由于<strong>知识存储在参数中</strong>，<strong>无法及时更新且易出现幻觉（Hallucination）</strong>；因此引入外部可检索的非参数化记忆，并将检索结果与模型结合，从而提升知识密集型任务的准确性与可追溯性。</p> <p>简单的人话表述就是，大模型需要外部的信息来帮助决策，提前将文档通过一些手段（分块、向量化等）存起来后，查询的时候可以在这些内容中搜索辅助大模型进行最终的回答，整个流程下来就是RAG要做的一个事情。</p> <p>RAG能流行是因为其解决了这么几个问题：</p> <ul> <li><strong>解决推理使用的是过时的训练语料库</strong>：尤其针对一些对时间较为敏感的数据，以及一些个人/企业知识库需要最新的</li> <li><strong>缓解幻觉（Hallucination）</strong>：RAG可以极强的缓解幻觉，这个核心还是因为模型基于上下文进行推理的过程可以产生更加可靠的结果</li> <li><strong>通用模型专业化</strong>：尤其针对垂直领域时，通用模型权重过于分散，在搭配该领域的知识库后，可以有效提升专业化，提高结果的可靠性</li> </ul> <p>我们采用Langchain官方这个<a href="https://python.langchain.com/docs/tutorials/rag/">教程</a>里的图演示RAG是怎么运作的：</p> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-10-01-ce101-5-rag/1759293252_1-480.webp 480w,/assets/img/2025-10-01-ce101-5-rag/1759293252_1-800.webp 800w,/assets/img/2025-10-01-ce101-5-rag/1759293252_1-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/2025-10-01-ce101-5-rag/1759293252_1.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> </div> </div> <p>文档通过这个流程进行分块、向量化和存储。然后到查询环节：</p> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-10-01-ce101-5-rag/1759293252_2-480.webp 480w,/assets/img/2025-10-01-ce101-5-rag/1759293252_2-800.webp 800w,/assets/img/2025-10-01-ce101-5-rag/1759293252_2-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/2025-10-01-ce101-5-rag/1759293252_2.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> </div> </div> <p>召回Top K的结果，结合提示词给到大模型做最后的输出。下面是一个简单的Demo：</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">logging</span>
<span class="kn">from</span> <span class="n">langchain_openai</span> <span class="kn">import</span> <span class="n">ChatOpenAI</span><span class="p">,</span> <span class="n">OpenAIEmbeddings</span>
<span class="kn">from</span> <span class="n">langchain.chains</span> <span class="kn">import</span> <span class="n">RetrievalQA</span>
<span class="kn">from</span> <span class="n">langchain.text_splitter</span> <span class="kn">import</span> <span class="n">CharacterTextSplitter</span>
<span class="kn">from</span> <span class="n">langchain_community.vectorstores</span> <span class="kn">import</span> <span class="n">FAISS</span>

<span class="c1"># 配置日志格式
</span>
<span class="n">logging</span><span class="p">.</span><span class="nf">basicConfig</span><span class="p">(</span>
<span class="n">level</span><span class="o">=</span><span class="n">logging</span><span class="p">.</span><span class="n">INFO</span><span class="p">,</span>
<span class="nb">format</span><span class="o">=</span><span class="sh">"</span><span class="s">%(asctime)s [%(levelname)s] %(message)s</span><span class="sh">"</span><span class="p">,</span>
<span class="p">)</span>

<span class="c1"># Step 1: 准备文档
</span>
<span class="n">docs</span> <span class="o">=</span> <span class="p">[</span>
<span class="sh">"</span><span class="s">Leo 发明了一种新的编程语言，名字叫做 CatLang。</span><span class="sh">"</span><span class="p">,</span>
<span class="sh">"</span><span class="s">CatLang 的语法非常简单，所有函数都以 </span><span class="sh">'</span><span class="s">喵</span><span class="sh">'</span><span class="s"> 开头。</span><span class="sh">"</span><span class="p">,</span>
<span class="sh">"</span><span class="s">在 2025 年，Leo 还发布了一个框架叫做 PurrNet，用于分布式 AI 计算。</span><span class="sh">"</span><span class="p">,</span>
<span class="sh">"</span><span class="s">PurrNet 的核心是通过小猫节点来进行任务调度，每个节点代号是 Kitten。</span><span class="sh">"</span><span class="p">,</span>
<span class="p">]</span>
<span class="n">logging</span><span class="p">.</span><span class="nf">info</span><span class="p">(</span><span class="sh">"</span><span class="s">准备文档完成，共 %d 条</span><span class="sh">"</span><span class="p">,</span> <span class="nf">len</span><span class="p">(</span><span class="n">docs</span><span class="p">))</span>

<span class="c1"># Step 2: 文本切分（可选）
</span>
<span class="n">splitter</span> <span class="o">=</span> <span class="nc">CharacterTextSplitter</span><span class="p">(</span><span class="n">chunk_size</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">chunk_overlap</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">texts</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">d</span> <span class="ow">in</span> <span class="n">docs</span><span class="p">:</span>
<span class="n">chunks</span> <span class="o">=</span> <span class="n">splitter</span><span class="p">.</span><span class="nf">split_text</span><span class="p">(</span><span class="n">d</span><span class="p">)</span>
<span class="n">texts</span><span class="p">.</span><span class="nf">extend</span><span class="p">(</span><span class="n">chunks</span><span class="p">)</span>
<span class="n">logging</span><span class="p">.</span><span class="nf">info</span><span class="p">(</span><span class="sh">"</span><span class="s">文档切分: 原文=%s -&gt; %d 个切片</span><span class="sh">"</span><span class="p">,</span> <span class="n">d</span><span class="p">,</span> <span class="nf">len</span><span class="p">(</span><span class="n">chunks</span><span class="p">))</span>
<span class="n">logging</span><span class="p">.</span><span class="nf">info</span><span class="p">(</span><span class="sh">"</span><span class="s">所有切分后的文本总数: %d</span><span class="sh">"</span><span class="p">,</span> <span class="nf">len</span><span class="p">(</span><span class="n">texts</span><span class="p">))</span>

<span class="c1"># Step 3: 向量化 &amp; 建立向量数据库
</span>
<span class="n">embeddings</span> <span class="o">=</span> <span class="nc">OpenAIEmbeddings</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="sh">"</span><span class="s">text-embedding-3-small</span><span class="sh">"</span><span class="p">)</span>
<span class="n">logging</span><span class="p">.</span><span class="nf">info</span><span class="p">(</span><span class="sh">"</span><span class="s">开始向量化...</span><span class="sh">"</span><span class="p">)</span>
<span class="n">vectorstore</span> <span class="o">=</span> <span class="n">FAISS</span><span class="p">.</span><span class="nf">from_texts</span><span class="p">(</span><span class="n">texts</span><span class="p">,</span> <span class="n">embeddings</span><span class="p">)</span>
<span class="n">logging</span><span class="p">.</span><span class="nf">info</span><span class="p">(</span><span class="sh">"</span><span class="s">向量数据库建立完成</span><span class="sh">"</span><span class="p">)</span>

<span class="c1"># Step 4: 构建 RAG QA Chain
</span>
<span class="n">retriever</span> <span class="o">=</span> <span class="n">vectorstore</span><span class="p">.</span><span class="nf">as_retriever</span><span class="p">(</span><span class="n">search_type</span><span class="o">=</span><span class="sh">"</span><span class="s">similarity</span><span class="sh">"</span><span class="p">,</span> <span class="n">search_kwargs</span><span class="o">=</span><span class="p">{</span><span class="sh">"</span><span class="s">k</span><span class="sh">"</span><span class="p">:</span> <span class="mi">2</span><span class="p">})</span>
<span class="n">llm</span> <span class="o">=</span> <span class="nc">ChatOpenAI</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="sh">"</span><span class="s">gpt-4o-mini</span><span class="sh">"</span><span class="p">)</span>
<span class="n">qa</span> <span class="o">=</span> <span class="n">RetrievalQA</span><span class="p">.</span><span class="nf">from_chain_type</span><span class="p">(</span><span class="n">llm</span><span class="o">=</span><span class="n">llm</span><span class="p">,</span> <span class="n">retriever</span><span class="o">=</span><span class="n">retriever</span><span class="p">)</span>
<span class="n">logging</span><span class="p">.</span><span class="nf">info</span><span class="p">(</span><span class="sh">"</span><span class="s">RAG QA Chain 构建完成</span><span class="sh">"</span><span class="p">)</span>

<span class="c1"># Step 5: 提问
</span>
<span class="n">query</span> <span class="o">=</span> <span class="sh">"</span><span class="s">什么是CatLang？</span><span class="sh">"</span>
<span class="n">logging</span><span class="p">.</span><span class="nf">info</span><span class="p">(</span><span class="sh">"</span><span class="s">开始提问: %s</span><span class="sh">"</span><span class="p">,</span> <span class="n">query</span><span class="p">)</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">qa</span><span class="p">.</span><span class="nf">run</span><span class="p">(</span><span class="n">query</span><span class="p">)</span>

<span class="c1"># 检索过程可视化（教学用）
</span>
<span class="n">logging</span><span class="p">.</span><span class="nf">info</span><span class="p">(</span><span class="sh">"</span><span class="s">检索到的相关文档（Top 2）:</span><span class="sh">"</span><span class="p">)</span>
<span class="n">retrieved_docs</span> <span class="o">=</span> <span class="n">retriever</span><span class="p">.</span><span class="nf">get_relevant_documents</span><span class="p">(</span><span class="n">query</span><span class="p">)</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">doc</span> <span class="ow">in</span> <span class="nf">enumerate</span><span class="p">(</span><span class="n">retrieved_docs</span><span class="p">,</span> <span class="mi">1</span><span class="p">):</span>
<span class="n">logging</span><span class="p">.</span><span class="nf">info</span><span class="p">(</span><span class="sh">"</span><span class="s">文档 %d: %s</span><span class="sh">"</span><span class="p">,</span> <span class="n">i</span><span class="p">,</span> <span class="n">doc</span><span class="p">.</span><span class="n">page_content</span><span class="p">)</span>

<span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="se">\n</span><span class="s">====== 最终结果 ======</span><span class="sh">"</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">问题:</span><span class="sh">"</span><span class="p">,</span> <span class="n">query</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">回答:</span><span class="sh">"</span><span class="p">,</span> <span class="n">result</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">=====================</span><span class="se">\n</span><span class="sh">"</span><span class="p">)</span>

</code></pre></div></div> <p>这是一个很简单的例子，我随便虚构了一些大模型不可能“知道”的内容，这样可以避免大模型作弊，然后写死了，运行后输出如下：</p> <div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code>2025-09-21 22:25:21,127 <span class="o">[</span>INFO] 准备文档完成，共 4 条
2025-09-21 22:25:21,127 <span class="o">[</span>INFO] 文档切分: 原文<span class="o">=</span>Leo 发明了一种新的编程语言，名字叫做 CatLang。 -&gt; 1 个切片
2025-09-21 22:25:21,127 <span class="o">[</span>INFO] 文档切分: 原文<span class="o">=</span>CatLang 的语法非常简单，所有函数都以 <span class="s1">'喵'</span> 开头。 -&gt; 1 个切片
2025-09-21 22:25:21,127 <span class="o">[</span>INFO] 文档切分: 原文<span class="o">=</span>在 2025 年，Leo 还发布了一个框架叫做 PurrNet，用于分布式 AI 计算。 -&gt; 1 个切片
2025-09-21 22:25:21,127 <span class="o">[</span>INFO] 文档切分: 原文<span class="o">=</span>PurrNet 的核心是通过小猫节点来进行任务调度，每个节点代号是 Kitten。 -&gt; 1 个切片
2025-09-21 22:25:21,127 <span class="o">[</span>INFO] 所有切分后的文本总数: 4
2025-09-21 22:25:21,335 <span class="o">[</span>INFO] 开始向量化...
2025-09-21 22:25:23,180 <span class="o">[</span>INFO] HTTP Request: POST https://api.openai.com/v1/embeddings <span class="s2">"HTTP/1.1 200 OK"</span>
2025-09-21 22:25:23,230 <span class="o">[</span>INFO] Loading faiss.
2025-09-21 22:25:23,279 <span class="o">[</span>INFO] Successfully loaded faiss.
2025-09-21 22:25:23,285 <span class="o">[</span>INFO] 向量数据库建立完成
2025-09-21 22:25:23,388 <span class="o">[</span>INFO] RAG QA Chain 构建完成
2025-09-21 22:25:23,388 <span class="o">[</span>INFO] 开始提问: 什么是CatLang？
2025-09-21 22:25:24,608 <span class="o">[</span>INFO] HTTP Request: POST https://api.openai.com/v1/embeddings <span class="s2">"HTTP/1.1 200 OK"</span>
2025-09-21 22:25:27,366 <span class="o">[</span>INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions <span class="s2">"HTTP/1.1 200 OK"</span>

2025-09-21 22:25:27,392 <span class="o">[</span>INFO] 检索到的相关文档（Top 2）:
2025-09-21 22:25:29,062 <span class="o">[</span>INFO] HTTP Request: POST https://api.openai.com/v1/embeddings <span class="s2">"HTTP/1.1 200 OK"</span>
2025-09-21 22:25:29,064 <span class="o">[</span>INFO] 文档 1: Leo 发明了一种新的编程语言，名字叫做 CatLang。
2025-09-21 22:25:29,065 <span class="o">[</span>INFO] 文档 2: CatLang 的语法非常简单，所有函数都以 <span class="s1">'喵'</span> 开头。

<span class="o">======</span> 最终结果 <span class="o">======</span>
问题: 什么是CatLang？
回答: CatLang是一种由Leo发明的新编程语言，其语法非常简单，所有函数都以“喵”开头。
<span class="o">=====================</span>
</code></pre></div></div> <p>这边我做了一个Top K搜索的模拟，实际上是不会打印的，这个简单的Demo让我们对RAG有一个初步的概念。总体而言，RAG是为了提高效果的技术，其结合文档检索，提供了合适模型的上下文，成为上下文工程中的核心技术之一。接下去我们来看一下RAG的基础架构和流程</p> <h2 id="512-架构与工作流程">5.1.2 架构与工作流程</h2> <p>接下去我们来看看RAG相关的架构和流程，这边我画了一张RAG架构图：</p> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-10-01-ce101-5-rag/1759293252_3-480.webp 480w,/assets/img/2025-10-01-ce101-5-rag/1759293252_3-800.webp 800w,/assets/img/2025-10-01-ce101-5-rag/1759293252_3-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/2025-10-01-ce101-5-rag/1759293252_3.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> </div> </div> <p>这是一个比较完整的RAG架构图，包含了流程中的一些关键节点，我们不需要马上理解每个环节，后面我们会陆续提到每个环节里的内容。</p> <p>RAG的基础架构相对简单，主要分为三个阶段：</p> <ol> <li><strong>查询（Query）</strong>：输入，通常为用户的查询或者问题等</li> <li><strong>检索（Retriever）</strong>：从相关知识库中获得与用户问题相关性最高的文档（Top K）</li> <li><strong>生成（Generation）</strong>：根据Query和检索得到的文档，生成高质量的回答</li> </ol> <p>下面是一个RAG实施的全过程：</p> <ol> <li>数据通过合理的分块（chunking），每块分别做向量化（embedding）后存到向量数据库</li> <li>查询进来后，将查询问题也通过同样的方式向量化后，去到向量数据库内做相似性搜索</li> <li>将搜索得到的top-k文档块的原始数据拼接后放在上下文中一起发送给大语言模型</li> <li>大语言模型基于响应的数据做最后的结果生成</li> </ol> <p>这样有了原始数据的参考，大模型就有了参照物，最终给出的答案也会更加稳定，避免自由发挥情况下容易产生幻觉或产生过时数据的情况发生。在开始深入RAG之前，我们可以先来了解一下检索方式，这有助于我们理解RAG里一个很核心的概念，检索。</p> <h2 id="513-检索方式">5.1.3 检索方式</h2> <p>在自然语言处理中有文本检索技术，分为：</p> <ol> <li>稀疏文本检索（Sparse Retrieval）</li> <li>稠密文本检索（Dense Retrieval）</li> </ol> <p>在现行的RAG语境下，更多是使用了向量化搜索，也就是稠密文本检索的方式。但是随着RAG应用的推广和普及，目前越来越多应用中会将两个检索方式结合起来使用，这个在下一节中也会了解到。现在我们先来了解一下这两种检索方式的原理和差异。</p> <h3 id="稀疏文本检索sparse-retrieval">稀疏文本检索（Sparse Retrieval）</h3> <p>原理是<strong>基于词频（Term Frequency）等显式词项统计信息，使用稀疏向量（Sparse Vector）表示文本，使用向量相似度进行匹配，返回最相关的文档</strong>。那么什么是稀疏向量呢？简单说就是大部分维度为0的向量。简单举个例子来理解，假设有个词表（vocabulary）：</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>["apple", "banana", "car", "dog", "elephant"]
</code></pre></div></div> <p>这个词表有5个词，对应一个5维的向量空间。现在有个文档：</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>I like banana
</code></pre></div></div> <p>我们用稀疏向量来表示这个文档时，会得到：</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>[0, 1, 0, 0, 0]
</code></pre></div></div> <p>很直观的可以看到，这是一个5维的向量，但是其中大部分的维度都是0（没出现），只有极少数是非0（有出现的词）。理论上我们会在这里持续增加词出现的频次，比如</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>banana banana banana!
</code></pre></div></div> <p>可以得到</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>[0, 3, 0, 0, 0]
</code></pre></div></div> <p>看着没什么问题，但是这种极致简单的词频统计，会在某些情况下有问题，比如像“the”、“is”、“you”这些词在所有文本中都很多，但它们没啥实际意义。所以出现次数多的词，并不一定重要。为了解决这个问题，我们就需要引入一些方法。常见的方法有：</p> <ul> <li><strong>TF-IDF（Term Frequency - Inverse Document Frequency）</strong>：在词频的基础上加入“逆文档频率”因素，降低常见词的权重，提高稀有词的权重。</li> <li><strong>BM25</strong>：一种改进的 TF-IDF 加权方案，同时考虑了词频饱和、文档长度归一化等因素，广泛应用于现代搜索引擎。</li> </ul> <p>这些方法都基于<strong>倒排索引（Inverted Index）</strong>结构实现高效检索。它们不再简单依赖“词频越高越重要”的假设，而是引入更多统计规律，使得检索系统能更准确地评估“哪些词更关键”。这个也是传统的搜索引擎的基础，像Google这类搜索引擎在早期就应用了这类技术去做搜索。另外全文检索里可以经常看到这两个技术，比如ES的全文检索就是利用了BM25来做的。</p> <p>可以看出<strong>稀疏文本检索的优点就是高效快速，消耗资源少，因此被广泛使用</strong>。其<strong>缺点就是无法理解一些语义相近但是词不重叠的文本</strong>，比如car和automobile这种，因此也就有了稠密文本检索来解决这个问题</p> <h3 id="稠密文本检索dense-retrieval">稠密文本检索（Dense Retrieval）</h3> <p>原理是<strong>通过神经网络（如Word2Vec、BERT）将查询和文档分别编码成低维稠密向量（Dense Vector），使用向量相似度（如内积或余弦相似度）进行匹配，返回最相关的文档</strong>。那么什么是稠密向量呢？和稀疏向量刚好反过来了：稠密向量是所有维度基本都有值的向量。每一维都用浮点数表示，通常没有“0”或者很少有“0”。</p> <p>这边的低维是相对于前面稀疏文本里的稀疏向量通常是极高维度的，因为那边的向量维度=词表大小，通常可以词表可以达到<strong>几十万甚至百万维</strong>，但是在稠密向量里，通常<strong>几十维到几千维</strong>的程度，所以是低维稠密向量。</p> <p>举个例子，还是前面这句话：</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>I love bananas

</code></pre></div></div> <p>我们将其送进一个神经网络模型（如BERT、DPR编码器），可以输出得到一个向量，如：</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>[0.12, -0.08, 0.91, 0.33, ..., 0.04]   // 共768维

</code></pre></div></div> <p>像现在流行的Embedding本质上就是这个原理，通过预训练语言模型后，可以通过模型将内容编码为向量，每个向量都是一个<strong>语义表示（Semantic Representation）</strong>，这些向量不是手动构造的，而是模型通过大量文本学习出来的。</p> <p>我们可以找到很多这种向量可视化的网站或者开源项目，比如<a href="https://projector.tensorflow.org/">tensorflow</a>这个展示了word2vec的向量在三维空间的表示，可以看两个词的可视化距离（相似度计算其实算的就是在对应维度空间下的两点之间的距离，只不过维度高到人类大脑无法轻易想象，也就是超越人类的认知，没办法像在二维和三维空间下可以轻松计算距离）</p> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-10-01-ce101-5-rag/1759293254_4-480.webp 480w,/assets/img/2025-10-01-ce101-5-rag/1759293254_4-800.webp 800w,/assets/img/2025-10-01-ce101-5-rag/1759293254_4-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/2025-10-01-ce101-5-rag/1759293254_4.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> </div> </div> <p>另外vectosphere这个，也可以同样可视化展示：</p> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-10-01-ce101-5-rag/1759293254_5-480.webp 480w,/assets/img/2025-10-01-ce101-5-rag/1759293254_5-800.webp 800w,/assets/img/2025-10-01-ce101-5-rag/1759293254_5-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/2025-10-01-ce101-5-rag/1759293254_5.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> </div> </div> <p>回过头来，常见的稠密文本检索方法有下面这些，有兴趣的可以自己去了解一下：</p> <p>我们平时最常见的RAG应用就是使用了Bi-Encoder，因为足够快，而ReRank时数量较少，可以利用Cross-Encoder来打分。</p> <p>到这里我们已经知道了稠密文本检索到底是做什么了，在提前向量化资料后，在后续问题来了之后可以将问题也进行向量化，然后通过向量相似度进行搜索，得到最相关的资料，这就是稠密文本检索的过程，<strong>能够检索语义相近但词不匹配的文档</strong>，并且<strong>适合复杂查询、开放域问答、RAG 等应用</strong>。</p> <p>其缺点也相对明显：<strong>需要大规模训练，消耗资源大，部署成本高，另外召回的结果可解释性低</strong></p> <h3 id="融合方法hybrid-retrieval">融合方法（Hybrid Retrieval）</h3> <p>两者各有优缺点，因此很多系统或者应用场景会将两者进行结合，比如用稀疏检索（如BM25）结合稠密检索先召回 Top K文档，再用重排模型（Dense Reranker，如Cross-Encoder）对结果进行重新排序，重新排序</p> <p>引用一张我之前发的关于Bi-Encoder和Cross-Encoder：</p> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-10-01-ce101-5-rag/1759293254_6-480.webp 480w,/assets/img/2025-10-01-ce101-5-rag/1759293254_6-800.webp 800w,/assets/img/2025-10-01-ce101-5-rag/1759293254_6-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/2025-10-01-ce101-5-rag/1759293254_6.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> </div> </div> <p>我们在实际应用中<strong>不会因为技术而技术</strong>，一定要记住这句话！否则很容易陷入拿着锤子找钉子的尴尬境地（现在其实有不少人就是拿着AI找钉子敲）。就比如前面提到的这些，有可能在实际的应用中只是简单的应用向量化去做检索就足够了，也可能复杂到需要结合关系型数据库做常规的数据检索+ES做全文检索+向量化检索+重排技术得到最匹配的结果去做方案。所以应用AI（Applied AI）的背后就是我们需要去了解每个技术背后的原理，是基于什么背景之下提出来的，以及这个技术目前发展到什么程度了，可以解决什么问题，在某个应用场景下是否合适，这样我们才可以真正做到将AI应用在有价值的地方，赋能业务产生真正的商业价值，而不是陷入技术自嗨中。</p> <p>了解完这个我们对于RAG的底层依托的技术已经有了比较清晰的认知了，接下去我们会进一步深入去了解RAG相关的技术以及衍生的一些应用方式。</p> <h1 id="52-rag进阶">5.2 RAG进阶</h1> <p>常规的RAG相对简单，在实际应用中，我们会在原本的架构之上，去运用一些技术和方法来提高，比如：</p> <ul> <li><strong>标量+向量</strong>：通常RAG是将文档分块（Chunk）后向量化（Embedding）入库，然后查询也向量化后到向量数据库进行相似性搜索。如前面提到，实际上还可以结合传统的数据库或者ES进行标量数据的匹配检索，最后可以得到标量+向量数据。</li> <li><strong>重排（Reranking）</strong>：不管是单向量还是结合了标量，在送到模型前可以用一些手段对文档进行重新排序，通常我们会使用重排模型对文档再进行评分排序，这样可以选择实际送到模型的文档</li> <li><strong>多跳RAG</strong>：当单跳查询无法满足复杂的查询时，结合多跳是可以达到更好的效果的。</li> <li><strong>图增强RAG（Graph-RAG）</strong>：结合图的能力来扩展RAG的能力，尤其是在文档处理阶段，可以利用图+大模型来细化一些实体和关系，甚至进一步形成社区或领域的形态。</li> </ul> <p>上面只是一部分技术或方法。在技术普及过程，开始会陆续出现体系化的知识，也是为了方便应用以及后来者学习，现在业界也有很多划分方式，比如<a href="https://www.dailydoseofds.com/tag/rag-crash-course/">Daily Dose of Data Science</a>这张图：</p> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-10-01-ce101-5-rag/1759293255_7-480.webp 480w,/assets/img/2025-10-01-ce101-5-rag/1759293255_7-800.webp 800w,/assets/img/2025-10-01-ce101-5-rag/1759293255_7-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/2025-10-01-ce101-5-rag/1759293255_7.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> </div> </div> <p>另外<a href="https://arxiv.org/pdf/2501.09136">这篇论文</a>里也提供了相应的划分方式：</p> <p>我们引用<a href="https://arxiv.org/pdf/2312.10997">这篇论文</a>里的一张示意图：</p> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-10-01-ce101-5-rag/1759293255_8-480.webp 480w,/assets/img/2025-10-01-ce101-5-rag/1759293255_8-800.webp 800w,/assets/img/2025-10-01-ce101-5-rag/1759293255_8-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/2025-10-01-ce101-5-rag/1759293255_8.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> </div> </div> <p>可以较为清楚的看出差别，分类是人为划分的，本质上就是针对基础的RAG在各个环节进行优化提升，目的都是为了提高最后输出的效果。</p> <p><strong>进阶RAG（Advanced RAG）</strong>就是加入了<strong>前处理阶段（Pre-Retrieval）</strong>来优化查询，比如查询重写或运用一些策略进行处理。并且加入了<strong>后处理阶段（Post-Retrieval）</strong>来优化检索后的文档块，比如重排、压缩或融合等手段，这样在最终给到大模型可以得到更好的结果提升。</p> <p><strong>模块化RAG（Modular RAG）</strong>则是将各种阶段或者功能单独成模块，每个模块是最小单元，可以自由的组合，形成一个类似workflow的流程，有点像是玩乐高积木，可以针对不同的业务场景自由组合。本质上里面的技术和方法没有变化，只不过是在工程化上进行了优化，方便不断复用和自由编排。</p> <p><strong>图RAG（Graph RAG）</strong>就是利用了图来辅助处理，万物皆可图，图的能力应用在RAG里，使得RAG得到了极大的提升，后面我们会在图RAG章节里会详细分析加入图能力，RAG得到的好处和提升。</p> <p><strong>智能体RAG（Agentic RAG）</strong>则是将RAG从简单的检索生成扩展成自主的Agent，可以基于一定的策略动态决策并进行多轮次检索，这个其实是对多跳RAG的一种提升，将AI Agent的思想融入RAG。</p> <p>到这里我们再回过头来看看我们前面的那张架构图：</p> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-10-01-ce101-5-rag/1759293256_9-480.webp 480w,/assets/img/2025-10-01-ce101-5-rag/1759293256_9-800.webp 800w,/assets/img/2025-10-01-ce101-5-rag/1759293256_9-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/2025-10-01-ce101-5-rag/1759293256_9.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> </div> </div> <p>这里面其实已经体现了很多的东西，我们可以把RAG分为：</p> <ol> <li>输入：可能有不同的输入方式，主流常见的是从Chat进来的问题</li> <li>前处理：检索前作一些前置处理动作，目的是增加召回效果</li> <li>检索：执行检索</li> <li>后处理：对检索的结果进行特定的处理，目的也是增加召回效果</li> <li>生成：给大模型输出最后的结果</li> <li>输出：将结果返回</li> </ol> <p>这个其实就是一个进阶RAG的流程了，至于模块化RAG，其实是将里面的功能模块都单独抽出来形成独立的单元，这样可以重复自由组织编排，而图RAG和智能体RAG则会在里面多个环节参与。下面我们会针对一些关键的节点和方式展开。</p> <h2 id="521-查询重写">5.2.1 查询重写</h2> <p>在传统的RAG里，通常就是将查询通过向量化的手段转成嵌入（embedding），做相似性搜索后给到大模型。这种情况下有明显可见的问题：<strong>输入查询无法顺利匹配到文档块</strong>。</p> <p>在实际场景下，用户输入的问题有可能因为过于简化或者表述不当而无法通过相似度搜索匹配到合适的文档块，使得最终的效果不符合预期。面对这个问题，可以应用查询重写来进一步缓解并提升效果。</p> <p>正如前面提到的，重写策略其实有挺多的，目前主流的有这么几种（更多还是一些类别的划分，实际上在不同的业务场景下还会有不同的策略浮现的，比如一些行业词汇重写、黑白词等等，这边就不过度展开）：</p> <ol> <li><strong>规范化重写（Canonicalization）</strong>：将随意、模糊、口语化表达转成标准清晰的问题</li> <li><strong>同义改写（Paraphrasing）</strong>：增强表达覆盖、抗embedding漏召</li> <li><strong>泛化重写（Step-Back Query）</strong>：提升复杂问题检索效果</li> <li><strong>多查询生成（Multi-query Generation）</strong>：多视角覆盖、提升召回率</li> <li><strong>问题分解策略（Question Decomposition）</strong>：将复杂查询拆分为多个子问题，分步检索和推理</li> </ol> <h3 id="规范化重写canonicalization"><strong>规范化重写（Canonicalization）</strong></h3> <p>规范化重写其实就是针对查询问题让大语言模型帮忙进行重写，使得问题更加规范化，这其中有一些不同的手法。我们先来看一个基础的示例：</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>周杰伦第一张专辑是什么？
</code></pre></div></div> <p>可以改写成</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>周杰伦第一张音乐专辑名称是什么？
</code></pre></div></div> <p>类似这样的规范化重写，可以将一个较为随意的问题转变成更加正式的问题。以便在向量化检索的过程中，可以更好的召回预期的文档块用于最终的结果生成。</p> <h3 id="同义改写paraphrasing"><strong>同义改写（Paraphrasing）</strong></h3> <p>同义改写的原理也是差不多的，对于不合适的表述，可以进行同义替换改写，使得输入的内容可以更容易匹配到合适的文档块。比如：</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code># 历史聊天记录
User: 马斯克现在拥有哪些公司
AI: 截至2025年，马斯克拥有或主导的公司包括特斯拉、SpaceX、xAI（含X）、Neuralink 和 The Boring Company。
User: 他现在个人财富估值是多少？
</code></pre></div></div> <p>历史信息已经出现过相应的人物名，但是在最新的Query中却没有重复表述，此时是可以通过重写将用户最新的问题重写成：</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>马斯克现在个人财富估值是多少？

</code></pre></div></div> <p>甚至是可以进一步结合前面规范化重写：</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>截止2025年7月，马斯克（Elon Musk）的个人净资产估值是多少？

</code></pre></div></div> <p>这样等于是把时间具体化，并且名词也更加规范化表述了。</p> <h3 id="泛化重写step-back-query"><strong>泛化重写（Step-Back Query）</strong></h3> <p>泛化重写是把具体的问题抽象，将问题覆盖范围扩大了，这样可以扩大检索范围和获取更完整的上下文信息，比如：</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code> 马斯克的出生地是哪里？
</code></pre></div></div> <p>可以改写成：</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code> 马斯克的个人背景和早年经历是什么？
</code></pre></div></div> <p>这种好处不是明显可见的，为什么这么说呢？因为问题被泛化之后，有可能会导致答案也进一步被泛化，当然最终的递送给大语言模型的Prompt是可以保留原始的问题的。泛化重写其实是应该结合多跳RAG这些技术来发挥更大的作用，这个在后续我们也会涉及到，简单说就是通过泛化先在一个方向上探索，再一步步细化定位到实际想要的结果中。</p> <h3 id="多查询生成multi-query-generation"><strong>多查询生成（Multi-query Generation）</strong></h3> <p>这个方式也是应对用户问题表述不清晰或含糊的情况，通过将单一问题生成多个问题的方式，对一个问题提供多个角度，这样可以提高覆盖度，达到更好的检索和结果生成效果。</p> <p>我们来看下例子：</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>周杰伦的第一张专辑是什么？
</code></pre></div></div> <p>多查询重写：</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>周杰伦最早发行的专辑是哪一张？
周杰伦第一张音乐专辑的名字是什么？
周杰伦早期的音乐作品有哪些？
周杰伦的音乐出道作品是哪一张专辑？
</code></pre></div></div> <p>这样就将一个问题扩展出基于不同角度的多个问题组合，这样可以以较为全面的角度去召回文档块了。</p> <h3 id="问题分解策略question-decomposition"><strong>问题分解策略（Question Decomposition）</strong></h3> <p>将一个复杂问题拆解成多个原子问题，使得可以基于多个问题去分别召回文档块，比如：</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>周杰伦从出道到现在有哪些重要的音乐成就？
</code></pre></div></div> <p>可以拆解成：</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>周杰伦是哪一年出道的？
周杰伦的第一张专辑是什么？
周杰伦获得过哪些音乐奖项？
周杰伦的代表作有哪些？
他对华语乐坛的影响体现在哪些方面？
</code></pre></div></div> <p>这样可以基于不同的问题去做处理了。这里其实还可以结合前面的一些重写策略进一步完善子问题。</p> <p>另外这种方式通常会结合一些MapReduce的思维去做时间，也就是基于不同的原子问题去做文档块的召回，并做不同的结果生成，最终再把所有的结果再进行汇总生成一个最终的结果。后续我们也会提到这块应用，尤其在Graph RAG里有很完备的应用示例可以学习。</p> <h2 id="522-检索结果重排">5.2.2 检索结果重排</h2> <p>重排是提升RAG检索效果里很重要的一步，也是目前实际应用中很广泛被采用的一种方式，主要有几种方式：</p> <ol> <li><strong>基于打分函数的传统重排方法</strong>：BM25，TF-IDF余弦相似度</li> <li><strong>语义匹配类重排方法</strong>：双塔结构（Bi-Encoder），交叉编码器（Cross-Encoder）</li> <li><strong>生成式重排方法</strong>：通过LLM进行评分和排序</li> </ol> <p>实际使用需要根据业务需求和所有的资源来决定，这边我们来看个例子，LangChain官方有一个<a href="https://python.langchain.com/docs/integrations/retrievers/flashrank-reranker/">FlashRank reranker</a>的例子，采用的是<a href="https://github.com/PrithivirajDamodaran/FlashRank">FlashRank</a>，主要支持Pointwise（单文档打分），Pairwise（双文档比较，看谁相关度更好）和Listwise（列表排序，一次对所有文档排序）两种方式</p> <p>下面是一个基础的RAG流程，对文档切分后建立embedding，然后在对问题做向量化后在里面检索出相似度最高的20条文档片段</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">langchain_community.document_loaders</span> <span class="kn">import</span> <span class="n">TextLoader</span>
<span class="kn">from</span> <span class="n">langchain_community.vectorstores</span> <span class="kn">import</span> <span class="n">FAISS</span>
<span class="kn">from</span> <span class="n">langchain_openai</span> <span class="kn">import</span> <span class="n">OpenAIEmbeddings</span>
<span class="kn">from</span> <span class="n">langchain_text_splitters</span> <span class="kn">import</span> <span class="n">RecursiveCharacterTextSplitter</span>

<span class="n">documents</span> <span class="o">=</span> <span class="nc">TextLoader</span><span class="p">(</span>
    <span class="sh">"</span><span class="s">../../how_to/state_of_the_union.txt</span><span class="sh">"</span><span class="p">,</span>
<span class="p">).</span><span class="nf">load</span><span class="p">()</span>
<span class="n">text_splitter</span> <span class="o">=</span> <span class="nc">RecursiveCharacterTextSplitter</span><span class="p">(</span><span class="n">chunk_size</span><span class="o">=</span><span class="mi">500</span><span class="p">,</span> <span class="n">chunk_overlap</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>
<span class="n">texts</span> <span class="o">=</span> <span class="n">text_splitter</span><span class="p">.</span><span class="nf">split_documents</span><span class="p">(</span><span class="n">documents</span><span class="p">)</span>
<span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="n">text</span> <span class="ow">in</span> <span class="nf">enumerate</span><span class="p">(</span><span class="n">texts</span><span class="p">):</span>
    <span class="n">text</span><span class="p">.</span><span class="n">metadata</span><span class="p">[</span><span class="sh">"</span><span class="s">id</span><span class="sh">"</span><span class="p">]</span> <span class="o">=</span> <span class="n">idx</span>

<span class="n">embedding</span> <span class="o">=</span> <span class="nc">OpenAIEmbeddings</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="sh">"</span><span class="s">text-embedding-ada-002</span><span class="sh">"</span><span class="p">)</span>
<span class="n">retriever</span> <span class="o">=</span> <span class="n">FAISS</span><span class="p">.</span><span class="nf">from_documents</span><span class="p">(</span><span class="n">texts</span><span class="p">,</span> <span class="n">embedding</span><span class="p">).</span><span class="nf">as_retriever</span><span class="p">(</span><span class="n">search_kwargs</span><span class="o">=</span><span class="p">{</span><span class="sh">"</span><span class="s">k</span><span class="sh">"</span><span class="p">:</span> <span class="mi">20</span><span class="p">})</span>

<span class="n">query</span> <span class="o">=</span> <span class="sh">"</span><span class="s">What did the president say about Ketanji Brown Jackson</span><span class="sh">"</span>
<span class="n">docs</span> <span class="o">=</span> <span class="n">retriever</span><span class="p">.</span><span class="nf">invoke</span><span class="p">(</span><span class="n">query</span><span class="p">)</span>
<span class="nf">pretty_print_docs</span><span class="p">(</span><span class="n">docs</span><span class="p">)</span>

</code></pre></div></div> <p>现在来应用一下FlashRank做重排，从前面读取<code class="language-plaintext highlighter-rouge">retriever</code>，构建<code class="language-plaintext highlighter-rouge">ContextualCompressionRetriever</code>，里面会使用<code class="language-plaintext highlighter-rouge">FlashrankRerank</code></p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">langchain.retrievers</span> <span class="kn">import</span> <span class="n">ContextualCompressionRetriever</span>
<span class="kn">from</span> <span class="n">langchain_community.document_compressors</span> <span class="kn">import</span> <span class="n">FlashrankRerank</span>
<span class="kn">from</span> <span class="n">langchain_openai</span> <span class="kn">import</span> <span class="n">ChatOpenAI</span>

<span class="n">llm</span> <span class="o">=</span> <span class="nc">ChatOpenAI</span><span class="p">(</span><span class="n">temperature</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

<span class="n">compressor</span> <span class="o">=</span> <span class="nc">FlashrankRerank</span><span class="p">()</span>
<span class="n">compression_retriever</span> <span class="o">=</span> <span class="nc">ContextualCompressionRetriever</span><span class="p">(</span>
    <span class="n">base_compressor</span><span class="o">=</span><span class="n">compressor</span><span class="p">,</span> <span class="n">base_retriever</span><span class="o">=</span><span class="n">retriever</span>
<span class="p">)</span>

<span class="n">compressed_docs</span> <span class="o">=</span> <span class="n">compression_retriever</span><span class="p">.</span><span class="nf">invoke</span><span class="p">(</span>
    <span class="sh">"</span><span class="s">What did the president say about Ketanji Jackson Brown</span><span class="sh">"</span>
<span class="p">)</span>
<span class="nf">print</span><span class="p">([</span><span class="n">doc</span><span class="p">.</span><span class="n">metadata</span><span class="p">[</span><span class="sh">"</span><span class="s">id</span><span class="sh">"</span><span class="p">]</span> <span class="k">for</span> <span class="n">doc</span> <span class="ow">in</span> <span class="n">compressed_docs</span><span class="p">])</span>

</code></pre></div></div> <p>对比一下前后的效果：</p> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-10-01-ce101-5-rag/1759293257_10-480.webp 480w,/assets/img/2025-10-01-ce101-5-rag/1759293257_10-800.webp 800w,/assets/img/2025-10-01-ce101-5-rag/1759293257_10-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/2025-10-01-ce101-5-rag/1759293257_10.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> </div> </div> <ul> <li>Document 1 -&gt; Document 1</li> <li>Document 4 -&gt; Document 2</li> <li>Document 6 -&gt; Document 3 经过重排后，获取到的Top 3文档不一样了</li> </ul> <h2 id="523-graph-rag">5.2.3 Graph RAG</h2> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-10-01-ce101-5-rag/1759293257_11-480.webp 480w,/assets/img/2025-10-01-ce101-5-rag/1759293257_11-800.webp 800w,/assets/img/2025-10-01-ce101-5-rag/1759293257_11-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/2025-10-01-ce101-5-rag/1759293257_11.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> </div> </div> <p><a href="https://microsoft.github.io/graphrag/">Graph RAG</a>是微软在2024年推出的一种结构化、分层的检索增强生成（RAG）方法，相较于仅使用纯文本片段进行语义搜索的朴素方法，它更加系统和智能。GraphRAG 的处理流程包括：从原始文本中提取知识图谱、构建社区层级结构、为这些社区生成摘要，并在执行基于 RAG 的任务时充分利用这些结构化信息。下面我们会做一个比较详细的分析</p> <h3 id="索引阶段">索引阶段</h3> <p>看看架构图可以有个全局的认知</p> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-10-01-ce101-5-rag/1759293258_12-480.webp 480w,/assets/img/2025-10-01-ce101-5-rag/1759293258_12-800.webp 800w,/assets/img/2025-10-01-ce101-5-rag/1759293258_12-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/2025-10-01-ce101-5-rag/1759293258_12.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> </div> </div> <p>我们来看看标准处理流程：</p> <ol> <li>文本处理 （Text Processing）</li> <li>文档处理（Document Processing）</li> <li>图提取（Graph Extraction）</li> <li>图增强（Graph Augmentation）</li> <li>声明提取（Claims Extraction）</li> <li>社区创建（Community Creation）</li> <li>文本单元最终化（(Final Text Units）</li> <li>社区报告生成（Community Reports）</li> <li>文本嵌入（Text Embeddings）</li> </ol> <h4 id="文本处理-text-processing">文本处理 （Text Processing）</h4> <p>主要接收多种数据输入，然后对输入的数据进行<strong>切分</strong>（支持按句子或者token进行切分），分块得到<strong>文本单元TextUnits</strong>。</p> <p>这步主要是为了<strong>方便后续的数据处理</strong>，因为后续的处理涉及多轮次的模型调用，以一个合理块大小的处理单元来处理，会更加方便且上下文不容超过，<strong>也适合并发调度处理</strong>。</p> <h4 id="文档处理document-processing">文档处理（Document Processing）</h4> <p>将文本处理阶段处理出来的TextUnits与原始文档建立引用关系，形成一个<strong>结构化的数据表</strong>，用于后续一些操作：</p> <ul> <li>跟踪每个文档包含哪些chunk</li> <li>后续社区摘要、图构建等流程中使用</li> <li>统一文档展示和可视化索引</li> </ul> <h4 id="图提取graph-extraction">图提取（Graph Extraction）</h4> <p>会包含几个阶段：</p> <ol> <li><strong>实体（Entity）</strong>和<strong>关系（Relationship）</strong>提取</li> <li>图数据进行摘要简化（Graph Summrization）</li> </ol> <p>首先会让大语言模型提取文本里的<strong>实体（Entity）</strong>，以及不同实体间的<strong>关系（Relationship）</strong>，还会附带<strong>关系强弱的评分</strong>用于<strong>计算实体间的关系权重</strong>。</p> <p>这期间会在内存中做一定的合并和更新。比如实体和关系的描述，持续的更新会导致描述膨胀，这种情况下需要再进行一步图摘要，也就是让模型再次帮忙将实体和关系里的描述做总结为单一简介描述</p> <h4 id="图增强graph-augmentation">图增强（Graph Augmentation）</h4> <p>图增强里主要是图<strong>最终化</strong>，也就是将初步提取出来的图数据（实体节点和关系边），经过清洗、加工、标准化并准备好用于下游使用的过程。因为这是图构建的最后阶段：</p> <ul> <li>之前：只有基础的实体名称、描述、关系</li> <li>之后：实体具备了向量表示、空间坐标、网络属性等完整特征</li> </ul> <p>简单说就是： <strong>初步提取的基础数据 -&gt; 可用于可视化、推理、检索和分析的结构化图</strong></p> <p>在对实体最终化流程中，会有这么一些操作和步骤：</p> <ul> <li>根据配置决定是否创建向量（embedding）</li> <li>根据配置决定是否对图做UMAP或其他布局（layout）方法，生成2D/3D坐标用于可视化</li> <li>计算每个实体节点的度数（degree），用于后续分析或排序</li> <li>合并、移除重复、预填充缺失字段、生成唯一id等等</li> </ul> <blockquote> <p>UMAP（Uniform Manifold Approximation and Projection）中文名为统一流形近似与投影算法，是一种非线性降维算法，可以用于把高维数据（比如向量嵌入embedding）映射到二维或三维空间，用于方便可视化或聚类分析。简单说就是： UMAP 是一种可以把高维“云雾向量”压缩成漂亮二维坐标点的方法，保留结构、方便展示和聚类</p> </blockquote> <p>关于实体节点的<strong>度数（degree）</strong>，其实是每个节点连接的边的数量，比如：</p> <ul> <li>Leo –写–&gt; 书</li> <li>Leo –开发–&gt; 应用</li> </ul> <p>那么Leo这个节点就有两条边，它的degree就是2。那为什么要算degree呢？因为在图分析/图机器学习中，degree是一个很有用的特征值，比如：</p> <ul> <li>找到重要节点：高度数可能表示实体在图中很核心</li> <li>控制布局：在图布局中（比如UMAP或Force-directed），高 degree 节点更可能在中心。</li> <li>下游模型特征：在图神经网络中，degree 是常用的节点特征之一</li> <li>图过滤：有时我们只保留degree&gt;=2的节点，忽略孤立点（degree=0）。</li> </ul> <h4 id="声明提取claims-extraction">声明提取（Claims Extraction）</h4> <p>Graph RAG里面是叫做<strong>共变量（Covariates）提取任务</strong>，一个道理，就是从文本单元里提取声明（Claims）的过程，并将其转换为结构化数据，供后续图构建或社区摘要使用。</p> <p>操作主要是让<strong>模型针对文本单元里的内容进行声明提取</strong>，Prompt里会包括实体、想找的主张，需要分析的原始内容，最终模型会输出声明主体、涉及对象、声明类型、声明状态（对/错/存疑）、时间范围、描述说明、原始文本这些信息。</p> <h4 id="社区创建community-creation">社区创建（Community Creation）</h4> <p>这里会借助Leiden算法将节点进行<strong>社区化</strong>，简单说就是<strong>把相似、相关的阶段放到统一个社区</strong>。社区是指内部连接多，外部连接少的一组节点，类比班级，一个班级内部的同学联系较为紧密，而不同的班级之间的联系相对就少一点，这里班级就是一个社区的概念。另外同一个班级之下还可以分兴趣小组，这样就出现了分层级的社区，也就是某个社区有可能归属于某个父社区。Leiden算法整体就是在做这么一件事情，我们不展开算法的细节，有兴趣的可以自行了解。</p> <p>通过构建，最终是可以得到一个这种结构的数据</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">(</span><span class="n">level</span><span class="p">,</span> <span class="n">cluster_id</span><span class="p">,</span> <span class="n">parent_cluster_id</span><span class="p">,</span> <span class="p">[</span><span class="n">node_ids</span><span class="p">])</span>
</code></pre></div></div> <p>示例数据</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">[</span>
  <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="p">[</span><span class="sh">'</span><span class="s">A</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">B</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">C</span><span class="sh">'</span><span class="p">]),</span>  <span class="c1"># 一级社区，ID=1，父节点=-1（说明是顶层），含有节点A/B/C
</span>  <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="p">[</span><span class="sh">'</span><span class="s">A</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">B</span><span class="sh">'</span><span class="p">]),</span>        <span class="c1"># 二级社区，ID=2，父节点是1，细分A/B
</span><span class="p">]</span>
</code></pre></div></div> <p>最终再通过一定的操作来<strong>整理聚合社区</strong>，只保留每个社区里实体和社区内实体间关系信息，社区之间的关系被忽略，这样最终就得到一份社区数据了，会存放到数据库里，类似</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">id</span><span class="p">,</span><span class="n">human_readable_id</span><span class="p">,</span><span class="n">community</span><span class="p">,</span><span class="n">parent</span><span class="p">,</span><span class="n">children</span><span class="p">,</span><span class="n">entity_ids</span><span class="p">,</span><span class="n">relationship_ids</span><span class="p">,</span><span class="n">text_unit_ids</span><span class="p">,</span><span class="n">level</span><span class="p">,</span><span class="n">title</span><span class="p">,</span><span class="n">period</span><span class="p">,</span><span class="n">size</span>
<span class="mf">1e2</span><span class="n">f3a00</span><span class="o">-</span><span class="n">aaaa</span><span class="o">-</span><span class="mi">1111</span><span class="o">-</span><span class="n">bbbb</span><span class="o">-</span><span class="mi">000000000001</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="sh">"</span><span class="s">[]</span><span class="sh">"</span><span class="p">,</span><span class="sh">"</span><span class="s">[</span><span class="sh">'</span><span class="s">e1</span><span class="sh">'</span><span class="s">, </span><span class="sh">'</span><span class="s">e2</span><span class="sh">'</span><span class="s">, </span><span class="sh">'</span><span class="s">e3</span><span class="sh">'</span><span class="s">]</span><span class="sh">"</span><span class="p">,</span><span class="sh">"</span><span class="s">[</span><span class="sh">'</span><span class="s">r1</span><span class="sh">'</span><span class="s">, </span><span class="sh">'</span><span class="s">r2</span><span class="sh">'</span><span class="s">]</span><span class="sh">"</span><span class="p">,</span><span class="sh">"</span><span class="s">[</span><span class="sh">'</span><span class="s">t1</span><span class="sh">'</span><span class="s">, </span><span class="sh">'</span><span class="s">t2</span><span class="sh">'</span><span class="s">, </span><span class="sh">'</span><span class="s">t3</span><span class="sh">'</span><span class="s">]</span><span class="sh">"</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="n">Community</span> <span class="mi">0</span><span class="p">,</span><span class="mi">2025</span><span class="o">-</span><span class="mi">07</span><span class="o">-</span><span class="mi">25</span><span class="p">,</span><span class="mi">3</span>
<span class="mi">4</span><span class="n">a6b7c00</span><span class="o">-</span><span class="n">bbbb</span><span class="o">-</span><span class="mi">2222</span><span class="o">-</span><span class="n">cccc</span><span class="o">-</span><span class="mi">000000000002</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="sh">"</span><span class="s">[]</span><span class="sh">"</span><span class="p">,</span><span class="sh">"</span><span class="s">[</span><span class="sh">'</span><span class="s">e4</span><span class="sh">'</span><span class="s">, </span><span class="sh">'</span><span class="s">e5</span><span class="sh">'</span><span class="s">]</span><span class="sh">"</span><span class="p">,</span><span class="sh">"</span><span class="s">[</span><span class="sh">'</span><span class="s">r3</span><span class="sh">'</span><span class="s">]</span><span class="sh">"</span><span class="p">,</span><span class="sh">"</span><span class="s">[</span><span class="sh">'</span><span class="s">t4</span><span class="sh">'</span><span class="s">, </span><span class="sh">'</span><span class="s">t5</span><span class="sh">'</span><span class="s">]</span><span class="sh">"</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="n">Community</span> <span class="mi">1</span><span class="p">,</span><span class="mi">2025</span><span class="o">-</span><span class="mi">07</span><span class="o">-</span><span class="mi">25</span><span class="p">,</span><span class="mi">2</span>
</code></pre></div></div> <h4 id="文本单元最终化final-text-units">文本单元最终化（(Final Text Units）</h4> <p>这一步主要是针对前面的几个步骤产生的<strong>中间数据做最终的聚合关联</strong>，也就是将文本单元（TextUnits）与实体（Entities）、关系（Relationships）和声明共变量（Covariates）。关联之后文本单元就拥有了实体id列表、关系列表、声明列表。</p> <p>大概数据如下：</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  <span class="p">{</span>
      <span class="sh">"</span><span class="s">id</span><span class="sh">"</span><span class="p">:</span> <span class="sh">"</span><span class="s">text_unit_001</span><span class="sh">"</span><span class="p">,</span>
      <span class="sh">"</span><span class="s">short_id</span><span class="sh">"</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span>
      <span class="sh">"</span><span class="s">text</span><span class="sh">"</span><span class="p">:</span> <span class="sh">"</span><span class="s">Apple Inc. is headquartered in Cupertino...</span><span class="sh">"</span><span class="p">,</span>
      <span class="sh">"</span><span class="s">n_tokens</span><span class="sh">"</span><span class="p">:</span> <span class="mi">127</span><span class="p">,</span>
      <span class="sh">"</span><span class="s">document_ids</span><span class="sh">"</span><span class="p">:</span> <span class="p">[</span><span class="sh">"</span><span class="s">doc_001</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">doc_002</span><span class="sh">"</span><span class="p">],</span>
      <span class="sh">"</span><span class="s">entity_ids</span><span class="sh">"</span><span class="p">:</span> <span class="p">[</span><span class="sh">"</span><span class="s">entity_apple</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">entity_cupertino</span><span class="sh">"</span><span class="p">],</span>      <span class="c1"># ⭐ 图数据关联
</span>      <span class="sh">"</span><span class="s">relationship_ids</span><span class="sh">"</span><span class="p">:</span> <span class="p">[</span><span class="sh">"</span><span class="s">rel_001</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">rel_002</span><span class="sh">"</span><span class="p">],</span>              <span class="c1"># ⭐ 图数据关联
</span>      <span class="sh">"</span><span class="s">covariate_ids</span><span class="sh">"</span><span class="p">:</span> <span class="p">[</span><span class="sh">"</span><span class="s">claim_001</span><span class="sh">"</span><span class="p">]</span>                           <span class="c1"># ⭐ 声明数据关联
</span>  <span class="p">}</span>
</code></pre></div></div> <p>这步的目的是为每个文本单元添加结构化语义（实体、关系、属性），为后续图创建和问答系统打下基础。</p> <h4 id="社区报告生成community-reports">社区报告生成（Community Reports）</h4> <p>这步核心目的是基于实体（Entities）、关系（Relationships）、社区（Communities）和声明（Claims），构建每个社区的<strong>摘要性报告</strong>。</p> <p>核心的处理步骤有：</p> <ul> <li>社区展开：将社区结构展开</li> <li>数据准备：预处理实体、关系和声明数据</li> <li>上下文创建：为每个社区构建上下文</li> <li>摘要生成：生成社区报告</li> </ul> <p>首先就是将原本的社区记录（一条记录是一个社区，包含多个实体和关系）展开，然后合并到实体里，这样实体里就包含了所属社区、层级这些信息了。</p> <p>然后就是针对实体、关系和声明做相应的结构化数据准备，补充一些缺失的描述，为后续构建Prompt做准备。</p> <p>接下去是针对每个社区构建一份<strong>本地上下文（Local Context）</strong>。首先会遍历社区的所有层级（从高到低，这边可以理解一层都有不同的社区，上层的社区下会继续划分子社区，所以是一个嵌套关系的），对每个社区聚合实体、边、声明，然后将结构化的社区上下文变成模型可读的Prompt，再发送给模型进行摘要。</p> <p>摘要生成主要是读取前一步产生的社区上下文信息，调用大语言模型去生成文字摘要。期间会有一些车略，比如处理上下超限的情况，会尝试用子社区报告替换本地上下文，如果无法替换则进行修剪本地上下文以适应限制。</p> <p>样例数据：</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>-----Reports-----
community_id,full_content
1,"Community 1 consists of software development entities focused on healthcare applications..."

-----Entities-----
id,entity,description,degree
5,MICROSOFT,Microsoft is a technology company,15
12,AZURE CLOUD,Azure is Microsoft's cloud computing platform,8
23,HEALTHCARE APP,A healthcare application developed by Microsoft,3

-----Relationships-----
id,source,target,description,degree
101,MICROSOFT,AZURE CLOUD,Microsoft owns and operates Azure Cloud platform,12
102,AZURE CLOUD,HEALTHCARE APP,Healthcare app is deployed on Azure Cloud,6

-----Claims-----
id,subject,type,status,description
201,MICROSOFT,CLAIM,CONFIRMED,Microsoft has strong presence in healthcare technology
202,HEALTHCARE APP,CLAIM,SUSPECTED,The app may have compliance issues
</code></pre></div></div> <h4 id="文本嵌入text-embeddings">文本嵌入（Text Embeddings）</h4> <p>这步是最后的环节了，用于为前面产生的各种文本内容生成对应的<strong>向量表示</strong>，用于后续检索阶段的语义搜索和向量检索。主要包括：</p> <ul> <li>完整文档内容</li> <li>实体标题和描述</li> <li>关系描述</li> <li>文本单元</li> <li>社区标题和摘要</li> <li>社区完整报告内容</li> </ul> <h3 id="检索阶段">检索阶段</h3> <p>Graph RAG针对不同的使用场景，提供了4种查询方法：</p> <ol> <li><strong>全局搜索（Global Search）</strong>：面向社区报告级别的全局搜索，适合高层知识查找</li> <li><strong>本地搜索（Local Search）</strong>：走了图和文本搜索，同时融合实体、关系、文本等细粒度搜索</li> <li><strong>动态推理搜索（DRIFT Search）</strong>：和本地搜索类似，但是引入了embedding对齐</li> <li><strong>基础搜索（Basic Search）</strong>：走了文本级别的搜索，是最轻量的文本向量语义检索</li> </ol> <h4 id="全局搜索global-search"><strong>全局搜索（Global Search）</strong></h4> <p>主要<strong>基于社区（Community）和其报告（Reports）进行粗粒度搜索</strong>。走的是Map Reduce的方式，也就是将社区报告拆成多个文本块（chunks），每个文本块分别发送给大语言模型做分析，会生成类似下面格式的内容</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>points,
        description
    ]
}}
</code></pre></div></div> <p>这里包括的是对应社区报告的摘要，精炼的内容描述和对应的重要性得分，评分会决定该观点是否值得被纳入最终的Reduce阶段。Reduce阶段只会过滤出score大于0的结果，并且对结果进行排序，使得较为重要的观点排在前面，最终会展现出类似这样的形式：</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>----Analyst 1----
Importance Score: 90
某个摘要句子...

----Analyst 2----
Importance Score: 88
另一个摘要句子...
</code></pre></div></div> <p>表现出不同的“分析员”（Analyst）的分析情况，然后把这份汇总的结果再次发送到大语言模型，将多个“分析员”的观点汇总成一个连贯、有逻辑且可读性较强的最终答案。输入的prompt片段类似：</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>---Target response length and format---

Multi-paragraph explanation with markdown headings

---Analyst Reports---

----Analyst 1----
Importance Score: 95
Company A violated environmental regulations in 2021 and was fined [Data: Reports (3, 6, 7)].

----Analyst 2----
Importance Score: 82
Whistleblowers from 2020 also claimed unsafe disposal methods by Company A [Data: Reports (12, 15, 19, 22, 26, +more)].
</code></pre></div></div> <p>最终输出的类似：</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>## Environmental Violations of Company A

Company A was found guilty of violating environmental regulations in 2021, resulting in multiple fines [Data: Reports (3, 6, 7)].

In addition, whistleblower reports from 2020 suggested unsafe disposal practices, further highlighting the company's failure in compliance [Data: Reports (12, 15, 19, 22, 26, +more)].
</code></pre></div></div> <h4 id="本地搜索local-search"><strong>本地搜索（Local Search）</strong></h4> <p>本地搜索会利用<strong>向量搜索</strong>去检索出<strong>合适的实体（Entities）</strong>，然后给予这个实体去构建对应的上下文，其中涉及到了以下的数据：</p> <ul> <li>实体</li> <li>关系</li> <li>文本单元</li> <li>社区摘要</li> <li>声明</li> </ul> <p>其中实体是通过向量化搜索得到的，社区则是通过排序后选出topK个社区摘要，其他的则是通过对应实体去检索。最终会将上面的这些数据构建成单个上下文（不像全局搜索用chunk的形式）。然后将这个上下文结合预设的Prompt一起发送到大语言模型生成结果。</p> <p>示例输入片段：</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>---Role---

You are a helpful assistant responding to questions about data in the tables provided.

...

---Target response length and format---

multi-paragraph summary

---Data tables---

Entities Table:
1. John Smith - CEO
2. ...
</code></pre></div></div> <p>输出示例：</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>## Key Individuals

John Smith is listed as CEO of Company A [Data: Entities (1)].

...

## Summary

These findings suggest ...
</code></pre></div></div> <h4 id="动态推理搜索drift-search"><strong>动态推理搜索（DRIFT Search）</strong></h4> <p>动态推理搜索（DRIFT Search，Dynamic Reasoning and Inference with Flexible Traversal）是最复杂也最智能的一种检索方式，它结合了推理驱动的层次搜索、查询拆分（Primer）、多步骤搜索和最终答案的合并（Reduce）。</p> <p>首先DRIFT会随机从社区报告里取一个<strong>全量文本</strong>出来，然后将输入的内容与随机取出的社区报告（作为模板）给到大语言模型去做相应的<strong>虚拟答案（Hypothetical Answer）</strong>生成，相应的Prompt是这样的：</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Create a hypothetical answer to the following query: {query}

Format it to follow the structure of the template below:

{template}

Ensure that the hypothetical answer does not reference new named entities that are not present in the original query.
</code></pre></div></div> <p>然后将虚拟的答案转成向量，通过计算余弦相似度（Sosine Similarity），可以得到虚拟答案和所有文档的相似度，取出topK社区报告。</p> <p>然后基于Primer做将topK社区报告进行分片，并发调用LLM对每一份报告进行子问题生成（Query Decomposition）。我们来看看其Prompt模板：</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>You are a helpful agent designed to reason over a knowledge graph in response to a user query.
This is a unique knowledge graph where edges are freeform text rather than verb operators. You will begin your reasoning looking at a summary of the content of the most relevant communites and will provide:

1. score: How well the intermediate answer addresses the query. A score of 0 indicates a poor, unfocused answer, while a score of 100 indicates a highly focused, relevant answer that addresses the query in its entirety.

2. intermediate_answer: This answer should match the level of detail and length found in the community summaries. The intermediate answer should be exactly 2000 characters long. This must be formatted in markdown and must begin with a header that explains how the following text is related to the query.

3. follow_up_queries: A list of follow-up queries that could be asked to further explore the topic. These should be formatted as a list of strings. Generate at least five good follow-up queries.

Use this information to help you decide whether or not you need more information about the entities mentioned in the report. You may also use your general knowledge to think of entities which may help enrich your answer.

You will also provide a full answer from the content you have available. Use the data provided to generate follow-up queries to help refine your search. Do not ask compound questions, for example: "What is the market cap of Apple and Microsoft?". Use your knowledge of the entity distribution to focus on entity types that will be useful for searching a broad area of the knowledge graph.

For the query:

{query}

The top-ranked community summaries:

{community_reports}

Provide the intermediate answer, and all scores in JSON format following:

intermediate_answer

Begin:
</code></pre></div></div> <p>这里的Prompt要求LLM以类人类推理者而不是抽象逻辑机器来推理，其作用是结合用户query与社区总结（community reports），引导LLM推理出一个中间答案（intermediate answer）和一组后续子查询（follow-up queries）</p> <p>输出示例：</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>{
  "intermediate_answer": "## Challenges Faced by EV Companies in 2024\n\nElectric vehicle companies encountered several critical challenges in...",
  "score": 91,
  "follow_up_queries": [
    "How are EV companies addressing battery material shortages?",
    "What trade policies are affecting Chinese EV exports?",
    "What steps is Tesla taking to resolve labor disputes in Berlin?",
    "How are legacy automakers improving their software capabilities?",
    "What impact do rising raw material costs have on EV pricing in 2024?"
  ]
}
</code></pre></div></div> <p>最终这个环节得到的是以虚拟答案检索出来的topK社区报告为语境种子，去生成对应的中间答案和子查询列表以及对应的评分。最后就是将所有的中间答案拼接起来，评分取平均数，子查询问题合并。</p> <p>接下去进入到循环执行动作（Action）的步骤了，会持续从当前状态中挑出尚未处理的动作（只保留top-k最重要的动作），每个动作进行搜索，这里的检索走的是本地搜索（Local Search），也就是针对query走图和文本搜索。这边还会控制最大深度，避免深度爆炸。</p> <p>最后将所有的结果进行聚合（Reduce），会将前面所有Action最终的回答拼接让模型帮忙汇总出最终答案</p> <h4 id="基础搜索basic-search"><strong>基础搜索（Basic Search）</strong></h4> <p>基础搜索的话只会将问题基于文本单元做<strong>向量检索</strong>，得到topK结果，然后到大语言模型进行生成。相对简单的一个检索。</p> <p>示例输入：</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>source_id|text
12|John Smith is the CEO of QuantumTech and has faced several allegations of insider trading.
34|QuantumTech has been under investigation by the SEC since 2022.
46|Multiple anonymous reports accuse John Smith of misusing company resources.
51|John Smith was previously CEO at FutureCorp, where a similar scandal occurred.
55|Internal emails obtained by regulators suggest conflicts of interest involving John Smith.
</code></pre></div></div> <p>示例输出：</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>---Target response length and format---

multiple paragraphs

---Data tables---

source_id|text
12|John Smith is the CEO of QuantumTech and has faced several allegations of insider trading.
34|QuantumTech has been under investigation by the SEC since 2022.
46|Multiple anonymous reports accuse John Smith of misusing company resources.
51|John Smith was previously CEO at FutureCorp, where a similar scandal occurred.
55|Internal emails obtained by regulators suggest conflicts of interest involving John Smith.
</code></pre></div></div> <h3 id="总结">总结</h3> <p>我们花了很长的篇幅来深入GraphRAG，是因为我觉得里面应用了很多相关技术实现，从最基础的向量化检索，到采用了图做结合，甚至里面也融合了多跳RAG或者说多跳推理的技术，还利用了HyDE（Hypothetical Response）的思想。因此非常值得深入了解和学习。</p> <p>总体而言Graph RAG通过将非结构化文本转化为图结构表示，突破了传统 RAG 仅依赖向量检索的局限性。它采用分阶段处理流程，从文本中提取实体与关系，构建社区结构与摘要信息，并融合图结构与向量嵌入，实现多种检索模式的协同支持。</p> <p>在复杂上下文与多样应用场景中，GraphRAG 提供了一个强有力的实践范式。尽管本质上仍受限于语言模型的上下文窗口，但它通过算法、工程与架构手段最大化信息利用效率，将原本偏单跳的 RAG 推进到更具多跳推理能力的方向。其核心目标始终是：<strong>获取最相关、最有用的上下文以支持更好的生成结果。</strong></p> <p>RAG这部分内容非常多，目前也只是走马观花式的覆盖了一部分内容，包括AgenticRAG在内的一些方式还没有展开篇幅去讲，但是我觉得整个篇幅的内容已经足够支撑每一位读者去开启RAG探索之路了。除了技术探索和学术研究以外，在Applied AI中，我们会更加关注实际的业务和需求，始终以此作为导向，利用技术去创造更多的商业价值，才是有意义的事情，因此技术不是目的而是手段，当我们遇到一个无法解决的问题时，或许应该再去看看业界有什么新的方法，如果刚好没有，就是创造这个新的方法的时候。</p> <p>那么我们就继续往下走，来看看工具之于上下文工程的意义和用法</p>]]></content><author><name></name></author><category term="AI"/><category term="AI"/><category term="Book"/><category term="CE101"/><summary type="html"><![CDATA[5.1 RAG基础与原理]]></summary></entry><entry><title type="html">同学你好，你已经签到30次了</title><link href="https://ifuryst.github.io/blog/2025/yo-you-checked-in-30-times-bitch/" rel="alternate" type="text/html" title="同学你好，你已经签到30次了"/><published>2025-09-30T00:00:00+00:00</published><updated>2025-09-30T00:00:00+00:00</updated><id>https://ifuryst.github.io/blog/2025/yo-you-checked-in-30-times-bitch</id><content type="html" xml:base="https://ifuryst.github.io/blog/2025/yo-you-checked-in-30-times-bitch/"><![CDATA[<p>充实的一个月。节前最后一天了，到新的城市、新的公司一个月了，我感觉好像过去好几个月的那种感觉。今天兄弟们都早早撤了，留下几个还在“假装”上班的人，包括我，哈哈。索性就写点东西</p> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-09-30-yo-you-checked-in-30-times-bitch/1759239137_1-480.webp 480w,/assets/img/2025-09-30-yo-you-checked-in-30-times-bitch/1759239137_1-800.webp 800w,/assets/img/2025-09-30-yo-you-checked-in-30-times-bitch/1759239137_1-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/2025-09-30-yo-you-checked-in-30-times-bitch/1759239137_1.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> </div> </div> <p>9月1日到现在刚好整整30天，也是我去健身房的第30次。没错，我也成了大厂人刻板印象中的一员。我觉得这能反应出这一个月来充斥的跟踪新奇未知和变化。</p> <h2 id="日常生活的变化流水账">日常生活的变化（流水账</h2> <p>我的Schedule变了，变得很彻底。</p> <p>我现在每天睡到8点起床，摸摸索索的走路去健身房，撸撸铁，关于健身这点，主要还是想对冲一下职业久坐和常年面对手机电脑的不健康，尤其是弓腰驼背。在生活节奏产生巨大变化的时候，恰恰就是组建新秩序的时刻，人是一种趋于有序的动物，或者说这就是人性。我们会希望打破一切不确定性，但是不确定性和未知却能带来新的生活节奏、创新等等。</p> <p>我现在喜欢上健身了，甚至连周末我都会过来运动一下再出门。我觉得健身有一种快感，有一点像是看书，健身还属于比较快可以得到正反馈的事情，在感受到自己身体一天天变化，就有一种莫名的舒适感，健康有形化了。</p> <p>不过我的态度依然如旧，我不会把它当成作业，反而是乐在其中，我可以边听Podcast边做各种我喜欢做的器械，没有很固定的训练计划，怎么高兴怎么来，但是我依然会认真扫每个器械上的二维码看小教程，也会资讯身边常年健身的人和ChatGPT，看看如何合理的结合自己的情况做搭配。这或许可以称得上一种生活哲学，如果不想做，那么就不要做。</p> <p>另外就是通勤的变化了。以前通勤开车通常要30、40分钟，通常在车上听听英语播客，但是现在走路十几分钟，基本上不太够听完一集播客，反而改成了练口语了，旁若无人的走着自己的路，练着自己的口语。以前noon break的时候，我都是在摄取资讯+练口语的，但是公司及周边人都太多了，乌央乌央的，也没找到好的地方，所以现在都是看书看杂志，错峰吃饭这点依然如旧。</p> <p>关于看书这点。这一个月，我看了6、7本书了，这个数字自己现在想想都特别夸张…</p> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-09-30-yo-you-checked-in-30-times-bitch/1759239137_2-480.webp 480w,/assets/img/2025-09-30-yo-you-checked-in-30-times-bitch/1759239137_2-800.webp 800w,/assets/img/2025-09-30-yo-you-checked-in-30-times-bitch/1759239137_2-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/2025-09-30-yo-you-checked-in-30-times-bitch/1759239137_2.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> </div> </div> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-09-30-yo-you-checked-in-30-times-bitch/1759239138_3-480.webp 480w,/assets/img/2025-09-30-yo-you-checked-in-30-times-bitch/1759239138_3-800.webp 800w,/assets/img/2025-09-30-yo-you-checked-in-30-times-bitch/1759239138_3-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/2025-09-30-yo-you-checked-in-30-times-bitch/1759239138_3.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> </div> </div> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-09-30-yo-you-checked-in-30-times-bitch/1759239139_4-480.webp 480w,/assets/img/2025-09-30-yo-you-checked-in-30-times-bitch/1759239139_4-800.webp 800w,/assets/img/2025-09-30-yo-you-checked-in-30-times-bitch/1759239139_4-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/2025-09-30-yo-you-checked-in-30-times-bitch/1759239139_4.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> </div> </div> <p>我把上海我能找到的比较出名的图书馆都集中去了一遍，也淘了不少书，甚至多抓鱼线下店都去了，这也是我喜欢上海的一点。另外公司楼下就有中信书店可太好了，偶尔可以过去淘书。现在想来，中午阅读也是一个挺好的安排，加上现在阅读速度提升了特别多，可以吸取更多不务正业的奇怪知识。</p> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-09-30-yo-you-checked-in-30-times-bitch/1759239141_5-480.webp 480w,/assets/img/2025-09-30-yo-you-checked-in-30-times-bitch/1759239141_5-800.webp 800w,/assets/img/2025-09-30-yo-you-checked-in-30-times-bitch/1759239141_5-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/2025-09-30-yo-you-checked-in-30-times-bitch/1759239141_5.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> </div> </div> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-09-30-yo-you-checked-in-30-times-bitch/1759239142_6-480.webp 480w,/assets/img/2025-09-30-yo-you-checked-in-30-times-bitch/1759239142_6-800.webp 800w,/assets/img/2025-09-30-yo-you-checked-in-30-times-bitch/1759239142_6-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/2025-09-30-yo-you-checked-in-30-times-bitch/1759239142_6.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> </div> </div> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-09-30-yo-you-checked-in-30-times-bitch/1759239143_7-480.webp 480w,/assets/img/2025-09-30-yo-you-checked-in-30-times-bitch/1759239143_7-800.webp 800w,/assets/img/2025-09-30-yo-you-checked-in-30-times-bitch/1759239143_7-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/2025-09-30-yo-you-checked-in-30-times-bitch/1759239143_7.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> </div> </div> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-09-30-yo-you-checked-in-30-times-bitch/1759239145_8-480.webp 480w,/assets/img/2025-09-30-yo-you-checked-in-30-times-bitch/1759239145_8-800.webp 800w,/assets/img/2025-09-30-yo-you-checked-in-30-times-bitch/1759239145_8-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/2025-09-30-yo-you-checked-in-30-times-bitch/1759239145_8.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> </div> </div> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-09-30-yo-you-checked-in-30-times-bitch/1759239146_9-480.webp 480w,/assets/img/2025-09-30-yo-you-checked-in-30-times-bitch/1759239146_9-800.webp 800w,/assets/img/2025-09-30-yo-you-checked-in-30-times-bitch/1759239146_9-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/2025-09-30-yo-you-checked-in-30-times-bitch/1759239146_9.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> </div> </div> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-09-30-yo-you-checked-in-30-times-bitch/1759239147_10-480.webp 480w,/assets/img/2025-09-30-yo-you-checked-in-30-times-bitch/1759239147_10-800.webp 800w,/assets/img/2025-09-30-yo-you-checked-in-30-times-bitch/1759239147_10-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/2025-09-30-yo-you-checked-in-30-times-bitch/1759239147_10.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> </div> </div> <p>但是其实反过来看根还是没有变。我现在8点起来到晚上12点睡觉，依然还是精力满满，战斗力爆棚，每天都是感觉能量很满的那种。依然保持着自己的态度和节奏去生活去工作，也继续保持自己乐爱分享的风格。</p> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-09-30-yo-you-checked-in-30-times-bitch/1759239149_11-480.webp 480w,/assets/img/2025-09-30-yo-you-checked-in-30-times-bitch/1759239149_11-800.webp 800w,/assets/img/2025-09-30-yo-you-checked-in-30-times-bitch/1759239149_11-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/2025-09-30-yo-you-checked-in-30-times-bitch/1759239149_11.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> </div> </div> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-09-30-yo-you-checked-in-30-times-bitch/1759239151_12-480.webp 480w,/assets/img/2025-09-30-yo-you-checked-in-30-times-bitch/1759239151_12-800.webp 800w,/assets/img/2025-09-30-yo-you-checked-in-30-times-bitch/1759239151_12-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/2025-09-30-yo-you-checked-in-30-times-bitch/1759239151_12.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> </div> </div> <h2 id="关于这座城市">关于这座城市</h2> <p>厦门是我的第二故乡，上海很有机会成为第三故乡。我和在上海多年的同学朋友约饭，让我感觉很魔幻的一点是，我在过往的岁月里，在杂志上看过很多上海有名有趣的地点，有一些我都记下来了，我问他们，不知道或没去过。这让我大为诧异，或许不是每一个人都会像我一样的心态来到这个城市吧？现在的我周一到周五依然那么“卷”，但是周末的我不卷了，或者说我开始卷这个城市。</p> <p>游客打卡的地方，我花一个周末就可以扫荡掉了，其他的是开始发现这座城市的魅力。我相信就业机会一定不是唯一留下大家的一点。这里很国际化，很多活动在这里都能第一时间参与。这里人很多，年轻人也很多，大家都有消费力，很多很前卫很个性的人，一起造就了这个城市的基调。</p> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-09-30-yo-you-checked-in-30-times-bitch/1759239155_13-480.webp 480w,/assets/img/2025-09-30-yo-you-checked-in-30-times-bitch/1759239155_13-800.webp 800w,/assets/img/2025-09-30-yo-you-checked-in-30-times-bitch/1759239155_13-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/2025-09-30-yo-you-checked-in-30-times-bitch/1759239155_13.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> </div> </div> <p>我相信很多人只是把自己当作城市的过客，我觉得这会丧失很多有趣的东西。或许可以尝试去感受这个城市，去生活在这个城市，而不是在这个城市打工。</p> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-09-30-yo-you-checked-in-30-times-bitch/1759239156_14-480.webp 480w,/assets/img/2025-09-30-yo-you-checked-in-30-times-bitch/1759239156_14-800.webp 800w,/assets/img/2025-09-30-yo-you-checked-in-30-times-bitch/1759239156_14-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/2025-09-30-yo-you-checked-in-30-times-bitch/1759239156_14.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> </div> </div> <p>我第一次体会了去线下听脱口秀，除了椅子硬了一点以外，感觉还是很有趣的。不过我也不太懂，第一次去就去了开放麦现场，希望后面可以去听一些以前觉得说段子比较有趣的人。</p> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-09-30-yo-you-checked-in-30-times-bitch/1759239157_15-480.webp 480w,/assets/img/2025-09-30-yo-you-checked-in-30-times-bitch/1759239157_15-800.webp 800w,/assets/img/2025-09-30-yo-you-checked-in-30-times-bitch/1759239157_15-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/2025-09-30-yo-you-checked-in-30-times-bitch/1759239157_15.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> </div> </div> <p>也去了晚上9点后的美术馆，人还真不少，感觉人一多就差点意思，以后我想试试早上很早去，比晚比不过，比早看看。</p> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-09-30-yo-you-checked-in-30-times-bitch/1759239158_16-480.webp 480w,/assets/img/2025-09-30-yo-you-checked-in-30-times-bitch/1759239158_16-800.webp 800w,/assets/img/2025-09-30-yo-you-checked-in-30-times-bitch/1759239158_16-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/2025-09-30-yo-you-checked-in-30-times-bitch/1759239158_16.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> </div> </div> <p>这句话还挺有意思的，虽然我不知道每个人的背景，但是我感觉我在我们Team里应该是学历最渣渣的家伙。这是一件很有趣的事情啊，我每次想到都会会心一笑。我从来不是唯学历论的人，我是拿着自己的热爱和别人的工作拼，热爱是我的力量来源！我觉得这句话还挺适合我的。我不属于任何流派，我只想创造属于自己的艺术。恰巧今天和我的一个同学吃饭聊到：我相信能进到这里的人都是在某一方面很厉害的，不管是能力、学历还是面试能力甚至是运气，我相信并且确信我可以从身边优秀的人身上学到很多东西，我也相信我有东西值得他们学习。希望自己能一直是一个自洽自信但不自负的人，至少目前的我是狂喜的，我可以学习，我有目标赶超。</p> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-09-30-yo-you-checked-in-30-times-bitch/1759239159_17-480.webp 480w,/assets/img/2025-09-30-yo-you-checked-in-30-times-bitch/1759239159_17-800.webp 800w,/assets/img/2025-09-30-yo-you-checked-in-30-times-bitch/1759239159_17-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/2025-09-30-yo-you-checked-in-30-times-bitch/1759239159_17.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> </div> </div> <p>西岸真是一个很有趣的地方，最早是在一财里看到，Gate M西岸梦中心，当时就是看看图片，但是默默记下了这个地点，确实是一个很棒的地方，这个月我已经去了好几次了，只不过最近有光影秀，人稍微有亿点多了。</p> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-09-30-yo-you-checked-in-30-times-bitch/1759239160_18-480.webp 480w,/assets/img/2025-09-30-yo-you-checked-in-30-times-bitch/1759239160_18-800.webp 800w,/assets/img/2025-09-30-yo-you-checked-in-30-times-bitch/1759239160_18-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/2025-09-30-yo-you-checked-in-30-times-bitch/1759239160_18.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> </div> </div> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-09-30-yo-you-checked-in-30-times-bitch/1759239162_19-480.webp 480w,/assets/img/2025-09-30-yo-you-checked-in-30-times-bitch/1759239162_19-800.webp 800w,/assets/img/2025-09-30-yo-you-checked-in-30-times-bitch/1759239162_19-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/2025-09-30-yo-you-checked-in-30-times-bitch/1759239162_19.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> </div> </div> <p>来这里也参与了很多活动，我酷爱参与这些活动，希望后续可以再多发掘一些有趣的活动，更好的是能遇到一些有趣的人，能唠嗑的人。</p> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-09-30-yo-you-checked-in-30-times-bitch/1759239162_20-480.webp 480w,/assets/img/2025-09-30-yo-you-checked-in-30-times-bitch/1759239162_20-800.webp 800w,/assets/img/2025-09-30-yo-you-checked-in-30-times-bitch/1759239162_20-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/2025-09-30-yo-you-checked-in-30-times-bitch/1759239162_20.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> </div> </div> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-09-30-yo-you-checked-in-30-times-bitch/1759239163_21-480.webp 480w,/assets/img/2025-09-30-yo-you-checked-in-30-times-bitch/1759239163_21-800.webp 800w,/assets/img/2025-09-30-yo-you-checked-in-30-times-bitch/1759239163_21-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/2025-09-30-yo-you-checked-in-30-times-bitch/1759239163_21.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> </div> </div> <p>Trae这个活动还挺魔幻的，报名之前我还不是ByteDancer，结果活动那天，我自己刷着工卡进来了，哈哈。就是没得机会搞一件文化衫。</p> <h2 id="关于这家公司">关于这家公司</h2> <p>其实我还是想不通为什么那么多人骂大厂？至少字节是我待过很舒服的一家公司了，以后再听到有人骂，我可以仔细听听他们到底在骂什么了。我自己瞎想的几点：</p> <ul> <li>工作时长问题：现在没有996了，不过对于有家庭的人，或者追求WLB的人，或许会有一些困扰，这点我倒是能理解。毕竟每个人的耐受度不同，期望也不同</li> <li>PUA：目前没感觉到，我们Team大家都很不错，老大人也很好。我相信应该有的团队会遇到，这个跟+1应该还是有很大关系的，但是如果对比一下国企或者中小企业，或许不足为道。没遇到自然没有话语权，但是我相信一个企业的文化是自上而下的，我相信张一鸣和梁汝波，因为我能从现行的企业文化和规范制度里感受到，我依然选择相信</li> <li>不培养、纯用：我有听说过这种说法，但是感觉这不应该成为骂的原因。至少社招来说，更多是业务和文化上面的了解和适应，其他的能力正是自己价值的体现才对</li> </ul> <p>其他的暂时没想到了，看了字节圈里的一些moment，不太想再看了。虽然我从来是站在个人的角度，而不是资本，但是我想说其实很多时候还是自己的心态出了问题。跟能力或许也没关系，跟勇气比较有关系，如果不是自己想要的生活，为了碎银几两，让自己沉浸在无尽的抱怨和负能量能中，或许是对短暂的生命的不负责任。或许可以考虑下自己有勇气去表达不满，是否有勇气去做出改变？如果有能力可以改变这个场，如果能力没那么大，是可以尝试改变自己。</p> <p>公司三餐都有，刚来一周我傻傻的，阿姨给多少我吃多少，结果每天都很撑，胖了2、3斤，吓屎了。现在都是狠狠的和阿姨Say No，一半就好，少点少点。算是感受到了大厂的路数了，把公司搞成跟你家一样，你就不想回家（笑。不过升降桌和舒服的椅子还有大4k真的是我的福音，救命的宝贝，腰也好了，颈椎也棒了。</p> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-09-30-yo-you-checked-in-30-times-bitch/1759239166_22-480.webp 480w,/assets/img/2025-09-30-yo-you-checked-in-30-times-bitch/1759239166_22-800.webp 800w,/assets/img/2025-09-30-yo-you-checked-in-30-times-bitch/1759239166_22-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/2025-09-30-yo-you-checked-in-30-times-bitch/1759239166_22.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> </div> </div> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-09-30-yo-you-checked-in-30-times-bitch/1759239167_23-480.webp 480w,/assets/img/2025-09-30-yo-you-checked-in-30-times-bitch/1759239167_23-800.webp 800w,/assets/img/2025-09-30-yo-you-checked-in-30-times-bitch/1759239167_23-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/2025-09-30-yo-you-checked-in-30-times-bitch/1759239167_23.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> </div> </div> <p>Inspire Creativity Enrich Life。不错的slogan。就是鸭舌帽带完，背包背了，妹子笑出屏幕了，领完就压箱底了。默默流泪。</p> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-09-30-yo-you-checked-in-30-times-bitch/1759239169_24-480.webp 480w,/assets/img/2025-09-30-yo-you-checked-in-30-times-bitch/1759239169_24-800.webp 800w,/assets/img/2025-09-30-yo-you-checked-in-30-times-bitch/1759239169_24-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/2025-09-30-yo-you-checked-in-30-times-bitch/1759239169_24.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> </div> </div> <p>Always Day 1。这边的价值观倒是和我蛮匹配的。前面断断续续的也说了一些有的没得，主要是还有一小时要关空调了，很闷，写完赶紧跑。不管怎么说最后总得升华一下吧？虽然中午的大闸蟹我没吃到。</p> <h2 id="写在最后">写在最后</h2> <p>倒也没想到翻翻相册能翻出这么多随手拍的照片，一个月很快也很慢，写下这些零碎的想法，其实也是为了给未来的自己看看现在的我是怎么想的。现在的科技很发达了，但是我却更难记得发生在我身边的很多东西。信息的载体有很多，但是或许只有文字可以让人用更加平静的心绪去记录和接收。</p> <p>我相信AI时代给我带来的变化，是一种被车撞了的感觉，然后获得一种奇怪的能力。但是仔细想过后，也不知道是因为AI时代的原因，还是我30岁了的原因，还是两者既有。也不重要了，或许我们可以把现在的时代按照一些宏大叙事来说，AI时代，怎么能不Hype一下，FOMO一下呢？但是时代里平凡的个体才是组成这个时代的一切，虽然在宏大叙事里的个人，微不足道，但是我们仍然有理由去追求美好的事物。</p> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-09-30-yo-you-checked-in-30-times-bitch/1759239169_25-480.webp 480w,/assets/img/2025-09-30-yo-you-checked-in-30-times-bitch/1759239169_25-800.webp 800w,/assets/img/2025-09-30-yo-you-checked-in-30-times-bitch/1759239169_25-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/2025-09-30-yo-you-checked-in-30-times-bitch/1759239169_25.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> </div> </div> <p>最近Nike重拾的广告词能表达同样的意思：Why do it? Just do it. 伟大的背后是平凡的生活，每个人都能谱写出属于自己的故事。</p>]]></content><author><name></name></author><category term="PersonalUpdate"/><category term="PersonalUpdate"/><category term="Thoughts"/><summary type="html"><![CDATA[充实的一个月。节前最后一天了，到新的城市、新的公司一个月了，我感觉好像过去好几个月的那种感觉。今天兄弟们都早早撤了，留下几个还在“假装”上班的人，包括我，哈哈。索性就写点东西]]></summary></entry><entry><title type="html">LeoTalk AI周知 2: Qwen is on fire!</title><link href="https://ifuryst.github.io/blog/2025/leotalk-ai-weekly-1-qwen-is-on-fire/" rel="alternate" type="text/html" title="LeoTalk AI周知 2: Qwen is on fire!"/><published>2025-09-29T00:00:00+00:00</published><updated>2025-09-29T00:00:00+00:00</updated><id>https://ifuryst.github.io/blog/2025/leotalk-ai-weekly-1-qwen-is-on-fire</id><content type="html" xml:base="https://ifuryst.github.io/blog/2025/leotalk-ai-weekly-1-qwen-is-on-fire/"><![CDATA[<h1 id="技术研究技术突破">技术研究/技术突破</h1> <h2 id="google-cloud-dora发布了一份ai使用报告">Google Cloud DORA发布了一份AI使用报告</h2> <blockquote> <p><strong>DORA（DevOps Research and Assessment）</strong>是Google Cloud推动的一个长期研究项目，起源于2014年，目前已经是业界最长期、最系统的关于软件交付性能与组织效能的学术研究之一</p> </blockquote> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-09-29-leotalk-ai-weekly-1-qwen-is-on-fire/1759147221_33.webp-480.webp 480w,/assets/img/2025-09-29-leotalk-ai-weekly-1-qwen-is-on-fire/1759147221_33.webp-800.webp 800w,/assets/img/2025-09-29-leotalk-ai-weekly-1-qwen-is-on-fire/1759147221_33.webp-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/2025-09-29-leotalk-ai-weekly-1-qwen-is-on-fire/1759147221_33.webp" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> </div> </div> <p>这次DORA发的2025年<a href="https://services.google.com/fh/files/misc/2025_state_of_ai_assisted_software_development.pdf">State of AI-assisted Software Development</a>，核心内容在官网blog的<a href="https://blog.google/technology/developers/dora-report-2025/">这篇文章</a>里总结了：</p> <ul> <li>AI已成为开发者标配：</li> <li>全球近90%软件开发从业者（开发、PM等）已采用AI，比去年提高14%</li> <li>他们平均每天花费约2小时使用AI工具</li> <li>65%的人对AI有较强依赖，其中20%表示依赖很多，8%表示依赖极大</li> <li>带来的好处：</li> <li>生产力提升：超过80%受访者认为AI提高了工作效率</li> <li>代码质量提升：59%的人表示AI对代码质量有正面影响</li> <li>交付频率提高：AI使用与更高的软件交付速度挂钩，逆转了去年的负面趋势</li> <li>信任与生产力的悖论</li> <li>尽管AI提高了效率，但信任度并不高：只有24%表示非常信任或比较信任AI，30%表示有点信任甚至完全不信任</li> <li>说明很多人虽然觉得AI游泳，但是仍然不会完全依赖，更多还是辅助共生的关系</li> <li>团队层面的影响：</li> <li>AI不仅提高个人效率，还像放大器：在高效协作团队中AI放大优势，让效率更高；在分散低效的团队中，AI反而会凸显问题</li> <li>报告提出了七类团队画像，从和谐高效到遗留瓶颈，帮助组织理解AI如何作用不同团队文化和环境</li> <li><a href="https://cloud.google.com/blog/products/ai-machine-learning/introducing-doras-inaugural-ai-capabilities-model">DORA AI能力模型</a></li> <li>DORA团队发布了首个AI能力模型（DORA AI Capabilities Model），目的是帮助组织从使用AI真正走向成功利用AI。研究基于78次深度访谈、专家意见和近5000名受访者的调查，筛选出7个对AI软件开发成功至关重要的能力（不仅涉及技术，还包括文化和流程建设）： <ol> <li><strong>清晰且传达良好的AI立场</strong>：组织必须明确并沟通AI工具使用立场，包括允许的工具范围、实验探索的支持和对AI使用的期望；清晰的立场能放大AI对个人效率和组织绩效的积极影响，并减少员工的摩擦感。这个能力衡量的不是AI使用政策的具体能容，而是政策是否能<strong>明确且被传达</strong>。</li> <li><strong>健康的数据生态系统</strong>：高质量、易获取、统一的内部数据能显著放大AI对组织绩效的积极影响。</li> <li><strong>AI可访问的内部数据</strong>：将AI工具与公司内部文档、代码库等数据进行连接，能提高开发者效率和代码质量，使AI成为高度专业化的助手</li> <li><strong>强健的版本控制实践</strong>；AI生成代码的体量和速度更快，因此频繁提交和熟练使用回滚功能，能有效提升个人效率和团队绩效</li> <li><strong>小批量工作</strong>：小批量开发是DORA的长期原则，小批量迭代在AI环境下更能放大对产品的正向影响，并降低团队摩擦</li> <li><strong>用户导向的专注</strong>：以用户体验为核心是AI团队成功的关键。缺乏用户导向时，AI甚至可能对团队绩效产生负面影响</li> <li><strong>高质量的内部平台</strong>：高质量的内部平台能提供共享能力和安全护栏，帮助组织有效规模AI的价值</li> </ol> </li> <li>强调光有AI工具不够，必须配合组织变革，才能释放AI的全部潜力</li> </ul> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-09-29-leotalk-ai-weekly-1-qwen-is-on-fire/1759147221_34.webp-480.webp 480w,/assets/img/2025-09-29-leotalk-ai-weekly-1-qwen-is-on-fire/1759147221_34.webp-800.webp 800w,/assets/img/2025-09-29-leotalk-ai-weekly-1-qwen-is-on-fire/1759147221_34.webp-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/2025-09-29-leotalk-ai-weekly-1-qwen-is-on-fire/1759147221_34.webp" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> </div> </div> <p><em>Opinion：AI正在从实验性工具转变成开发世界的核心基础设施。低信任+高采用率可能不是矛盾，而是一种平衡，开发者一来AI提升效率，同时仍然人工判断把关质量。我依然相信可预见的这几年，AI和人是共生关系，而不是替代关系，个人和企业在市场化经济里竞争，比的不是谁能以光速赛跑，而是只要能比竞争对手多跑快一点点就够了，AI能带来的就是跑得快的能力，至于跑得稳和跑得远，还是极度依赖个人和企业的能力</em></p> <h2 id="cloudera发布ai的调查报告">Cloudera发布AI的调查报告</h2> <p>Cloudera发布了<a href="https://www.cloudera.com/content/dam/www/marketing/resources/analyst-reports/the-evolution-of-ai-the-state-of-enterprise-ai-and-data-architecture.pdf?daqp=true"><strong>The Evolution of AI: The State of Enterprise AI and Data Architecture</strong></a>，一些比较有趣的点：</p> <ul> <li>企业AI的普及和价值：</li> <li>AI成为刚需：96%的企业在核心业务流程中整合了AI</li> <li>AI带来实际价值：52%的受访者认为他们从AI中获得了可衡量的业务价值</li> <li>AI Agents兴起：36%已经使用AI Agent，83%认为投资Agent对保持竞争力很重要</li> <li>AI落地的挑战</li> <li>数据可用性不足：只有9%的企业能让100%的数据可被AI使用，大部分仍然存在数据孤岛</li> <li>算力成本激增：2024年只有8%认为训练算力成本太高，2025年增长到42%</li> <li>安全与合规挑战：</li> <li>主要安全顾虑：数据泄漏50%，未授权访问48%，不安全的三方AI工具43%，模型投毒35%，合规问题35%，其他是幻觉、模型可解性不足等</li> </ul> <p><em>Opinion：算是相关从业者的报告，必然是会偏乐观的。我们能持续看到各方发布的跟AI有关的报告，有很悲观，也有很乐观的，很难甄别具体的采样规模和受众群体是否有代表，是否适应每个读者。但是不可否认的是，泡沫的出现是好事，有声量的技术和趋势永远好于无人问津的故事，客观对待每一份报告，结合所在行业的业务情况，可以有效的通过不同角度的报告来印证一些想法和趋势。一份报告的价值不在于正确与否，而在于能提供一些有价值的视角和观点。</em></p> <h1 id="产品模型发布">产品&amp;模型发布</h1> <ul> <li><a href="https://openai.com/index/introducing-chatgpt-pulse/">OpenAI推出ChatGPT Pulse</a>：基于ChatGPT的一个新功能，每天晚上自动整理近期的兴趣、目标和上下文，第二天早上生成一组个性化的信息卡片。还可以连接外部应用比如Gmail、Google Calendar之类的。目前仅Pro可用，后续会推向plus和免费用户</li> <li><a href="https://about.fb.com/news/2025/09/introducing-vibes-ai-videos/">Meta推出Vibes</a>：AI视频Feed，可以创建和浏览AI视频</li> <li><a href="https://x.com/Kimi_Moonshot/status/1971078467560276160">Kimi推出Agent模式</a></li> <li><a href="https://blog.google/technology/google-labs/mixboard/">Google推出了MixBoard</a>：画布产品，目前看着更多还是基于Nano Banana的能力做概念设计画板（Concepting Board）</li> <li><a href="https://developers.googleblog.com/en/building-the-next-generation-of-physical-agents-with-gemini-robotics-er-15/">DeepMind发布机器人AI模型Gemini Robotics ER 1.5</a>：ER代表具身推理（Embodied Resoning）</li> <li><a href="https://x.com/SunoMusic/status/1970583230807167300">Suno v5发布</a>：结合Spotify的政策，看各方对AI不同态度很有趣</li> <li><a href="https://x.com/deepseek_ai/status/1970117808035074215">DeepSeek推出DeepSeek-V3.1-Terminus</a>：V3.1的一个稳定增强版，主要是稳定性和Agent能力提升</li> <li><a href="https://ollama.com/blog/web-search">Ollama提供免费的Web Search API</a></li> <li><a href="https://developers.googleblog.com/en/continuing-to-bring-you-our-latest-models-with-an-improved-gemini-2-5-flash-and-flash-lite-release/">Google更新了Gemini 2.5 Flash和Flash-Lite</a></li> <li><a href="https://scale.com/blog/showdown">Scale AI推出SEAL Showdown</a>：一份基于来自真实用户的Benchmark，试图挑战LMArena</li> <li><a href="https://newsroom.spotify.com/2025-09-25/spotify-strengthens-ai-protections/">Spotify加大对AI音乐的监管</a>：艺术家必须使用音乐数据标准（DDEX）来标注AI的参与，虚假和未经授权的AI声音克隆将被拦截</li> <li><a href="https://github.com/Tencent-Hunyuan/HunyuanImage-3.0">腾讯开源HunyuanImage-3.0</a></li> </ul> <h2 id="阿里推出多个模型">阿里推出多个模型</h2> <p>这周阿里火力全开，连发了好几个模型</p> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-09-29-leotalk-ai-weekly-1-qwen-is-on-fire/1759147221_35-480.webp 480w,/assets/img/2025-09-29-leotalk-ai-weekly-1-qwen-is-on-fire/1759147221_35-800.webp 800w,/assets/img/2025-09-29-leotalk-ai-weekly-1-qwen-is-on-fire/1759147221_35-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/2025-09-29-leotalk-ai-weekly-1-qwen-is-on-fire/1759147221_35.jpeg" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> </div> </div> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-09-29-leotalk-ai-weekly-1-qwen-is-on-fire/1759147221_36-480.webp 480w,/assets/img/2025-09-29-leotalk-ai-weekly-1-qwen-is-on-fire/1759147221_36-800.webp 800w,/assets/img/2025-09-29-leotalk-ai-weekly-1-qwen-is-on-fire/1759147221_36-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/2025-09-29-leotalk-ai-weekly-1-qwen-is-on-fire/1759147221_36.jpeg" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> </div> </div> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-09-29-leotalk-ai-weekly-1-qwen-is-on-fire/1759147222_37-480.webp 480w,/assets/img/2025-09-29-leotalk-ai-weekly-1-qwen-is-on-fire/1759147222_37-800.webp 800w,/assets/img/2025-09-29-leotalk-ai-weekly-1-qwen-is-on-fire/1759147222_37-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/2025-09-29-leotalk-ai-weekly-1-qwen-is-on-fire/1759147222_37.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> </div> </div> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-09-29-leotalk-ai-weekly-1-qwen-is-on-fire/1759147222_38-480.webp 480w,/assets/img/2025-09-29-leotalk-ai-weekly-1-qwen-is-on-fire/1759147222_38-800.webp 800w,/assets/img/2025-09-29-leotalk-ai-weekly-1-qwen-is-on-fire/1759147222_38-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/2025-09-29-leotalk-ai-weekly-1-qwen-is-on-fire/1759147222_38.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> </div> </div> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-09-29-leotalk-ai-weekly-1-qwen-is-on-fire/1759147222_39-480.webp 480w,/assets/img/2025-09-29-leotalk-ai-weekly-1-qwen-is-on-fire/1759147222_39-800.webp 800w,/assets/img/2025-09-29-leotalk-ai-weekly-1-qwen-is-on-fire/1759147222_39-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/2025-09-29-leotalk-ai-weekly-1-qwen-is-on-fire/1759147222_39.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> </div> </div> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-09-29-leotalk-ai-weekly-1-qwen-is-on-fire/1759147222_40-480.webp 480w,/assets/img/2025-09-29-leotalk-ai-weekly-1-qwen-is-on-fire/1759147222_40-800.webp 800w,/assets/img/2025-09-29-leotalk-ai-weekly-1-qwen-is-on-fire/1759147222_40-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/2025-09-29-leotalk-ai-weekly-1-qwen-is-on-fire/1759147222_40.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> </div> </div> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-09-29-leotalk-ai-weekly-1-qwen-is-on-fire/1759147223_41-480.webp 480w,/assets/img/2025-09-29-leotalk-ai-weekly-1-qwen-is-on-fire/1759147223_41-800.webp 800w,/assets/img/2025-09-29-leotalk-ai-weekly-1-qwen-is-on-fire/1759147223_41-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/2025-09-29-leotalk-ai-weekly-1-qwen-is-on-fire/1759147223_41.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> </div> </div> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-09-29-leotalk-ai-weekly-1-qwen-is-on-fire/1759147223_42-480.webp 480w,/assets/img/2025-09-29-leotalk-ai-weekly-1-qwen-is-on-fire/1759147223_42-800.webp 800w,/assets/img/2025-09-29-leotalk-ai-weekly-1-qwen-is-on-fire/1759147223_42-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/2025-09-29-leotalk-ai-weekly-1-qwen-is-on-fire/1759147223_42.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> </div> </div> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-09-29-leotalk-ai-weekly-1-qwen-is-on-fire/1759147223_43-480.webp 480w,/assets/img/2025-09-29-leotalk-ai-weekly-1-qwen-is-on-fire/1759147223_43-800.webp 800w,/assets/img/2025-09-29-leotalk-ai-weekly-1-qwen-is-on-fire/1759147223_43-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/2025-09-29-leotalk-ai-weekly-1-qwen-is-on-fire/1759147223_43.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> </div> </div> <h2 id="openai推出responses-api">OpenAI推出Responses API</h2> <p>OpenAPI<a href="https://developers.openai.com/blog/responses-api">发布</a>了<a href="https://platform.openai.com/docs/api-reference/responses">Responses API</a>，是基于<code class="language-plaintext highlighter-rouge">/v1/completions</code>和<code class="language-plaintext highlighter-rouge">/v1/chat/completions</code>之后的一个新的接口：<strong>一个具备持久推理、原声多模态和托管工具的状态化Agent接口，让开发者可以在一次API中同时获取模型的对话内容、推理过程中的动作（如函数调用）以及工具使用结果</strong>。</p> <p><em>Opinion：可以看我写的文章</em><a href="https://ifuryst.substack.com/p/openairesponses-api"><strong><em>为什么OpenAI要推出Responses API</em></strong></a></p> <h1 id="投资商业">投资&amp;商业</h1> <h2 id="nvidia和openai达成战略合作">Nvidia和OpenAI达成战略合作</h2> <p>9月22日<a href="https://openai.com/index/openai-nvidia-systems-partnership/">Nvidia</a>和<a href="https://openai.com/index/openai-nvidia-systems-partnership/">OpenAI</a>宣布达成战略合作，包括：</p> <ul> <li>部署至少10吉瓦（GW）算力的AI数据中心（配套了NVIDIA相关系统），涉及数百万卡的规模</li> <li>Nvidia会随着每1吉瓦部署为节点，陆续投资1千亿美元</li> <li>第1吉瓦会在2026年下半年上线，基于Nvidia的Vera Rubin平台</li> </ul> <p><em>Opinion: 英伟达4万亿俱乐部，市值第一，现在开始疯狂对外投资，而且有一些是以显卡来投资，反向反哺自己的核心业务，非常聪明的做法。</em></p> <h1 id="机器人相关">机器人相关</h1> <ul> <li><a href="https://x.com/SkildAI/status/1970940614234771579">Skild AI发布“全能机器人大脑”（omni-bodied robot brain）</a>：与传统机器人控制器记忆单一机器人解决方案不同，无需针对特定机器人编程即可控制机器人。展示了不管是肢体坏了还是电机卡死，只要机器人还能动，就能让他动</li> <li><a href="https://spectrum.ieee.org/swallowable-robotic-pill-gut-health">国内研究人员公布药丸大小的机器人</a></li> <li><a href="https://www.nytimes.com/2025/09/25/business/china-factory-robots.html">国内去年安装了近30万台工厂机器人</a>：数量超过世界其他国家的总和，目前预计有超过200万台机器人在运作。</li> <li><a href="https://www.youtube.com/watch?v=w4kC-XCEXaQ">国内机器人公司AheadForm发布一款人形机器人头部</a>：面部逼真以及自然眨眼的动作。</li> </ul> <h1 id="热点论文">热点论文</h1> <ul> <li><a href="https://ai.meta.com/research/publications/cwm-an-open-weights-llm-for-research-on-code-generation-with-world-models/">CWM: An Open-Weights LLM for Research on Code Generation with World Models</a></li> <li><a href="https://arxiv.org/abs/2509.17765">Qwen3-Omni Technical Report</a></li> <li><a href="https://arxiv.org/abs/2509.19736">UserRL: Training Interactive User-Centric Agent via Reinforcement Learning</a></li> <li><a href="https://arxiv.org/abs/2509.17567">LIMI: Less is More for Agency</a></li> <li><a href="https://ai.meta.com/research/publications/are-scaling-up-agent-environments-and-evaluations/">ARE: scaling up agent environments and evaluations</a></li> <li><a href="https://arxiv.org/abs/2503.20523">GAIA-2: A Controllable Multi-View Generative World Model for Autonomous Driving</a></li> <li><a href="https://cdn.openai.com/pdf/d5eb7428-c4e9-4a33-bd86-86dd4bcf12ce/GDPval.pdf">GDPVAL</a>: <a href="https://openai.com/index/gdpval/">Measuring the performance of our models on real-world tasks</a></li> </ul> <h1 id="其他阅读">其他阅读</h1> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-09-29-leotalk-ai-weekly-1-qwen-is-on-fire/1759147223_44-480.webp 480w,/assets/img/2025-09-29-leotalk-ai-weekly-1-qwen-is-on-fire/1759147223_44-800.webp 800w,/assets/img/2025-09-29-leotalk-ai-weekly-1-qwen-is-on-fire/1759147223_44-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/2025-09-29-leotalk-ai-weekly-1-qwen-is-on-fire/1759147223_44.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> </div> </div> <ul> <li><a href="https://spectrum.ieee.org/top-programming-languages-2025">The Top Programming Languages 2025</a>：乘AI这股风的Python一骑绝尘。一个不错的观点：LLM的出现让一些新的编程语言几乎不可能流行，人们不再直接写代码，少量的示例和教程也不足以支撑AI学习这门新语言，因此新语言生成的代码效果会很差，下降螺旋。</li> <li><a href="https://www.julian.ac/blog/2025/09/27/failing-to-understand-the-exponential-again/">Failing to Understand the Exponential, Again</a>：关于AI的争论不休，但是过去几年AI确实实现了指数级的发展趋势了。</li> <li><a href="https://github.com/humanlayer/advanced-context-engineering-for-coding-agents/blob/main/ace-fca.md">Getting AI to Work in Complex Codebases</a>：很好的文章，把上下文工程的哲学运用到使用AI中，TL或者每一位一线的Dev、架构师和产品都值得看一下</li> <li><a href="https://www.dge.gov.ae/en/news/cx-strategy">阿布扎比公布一项新战略</a>：计划2027年成为全球首个完全AI原生的政府，并将在各个部门部署200多个AI解决方案</li> <li><a href="https://platform.leolabs.space/visualization">Low Earth Orbit Visualization</a>：可视化近地轨道，看看密密麻麻的近地轨道卫星</li> </ul>]]></content><author><name></name></author><category term="AI"/><category term="AI"/><category term="LeoTalkAIWeekly"/><summary type="html"><![CDATA[技术研究/技术突破]]></summary></entry><entry><title type="html">为什么OpenAI要推出Responses API</title><link href="https://ifuryst.github.io/blog/2025/why-openai-built-the-responses-api/" rel="alternate" type="text/html" title="为什么OpenAI要推出Responses API"/><published>2025-09-24T00:00:00+00:00</published><updated>2025-09-24T00:00:00+00:00</updated><id>https://ifuryst.github.io/blog/2025/why-openai-built-the-responses-api</id><content type="html" xml:base="https://ifuryst.github.io/blog/2025/why-openai-built-the-responses-api/"><![CDATA[<p>9月22日OpenAPI<a href="https://developers.openai.com/blog/responses-api">发布</a>了<a href="https://platform.openai.com/docs/api-reference/responses">Responses API</a>，是基于<code class="language-plaintext highlighter-rouge">/v1/completions</code>和<code class="language-plaintext highlighter-rouge">/v1/chat/completions</code>之后的一个新的接口：<strong>一个具备持久推理、原声多模态和托管工具的状态化Agent接口，让开发者可以在一次API中同时获取模型的对话内容、推理过程中的动作（如函数调用）以及工具使用结果</strong>。</p> <p>原来的<code class="language-plaintext highlighter-rouge">/v1/chat/completions</code> 是基于回合返回的，也就是一来一往，虽然相比于最早的<code class="language-plaintext highlighter-rouge">/v1/completions</code>来说已经支持了不同的Role，这样可以通过聊天记录的形式对大模型展示之前的聊天记录，但是过程数据有困难在后续的推理请求中被丢弃，比如下图展示的</p> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-09-24-why-openai-built-the-responses-api/1758720622_31-480.webp 480w,/assets/img/2025-09-24-why-openai-built-the-responses-api/1758720622_31-800.webp 800w,/assets/img/2025-09-24-why-openai-built-the-responses-api/1758720622_31-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/2025-09-24-why-openai-built-the-responses-api/1758720622_31.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> </div> </div> <p>可以看到第一次请求的推理信息在第二次请求的时候被丢弃了。其实我不觉得这一定是一个不好的事情，从上下文工程的角度来看，这个行为很难评判其效果。OAI在这里是为了展示一个推理的连续性，让大模型拥有足够的上下文信息，而不是缺少。就好像Anthropic决定让Claude Code保留哪怕是工具执行失败的信息在上下文里，就是为了达到这个效果，哪怕看似没用的上下文，对于大模型在某次的推理中都有可能起到重要作用。目前的上下文工程难点之一就是难以鉴别到底什么上下文数据是“合适的”，在现在的发展阶段，这是一个很难量化的东西。</p> <p><code class="language-plaintext highlighter-rouge">/v1/chat/completions</code> 这个接口确实有一定的局限性，文章中这段话很精辟：</p> <blockquote> <p>Chat completions emits one <strong>message</strong> per request. The structure of a message is limiting: did the message or the function call come first?</p> </blockquote> <div class="language-javascript highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">{</span>
  <span class="dl">"</span><span class="s2">message</span><span class="dl">"</span><span class="p">:</span> <span class="p">{</span>
    <span class="dl">"</span><span class="s2">role</span><span class="dl">"</span><span class="p">:</span> <span class="dl">"</span><span class="s2">assistant</span><span class="dl">"</span><span class="p">,</span>
    <span class="dl">"</span><span class="s2">content</span><span class="dl">"</span><span class="p">:</span> <span class="dl">"</span><span class="s2">I'm going to use the get_weather tool to find the weather.</span><span class="dl">"</span><span class="p">,</span>
    <span class="dl">"</span><span class="s2">tool_calls</span><span class="dl">"</span><span class="p">:</span> <span class="p">[</span>
      <span class="p">{</span>
        <span class="dl">"</span><span class="s2">id</span><span class="dl">"</span><span class="p">:</span> <span class="dl">"</span><span class="s2">call_88O3ElkW2RrSdRTNeeP1PZkm</span><span class="dl">"</span><span class="p">,</span>
        <span class="dl">"</span><span class="s2">type</span><span class="dl">"</span><span class="p">:</span> <span class="dl">"</span><span class="s2">function</span><span class="dl">"</span><span class="p">,</span>
        <span class="dl">"</span><span class="s2">function</span><span class="dl">"</span><span class="p">:</span> <span class="p">{</span>
          <span class="dl">"</span><span class="s2">name</span><span class="dl">"</span><span class="p">:</span> <span class="dl">"</span><span class="s2">get_weather</span><span class="dl">"</span><span class="p">,</span>
          <span class="dl">"</span><span class="s2">arguments</span><span class="dl">"</span><span class="p">:</span> <span class="dl">"</span><span class="s2">{</span><span class="se">\"</span><span class="s2">location</span><span class="se">\"</span><span class="s2">:</span><span class="se">\"</span><span class="s2">New York, NY</span><span class="se">\"</span><span class="s2">,</span><span class="se">\"</span><span class="s2">unit</span><span class="se">\"</span><span class="s2">:</span><span class="se">\"</span><span class="s2">f</span><span class="se">\"</span><span class="s2">}</span><span class="dl">"</span>
        <span class="p">}</span>
      <span class="p">}</span>
    <span class="p">],</span>
    <span class="dl">"</span><span class="s2">refusal</span><span class="dl">"</span><span class="p">:</span> <span class="kc">null</span><span class="p">,</span>
    <span class="dl">"</span><span class="s2">annotations</span><span class="dl">"</span><span class="p">:</span> <span class="p">[]</span>
  <span class="p">}</span>
<span class="p">}</span>
</code></pre></div></div> <p>消息和工具调用哪个先产生呢？这种同时到达的消息在某种程度上会造成一定的语义和逻辑困扰。我们应该走消息响应还是工具调用的流程？完全靠开发者去判断。这就是时序和结构不清晰带来的问题。</p> <p>为什么会存在这种问题呢？哈哈，背后的故事似乎也算是意料之外情理之中：<code class="language-plaintext highlighter-rouge">/v1/chat/completions</code>这个接口是<a href="https://x.com/athyuttamre">Atty Eleti</a>和<a href="https://x.com/_rlys">Rachel Lim</a>在<a href="https://x.com/athyuttamre/status/1899541474297180664">一个周末的时间里Build出来的</a>，然后全世界都adopt了。贴一张我的quote</p> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-09-24-why-openai-built-the-responses-api/1758720622_32-480.webp 480w,/assets/img/2025-09-24-why-openai-built-the-responses-api/1758720622_32-800.webp 800w,/assets/img/2025-09-24-why-openai-built-the-responses-api/1758720622_32-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/2025-09-24-why-openai-built-the-responses-api/1758720622_32.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> </div> </div> <p>很多人一定会有这种感受，买定离手的那种感觉，你永远不知道自己多草率决定的一个东西，居然因为大火被很多人采用之后，你的那种感觉！</p> <p>回到前面，从某个角度，我们可以认为Responses API是OAI在还债！我们常常听到的技术债！另外顺带做一些提升，也迎合一下市场对于Agentic API的需求。两全其美？现在Responses API返回的数据相对来说也更加合理的，按照时间线的形式来展示，非常清晰：</p> <div class="language-javascript highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">[</span>
  <span class="p">{</span>
    <span class="na">id</span><span class="p">:</span> <span class="dl">"</span><span class="s2">rs_6888f6d0606c819aa8205ecee386963f0e683233d39188e7</span><span class="dl">"</span><span class="p">,</span>
    <span class="na">type</span><span class="p">:</span> <span class="dl">"</span><span class="s2">reasoning</span><span class="dl">"</span><span class="p">,</span>
    <span class="na">summary</span><span class="p">:</span> <span class="p">[</span>
      <span class="p">{</span>
        <span class="na">type</span><span class="p">:</span> <span class="dl">"</span><span class="s2">summary_text</span><span class="dl">"</span><span class="p">,</span>
        <span class="na">text</span><span class="p">:</span> <span class="dl">"</span><span class="s2">**Determining weather response**</span><span class="se">\n\n</span><span class="s2">I need to answer the user's question about the weather in San Francisco. ....</span><span class="dl">"</span><span class="p">,</span>
      <span class="p">},</span>
    <span class="p">],</span>
  <span class="p">},</span>
  <span class="p">{</span>
    <span class="na">id</span><span class="p">:</span> <span class="dl">"</span><span class="s2">msg_6888f6d83acc819a978b51e772f0a5f40e683233d39188e7</span><span class="dl">"</span><span class="p">,</span>
    <span class="na">type</span><span class="p">:</span> <span class="dl">"</span><span class="s2">message</span><span class="dl">"</span><span class="p">,</span>
    <span class="na">status</span><span class="p">:</span> <span class="dl">"</span><span class="s2">completed</span><span class="dl">"</span><span class="p">,</span>
    <span class="na">content</span><span class="p">:</span> <span class="p">[</span>
      <span class="p">{</span>
        <span class="na">type</span><span class="p">:</span> <span class="dl">"</span><span class="s2">output_text</span><span class="dl">"</span><span class="p">,</span>
        <span class="na">text</span><span class="p">:</span> <span class="dl">"</span><span class="s2">I’m going to check a live weather service to get the current conditions in San Francisco, providing the temperature in both Fahrenheit and Celsius so it matches your preference.</span><span class="dl">"</span><span class="p">,</span>
      <span class="p">},</span>
    <span class="p">],</span>
    <span class="na">role</span><span class="p">:</span> <span class="dl">"</span><span class="s2">assistant</span><span class="dl">"</span><span class="p">,</span>
  <span class="p">},</span>
  <span class="p">{</span>
    <span class="na">id</span><span class="p">:</span> <span class="dl">"</span><span class="s2">fc_6888f6d86e28819aaaa1ba69cca766b70e683233d39188e7</span><span class="dl">"</span><span class="p">,</span>
    <span class="na">type</span><span class="p">:</span> <span class="dl">"</span><span class="s2">function_call</span><span class="dl">"</span><span class="p">,</span>
    <span class="na">status</span><span class="p">:</span> <span class="dl">"</span><span class="s2">completed</span><span class="dl">"</span><span class="p">,</span>
    <span class="na">arguments</span><span class="p">:</span> <span class="dl">'</span><span class="s1">{"location":"San Francisco, CA","unit":"f"}</span><span class="dl">'</span><span class="p">,</span>
    <span class="na">call_id</span><span class="p">:</span> <span class="dl">"</span><span class="s2">call_XOnF4B9DvB8EJVB3JvWnGg83</span><span class="dl">"</span><span class="p">,</span>
    <span class="na">name</span><span class="p">:</span> <span class="dl">"</span><span class="s2">get_weather</span><span class="dl">"</span><span class="p">,</span>
  <span class="p">},</span>
<span class="p">];</span>
</code></pre></div></div> <p>OAI也明确表明了未来几年会主推这个接口，希望其可以成为默认的接口，我觉得Agentic API确实有其独到之处，从上下文工程的角度来看，内化了状态化和上下文隔离的手段。但是这会不会让开发者丧失更多的控制权呢？让子弹再飞一会。</p>]]></content><author><name></name></author><category term="AI"/><category term="AI"/><category term="Insights"/><summary type="html"><![CDATA[9月22日OpenAPI发布了Responses API，是基于/v1/completions和/v1/chat/completions之后的一个新的接口：一个具备持久推理、原声多模态和托管工具的状态化Agent接口，让开发者可以在一次API中同时获取模型的对话内容、推理过程中的动作（如函数调用）以及工具使用结果。]]></summary></entry><entry><title type="html">LeoTalk AI周知 1: 新信息排泄物实验</title><link href="https://ifuryst.github.io/blog/2025/leotalk-ai-weekly-1-an-experiment-in-information-e/" rel="alternate" type="text/html" title="LeoTalk AI周知 1: 新信息排泄物实验"/><published>2025-09-22T00:00:00+00:00</published><updated>2025-09-22T00:00:00+00:00</updated><id>https://ifuryst.github.io/blog/2025/leotalk-ai-weekly-1-an-experiment-in-information-e</id><content type="html" xml:base="https://ifuryst.github.io/blog/2025/leotalk-ai-weekly-1-an-experiment-in-information-e/"><![CDATA[<p>这是我在尝试的一个每周资讯汇总的栏目，根因是自己摄入的信息太多了，但是越来越没有时间去支撑我做高密度的信息输出了，我转向寻求低频高质量的信息输出模式。这个内容算是这个模式里的一个专栏，主要用于汇集过去一周我看到的一些我觉得有价值的信息，主要以科技和AI为主，会相对垂直一点，这样有助于让感兴趣的人专注在这份有价值的信息上。目前还处于探索和尝试阶段，这周末又特别的忙，现在已经是半夜1点多了，我在周末忙完了一切我认为必须要做的事情之后，自己花了几个小时把信息规整完毕输出，算是赶鸭子上架了，我觉得有很多事情都是倒逼着去做反而能在高压下产出不错的东西，这也是我觉得Just Do It的精髓，不要追求完美，只需要开始即可。希望本文对你有所帮助，有任何想法和反馈都欢迎。</p> <h1 id="技术研究技术突破">技术研究/技术突破</h1> <h2 id="thinking-machines发布文章探讨解决大模型推理非确定性问题">Thinking Machines发布文章探讨解决大模型推理非确定性问题</h2> <p>Thinking Machines发布了<a href="https://thinkingmachines.ai/blog/defeating-nondeterminism-in-llm-inference/">Defeating Nondeterminism in LLM Inference</a>，文章揭示了大模型推理中非确定性的真正根源在于批量大小变化导致的算子非批量不变性（而非简单的并发+浮点非结合性），并提出通过设计批量不变的RMSNorm、矩阵乘法和注意力算子来实现真正可复现的确定性推理。</p> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-09-22-leotalk-ai-weekly-1-an-experiment-in-information-e/1758506416_1-480.webp 480w,/assets/img/2025-09-22-leotalk-ai-weekly-1-an-experiment-in-information-e/1758506416_1-800.webp 800w,/assets/img/2025-09-22-leotalk-ai-weekly-1-an-experiment-in-information-e/1758506416_1-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/2025-09-22-leotalk-ai-weekly-1-an-experiment-in-information-e/1758506416_1.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> </div> </div> <h2 id="xai发布grok-4-fast">xAI发布Grok 4 Fast</h2> <p>xAI<a href="https://x.ai/news/grok-4-fast">发布</a>了Grok 4 Fast，从名字能看出来，就是快！关键点：</p> <ul> <li>高性价比推理模型，定位更小更快更便宜的SOTA模型</li> <li>与Grok4性能接近，减少40%的Token消耗</li> <li>推理+非推理模型融合，通过系统提示词切换</li> <li>200万上下文长度！</li> <li>原生工具使用（RL训练过）</li> </ul> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-09-22-leotalk-ai-weekly-1-an-experiment-in-information-e/1758506416_2-480.webp 480w,/assets/img/2025-09-22-leotalk-ai-weekly-1-an-experiment-in-information-e/1758506416_2-800.webp 800w,/assets/img/2025-09-22-leotalk-ai-weekly-1-an-experiment-in-information-e/1758506416_2-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/2025-09-22-leotalk-ai-weekly-1-an-experiment-in-information-e/1758506416_2.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> </div> </div> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-09-22-leotalk-ai-weekly-1-an-experiment-in-information-e/1758506417_3-480.webp 480w,/assets/img/2025-09-22-leotalk-ai-weekly-1-an-experiment-in-information-e/1758506417_3-800.webp 800w,/assets/img/2025-09-22-leotalk-ai-weekly-1-an-experiment-in-information-e/1758506417_3-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/2025-09-22-leotalk-ai-weekly-1-an-experiment-in-information-e/1758506417_3.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> </div> </div> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-09-22-leotalk-ai-weekly-1-an-experiment-in-information-e/1758506417_4-480.webp 480w,/assets/img/2025-09-22-leotalk-ai-weekly-1-an-experiment-in-information-e/1758506417_4-800.webp 800w,/assets/img/2025-09-22-leotalk-ai-weekly-1-an-experiment-in-information-e/1758506417_4-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/2025-09-22-leotalk-ai-weekly-1-an-experiment-in-information-e/1758506417_4.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> </div> </div> <h2 id="千问发布通义deep-research">千问发布通义Deep Research</h2> <p>千问<a href="https://tongyi-agent.github.io/blog/introducing-tongyi-deep-research/">发布</a><a href="https://github.com/Alibaba-NLP/DeepResearch">Tongyi Deep Research</a>（开源），效果和OpenAI DeepSearch持平</p> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-09-22-leotalk-ai-weekly-1-an-experiment-in-information-e/1758506417_5-480.webp 480w,/assets/img/2025-09-22-leotalk-ai-weekly-1-an-experiment-in-information-e/1758506417_5-800.webp 800w,/assets/img/2025-09-22-leotalk-ai-weekly-1-an-experiment-in-information-e/1758506417_5-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/2025-09-22-leotalk-ai-weekly-1-an-experiment-in-information-e/1758506417_5.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> </div> </div> <p>关键点：</p> <ul> <li>首个开源对标SOTA效果的DeepResearch</li> <li>全链路合成数据（无人工标注）：从预训练、SFT 到 RL</li> <li>提出了Agentic CPT（Continual Pre-training，持续预训练）+ IterResearch（避免上下文污染）</li> <li>数据飞轮：自动生成博士级复杂问题，迭代升级</li> <li>发现高质量合成数据+稳定环境比算法本身更关键</li> <li>已经在实际的生产环境中使用了：高德小高和通义法睿</li> </ul> <h2 id="openai在icpc夺魁">OpenAI在ICPC夺魁</h2> <p>OpenAI在ICPC（国际大学生程序设计竞赛，International Collegiate Programming Contest）中超越人类，取得了12/12的满分战绩，而Google的Gemini2.25 Deep Think只解决了10道题（获得第二名）。</p> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-09-22-leotalk-ai-weekly-1-an-experiment-in-information-e/1758506418_6-480.webp 480w,/assets/img/2025-09-22-leotalk-ai-weekly-1-an-experiment-in-information-e/1758506418_6-800.webp 800w,/assets/img/2025-09-22-leotalk-ai-weekly-1-an-experiment-in-information-e/1758506418_6-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/2025-09-22-leotalk-ai-weekly-1-an-experiment-in-information-e/1758506418_6.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> </div> </div> <p>背景信息：来自100多个国家的139所大学参赛，但没有任何人类队伍能拿到满分。OpenAI 在首轮就解出了11道题，并在第9次尝试时攻克了最难的一题。</p> <p><em>Opinion：有一些有数学竞赛背景的人对这个新闻细思极恐，很多人说大模型没有思考能力，但是这些数学竞赛的题目被一个预测Token的模型解决，还是非常震惊人的，或许我们对于大模型涌现后的能力的认知还是太少了，可解释性不足。</em></p> <h2 id="openbmb推出了voxcpm">OpenBMB推出了VoxCPM</h2> <p><a href="https://x.com/OpenBMB/status/1968205159949107502">https://x.com/OpenBMB/status/1968205159949107502</a> TTS，只有0.5B参数量，但是效果听起来还是不错的</p> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-09-22-leotalk-ai-weekly-1-an-experiment-in-information-e/1758506418_7-480.webp 480w,/assets/img/2025-09-22-leotalk-ai-weekly-1-an-experiment-in-information-e/1758506418_7-800.webp 800w,/assets/img/2025-09-22-leotalk-ai-weekly-1-an-experiment-in-information-e/1758506418_7-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/2025-09-22-leotalk-ai-weekly-1-an-experiment-in-information-e/1758506418_7.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> </div> </div> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-09-22-leotalk-ai-weekly-1-an-experiment-in-information-e/1758506419_8-480.webp 480w,/assets/img/2025-09-22-leotalk-ai-weekly-1-an-experiment-in-information-e/1758506419_8-800.webp 800w,/assets/img/2025-09-22-leotalk-ai-weekly-1-an-experiment-in-information-e/1758506419_8-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/2025-09-22-leotalk-ai-weekly-1-an-experiment-in-information-e/1758506419_8.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> </div> </div> <h2 id="vllm推出semantic-router">vLLM推出Semantic Router</h2> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-09-22-leotalk-ai-weekly-1-an-experiment-in-information-e/1758506419_9-480.webp 480w,/assets/img/2025-09-22-leotalk-ai-weekly-1-an-experiment-in-information-e/1758506419_9-800.webp 800w,/assets/img/2025-09-22-leotalk-ai-weekly-1-an-experiment-in-information-e/1758506419_9-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/2025-09-22-leotalk-ai-weekly-1-an-experiment-in-information-e/1758506419_9.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> </div> </div> <blockquote> <p>Intelligent Mixture-of-Models Router for Efficient LLM Inference <strong>路由模型</strong>，简单说就是类似OAI的Switcher，用于根据问题路由到不同的模型，可以大小模型、推理模型等混合使用。</p> </blockquote> <p>很好理解，毕竟OAI用GPT-5糟糕的发布教会我们什么是路由模型。关键点是：效果、成本和安全：</p> <ul> <li>简单请求可以让小模型处理，速度更快且成本更低。诸如你好，谢谢这类简单问题在Chat场景是非常常见且占比不小</li> <li>一些复杂问题用大参数甚至推理模型来处理，有更好的效果。甚至有一个反直觉的，复杂任务用更“便宜”的模型，也就是参数小的模型来处理，实际上在推理密集的任务里反而更贵，且效果可能更不好</li> <li>再进一步，就是专门的任务专门的模型来处理，效果的提升</li> <li>会利用一下jailbreak的数据集来训练，可以分辨一些安全问题</li> </ul> <p>做个不恰当的比喻，类比MoE模型的门控网络（Gating Network）去分流激活对应的专家（Experts）。路由模型的范式有点类似外化了这个能力，虽然本质上这两个不是一个东西，不过理念会有一点点交集。</p> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-09-22-leotalk-ai-weekly-1-an-experiment-in-information-e/1758506419_10-480.webp 480w,/assets/img/2025-09-22-leotalk-ai-weekly-1-an-experiment-in-information-e/1758506419_10-800.webp 800w,/assets/img/2025-09-22-leotalk-ai-weekly-1-an-experiment-in-information-e/1758506419_10-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/2025-09-22-leotalk-ai-weekly-1-an-experiment-in-information-e/1758506419_10.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> </div> </div> <p>另外这类路由模型通常会基于Encoder模型（适合做分析、分类、检索任务的）来做，比如这里用的<a href="https://arxiv.org/abs/2412.13663">ModernBERT</a>是一个Encoder-only的Transformer模型。</p> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-09-22-leotalk-ai-weekly-1-an-experiment-in-information-e/1758506420_11-480.webp 480w,/assets/img/2025-09-22-leotalk-ai-weekly-1-an-experiment-in-information-e/1758506420_11-800.webp 800w,/assets/img/2025-09-22-leotalk-ai-weekly-1-an-experiment-in-information-e/1758506420_11-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/2025-09-22-leotalk-ai-weekly-1-an-experiment-in-information-e/1758506420_11.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> </div> </div> <p>官方网站：<a href="https://vllm-semantic-router.com/">https://vllm-semantic-router.com/</a> 官方Repo：<a href="https://github.com/vllm-project/semantic-router">https://github.com/vllm-project/semantic-router</a></p> <p>vllm也分享了<a href="https://vllm-semantic-router.com/docs/training/training-overview">模型训练相关的内容</a>，我也随手收集了一些相关的路由模型和数据集：</p> <ul> <li><a href="https://huggingface.co/datasets/qgyd2021/few_shot_intent_sft">https://huggingface.co/datasets/qgyd2021/few_shot_intent_sft</a></li> <li><a href="https://huggingface.co/AdamLucek/ModernBERT-large-llm-router">https://huggingface.co/AdamLucek/ModernBERT-large-llm-router</a></li> <li><a href="https://huggingface.co/datasets/DevQuasar/llm_router_dataset-synth">https://huggingface.co/datasets/DevQuasar/llm_router_dataset-synth</a></li> <li><a href="https://colab.research.google.com/drive/1G7oHp_8R4fmOSpjwaNB_T2NUJsmMh4Kw">Finetuning ModernBERT Large for LLM Router Classification</a>这个Notebook一步步说明了如何基于ModernBERT微调出路由模型，值得一看！</li> <li><a href="https://huggingface.co/datasets/Muhammad2003/routing-dataset">https://huggingface.co/datasets/Muhammad2003/routing-dataset</a></li> <li><a href="https://github.com/MuhammadBinUsman03/Query-Router">https://github.com/MuhammadBinUsman03/Query-Router</a></li> <li><a href="https://huggingface.co/datasets/jackhhao/jailbreak-classification">https://huggingface.co/datasets/jackhhao/jailbreak-classification</a></li> </ul> <h1 id="产品模型发布">产品&amp;模型发布</h1> <h2 id="claude-code降智的背后三次故障">Claude Code降智的背后：三次故障</h2> <p>8月份以来非常多人陆陆续续感受到Claude Code降智了，并且持续没有好转，关于原因或者动机，充满了各种猜测。9月17日Anthropic<a href="https://x.com/_thomasip/status/1968419157755453812">发布</a>了一篇<a href="https://www.anthropic.com/engineering/a-postmortem-of-three-recent-issues">故障报告</a>讲述了这一个多月时间内发生的3起AI Infra的故障，时间线如下：</p> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-09-22-leotalk-ai-weekly-1-an-experiment-in-information-e/1758506420_12-480.webp 480w,/assets/img/2025-09-22-leotalk-ai-weekly-1-an-experiment-in-information-e/1758506420_12-800.webp 800w,/assets/img/2025-09-22-leotalk-ai-weekly-1-an-experiment-in-information-e/1758506420_12-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/2025-09-22-leotalk-ai-weekly-1-an-experiment-in-information-e/1758506420_12.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> </div> </div> <p>Anthropic有一方API、AWS Bedrock、Google Cloud Vertex AI三个渠道，并且有多个模型，3个问题分别影响的也不同。总结来说三个问题的原因是：</p> <ol> <li><strong>上下文窗口路由错误</strong>：短上下文请求被错误地路由到长上下文服务器，导致输出质量下降</li> <li><strong>输出损坏</strong>：升级了TPU配置（优化运行时性能），但是错误配置会偶尔让低概率token获得异常高概率，生成了错误语言内容、乱码、错误代码或不合语境的内容。</li> <li><strong>Approximate top-k 编译错误</strong>：TPU 编译器的混合精度bug让近似top-k算法有时丢掉了最高概率 token，输出完全偏离预期（或者说错误）的结果。</li> </ol> <p>近年来AI高速发展，很多因为AI Infra经验不足或者解决方案不够成熟导致的事故不少，AI可观测性的重要程度也不断提升，一个是反哺AI去提升性能和效果，另一个是可提早发现问题、加速定位问题的作用。另外就是从确定性到非确定性的范式转变，导致一些测试的覆盖变得更加的困难了，AI在一定的范围内也有“能动性”，可以应对某些测试的覆盖。这些</p> <p><em>Opinion：首先是技术报告或者说复盘报告，应该学一下Cloudflare，Anthropic这篇写的含糊其辞，细节不展示，具体问题不披露，让人有一种在用户流失后出来发挥公关作用的文章。Codex+GPT5这波顺利承接了CC流失的用户，有一点几个月前CC承接Cursor用户的即视感。这段时间挺感慨反垄断法存在的必要性，市场充分竞争下，不仅能保证技术和服务的持续进步，也能让消费者有选择，不至于被捆绑和裹挟。</em></p> <h2 id="openai推出gpt-5-codex模型">OpenAI推出GPT-5-Codex模型</h2> <p>OAI<a href="https://openai.com/index/introducing-upgrades-to-codex/">发布</a>了GPT‑5-Codex模型，专为AI编程的GPT-5变体版本（目前官方声称的是GPT-5的一个版本，没有明确说明是一个微调版本），目前在Codex中可以使用，但是API还没上线。</p> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-09-22-leotalk-ai-weekly-1-an-experiment-in-information-e/1758506420_13-480.webp 480w,/assets/img/2025-09-22-leotalk-ai-weekly-1-an-experiment-in-information-e/1758506420_13-800.webp 800w,/assets/img/2025-09-22-leotalk-ai-weekly-1-an-experiment-in-information-e/1758506420_13-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/2025-09-22-leotalk-ai-weekly-1-an-experiment-in-information-e/1758506420_13.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> </div> </div> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-09-22-leotalk-ai-weekly-1-an-experiment-in-information-e/1758506420_14-480.webp 480w,/assets/img/2025-09-22-leotalk-ai-weekly-1-an-experiment-in-information-e/1758506420_14-800.webp 800w,/assets/img/2025-09-22-leotalk-ai-weekly-1-an-experiment-in-information-e/1758506420_14-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/2025-09-22-leotalk-ai-weekly-1-an-experiment-in-information-e/1758506420_14.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> </div> </div> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-09-22-leotalk-ai-weekly-1-an-experiment-in-information-e/1758506420_15-480.webp 480w,/assets/img/2025-09-22-leotalk-ai-weekly-1-an-experiment-in-information-e/1758506420_15-800.webp 800w,/assets/img/2025-09-22-leotalk-ai-weekly-1-an-experiment-in-information-e/1758506420_15-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/2025-09-22-leotalk-ai-weekly-1-an-experiment-in-information-e/1758506420_15.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> </div> </div> <p>一些关键点：</p> <ul> <li>基准测试优于GPT-5，重构任务上提升明显</li> <li>动态调整推理时间：简单任务更快完成，Token消耗量减少94%；复杂问题上多投入2倍推理时间，最长可自主运行7小时！</li> <li>针对代码Review专门训练过，内置的代码审查功能能浏览完整代码库、执行测试、验证依赖</li> </ul> <p><em>Opinion：官方论坛里也有人将动态调整能力类比ChatGPT里的Switcher，也就是效果不尽人意，比不上GPT-5 High，因此自己测试才是王道，尝试过才知道。总体而言是个好的趋势，Codex主要用来和Anthropic的Claude竞争了，对消费者是很好的</em></p> <h2 id="chrome推出新ai特性">Chrome推出新AI特性</h2> <p>Chrome<a href="https://x.com/googlechrome/status/1968721681129566379">宣布</a>针对美国用户推出了AI特性，侧边栏形式。市面上已经有Comet、Arc、Dia、Brave之类的AI浏览器，看Google这次如catch up，是抄作业还是创新，拭目以待。（也可以看官方Blog的<a href="https://blog.google/products/chrome/new-ai-features-for-chrome/">文章</a>）</p> <h2 id="ap2">AP2</h2> <p>Google<a href="https://cloud.google.com/blog/products/ai-machine-learning/announcing-agents-to-payments-ap2-protocol">推出</a>了<a href="https://github.com/google-agentic-commerce/AP2">AP2</a>（Agent Payment Protocol）的开放协议，让AI Agent可以在用户授权的情况下安全完成支付，目前有60多家金融和科技巨头加入支持，美国运通、万事达、PayPal等也为其背书。</p> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-09-22-leotalk-ai-weekly-1-an-experiment-in-information-e/1758506420_16-480.webp 480w,/assets/img/2025-09-22-leotalk-ai-weekly-1-an-experiment-in-information-e/1758506420_16-800.webp 800w,/assets/img/2025-09-22-leotalk-ai-weekly-1-an-experiment-in-information-e/1758506420_16-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/2025-09-22-leotalk-ai-weekly-1-an-experiment-in-information-e/1758506420_16.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> </div> </div> <p>主要包含的角色：</p> <ul> <li><strong>购物代理（Shopping Agent）</strong>：主要的协调者，负责处理用户的购物请求，并将任务分配给其他专业代理。</li> <li><strong>商户代理（Merchant Agent）</strong>：处理来自购物代理的商品查询。</li> <li><strong>商户支付处理代理（Merchant Payment Processor Agent）</strong>：代表商户进行支付。</li> <li><strong>凭证提供者代理（Credentials Provider Agent）</strong>：保存用户支付凭证的代理，主要职责：</li> <li>为购物代理提供用户钱包中的可用支付方式列表。</li> <li>协助购物代理与商户支付处理方完成支付。</li> </ul> <h2 id="腾讯推出了浑元3d-30">腾讯推出了浑元3D 3.0</h2> <p>具备3倍精度提升、1536³ 几何分辨率，以及 36 亿体素超高清建模。搞笑花絮，发<a href="https://x.com/TencentHunyuan/status/1967873084960260470">英文推</a>，<a href="https://3d.hunyuan.tencent.com/">官网</a>只能中文，蚌埠住了</p> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-09-22-leotalk-ai-weekly-1-an-experiment-in-information-e/1758506421_17-480.webp 480w,/assets/img/2025-09-22-leotalk-ai-weekly-1-an-experiment-in-information-e/1758506421_17-800.webp 800w,/assets/img/2025-09-22-leotalk-ai-weekly-1-an-experiment-in-information-e/1758506421_17-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/2025-09-22-leotalk-ai-weekly-1-an-experiment-in-information-e/1758506421_17.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> </div> </div> <h1 id="meta发布新眼镜">Meta发布新眼镜</h1> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-09-22-leotalk-ai-weekly-1-an-experiment-in-information-e/1758506423_18-480.webp 480w,/assets/img/2025-09-22-leotalk-ai-weekly-1-an-experiment-in-information-e/1758506423_18-800.webp 800w,/assets/img/2025-09-22-leotalk-ai-weekly-1-an-experiment-in-information-e/1758506423_18-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/2025-09-22-leotalk-ai-weekly-1-an-experiment-in-information-e/1758506423_18.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> </div> </div> <p>Meta<a href="https://www.meta.com/ae/ai-glasses/">发布</a>三款新眼镜：<strong>Ray-Ban Display</strong>（799🔪起）、<strong>Ray-Ban Meta (Gen 2)</strong>（379🔪起）和<strong>Oakley Meta Vanguard</strong>（499🔪起）。其中Meta Ray-Ban Display右镜片带有内置显示屏 (in-lens display)，另外还搭配有腕带（Neural Band），支持通过语音和手势控制</p> <p><em>Opinion：发布会翻车了，不过依然掩盖不住小扎的野望，眼镜的场景更多还是在录像拍照，也就是之前最多使用的运动场景，用于取代GoPro之类的运动相机上有优势。另外电池技术还需要再飞一会。最后就是不知道有没有考虑过没戴眼镜的人的感受</em></p> <h1 id="投资商业">投资&amp;商业</h1> <h2 id="nvidia投资intel-5b">NVIDIA投资Intel $5b</h2> <p>Nvidia<a href="https://www.wsj.com/tech/ai/nvidia-intel-5-billion-investment-ad940533">宣布</a>投资Intel 50亿🔪（以23.28🔪每股的价格购买普通股），消息后Intel股票涨到30🔪，Nvidia这笔投资已经是正收益了。宣布投资后也<a href="https://nvidianews.nvidia.com/news/nvidia-and-intel-to-develop-ai-infrastructure-and-personal-computing-products">Nvidia</a>和<a href="https://newsroom.intel.com/artificial-intelligence/intel-and-nvidia-to-jointly-develop-ai-infrastructure-and-personal-computing-products">Intel</a>共同宣布要在数据中心和个人计算产品上联合开发AI基础设施和PC产品</p> <h1 id="热点论文">热点论文</h1> <ul> <li><a href="https://arxiv.org/abs/2509.07604">K2-Think: A Parameter-Efficient Reasoning System</a></li> <li><a href="https://arxiv.org/abs/2509.10446">DeepDive: Advancing Deep Search Agents with Knowledge Graphs and Multi-Turn RL</a></li> <li><a href="https://arxiv.org/abs/2509.10414">Is In-Context Learning Learning?</a></li> <li><a href="https://arxiv.org/abs/2509.13311">Towards General Agentic Intelligence via Environment Scaling</a></li> <li><a href="https://arxiv.org/abs/2509.11826">Collaborative Document Editing with Multiple Users and AI Agents</a></li> <li><a href="https://www.nature.com/articles/s41586-025-09422-z">DeepSeek-R1 incentivizes reasoning in LLMs through reinforcement learning</a></li> <li><a href="https://arxiv.org/abs/2509.08653">Generative Data Refinement: Just Ask for Better Data</a></li> </ul> <h1 id="其他阅读">其他阅读</h1> <ul> <li><a href="https://www.youtube.com/watch?v=48pxVdmkMIE"><strong>自主机器人比你想象的更近（YouTube视频）</strong></a>：顶尖机器人学者、Physical Intelligence 联合创始人 Sergey Levine 认为，完全自主机器人的实现已近在眼前，行业正处于“自我改进飞轮”的临界点。</li> <li><a href="https://artificialintelligencemadesimple.substack.com/p/how-to-build-agentic-ai-2-with-frameworks">How to Build Agentic AI 2 (with frameworks) [Agents]</a>：Devansh分享的关于如何构建AgenticAI的方法以及框架</li> <li><a href="https://toddlerbot.github.io/">ToddlerBot: Open-Source ML-Compatible Humanoid Platform for Loco-Manipulation</a>：一款低成本、开源的人形机器人，用于AI与机器人研究。</li> </ul> <h2 id="openai和anthropic的ai使用报告">OpenAI和Anthropic的AI使用报告</h2> <p><a href="https://openai.com/index/how-people-are-using-chatgpt/">OpenAI</a>和Anthropic在同一天（2025年9月15日）发布了AI使用报告，很容易让人联想到是不是越好了一起发的：</p> <ul> <li><a href="https://cdn.openai.com/pdf/a253471f-8260-40c6-a2cc-aa93fe9f142e/economic-research-chatgpt-usage-paper.pdf">How People Use ChatGPT</a></li> <li><a href="https://www.anthropic.com/research/economic-index-geography">Anthropic Economic Index: Tracking AI’s role in the US and global economy</a></li> </ul> <p>篇幅特别长，数据量很多，我汇总了一下大概关键信息如下</p> <p><strong>OpenAI的：</strong></p> <ul> <li>性别差距缩小：2024年初女性用户占比 37%，到2025年中已上升到 52%，几乎与总体人口结构一致</li> <li>全球普及：在低收入和中等收入国家的增长速度是高收入国家的4倍以上</li> <li>年轻人主力：近一半成年用户的消息来自18–25岁群体</li> <li>整体分布：约70%用于个人生活，30%与工作相关</li> <li>主要用来做三个类型的任务：Asking（提问/寻求建议）49%，Doing（执行/任务完成）40%，Expressing（表达/探索）11%</li> <li>具体任务：写作是最主要的工作场景（40%）但2/3是编辑、润色或翻译，而非从零写作；编程较少（4.2%）；关系/朋友聊天和（1.9%）游戏/角色扮演更少（0.4%）；日常指导和信息查询（70%） 的整体使用</li> <li>个人用途快速超越工作：从2024年的53%占比到2025年的73%。</li> </ul> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-09-22-leotalk-ai-weekly-1-an-experiment-in-information-e/1758506423_19-480.webp 480w,/assets/img/2025-09-22-leotalk-ai-weekly-1-an-experiment-in-information-e/1758506423_19-800.webp 800w,/assets/img/2025-09-22-leotalk-ai-weekly-1-an-experiment-in-information-e/1758506423_19-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/2025-09-22-leotalk-ai-weekly-1-an-experiment-in-information-e/1758506423_19.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> </div> </div> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-09-22-leotalk-ai-weekly-1-an-experiment-in-information-e/1758506424_20-480.webp 480w,/assets/img/2025-09-22-leotalk-ai-weekly-1-an-experiment-in-information-e/1758506424_20-800.webp 800w,/assets/img/2025-09-22-leotalk-ai-weekly-1-an-experiment-in-information-e/1758506424_20-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/2025-09-22-leotalk-ai-weekly-1-an-experiment-in-information-e/1758506424_20.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> </div> </div> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-09-22-leotalk-ai-weekly-1-an-experiment-in-information-e/1758506424_21-480.webp 480w,/assets/img/2025-09-22-leotalk-ai-weekly-1-an-experiment-in-information-e/1758506424_21-800.webp 800w,/assets/img/2025-09-22-leotalk-ai-weekly-1-an-experiment-in-information-e/1758506424_21-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/2025-09-22-leotalk-ai-weekly-1-an-experiment-in-information-e/1758506424_21.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> </div> </div> <p><strong>Anthropic的：</strong> 美国是最多人使用的国家（合规国家范围内）</p> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-09-22-leotalk-ai-weekly-1-an-experiment-in-information-e/1758506424_22-480.webp 480w,/assets/img/2025-09-22-leotalk-ai-weekly-1-an-experiment-in-information-e/1758506424_22-800.webp 800w,/assets/img/2025-09-22-leotalk-ai-weekly-1-an-experiment-in-information-e/1758506424_22-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/2025-09-22-leotalk-ai-weekly-1-an-experiment-in-information-e/1758506424_22.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> </div> </div> <p>AUI(<strong>Anthropic AI Usage Index</strong>)=使用人数/该国劳动人口。经济水平越高的地区，这个数值约大，有正相关效应（人均GDP每增加1%，AUI大约增加0.7%），似乎也引发了经济分发的趋势（国家或地区间贫富差距和新技术加成造成的马太效应）</p> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-09-22-leotalk-ai-weekly-1-an-experiment-in-information-e/1758506424_23-480.webp 480w,/assets/img/2025-09-22-leotalk-ai-weekly-1-an-experiment-in-information-e/1758506424_23-800.webp 800w,/assets/img/2025-09-22-leotalk-ai-weekly-1-an-experiment-in-information-e/1758506424_23-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/2025-09-22-leotalk-ai-weekly-1-an-experiment-in-information-e/1758506424_23.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> </div> </div> <p>美国各州使用情况和人均GDP也有很大正相关，但是其他因素（如产业结构）也很重要。一些有代表性的州的使用AI完成的任务情况：</p> <ul> <li>华盛顿特区：AUI最高，任务主要是文档编辑和信息检索</li> <li>加州：编程任务占比高</li> <li>纽约：金融相关任务占比高</li> <li>夏威夷：旅游相关任务使用率是全美平均的两倍</li> </ul> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-09-22-leotalk-ai-weekly-1-an-experiment-in-information-e/1758506425_24-480.webp 480w,/assets/img/2025-09-22-leotalk-ai-weekly-1-an-experiment-in-information-e/1758506425_24-800.webp 800w,/assets/img/2025-09-22-leotalk-ai-weekly-1-an-experiment-in-information-e/1758506425_24-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/2025-09-22-leotalk-ai-weekly-1-an-experiment-in-information-e/1758506425_24.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> </div> </div> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-09-22-leotalk-ai-weekly-1-an-experiment-in-information-e/1758506425_25-480.webp 480w,/assets/img/2025-09-22-leotalk-ai-weekly-1-an-experiment-in-information-e/1758506425_25-800.webp 800w,/assets/img/2025-09-22-leotalk-ai-weekly-1-an-experiment-in-information-e/1758506425_25-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/2025-09-22-leotalk-ai-weekly-1-an-experiment-in-information-e/1758506425_25.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> </div> </div> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-09-22-leotalk-ai-weekly-1-an-experiment-in-information-e/1758506425_26-480.webp 480w,/assets/img/2025-09-22-leotalk-ai-weekly-1-an-experiment-in-information-e/1758506425_26-800.webp 800w,/assets/img/2025-09-22-leotalk-ai-weekly-1-an-experiment-in-information-e/1758506425_26-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/2025-09-22-leotalk-ai-weekly-1-an-experiment-in-information-e/1758506425_26.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> </div> </div> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-09-22-leotalk-ai-weekly-1-an-experiment-in-information-e/1758506426_27-480.webp 480w,/assets/img/2025-09-22-leotalk-ai-weekly-1-an-experiment-in-information-e/1758506426_27-800.webp 800w,/assets/img/2025-09-22-leotalk-ai-weekly-1-an-experiment-in-information-e/1758506426_27-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/2025-09-22-leotalk-ai-weekly-1-an-experiment-in-information-e/1758506426_27.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> </div> </div> <p>相比于去年，使用趋势也发生了一些变化：</p> <ul> <li>计算机和数据任务占比接近一半：37-40%</li> <li>过去9个月，知识密集型领域增长明显：教育9%-13%（+40%），物理和社会科学6%-8%（+33%）</li> <li>自动化任务（AI独立完成49.1%）超过增强任务（人机协作47%）</li> </ul> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-09-22-leotalk-ai-weekly-1-an-experiment-in-information-e/1758506426_28-480.webp 480w,/assets/img/2025-09-22-leotalk-ai-weekly-1-an-experiment-in-information-e/1758506426_28-800.webp 800w,/assets/img/2025-09-22-leotalk-ai-weekly-1-an-experiment-in-information-e/1758506426_28-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/2025-09-22-leotalk-ai-weekly-1-an-experiment-in-information-e/1758506426_28.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> </div> </div> <p>走API（主要企业或开发者）和直接通过ChatBot（普通用户、开发者和企业）使用模式有差异：</p> <ul> <li>API主要集中在编程和行政任务，占比44%（Claude.ai为36%）</li> <li>API77%自动化，Claude.ai只有约一半</li> <li>API在高成本任务上使用更频繁。对于企业来说，模型能力和模型产生的经济价值比完成任务所需的成本来的更加重要</li> </ul> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-09-22-leotalk-ai-weekly-1-an-experiment-in-information-e/1758506427_29-480.webp 480w,/assets/img/2025-09-22-leotalk-ai-weekly-1-an-experiment-in-information-e/1758506427_29-800.webp 800w,/assets/img/2025-09-22-leotalk-ai-weekly-1-an-experiment-in-information-e/1758506427_29-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/2025-09-22-leotalk-ai-weekly-1-an-experiment-in-information-e/1758506427_29.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> </div> </div> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-09-22-leotalk-ai-weekly-1-an-experiment-in-information-e/1758506427_30-480.webp 480w,/assets/img/2025-09-22-leotalk-ai-weekly-1-an-experiment-in-information-e/1758506427_30-800.webp 800w,/assets/img/2025-09-22-leotalk-ai-weekly-1-an-experiment-in-information-e/1758506427_30-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/2025-09-22-leotalk-ai-weekly-1-an-experiment-in-information-e/1758506427_30.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> </div> </div>]]></content><author><name></name></author><category term="Blog"/><category term="Blog"/><category term="Substack"/><category term="微信公众号"/><summary type="html"><![CDATA[这是我在尝试的一个每周资讯汇总的栏目，根因是自己摄入的信息太多了，但是越来越没有时间去支撑我做高密度的信息输出了，我转向寻求低频高质量的信息输出模式。这个内容算是这个模式里的一个专栏，主要用于汇集过去一周我看到的一些我觉得有价值的信息，主要以科技和AI为主，会相对垂直一点，这样有助于让感兴趣的人专注在这份有价值的信息上。目前还处于探索和尝试阶段，这周末又特别的忙，现在已经是半夜1点多了，我在周末忙完了一切我认为必须要做的事情之后，自己花了几个小时把信息规整完毕输出，算是赶鸭子上架了，我觉得有很多事情都是倒逼着去做反而能在高压下产出不错的东西，这也是我觉得Just Do It的精髓，不要追求完美，只需要开始即可。希望本文对你有所帮助，有任何想法和反馈都欢迎。]]></summary></entry></feed>
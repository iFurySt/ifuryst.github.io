<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.3.3">Jekyll</generator><link href="https://ifuryst.github.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://ifuryst.github.io/" rel="alternate" type="text/html" hreflang="en"/><updated>2025-09-02T00:09:16+00:00</updated><id>https://ifuryst.github.io/feed.xml</id><title type="html">ifuryst</title><subtitle>📝 &amp; 💭 </subtitle><entry><title type="html">大模型上下文工程实践指南-第2章：上下文工程技术栈</title><link href="https://ifuryst.github.io/blog/2025/context-engineering-stack/" rel="alternate" type="text/html" title="大模型上下文工程实践指南-第2章：上下文工程技术栈"/><published>2025-09-02T00:00:00+00:00</published><updated>2025-09-02T00:00:00+00:00</updated><id>https://ifuryst.github.io/blog/2025/context-engineering-stack</id><content type="html" xml:base="https://ifuryst.github.io/blog/2025/context-engineering-stack/"><![CDATA[<h1 id="21-上下文窗口限制与问题分类">2.1 上下文窗口限制与问题分类</h1> <h2 id="211-长上下文好上下文">2.1.1 长上下文≠好上下文</h2> <h3 id="上下文窗口"><strong>上下文窗口</strong></h3> <p>要了解和学习上下文工程， 首先需要理解上下文窗口。我们先来看下面这个表：</p> <p>可以看到，现在所有的SOTA大模型的上下文空间都在<strong>1M以内</strong>（<a href="https://ai.meta.com/blog/llama-4-multimodal-intelligence/">Llama4有10M</a>），这个就是天然的限制，也是<strong>为什么上下文工程存在的原因之一</strong>。这就好比内存之于CPU一样，CPU运算的时候需要不断访问数据，而硬盘的访问速度太慢，因此需要借助内存来提供较快的访问速度，但是内存是有上限的，所以计算机不能无限制的运行程序（运行程序就是将程序和对应的数据都加载到内存中），随着技术的发展，也延伸出很多相关的内存技术，比如分页分段、虚拟内存、内存置换等等。虽然现在内存不断提升，尤其在大语言模型训练和推理过程中都使用了大量的内存，但是依然没有逃脱资源限制的问题。上下文空间就是这么一个存在，让大语言模型可以基于这些数据去推理，因此才有了围绕上下文空间限制而衍生的一系列技术，这些技术就统称为上下文工程技术。</p> <p>围绕着上下文窗口，可以很直观的得出这么几个场景：</p> <ul> <li>上下文太长，超过上下文窗口限制</li> <li>上下文太短，不足以支撑推理</li> <li>上下文很长，但是还没超过上下文窗口限制</li> <li>上下文适中</li> </ul> <p>基本上从长度来说，我们可以得出这些情况，进一步看看。首先我们会遇到第一个问题<strong>上下文长度限制</strong>，现在的大语言模型都有上下文窗口长度，通常SOTA模型是1百万左右的上下文空间，因此我们能传入的上下文有长度限制，此时就会遇到第一个情况，上下文超过上下文窗口限制的情况。</p> <p>其次是当上下文存在长度限制的时候，我们可以在有限范围内组装上下文，这就有这么几种情况，传入太少的上下文，这种情况可能会导致<strong>上下文不足</strong>，导致模型无法顺利输出想要的结果。那我们尽可能填满上下文窗口呢？也就是尽可能多的上下文，这种情况会出现几种问题，<strong>过多的上下文</strong>会导致模型无法聚焦于关键目标，容易分心。因此在长度这个维度，我们的目标是提供<strong>合适长度的上下文</strong>。</p> <h3 id="从长度到语义">从长度到语义</h3> <p>上面是基于上下文长短来进行分类的，但是实际上上下文工程里遇到的问题不是这么简单的问题，还有更深层的问题， 因为上下文说到底还是自然语言的范畴，是为了让大模型更容易理解背景信息和目标而提供的内容，因此其实我们海英个进一步关注上下文遇到的问题。<a href="https://x.com/dbreunig?lang=en">Drew Breunig</a>在<a href="https://www.dbreunig.com/2025/06/22/how-contexts-fail-and-how-to-fix-them.html">这篇文章中</a>提出了四个定义：</p> <ol> <li><strong>上下文污染（Context Poisoning）</strong>：幻觉等错误进入上下文，被模型反复引用，导致持续的错误</li> <li><strong>上下文分心（Context Distraction）</strong>：上下文太长，模型反而忽略了训练中学到的东西</li> <li><strong>上下文混淆（Context Confusion）</strong>：无关的上下文被模型用来生成低质量回答</li> <li><strong>上下文冲突（Context Clash）</strong>：上下文中的不同信息或工具互相矛盾</li> </ol> <p>这几个分类涵盖了我们前面分析拆解的几种情况，因此我们会按照这几个划分的方向来看看。只不过这几个方向有些许重叠，我思考了一下，总结出有这么几个分类：</p> <ol> <li><strong>信息污染（Information Poisoning）</strong>：错误信息持续留在上下文中，其实不局限于当前的上下文，这个信息污染是有可能从运行时的上下文外溢到外部存储的，比如长短期记忆，或者一些Specification。容易造成重复错误行为、目标偏离和行为死循环。</li> <li><strong>注意力偏移（Attention Misalignment）</strong>：上下文长度增加会导致效果变差，其中的核心是上下文分心，模型被上下文分散了注意力，并且还会进一步让注意力从目标或指令转向无关的上下文，容易造成忽略指令、回答随机和无法聚焦。</li> <li><strong>语义冲突与混乱（Semantic Conflict &amp; Confusion）</strong>：上下文存在歧义、矛盾或冗余等情况，导致模型难以理解和识别，导致最终效果不符合预期。容易造成误解、矛盾回答和答非所问。</li> </ol> <p>这个是我自己的分类，其实整体识别和认识的问题是类似的，我们也会借用Drew Breunig的一些例子和其他的资料引用来说明和佐证。我们基于这几个分类分析学习，未来遇到问题时能快速分类定位并进一步思考解决方案。</p> <h2 id="212-常见问题分类">2.1.2 常见问题分类</h2> <h3 id="信息污染information-poisoning">信息污染（Information Poisoning）</h3> <p><strong>信息污染（Information Poisoning）</strong>是在上下文中充满了各种数据，尤其是在Agent这种复杂环境下，容易产生很多相关和不相干的数据。随着时间的推移，上下文就会堆积各种数据，当以Transformer的注意力机制驱动的大模型在推理的时候，就会导致被大量不相关的内容分散注意力，此时就会导致效果的下降。</p> <p>这里面比较严重且突出的问题是<strong>上下文污染（Context Poisoning）</strong>，或者也可以称为<strong>上下文投毒</strong>。<a href="https://storage.googleapis.com/deepmind-media/gemini/gemini_v2_5_report.pdf">Gemini 2.5 技术报告</a>里描述了Gemini 2.5 Pro被用来作为Agent自主通关了宝可梦游戏，这份报告主要展现了Gemini 2.5 Pro的长上下文推理和多步任务规划能力，能够解决复杂迷宫、道具获取、战斗策略等问题。里面有一部分值得我们注意的，就是关于在处理超长历史时偶尔会陷入重复行为或幻觉，在部分情境下会很出现目标混淆或策略固执等问题。文中有一段是这样描述的：</p> <blockquote> <p>Fixations on delusions due to goal-setting and also due to the Guidance Gemini instance are not an uncommon occurrence in watching Gemini Plays Pokémon - the TEA incidence is hardly the only example of this behavior. An especially egregious form of this issue can take place with “context poisoning” – where many parts of the context (goals, summary) are “poisoned” with misinformation about the game state, which can often take a very long time to undo. As a result, the model can become fixated on achieving impossible or irrelevant goals. This failure mode is also highly related to the looping issue mentioned above. These delusions, though obviously nonsensical to a human (“Let me try to go through the entrance to a house and back out again. Then, hopefully the guard who is blocking the entrance might move.”), by virtue of poisoning the context in many places, can lead the model to ignore common sense and repeat the same incorrect statement. Context poisoning can also lead to strategies like the “black-out” strategy (cause all Pokémon in the party to faint, “blacking out” and teleporting to the nearest Pokémon Center and losing half your money, instead of attempting to leave). 翻译成中文是 在观看 Gemini 玩《宝可梦》的过程中，常常会看到因为设定目标或受到“指导版 Gemini 实例”的影响而产生的执念式妄想，这并不是个别现象，TEA 事件也只是其中一个例子而已。其中一种更严重的情况被称为“上下文污染”（context poisoning）——即大量关于游戏状态的错误信息被写入到上下文中（包括目标设定、总结等部分），这类污染往往需要很长时间才能纠正。一旦发生这种情况，模型可能会执着于实现一些根本不可能或毫无意义的目标。这种错误还常常伴随着“死循环”现象。尽管这些行为对人类来说明显是荒谬的，比如模型可能会不断尝试“进出一座房子，希望门口的守卫因此移动位置”，但由于上下文中的错误信息大量存在，它会使模型忽视常识，不断重复错误的判断。上下文污染甚至会导致模型采取一些极端策略，比如所谓的“黑屏策略”：故意让队伍中所有宝可梦全部昏迷，从而“黑屏”被传送回最近的宝可梦中心，同时损失一半的钱，而不是尝试正常离开当前区域。 也就是<strong>在上下文过长的情况之下，因为一些错误或者不合适的信息混杂在上下文并且一直持续存在于上下文中，导致Agent可能不断重复做出错误的决策或举动，这个负面效果需要经历较长的时间，这个时间就是对应的信息慢慢从上下文中淡化或者消失的过程。</strong></p> </blockquote> <p>因此上下文窗口大小在现在这个发展阶段仍是一把双刃剑，而不是银弹，也就是意味着更大的上下文不一定是最好的选择，还是要取决于具体的使用场景和上下文工程策略来决定，因此不要盲目追求大上下文窗口和超长上下文的组装，那样有可能让结果恶化，并且这个不一定在开发阶段能感知到，很有可能是一个较为隐蔽不好观测的一个情况。</p> <p>之前我也<a href="https://ifuryst.substack.com/p/manusai-agent">分析</a>过，Manus分享的<a href="https://manus.im/blog/Context-Engineering-for-AI-Agents-Lessons-from-Building-Manus">这篇AI Agent的上下文实践的文章</a>中提到，AI Agent实践中使用少样本提示（Few-Shot）需要谨慎：</p> <blockquote> <p>Language models are excellent mimics; they imitate the pattern of behavior in the context. If your context is full of similar past action-observation pairs, the model will tend to follow that pattern, even when it’s no longer optimal. This can be dangerous in tasks that involve repetitive decisions or actions. For example, when using Manus to help review a batch of 20 resumes, the agent often falls into a rhythm—repeating similar actions simply because that’s what it sees in the context. This leads to drift, overgeneralization, or sometimes hallucination. 翻译成中文是： Few-shot 提示是一种常见的技术，用于提升大语言模型（LLM）的输出质量。但在智能体（agent）系统中，它有时却会在不经意间带来反效果。 语言模型擅长“模仿”，它们会学习和复刻上下文中呈现的行为模式。如果你提供的上下文里充满了相似的“动作—观察”对，模型往往会机械地遵循这些模式，即便这些行为已经不再是最优选择。 在需要重复决策或执行操作的任务中，这种问题尤为明显。比如，当使用 Manus 帮助审阅一批共 20 份简历时，智能体很容易陷入“节奏”中——重复执行同样的操作，只因为它在上下文中看到类似的例子。这种现象会导致“漂移”、过度泛化，甚至出现幻觉（hallucination）。 大模型倾向于模仿，因此如果提供的样本是规律重复的，就会导致模型倾向于模仿样本，导致后续的行为不断重复。尤其当你把模型先前的响应结果一起带入到新一轮推理中时，就可能造成结果偏差。模型会误以为“你希望我继续往这个方向走”，久而久之形成错误的趋势。</p> </blockquote> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-09-02-context-engineering-stack/1756742889_1-480.webp 480w,/assets/img/2025-09-02-context-engineering-stack/1756742889_1-800.webp 800w,/assets/img/2025-09-02-context-engineering-stack/1756742889_1-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/2025-09-02-context-engineering-stack/1756742889_1.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> </div> </div> <p>Manus的解决方法：</p> <blockquote> <p>The fix is to increase diversity. Manus introduces small amounts of structured variation in actions and observations—different serialization templates, alternate phrasing, minor noise in order or formatting. This controlled randomness helps break the pattern and tweaks the model’s attention. In other words, <strong>don’t few-shot yourself into a rut</strong>. The more uniform your context, the more brittle your agent becomes. 中文是： 解决方法是引入更多的多样性。Manus 通过在动作和观察中加入少量有结构的变化来实现这一点——比如使用不同的序列化模板、替换措辞、在顺序或格式上加入细微扰动。这种“可控的随机性”有助于打破固定模式，重新调整模型的注意力焦点。 换句话说，别让 few-shot 提示把你困在一种套路里。上下文越单一、越一致，你的智能体就越脆弱。 也就是通过一定得刻意微调，避免大模型陷入一个循环圈套里，这是一个小技巧。</p> </blockquote> <p>无论是Gemini在游戏中陷入错误幻觉与循环，还是Agent因少样本提示而产生重复行为，背后都体现了同一个风险：<strong>当上下文中充斥了不相关、误导性强或错误的信息时，大模型容易产出错误倾向的结果。</strong>并且这种错误倾向无法在短期内被快速纠正，通常需要有检测和预防机制才可有效缓解和进一步解决这类问题。</p> <h3 id="注意力偏移attention-misalignment">注意力偏移（Attention Misalignment）</h3> <p>虽然上下文空间的长度已经拉到了1M的Tokens数，但是实际我们在应用中，为了保持好的效果输出，几乎<strong>不会撑满整个上下文空间</strong>，因为<strong>随着上下文的长度增大，最终的效果并不会持续正向提升，甚至有可能是降低的</strong>。因为大语言模型底层是以Transformer为主的注意力机制驱动的，<strong>过多的上下文会使注意力分散</strong>，这个在后续Prompt技术中我们也会了解到，类似Claude Code里会有保证不断回想之前计划的目标以便模型不断集中在目标的执行上。</p> <p>因此<strong>注意力偏移（Attention Misalignment）</strong>就是包括这一类问题，随着上下文长度增加，开始出现效果下降的现象。我们首先可以来看看<a href="https://research.trychroma.com/context-rot">Chroma的一篇技术报告</a>，开篇提到了：</p> <blockquote> <p>Large Language Models (LLMs) are typically presumed to process context uniformly—that is, the model should handle the 10,000th token just as reliably as the 100th. However, in practice, this assumption does not hold. We observe that model performance varies significantly as input length changes, even on simple tasks. 大模型通常被假设可以均匀处理上下文，比如处理第10,000个token的效果和处理第100个token一样可靠。实际上这个假设不成立，即便是简单任务，随着输入上下文长度的变化，模型的表现会出现显著差异。</p> </blockquote> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-09-02-context-engineering-stack/1756742890_2-480.webp 480w,/assets/img/2025-09-02-context-engineering-stack/1756742890_2-800.webp 800w,/assets/img/2025-09-02-context-engineering-stack/1756742890_2-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/2025-09-02-context-engineering-stack/1756742890_2.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> </div> </div> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-09-02-context-engineering-stack/1756742890_3-480.webp 480w,/assets/img/2025-09-02-context-engineering-stack/1756742890_3-800.webp 800w,/assets/img/2025-09-02-context-engineering-stack/1756742890_3-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/2025-09-02-context-engineering-stack/1756742890_3.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> </div> </div> <p>这张图是基于输入不同长度的重复单词，让模型去输出重复的单词，但是里面会包含一些特定的相似但是却不同的词汇，比如： ```plain text Simply replicate the following text, output the exact same text: apple apple apple apple <strong>apples</strong> apple apple apple apple apple apple apple apple apple apple apple apple apple apple apple apple apple apple apple apple</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>大模型处理过程中，可以看到随着输入的长度增加，输出的效果呈现下降的趋势，也就是模型无法正常输出输入的文本了。可以观察长上下文对于模型效果的影响。

其中还做了另外一个实验，在语料库里增加**相似文本**，是会影响效果的
&lt;div class="row mt-3"&gt;
    &lt;div class="col-sm mt-0 mb-0"&gt;
        &lt;div class="row mt-3"&gt;
    &lt;div class="col-sm mt-0 mb-0"&gt;
        

&lt;figure
  
&gt;
  &lt;picture&gt;
    &lt;!-- Auto scaling with imagemagick --&gt;
    &lt;!--
      See https://www.debugbear.com/blog/responsive-images#w-descriptors-and-the-sizes-attribute and
      https://developer.mozilla.org/en-US/docs/Learn/HTML/Multimedia_and_embedding/Responsive_images for info on defining 'sizes' for responsive images
    --&gt;
    
      &lt;source
        class="responsive-img-srcset"
        srcset="/assets/img/2025-09-02-context-engineering-stack/1756742890_4-480.webp 480w,/assets/img/2025-09-02-context-engineering-stack/1756742890_4-800.webp 800w,/assets/img/2025-09-02-context-engineering-stack/1756742890_4-1400.webp 1400w,"
        
          sizes="95vw"
        
        type="image/webp"
      &gt;
    
    &lt;img
      src="/assets/img/2025-09-02-context-engineering-stack/1756742890_4.png"
      
        class="img-fluid rounded z-depth-1"
      
      
        width="100%"
      
      
        height="auto"
      
      
      
      
      
        data-zoomable
      
      
        loading="eager"
      
      onerror="this.onerror=null; $('.responsive-img-srcset').remove();"
    &gt;
  &lt;/picture&gt;

  
&lt;/figure&gt;

    &lt;/div&gt;
&lt;/div&gt;
    &lt;/div&gt;
&lt;/div&gt;
上面这个Needle就是正确的答案所在的位置，而Distractor是分散注意力的文本，也就是和答案有一定相似性的内容，而其他绿色部分则是完全不想关的内容。基于这个可以增加更多的干扰文本，如下图，分别表示不同数量的干扰文本。
&lt;div class="row mt-3"&gt;
    &lt;div class="col-sm mt-0 mb-0"&gt;
        &lt;div class="row mt-3"&gt;
    &lt;div class="col-sm mt-0 mb-0"&gt;
        

&lt;figure
  
&gt;
  &lt;picture&gt;
    &lt;!-- Auto scaling with imagemagick --&gt;
    &lt;!--
      See https://www.debugbear.com/blog/responsive-images#w-descriptors-and-the-sizes-attribute and
      https://developer.mozilla.org/en-US/docs/Learn/HTML/Multimedia_and_embedding/Responsive_images for info on defining 'sizes' for responsive images
    --&gt;
    
      &lt;source
        class="responsive-img-srcset"
        srcset="/assets/img/2025-09-02-context-engineering-stack/1756742890_5-480.webp 480w,/assets/img/2025-09-02-context-engineering-stack/1756742890_5-800.webp 800w,/assets/img/2025-09-02-context-engineering-stack/1756742890_5-1400.webp 1400w,"
        
          sizes="95vw"
        
        type="image/webp"
      &gt;
    
    &lt;img
      src="/assets/img/2025-09-02-context-engineering-stack/1756742890_5.png"
      
        class="img-fluid rounded z-depth-1"
      
      
        width="100%"
      
      
        height="auto"
      
      
      
      
      
        data-zoomable
      
      
        loading="eager"
      
      onerror="this.onerror=null; $('.responsive-img-srcset').remove();"
    &gt;
  &lt;/picture&gt;

  
&lt;/figure&gt;

    &lt;/div&gt;
&lt;/div&gt;
    &lt;/div&gt;
&lt;/div&gt;
基于这个情况，结果如下：
&lt;div class="row mt-3"&gt;
    &lt;div class="col-sm mt-0 mb-0"&gt;
        &lt;div class="row mt-3"&gt;
    &lt;div class="col-sm mt-0 mb-0"&gt;
        

&lt;figure
  
&gt;
  &lt;picture&gt;
    &lt;!-- Auto scaling with imagemagick --&gt;
    &lt;!--
      See https://www.debugbear.com/blog/responsive-images#w-descriptors-and-the-sizes-attribute and
      https://developer.mozilla.org/en-US/docs/Learn/HTML/Multimedia_and_embedding/Responsive_images for info on defining 'sizes' for responsive images
    --&gt;
    
      &lt;source
        class="responsive-img-srcset"
        srcset="/assets/img/2025-09-02-context-engineering-stack/1756742890_6-480.webp 480w,/assets/img/2025-09-02-context-engineering-stack/1756742890_6-800.webp 800w,/assets/img/2025-09-02-context-engineering-stack/1756742890_6-1400.webp 1400w,"
        
          sizes="95vw"
        
        type="image/webp"
      &gt;
    
    &lt;img
      src="/assets/img/2025-09-02-context-engineering-stack/1756742890_6.png"
      
        class="img-fluid rounded z-depth-1"
      
      
        width="100%"
      
      
        height="auto"
      
      
      
      
      
        data-zoomable
      
      
        loading="eager"
      
      onerror="this.onerror=null; $('.responsive-img-srcset').remove();"
    &gt;
  &lt;/picture&gt;

  
&lt;/figure&gt;

    &lt;/div&gt;
&lt;/div&gt;
    &lt;/div&gt;
&lt;/div&gt;
可以看到，在上下文固定的情况之下，随着相似文本数量增加，最终的效果也是呈现下降趋势的。
这里我们进一步引出上下文分心这个问题。上下文分心有多种可能，上面这个是因为**上下文充满了一些相似但是对结果没有帮助的干扰文本，甚至有些内容是和真正有用的内容是矛盾的**，这些综合起来就会对大模型产生干扰，使得生成效果下降。除此之外就是前面提到的上下文长度增加导致效果下降，这个问题不仅会导致分心，甚至会导致模型忘记了在训练过程中获得的通识能力。我们一起来看看这个情况。

**当上下文长度到达一定程度的时候，会导致模型过于专注于上下文，而忽略了在训练时获得的知识。**通常而言，哪怕我们没有提供任何上下文，模型都可以在接收到问题时给出回答，这是因为模型通过极其庞大的语料库训练之后，拥有了一定程度上的通识能力，而上下文可以看作是实时的信息。就好比我们一个普通的高中生可能就是一个拥有基础的通识能力的人，但是到大学就会选择不同的专业，目的就是成为一个专才，后续可以在某个行业里就业。

问题在于，随着多轮次的交互，上下文历史不断构建和累积，有可能会导致模型注意被过度集中在上下文而导致效果不佳的情况出现，我们依然还是在Gemini的技术报告中可以看到一段这样的描述：
&gt; While Gemini 2.5 Pro supports 1M+ token context, making effective use of it for agents presents a new research frontier. In this agentic setup, it was observed that as the context grew significantly beyond 100k tokens, the agent showed a tendency toward favoring repeating actions from its vast history rather than synthesizing novel plans. This phenomenon, albeit anecdotal, highlights an important distinction between long-context for retrieval and long-context for multi-step, generative reasoning.
翻译成中文是：
&gt; 虽然 Gemini 2.5 Pro 支持超过 100 万个 token 的上下文，但如何在智能体（agent）系统中有效利用这一能力，仍是一个新的研究前沿。在这类 agentic 设置中，有观察发现：当上下文显著超过 10 万 token 时，智能体往往倾向于重复其历史中的动作，而不是生成新的计划。这种现象虽然仍属经验观察，但它揭示了一个重要的区别：长上下文在检索任务中的应用，与在多步生成式推理中的作用，其实并不相同。
其实前面我们也有看到类似的情况了，也就是随着上下文不断累积，模型出现了不断重复一些动作，哪怕那些动作是错误的，为什么会出现这个情况呢？其实本质上就是因为模型过于关注上下文内容了，这其实也从另一个侧面说明了上下文之于模型推理的重要性，也间接说明了，**如果我们构建的上下文是不合适的或错误的，那么对于模型的推理有可能起到副作用**，这也是上下文工程中很重要的一点。

[Databrcks有一篇研究](https://www.databricks.com/blog/long-context-rag-performance-llms)给出了一些有趣的结论：**使用更长的上下文并不总能提升RAG的表现**。
&lt;div class="row mt-3"&gt;
    &lt;div class="col-sm mt-0 mb-0"&gt;
        &lt;div class="row mt-3"&gt;
    &lt;div class="col-sm mt-0 mb-0"&gt;
        

&lt;figure
  
&gt;
  &lt;picture&gt;
    &lt;!-- Auto scaling with imagemagick --&gt;
    &lt;!--
      See https://www.debugbear.com/blog/responsive-images#w-descriptors-and-the-sizes-attribute and
      https://developer.mozilla.org/en-US/docs/Learn/HTML/Multimedia_and_embedding/Responsive_images for info on defining 'sizes' for responsive images
    --&gt;
    
      &lt;source
        class="responsive-img-srcset"
        srcset="/assets/img/2025-09-02-context-engineering-stack/1756742890_7-480.webp 480w,/assets/img/2025-09-02-context-engineering-stack/1756742890_7-800.webp 800w,/assets/img/2025-09-02-context-engineering-stack/1756742890_7-1400.webp 1400w,"
        
          sizes="95vw"
        
        type="image/webp"
      &gt;
    
    &lt;img
      src="/assets/img/2025-09-02-context-engineering-stack/1756742890_7.png"
      
        class="img-fluid rounded z-depth-1"
      
      
        width="100%"
      
      
        height="auto"
      
      
      
      
      
        data-zoomable
      
      
        loading="eager"
      
      onerror="this.onerror=null; $('.responsive-img-srcset').remove();"
    &gt;
  &lt;/picture&gt;

  
&lt;/figure&gt;

    &lt;/div&gt;
&lt;/div&gt;
    &lt;/div&gt;
&lt;/div&gt;
这边是基于4份数据集来做RAG的效果评估。可以看到随着上下文增加，RAG的平均效果曲线不一样，随着上下文长度的增加，一开始所有模型的表现都是准确率的提升，但是随后开始不太一样，小参数模型开始出现恶化，准确率不升反降；而大参数级别的模型，还能多增长一小会才开始进入准确率的衰减区间；最后是大参数级别的SOTA模型，在增长到一定的程度后准确率的提升开始趋缓，也就是说到一定程度不再有明显的效果提升。

这里可以明确看到小参数模型对于上下文长度增加的耐受程度更低，而SOTA模型可以有更好的抵抗作用，但是可以明显感受到，**最初的上下文带来的增量是收益最好的**，因此在成本和效果直接，我们很容易找到平衡点应该是中间偏左的区域里，换句话说**在实际应用中不应盲目追求更多的上下文，而是要追求最好最合适的上下文**。

上下文分心还有一点，就是因为**上下文过长，模型无法专注于指令（instruction）**，比如我们在System Prompt里给出了对应的指示甚至是目标，但是在执行过程中，持续增长的上下文会导致指令和目标被“淹没”，使得模型忽略了一些很重要的信息，在Databricks这篇研究中也有提到失败的有几种原因：
- **重复内容(repeated_content)**：当大模型的回答是完全重复的词语或字符（无意义的重复）。
- **随机内容(random_content)**：当模型生成的回答完全是随机的、与内容无关，或在逻辑或语法上不通顺。
- **未遵循指令（fail_to_follow_instruction）**：当模型没有理解指令的意图，或未按照问题中指定的要求作答。例如，指令要求根据给定上下文回答问题，而模型却去总结上下文。
- **错误回答（wrong_answer）**：当模型试图按照指令作答，但提供的答案是错误的。
- **其他（others）**：当失败情况不属于上述任何一种类别时使用。
&lt;div class="row mt-3"&gt;
    &lt;div class="col-sm mt-0 mb-0"&gt;
        &lt;div class="row mt-3"&gt;
    &lt;div class="col-sm mt-0 mb-0"&gt;
        

&lt;figure
  
&gt;
  &lt;picture&gt;
    &lt;!-- Auto scaling with imagemagick --&gt;
    &lt;!--
      See https://www.debugbear.com/blog/responsive-images#w-descriptors-and-the-sizes-attribute and
      https://developer.mozilla.org/en-US/docs/Learn/HTML/Multimedia_and_embedding/Responsive_images for info on defining 'sizes' for responsive images
    --&gt;
    
      &lt;source
        class="responsive-img-srcset"
        srcset="/assets/img/2025-09-02-context-engineering-stack/1756742891_8-480.webp 480w,/assets/img/2025-09-02-context-engineering-stack/1756742891_8-800.webp 800w,/assets/img/2025-09-02-context-engineering-stack/1756742891_8-1400.webp 1400w,"
        
          sizes="95vw"
        
        type="image/webp"
      &gt;
    
    &lt;img
      src="/assets/img/2025-09-02-context-engineering-stack/1756742891_8.png"
      
        class="img-fluid rounded z-depth-1"
      
      
        width="100%"
      
      
        height="auto"
      
      
      
      
      
        data-zoomable
      
      
        loading="eager"
      
      onerror="this.onerror=null; $('.responsive-img-srcset').remove();"
    &gt;
  &lt;/picture&gt;

  
&lt;/figure&gt;

    &lt;/div&gt;
&lt;/div&gt;
    &lt;/div&gt;
&lt;/div&gt;
&lt;div class="row mt-3"&gt;
    &lt;div class="col-sm mt-0 mb-0"&gt;
        &lt;div class="row mt-3"&gt;
    &lt;div class="col-sm mt-0 mb-0"&gt;
        

&lt;figure
  
&gt;
  &lt;picture&gt;
    &lt;!-- Auto scaling with imagemagick --&gt;
    &lt;!--
      See https://www.debugbear.com/blog/responsive-images#w-descriptors-and-the-sizes-attribute and
      https://developer.mozilla.org/en-US/docs/Learn/HTML/Multimedia_and_embedding/Responsive_images for info on defining 'sizes' for responsive images
    --&gt;
    
      &lt;source
        class="responsive-img-srcset"
        srcset="/assets/img/2025-09-02-context-engineering-stack/1756742891_9-480.webp 480w,/assets/img/2025-09-02-context-engineering-stack/1756742891_9-800.webp 800w,/assets/img/2025-09-02-context-engineering-stack/1756742891_9-1400.webp 1400w,"
        
          sizes="95vw"
        
        type="image/webp"
      &gt;
    
    &lt;img
      src="/assets/img/2025-09-02-context-engineering-stack/1756742891_9.png"
      
        class="img-fluid rounded z-depth-1"
      
      
        width="100%"
      
      
        height="auto"
      
      
      
      
      
        data-zoomable
      
      
        loading="eager"
      
      onerror="this.onerror=null; $('.responsive-img-srcset').remove();"
    &gt;
  &lt;/picture&gt;

  
&lt;/figure&gt;

    &lt;/div&gt;
&lt;/div&gt;
    &lt;/div&gt;
&lt;/div&gt;
我们再来看看，在[Claude Code](https://www.anthropic.com/claude-code)执行任务的过程中，我们可以反复看到其会不断更新目标：
&lt;div class="row mt-3"&gt;
    &lt;div class="col-sm mt-0 mb-0"&gt;
        &lt;div class="row mt-3"&gt;
    &lt;div class="col-sm mt-0 mb-0"&gt;
        

&lt;figure
  
&gt;
  &lt;picture&gt;
    &lt;!-- Auto scaling with imagemagick --&gt;
    &lt;!--
      See https://www.debugbear.com/blog/responsive-images#w-descriptors-and-the-sizes-attribute and
      https://developer.mozilla.org/en-US/docs/Learn/HTML/Multimedia_and_embedding/Responsive_images for info on defining 'sizes' for responsive images
    --&gt;
    
      &lt;source
        class="responsive-img-srcset"
        srcset="/assets/img/2025-09-02-context-engineering-stack/1756742891_10-480.webp 480w,/assets/img/2025-09-02-context-engineering-stack/1756742891_10-800.webp 800w,/assets/img/2025-09-02-context-engineering-stack/1756742891_10-1400.webp 1400w,"
        
          sizes="95vw"
        
        type="image/webp"
      &gt;
    
    &lt;img
      src="/assets/img/2025-09-02-context-engineering-stack/1756742891_10.png"
      
        class="img-fluid rounded z-depth-1"
      
      
        width="100%"
      
      
        height="auto"
      
      
      
      
      
        data-zoomable
      
      
        loading="eager"
      
      onerror="this.onerror=null; $('.responsive-img-srcset').remove();"
    &gt;
  &lt;/picture&gt;

  
&lt;/figure&gt;

    &lt;/div&gt;
&lt;/div&gt;
    &lt;/div&gt;
&lt;/div&gt;
&lt;div class="row mt-3"&gt;
    &lt;div class="col-sm mt-0 mb-0"&gt;
        &lt;div class="row mt-3"&gt;
    &lt;div class="col-sm mt-0 mb-0"&gt;
        

&lt;figure
  
&gt;
  &lt;picture&gt;
    &lt;!-- Auto scaling with imagemagick --&gt;
    &lt;!--
      See https://www.debugbear.com/blog/responsive-images#w-descriptors-and-the-sizes-attribute and
      https://developer.mozilla.org/en-US/docs/Learn/HTML/Multimedia_and_embedding/Responsive_images for info on defining 'sizes' for responsive images
    --&gt;
    
      &lt;source
        class="responsive-img-srcset"
        srcset="/assets/img/2025-09-02-context-engineering-stack/1756742892_11-480.webp 480w,/assets/img/2025-09-02-context-engineering-stack/1756742892_11-800.webp 800w,/assets/img/2025-09-02-context-engineering-stack/1756742892_11-1400.webp 1400w,"
        
          sizes="95vw"
        
        type="image/webp"
      &gt;
    
    &lt;img
      src="/assets/img/2025-09-02-context-engineering-stack/1756742892_11.png"
      
        class="img-fluid rounded z-depth-1"
      
      
        width="100%"
      
      
        height="auto"
      
      
      
      
      
        data-zoomable
      
      
        loading="eager"
      
      onerror="this.onerror=null; $('.responsive-img-srcset').remove();"
    &gt;
  &lt;/picture&gt;

  
&lt;/figure&gt;

    &lt;/div&gt;
&lt;/div&gt;
    &lt;/div&gt;
&lt;/div&gt;
可以看到一个小任务计划出来5个目标，在执行过程中会持续更新目标，一个是给用户进度反馈，另一个更重要的是让模型持续聚焦于模型中。我们可以在抓包的请求里看到上下文是非常的多
&lt;div class="row mt-3"&gt;
    &lt;div class="col-sm mt-0 mb-0"&gt;
        &lt;div class="row mt-3"&gt;
    &lt;div class="col-sm mt-0 mb-0"&gt;
        

&lt;figure
  
&gt;
  &lt;picture&gt;
    &lt;!-- Auto scaling with imagemagick --&gt;
    &lt;!--
      See https://www.debugbear.com/blog/responsive-images#w-descriptors-and-the-sizes-attribute and
      https://developer.mozilla.org/en-US/docs/Learn/HTML/Multimedia_and_embedding/Responsive_images for info on defining 'sizes' for responsive images
    --&gt;
    
      &lt;source
        class="responsive-img-srcset"
        srcset="/assets/img/2025-09-02-context-engineering-stack/1756742892_12-480.webp 480w,/assets/img/2025-09-02-context-engineering-stack/1756742892_12-800.webp 800w,/assets/img/2025-09-02-context-engineering-stack/1756742892_12-1400.webp 1400w,"
        
          sizes="95vw"
        
        type="image/webp"
      &gt;
    
    &lt;img
      src="/assets/img/2025-09-02-context-engineering-stack/1756742892_12.png"
      
        class="img-fluid rounded z-depth-1"
      
      
        width="100%"
      
      
        height="auto"
      
      
      
      
      
        data-zoomable
      
      
        loading="eager"
      
      onerror="this.onerror=null; $('.responsive-img-srcset').remove();"
    &gt;
  &lt;/picture&gt;

  
&lt;/figure&gt;

    &lt;/div&gt;
&lt;/div&gt;
    &lt;/div&gt;
&lt;/div&gt;
这是一次请求的请求体内容，实际上消耗的token没有这么多的
&lt;div class="row mt-3"&gt;
    &lt;div class="col-sm mt-0 mb-0"&gt;
        &lt;div class="row mt-3"&gt;
    &lt;div class="col-sm mt-0 mb-0"&gt;
        

&lt;figure
  
&gt;
  &lt;picture&gt;
    &lt;!-- Auto scaling with imagemagick --&gt;
    &lt;!--
      See https://www.debugbear.com/blog/responsive-images#w-descriptors-and-the-sizes-attribute and
      https://developer.mozilla.org/en-US/docs/Learn/HTML/Multimedia_and_embedding/Responsive_images for info on defining 'sizes' for responsive images
    --&gt;
    
      &lt;source
        class="responsive-img-srcset"
        srcset="/assets/img/2025-09-02-context-engineering-stack/1756742892_13-480.webp 480w,/assets/img/2025-09-02-context-engineering-stack/1756742892_13-800.webp 800w,/assets/img/2025-09-02-context-engineering-stack/1756742892_13-1400.webp 1400w,"
        
          sizes="95vw"
        
        type="image/webp"
      &gt;
    
    &lt;img
      src="/assets/img/2025-09-02-context-engineering-stack/1756742892_13.png"
      
        class="img-fluid rounded z-depth-1"
      
      
        width="100%"
      
      
        height="auto"
      
      
      
      
      
        data-zoomable
      
      
        loading="eager"
      
      onerror="this.onerror=null; $('.responsive-img-srcset').remove();"
    &gt;
  &lt;/picture&gt;

  
&lt;/figure&gt;

    &lt;/div&gt;
&lt;/div&gt;
    &lt;/div&gt;
&lt;/div&gt;
根据响应可以看到大部分是命中缓存的，关于这个我们在Agent环节有机会讲一下大模型推理缓存相关的技术。
&lt;div class="row mt-3"&gt;
    &lt;div class="col-sm mt-0 mb-0"&gt;
        &lt;div class="row mt-3"&gt;
    &lt;div class="col-sm mt-0 mb-0"&gt;
        

&lt;figure
  
&gt;
  &lt;picture&gt;
    &lt;!-- Auto scaling with imagemagick --&gt;
    &lt;!--
      See https://www.debugbear.com/blog/responsive-images#w-descriptors-and-the-sizes-attribute and
      https://developer.mozilla.org/en-US/docs/Learn/HTML/Multimedia_and_embedding/Responsive_images for info on defining 'sizes' for responsive images
    --&gt;
    
      &lt;source
        class="responsive-img-srcset"
        srcset="/assets/img/2025-09-02-context-engineering-stack/1756742892_14-480.webp 480w,/assets/img/2025-09-02-context-engineering-stack/1756742892_14-800.webp 800w,/assets/img/2025-09-02-context-engineering-stack/1756742892_14-1400.webp 1400w,"
        
          sizes="95vw"
        
        type="image/webp"
      &gt;
    
    &lt;img
      src="/assets/img/2025-09-02-context-engineering-stack/1756742892_14.png"
      
        class="img-fluid rounded z-depth-1"
      
      
        width="100%"
      
      
        height="auto"
      
      
      
      
      
        data-zoomable
      
      
        loading="eager"
      
      onerror="this.onerror=null; $('.responsive-img-srcset').remove();"
    &gt;
  &lt;/picture&gt;

  
&lt;/figure&gt;

    &lt;/div&gt;
&lt;/div&gt;
    &lt;/div&gt;
&lt;/div&gt;
回过头来看，我们可以看到在上下文传递中，Claude Code会持续拼接TODO List到上下文中，给大模型判断目前的进度情况和正在进行的任务。这就是为了让大模型不要在如此长的上下文中无法聚焦要处理什么任务，要达成什么样的目标。换句话说就是用于**锚定大模型的注意力**。
这点其实在Manus那篇分享中也有提到
&lt;div class="row mt-3"&gt;
    &lt;div class="col-sm mt-0 mb-0"&gt;
        &lt;div class="row mt-3"&gt;
    &lt;div class="col-sm mt-0 mb-0"&gt;
        

&lt;figure
  
&gt;
  &lt;picture&gt;
    &lt;!-- Auto scaling with imagemagick --&gt;
    &lt;!--
      See https://www.debugbear.com/blog/responsive-images#w-descriptors-and-the-sizes-attribute and
      https://developer.mozilla.org/en-US/docs/Learn/HTML/Multimedia_and_embedding/Responsive_images for info on defining 'sizes' for responsive images
    --&gt;
    
      &lt;source
        class="responsive-img-srcset"
        srcset="/assets/img/2025-09-02-context-engineering-stack/1756742893_15-480.webp 480w,/assets/img/2025-09-02-context-engineering-stack/1756742893_15-800.webp 800w,/assets/img/2025-09-02-context-engineering-stack/1756742893_15-1400.webp 1400w,"
        
          sizes="95vw"
        
        type="image/webp"
      &gt;
    
    &lt;img
      src="/assets/img/2025-09-02-context-engineering-stack/1756742893_15.png"
      
        class="img-fluid rounded z-depth-1"
      
      
        width="100%"
      
      
        height="auto"
      
      
      
      
      
        data-zoomable
      
      
        loading="eager"
      
      onerror="this.onerror=null; $('.responsive-img-srcset').remove();"
    &gt;
  &lt;/picture&gt;

  
&lt;/figure&gt;

    &lt;/div&gt;
&lt;/div&gt;
    &lt;/div&gt;
&lt;/div&gt;
Manus也是一样的做法，通过复述来操控注意力：
&gt; If you've worked with Manus, you've probably noticed something curious: when handling complex tasks, it tends to create a todo.md file—and update it step-by-step as the task progresses, checking off completed items.
That's not just cute behavior—it's a deliberate mechanism to **manipulate attention**.
A typical task in Manus requires around **50 tool calls** on average. That's a long loop—and since Manus relies on LLMs for decision-making, it's vulnerable to drifting off-topic or forgetting earlier goals, especially in long contexts or complicated tasks.
By constantly rewriting the todo list, Manus is **reciting its objectives into the end of the context**. This pushes the global plan into the model's recent attention span, avoiding "**lost-in-the-middle**" issues and reducing goal misalignment. In effect, it's using natural language to bias its own focus toward the task objective—without needing special architectural changes.
中文是：
&gt; 如果你用过 Manus，可能会注意到一个有趣的现象：在处理复杂任务时，它常常会创建一个 todo.md 文件，并在任务执行过程中逐步更新，勾选已经完成的项目。
这并不是一种“可爱”的行为，而是一种有意设计的注意力操控机制。
Manus 处理的典型任务平均需要调用大约 50 次工具。这是一个非常长的执行链——而由于 Manus 的决策依赖 LLM，它在上下文很长或任务很复杂的情况下，容易出现跑题或忘记最初目标的问题。
通过不断地重写这份待办清单，Manus 实质上是在将任务目标“复述”到上下文的结尾处。这样做可以把全局计划强行推入模型最近的注意力范围，避免“上下文中段丢失”问题，同时减少目标偏移。换句话说，它是在用自然语言主动引导模型关注核心任务目标——无需修改模型结构，就能实现注意力的偏置。
Manus可以看作是和Claude Code相差不会特别大的AI Agent的产品，因此我们可以看到殊途同归，业界的实践方式都是相似的，你也可以在其他的AI Agent里看到同样的实践，目的都是为了让注意力不要产生偏移。

其实提示词技术（或者说上下文）在某种程度就是加强或者说提供一个遮罩层，这样可以对训练时获得的权重进行一定程度的补充，使得结果偏向于更正确的可能，但是某些情况下会导致模型分散了注意力。

### 语义冲突与混乱（Semantic Conflict &amp; Confusion）
在多轮交互或复杂上下文环境中，语义冲突与混乱是影响大模型表现的重要隐患之一。它通常表现为：**新引入的信息或工具与已有上下文中的内容产生矛盾，导致模型产生困惑、做出错误判断，甚至出现“随机选择”的不稳定行为**

[微软和Salesforce在一篇论文](https://arxiv.org/pdf/2505.06120)中展示了这样一个现象：将单轮次的交互拆成多轮次，会导致模型的效果显著下降。
&lt;div class="row mt-3"&gt;
    &lt;div class="col-sm mt-0 mb-0"&gt;
        &lt;div class="row mt-3"&gt;
    &lt;div class="col-sm mt-0 mb-0"&gt;
        

&lt;figure
  
&gt;
  &lt;picture&gt;
    &lt;!-- Auto scaling with imagemagick --&gt;
    &lt;!--
      See https://www.debugbear.com/blog/responsive-images#w-descriptors-and-the-sizes-attribute and
      https://developer.mozilla.org/en-US/docs/Learn/HTML/Multimedia_and_embedding/Responsive_images for info on defining 'sizes' for responsive images
    --&gt;
    
      &lt;source
        class="responsive-img-srcset"
        srcset="/assets/img/2025-09-02-context-engineering-stack/1756742893_16-480.webp 480w,/assets/img/2025-09-02-context-engineering-stack/1756742893_16-800.webp 800w,/assets/img/2025-09-02-context-engineering-stack/1756742893_16-1400.webp 1400w,"
        
          sizes="95vw"
        
        type="image/webp"
      &gt;
    
    &lt;img
      src="/assets/img/2025-09-02-context-engineering-stack/1756742893_16.png"
      
        class="img-fluid rounded z-depth-1"
      
      
        width="100%"
      
      
        height="auto"
      
      
      
      
      
        data-zoomable
      
      
        loading="eager"
      
      onerror="this.onerror=null; $('.responsive-img-srcset').remove();"
    &gt;
  &lt;/picture&gt;

  
&lt;/figure&gt;

    &lt;/div&gt;
&lt;/div&gt;
    &lt;/div&gt;
&lt;/div&gt;
也就是类似我们平时与模型交互，我们会一次性发送相关的问题和描述，但是当我们把这个输入进行分片（Sharding），拆成多次给到模型，会导致效果下降。原因是，**每次模型接收到的信息都是局部的，不够完整，模型在早期做出了不完整甚至是错误的回答，这些错误信息会持续留在上下文中，并在最终生成答案时影响模型判断。**

现在AI Agent基本都会挂载工具集，不管是内置的还是遵循MCP协议的工具调用，从几个到几十个甚至上百个工具，这种情况下就有可能出现工具出现相似描述导致模型不知道选择哪个，最终结果就是在相似的工具里进行**非确定性选择**（或可称为随机选择），导致生成结果不稳定甚至错误。这种混乱的根源在于上下文中存在过多、冗余且难以区分的信息。

# 2.2 上下文工程技术（Techniques in CE）
前面我们提到了在实际应用中上下文出现不足、过长、矛盾和混淆等问题。本节我们将总览几类可用于解决这些问题的上下文工程技术。它们各自针对不同挑战，在系统架构中承担不同职责。更深入的技术细节和实现方式将在第二部分具体展开。

这里我会将上下文涉及的一些技术手段划分为这三个类别：
1. **上下文增强（Context Augmentation）**：主要目的是补充信息，比如提示词技术、RAG和MCP
2. **上下文优化（Context Optimization）**：主要目的是清洗和优化上下文，会包括隔离、修剪和压缩等手段
3. **上下文持久化（Context Persistence）**：主要目的是保留信息，涉及一些外部记忆模块的持久化服务

## 2.2.1 上下文增强（Context Augmentation）
### 提示词技术（Prompting）
提示词技术也就是Prompting，一直以来就是为了增强模型输出的存在，虽然现在我们关注的目标是上下文，但是提示词技术仍然是上下文工程里很重要的一个东西，最基础的就是写好系统提示词。现在几乎所有的AI应用和产品都离不开提示词，甚至有些服务里会有很多的提示词，需要在不同的场景下加载不同的提示词到上下文中。

我们会着重关注在一些主流的提示词技术，来帮助我们写出更好、更适用的提示词。

### RAG（Retrieval-Augmented Generation）
RAG是一种结合检索外部文档来辅助推理，提高结果准确性的技术：通过从外部知识库中检索相关信息，再将其与用户输入一同送入生成模型，从而提升响应的准确性与上下文的丰富性。

其优势在于：
1. 减少幻觉（Hallucination）
2. 提升信息的时效性
3. 专业或领域信息增强

关键技术：
- 索引：切分策略（语义/结构化切分）、元数据（时间、作者、标签）、多索引（向量+倒排）、段落-表格-图片多模态
- 查询加工：重写（Query Rewriting）、多路查询（Multi-Query）、分解（Decomposition）、意图判别（是否需要检索）
- 检排：向量召回+交叉编码器重排（Rerank）；MMR/多样性；新鲜度与时效权重
- 变体：多跳/链式RAG、Agentic RAG（规划+迭代检索）、GraphRAG（图结构汇总）、结构化检索（SQL/知识图谱）

在此前，每次SOTA模型的上下文窗口增长，势必会带来RAG是否已死的争论，但是就目前行业的实践来看，**长上下文模型≠RAG替代品**，更长的上下文窗口实际上是增强了RAG的效果，而不是取代RAG。我们有理由相信在可预见的未来一段时间内，RAG依然会在上下文工程中持续扮演非常重要的角色，是大模型应用过程中不可或缺的一个技术。

### 工具集成与函数调用（MCP）
当模型自身通过训练得到的权重里包含的基础知识和上下文内容结合都无法回答用户问题的时候，模型可以基于预定的外部工具来获取外部数据或执行相应的任务。这一配套相当于解放了模型，**使模型从一个孤岛系统成功接入了现实世界**，可以从浏览器、本地计算机、外部接口等地方获取相应的数据来辅助决策，也可以直接执行某些动作，比如创建一个日程待办，发送一封邮件等等。

甚至现在具身智能领域为模型配上了类人的躯体，拥有视觉、触觉，有四肢可以与现实世界交互，得到信息，决策后续采取的行动。本质上模型就类似人类的大脑，人类也是解决外部的工具与这个世界交流，眼睛、鼻子、耳朵和手脚等都可以收集相应的信息，进而基于这些信息与我们自身已经学到的知识做出合适的决策和行动。

在大语言模型刚流行的头两年，不同模型都各自实现了工具调用（Tool Calling）或函数调用（Function Calling），在2024年11月Anthropic推出了[MCP（Model Context Protocol）](https://modelcontextprotocol.io/)，旨在规范模型与外部环境的交互过程，推动上下文管理与工具调用机制的标准化。这也是我在这个小标题里的英文写的是MCP，因为目前大部分模型厂商都宣布支持MCP，以MCP为主的服务也不断涌现，因此我们会着重以MCP为出发点去了解这部分内容。

下面是一张我没找到出处但在网上广为流传的图，用于将MCP类比成TypeC的存在：
&lt;div class="row mt-3"&gt;
    &lt;div class="col-sm mt-0 mb-0"&gt;
        &lt;div class="row mt-3"&gt;
    &lt;div class="col-sm mt-0 mb-0"&gt;
        

&lt;figure
  
&gt;
  &lt;picture&gt;
    &lt;!-- Auto scaling with imagemagick --&gt;
    &lt;!--
      See https://www.debugbear.com/blog/responsive-images#w-descriptors-and-the-sizes-attribute and
      https://developer.mozilla.org/en-US/docs/Learn/HTML/Multimedia_and_embedding/Responsive_images for info on defining 'sizes' for responsive images
    --&gt;
    
      &lt;source
        class="responsive-img-srcset"
        srcset="/assets/img/2025-09-02-context-engineering-stack/1756742893_17-480.webp 480w,/assets/img/2025-09-02-context-engineering-stack/1756742893_17-800.webp 800w,/assets/img/2025-09-02-context-engineering-stack/1756742893_17-1400.webp 1400w,"
        
          sizes="95vw"
        
        type="image/webp"
      &gt;
    
    &lt;img
      src="/assets/img/2025-09-02-context-engineering-stack/1756742893_17.png"
      
        class="img-fluid rounded z-depth-1"
      
      
        width="100%"
      
      
        height="auto"
      
      
      
      
      
        data-zoomable
      
      
        loading="eager"
      
      onerror="this.onerror=null; $('.responsive-img-srcset').remove();"
    &gt;
  &lt;/picture&gt;

  
&lt;/figure&gt;

    &lt;/div&gt;
&lt;/div&gt;
    &lt;/div&gt;
&lt;/div&gt;
MCP的出现标志着大模型调用外部工具的标准化，使得各厂商和模型之间都可以遵循统一协议，从而使得应用层更容易复用底层模型能力。同时，外部工具也可以在 MCP 统一规范下形成可共享的生态体系，各使用方只需通过简单配置，即可接入市场上已有的 MCP Server，实现即插即用。

也使得外部工具得以在遵循相同标准下衍生出生态，各使用方可以通过简单的配置就能使用市场上存在的MCP Server。这一模式的兴起，或可被视为大语言模型时代“应用商店”概念的雏形，为模型赋能提供了新的基础设施。

随着MCP的发展和普及，现在客户端可能挂载了数十甚至上百的MCP Server，每个MCP Server内含几个到几十个工具，因此这种情况下，MCP或者说工具的治理已经成为一个重要研究方向。
## 2.2.2 上下文优化（Context Optimization）
### 上下文隔离（Context Isolation）
这个技术在多智能体（Multi-Agent）上得到了极好的发挥。也就是将复杂任务通过拆分，细化成多个智能体（Agent），每个智能体单独执行专一的任务，每个智能体拥有独立的上下文窗口，可以使用合适的MCP服务，可以搭配不同的RAG等，正因为隔离，所以多个智能体之间无需关注非必要的上下文，进而减少了干扰。

多智能体是上下文隔离的一种应用，在不同的应用场景下，还有其他的一些手法：
- **任务分片（Task Sharding）**：将任务分成多个子流程或阶段，每一阶段单独运行于自己的上下文中，避免累积无关信息
- **记忆系统分区（Memory Partitioning）**：通过将长期记忆和短期记忆隔离管理，只在需要时引用跨区域记忆，避免上下文污染
- **领域专属上下文（Domain-specific Context Pools）**：为不同的任务域（如法律、医疗、编程）配置专属上下文池，确保大语言模型使用最相关的信息

在实际应用中，应根据任务复杂度、协同粒度和系统架构需求，灵活选择或组合这些策略。

### 上下文压缩（Context Compression）
**上下文压缩（Context Compression）**或者也可以说是**上下文摘要（Context Summarization）**，在某些地方也会以**上下文修剪（Context Pruning）**出现，可以视为相同的东西，但是我觉得上下文压缩会比较贴切一点，且涵盖的范围更广一点。这一策略最早的出现是为了应对上下文窗口不足的问题，但是现在依然是一个非常重要的技术。常见的上下文压缩策略包括：
- **提取式摘要（Extractive Summarization）**：直接选出原文中最相关的段落、句子
- **抽象式摘要（Abstractive Summarization**）：用自己的话总结信息，常结合LLM实现
- **结构化摘要（Structured Summarization）**：提取出知识点、任务、目标等结构化信息，如To-do列表、决策路径
- **自我总结（Self-summarization）**：模型每一轮对话之后，自动总结这轮信息并作为输入传递，形成压缩上下文链
- **摘要记忆（Summarized Memory）**：结合记忆机制，将历史摘要作为长期记忆引用
- **时间窗口裁剪（Time-based Pruning）**：仅保留最近或关键时段的上下文，剔除历史冗余信息，提升推理精度
上下文压缩在实际使用中非常常见，也是多轮次、长会话和智能体里必备的一个技术，**它不仅节省了上下文窗口，还提升了信息的结构化程度**。我们经常可以在AI Agent中看到需要对上下文进行压缩的动作，这也是Agent在持续运作过程中会累积历史上下文，当接近上下文窗口或者一定阈值的情况下就需要进行上下文压缩，使得Agent可以持续运作。甚至在很多情况下我们都会主动进行压缩，就如前面提到的，上下文长度增加有可能会导致效果的下降，因此有时候保持上下文在低水位是有助于任务执行速度和效果的。

我们来看一份Claude Code是怎么做压缩的。Claude Code里是借助大语言模型配合提示词进行压缩的，提示词如下：
```plain text
Your task is to create a detailed summary of the conversation so far, paying close attention to the user's explicit requests and your previous actions.
This summary should be thorough in capturing technical details, code patterns, and architectural decisions that would be essential for continuing development work without losing context.

Before providing your final summary, wrap your analysis in &lt;analysis&gt; tags to organize your thoughts and ensure you've covered all necessary points. In your analysis process:

1. Chronologically analyze each message and section of the conversation. For each section thoroughly identify:
   - The user's explicit requests and intents
   - Your approach to addressing the user's requests
   - Key decisions, technical concepts and code patterns
   - Specific details like:
     - file names
     - full code snippets
     - function signatures
     - file edits
  - Errors that you ran into and how you fixed them
  - Pay special attention to specific user feedback that you received, especially if the user told you to do something differently.
2. Double-check for technical accuracy and completeness, addressing each required element thoroughly.

Your summary should include the following sections:

1. Primary Request and Intent: Capture all of the user's explicit requests and intents in detail
2. Key Technical Concepts: List all important technical concepts, technologies, and frameworks discussed.
3. Files and Code Sections: Enumerate specific files and code sections examined, modified, or created. Pay special attention to the most recent messages and include full code snippets where applicable and include a summary of why this file read or edit is important.
4. Errors and fixes: List all errors that you ran into, and how you fixed them. Pay special attention to specific user feedback that you received, especially if the user told you to do something differently.
5. Problem Solving: Document problems solved and any ongoing troubleshooting efforts.
6. All user messages: List ALL user messages that are not tool results. These are critical for understanding the users' feedback and changing intent.
6. Pending Tasks: Outline any pending tasks that you have explicitly been asked to work on.
7. Current Work: Describe in detail precisely what was being worked on immediately before this summary request, paying special attention to the most recent messages from both user and assistant. Include file names and code snippets where applicable.
8. Optional Next Step: List the next step that you will take that is related to the most recent work you were doing. IMPORTANT: ensure that this step is DIRECTLY in line with the user's explicit requests, and the task you were working on immediately before this summary request. If your last task was concluded, then only list next steps if they are explicitly in line with the users request. Do not start on tangential requests without confirming with the user first.
                       If there is a next step, include direct quotes from the most recent conversation showing exactly what task you were working on and where you left off. This should be verbatim to ensure there's no drift in task interpretation.

Here's an example of how your output should be structured:

&lt;example&gt;
&lt;analysis&gt;
[Your thought process, ensuring all points are covered thoroughly and accurately]
&lt;/analysis&gt;

&lt;summary&gt;
1. Primary Request and Intent:
   [Detailed description]

2. Key Technical Concepts:
   - [Concept 1]
   - [Concept 2]
   - [...]

3. Files and Code Sections:
   - [File Name 1]
      - [Summary of why this file is important]
      - [Summary of the changes made to this file, if any]
      - [Important Code Snippet]
   - [File Name 2]
      - [Important Code Snippet]
   - [...]

4. Errors and fixes:
    - [Detailed description of error 1]:
      - [How you fixed the error]
      - [User feedback on the error if any]
    - [...]

5. Problem Solving:
   [Description of solved problems and ongoing troubleshooting]

6. All user messages:
    - [Detailed non tool use user message]
    - [...]

7. Pending Tasks:
   - [Task 1]
   - [Task 2]
   - [...]

8. Current Work:
   [Precise description of current work]

9. Optional Next Step:
   [Optional Next step to take]

&lt;/summary&gt;
&lt;/example&gt;

Please provide your summary based on the conversation so far, following this structure and ensuring precision and thoroughness in your response.

There may be additional summarization instructions provided in the included context. If so, remember to follow these instructions when creating the above summary. Examples of instructions include:
&lt;example&gt;
## Compact Instructions
When summarizing the conversation focus on typescript code changes and also remember the mistakes you made and how you fixed them.
&lt;/example&gt;

&lt;example&gt;
# Summary instructions
When you are using compact - please focus on test output and code changes. Include file reads verbatim.
&lt;/example&gt;

</code></pre></div></div> <p>翻译成中文如下：</p> <p>```plain text 你的任务是创建一份当前对话的详细总结，需特别关注用户的明确请求以及你之前的操作记录。 这份总结必须详尽，准确捕捉技术细节、代码模式和架构决策，以确保继续开发工作时不丢失上下文。</p> <p>在提供最终总结之前，请将你的分析过程包裹在 <code class="language-plaintext highlighter-rouge">&lt;analysis&gt;</code> 标签中，用以组织你的思考，并确保你已覆盖所有必要内容。在分析过程中：</p> <ol> <li>按时间顺序分析对话的每条消息和每个部分。对每个部分请详细识别： <ul> <li>用户的明确请求和意图</li> <li>你是如何响应用户请求的</li> <li>关键的决策、技术概念和代码模式</li> <li>包括以下内容在内的具体细节： <ul> <li>文件名</li> <li>完整代码片段</li> <li>函数签名</li> <li>文件修改情况</li> </ul> </li> <li>出现的错误以及你是如何修复的</li> <li>特别注意用户反馈，尤其是用户要求你更改做法的地方</li> </ul> </li> <li>仔细检查技术准确性和完整性，确保每个要素都得到详尽处理。</li> </ol> <p>你的总结应包含以下部分：</p> <h2 id="1-primary-request-and-intent主要请求与意图">1. Primary Request and Intent（主要请求与意图）</h2> <p>详细记录用户所有明确的请求与意图。</p> <h2 id="2-key-technical-concepts关键技术概念">2. Key Technical Concepts（关键技术概念）</h2> <p>列出所有讨论过的重要技术概念、技术框架等。</p> <h2 id="3-files-and-code-sections涉及的文件与代码部分">3. Files and Code Sections（涉及的文件与代码部分）</h2> <p>列出查看、修改或创建的具体文件与代码片段。特别注意最新的消息，提供完整代码片段并说明其重要性。</p> <h2 id="4-errors-and-fixes错误与修复">4. Errors and fixes（错误与修复）</h2> <p>列出出现的所有错误及其修复方式，尤其是用户给出的反馈和修正指示。</p> <h2 id="5-problem-solving问题解决">5. Problem Solving（问题解决）</h2> <p>说明已解决的问题和仍在进行的问题排查工作。</p> <h2 id="6-all-user-messages所有用户消息">6. All user messages（所有用户消息）</h2> <p>列出所有用户的非工具使用消息。这对于理解用户反馈和意图变化至关重要。</p> <h2 id="7-pending-tasks待办任务">7. Pending Tasks（待办任务）</h2> <p>列出用户明确要求你继续完成的任务。</p> <h2 id="8-current-work当前工作">8. Current Work（当前工作）</h2> <p>详细说明在本次总结请求前你正在处理的具体任务，尤其要关注 assistant 和 user 最近的互动内容，并附带文件名和代码片段（若有）。</p> <h2 id="9-optional-next-step可选的下一步">9. Optional Next Step（可选的下一步）</h2> <p>列出与你最近正在进行的工作直接相关的下一步行动。<strong>必须</strong>确保此步骤完全符合用户的明确请求，并引用最近对话中的原话作为依据。若上一任务已结束，仅在用户有明确指示时列出下一步。</p> <hr/> <h2 id="示例结构example-structure">示例结构（Example Structure）</h2> <p>以下是你的输出应遵循的结构示例：</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
&lt;example&gt;
&lt;analysis&gt;
[你的思考过程，确保所有要点都被充分且准确地覆盖]
&lt;/analysis&gt;

&lt;summary&gt;
1. Primary Request and Intent:
   [详细描述]

2. Key Technical Concepts:

   - [概念1]
   - [概念2]
   - [...]

3. Files and Code Sections:

   - [文件名1]
     - [为何该文件重要的说明]
     - [对该文件所做的修改总结（如有）]
     - [重要的代码片段]
   - [文件名2]
     - [重要的代码片段]
   - [...]

4. Errors and fixes:

   - [错误1的详细描述]：
     - [你是如何修复该错误的]
     - [用户对该错误的反馈（如有）]
   - [...]

5. Problem Solving:
   [已解决的问题及任何仍在排查的问题]

6. All user messages:

   - [用户的非工具请求消息]
   - [...]

7. Pending Tasks:

   - [任务1]
   - [任务2]
   - [...]

8. Current Work:
   [当前正在处理的任务具体说明]

9. Optional Next Step:
   [下一步行动（如适用）]

&lt;/summary&gt;
&lt;/example&gt;
</code></pre></div></div> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>可以看到，这里应用了提示词技术，来指示大模型通过什么样的方式来进行上下文压缩，这一段非常值得学习，说是压缩，其实结合了9个不同方向的摘要，这样确保重要信息都压缩保留，如果没有明确指示这9点的话，可能会导致压缩的时候其中一些重要的信息被过滤掉，导致后续执行的效果下降。

## 2.2.3 上下文持久化（Context Persistence）
**上下文持久化（Context Persistence）**指的是将模型历史的上下文内容，尤其是重要的用户信息、对话摘要、任务状态等进行**长期存储**，以便后续访问和复用。这类机制在类人交互系统、Agent 系统中非常关键，它帮助模型记住用户的偏好、上下文、历史任务等信息。

上下文持久化的典型方式包括：

存储介质：
- 文件系统（如.json, .txt）
- 数据库存储（PostgreSQL, MongoDB 等）
- 向量数据库（用于检索式记忆）
- Key-Value 缓存（如Redis）

应用场景：
- 会话记忆（Chat Memory）：例如对话中用户提到“我下周要去东京”，可以在后续对话中继续引用；
- Agent任务状态保存：例如 Agent 正在处理一个流程任务，下次接入可从断点恢复；
- 用户偏好记录：如用户喜欢markdown格式、喜欢精炼回答等。

持久化策略：
- 自动摘要持久化（如每天一次自动保存摘要）
- 用户关键输入保存（如计划、目标等）
- 分阶段持久化（如每完成一个任务后存储）
# 小结
第一部分到这里就结束了，这一部分更多还是一些概念上和理论上的内容，算是从全局的角度来了解上下文工程的前世今生，接下去我们即将进入到第二部分，这部分会主要集中在几个比较重要的上下文工程技术，这也是目前在AI应用层中会涉及的主要技术。

在第二部分最后一个章节我们也会深入AI Agent，虽然这个狭义上来说不好算作上下文工程的一个技术，但是其实从广义的角度来看，可以算。Agent这个概念并不新，我们最常用的浏览器本身就是一个Agent，或者叫User Agent，也就是用户代理，因此AI Agent其实也就是一个应用，代理了我们与AI（大模型）交互，在此过程中这个Agent自然就会将上下文工程涉及的技术都应用进来，去构建合适的上下文，以达到最好的效果，这样这个Agent就可以在大模型的帮助之下完成我们的任务。因此AI Agent是现在最热门的AI应用方向。

现在，让我们一起进入第二部分：核心技术篇
</code></pre></div></div>]]></content><author><name></name></author><category term="AI"/><category term="AI"/><category term="Book"/><category term="CE101"/><summary type="html"><![CDATA[2.1 上下文窗口限制与问题分类]]></summary></entry><entry><title type="html">LeoTalk · Hacker News Daily · 2025.09.02</title><link href="https://ifuryst.github.io/blog/2025/leotalk-hacker-news-daily-september-2-2025/" rel="alternate" type="text/html" title="LeoTalk · Hacker News Daily · 2025.09.02"/><published>2025-09-02T00:00:00+00:00</published><updated>2025-09-02T00:00:00+00:00</updated><id>https://ifuryst.github.io/blog/2025/leotalk-hacker-news-daily-september-2-2025</id><content type="html" xml:base="https://ifuryst.github.io/blog/2025/leotalk-hacker-news-daily-september-2-2025/"><![CDATA[<h2 id="-今日重点top-picks">🔥 今日重点（Top Picks）</h2> <ul> <li><strong>Google AI Overview制造不实信息</strong>：一位用户分享了Google AI Overview如何为其编造了一个详细的虚假故事。(<a href="https://bsky.app/profile/bennjordan.bsky.social/post/3lxojrbessk2z">bsky.app</a>)</li> <li><strong>如何“杀死”Google AI Overview</strong>：用户发现通过在搜索中加入特定词汇，可以有效地绕过或禁用Google AI Overview。(<a href="https://news.ycombinator.com/item?id=45090872">Hacker News</a>)</li> </ul> <h2 id="-ai--开发工具">📦 AI &amp; 开发工具</h2> <ul> <li><strong>Bear博客平台转为源代码可用</strong>：Herman旗下的Bear博客平台现已开放源代码。(<a href="https://herman.bearblog.dev/license/">herman.bearblog.dev</a>)</li> <li><strong>CocoaPods Specs仓库将转为只读</strong>：CocoaPods发布其Specs仓库即将实施只读计划的公告。(<a href="https://blog.cocoapods.org/CocoaPods-Specs-Repo/">blog.cocoapods.org</a>)</li> <li><strong>预算受限下的自适应LLM路由</strong>：一篇研究论文探讨了在成本限制下如何优化大型语言模型请求的路由策略。(<a href="https://arxiv.org/abs/2508.21141">arXiv</a>)</li> <li><strong>Linux内核32位支持的未来</strong>：深入探讨Linux内核对32位架构支持的现状与未来发展方向。(<a href="https://lwn.net/SubscriberLink/1035727/4837b0d3dccf1cbb/">lwn.net</a>)</li> </ul> <h2 id="-思维激荡mind-food">🧠 思维激荡（Mind Food）</h2> <ul> <li><strong>Patrick Winston: 如何演讲 (2018)</strong>：麻省理工学院著名教授Patrick Winston关于有效演讲的经典课程视频。(<a href="https://www.youtube.com/watch?v=Unzc731iCUY">YouTube</a>)</li> <li><strong>高效学习：知识组织规则 (1999)</strong>：SuperMemo创始人提出的20条有效构建和记忆知识的规则。(<a href="https://www.supermemo.com/en/blog/twenty-rules-of-formulating-knowledge">supermemo.com</a>)</li> <li><strong>国际象棋中的“复杂性”</strong>：Lichess博客文章探讨了国际象棋中“复杂性”这一概念的深层含义。(<a href="https://lichess.org/@/Toadofsky/blog/what-is-complexity/pKo1swFh">lichess.org</a>)</li> <li><strong>关于亚马逊式领导力的思考</strong>：一篇博客文章分享了对亚马逊独特领导力文化的反思和见解。(<a href="https://www.daemonology.net/blog/2025-09-01-Thoughts-on-Amazonian-Leadership.html">daemonology.net</a>)</li> </ul> <h2 id="-科技与社会趋势">🌐 科技与社会趋势</h2> <ul> <li><strong>Cloudflare Radar: AI洞察报告</strong>：Cloudflare发布了关于AI流量和使用趋势的最新分析报告。(<a href="https://radar.cloudflare.com/ai-insights">radar.cloudflare.com</a>)</li> <li><strong>学者团体指控以色列在加沙犯下种族灭绝</strong>：多位学者联合声明，指出以色列在加沙地带的行为构成种族灭绝。(<a href="https://www.aljazeera.com/news/2025/9/1/israel-committing-genocide-in-gaza-scholars-group-says">Al Jazeera</a>)</li> <li><strong>亚马逊未积极参与AI人才战</strong>：内部文件显示，亚马逊在当前激烈的AI人才争夺中表现相对平淡。(<a href="https://www.businessinsider.com/amazon-ai-talent-wars-internal-document-2025-8">Business Insider</a>)</li> <li><strong>2025年第二季度搜索引擎推荐报告</strong>：Cloudflare发布了最新的搜索引擎市场份额及推荐流量报告。(<a href="https://radar.cloudflare.com/reports/search-engine-market-share-2025-q2">radar.cloudflare.com</a>)</li> <li><strong>英国最大电池储能设施并网</strong>：英国国家电网在蒂尔伯里变电站成功连接了该国最大的电池储能设施。(<a href="https://www.nationalgrid.com/national-grid-connects-uks-largest-battery-storage-facility-tilbury-substation">nationalgrid.com</a>)</li> <li><strong>前CDC领导者：Kennedy危害美国健康</strong>：前疾病控制与预防中心（CDC）领导者撰文，警告Kennedy的政策对美国公共卫生构成威胁。(<a href="https://www.nytimes.com/2025/09/01/opinion/cdc-leaders-kennedy.html">NYT</a>)</li> </ul> <h2 id="-快速浏览">🎯 快速浏览</h2> <ul> <li><strong>iPhone闹钟时间选择器之谜</strong>：揭示iPhone闹钟的时间选择器并非圆形界面，而是一个巧妙隐藏的长列表。(<a href="https://old.reddit.com/r/interestingasfuck/comments/1n5lztw/the_time_picker_on_the_iphones_alarm_app_isnt/">Reddit</a>)</li> <li><strong>Ask HN: 谁在招聘？(2025年9月)</strong>：Hacker News每月一次的招聘帖子，为求职者和招聘公司提供交流平台。(<a href="https://news.ycombinator.com/item?id=45093192">Hacker News</a>)</li> </ul> <h2 id="-dev-tricks">🧰 Dev Tricks</h2> <ul> <li><strong>实现箔面贴纸效果</strong>：一篇关于如何在网页上实现逼真箔面贴纸视觉效果的教程。(<a href="https://www.4rknova.com/blog/2025/08/30/foil-sticker">4rknova.com</a>)</li> <li><strong>解耦TOTP验证码与Google生态</strong>：一篇指南探讨如何将一次性密码（TOTP）验证码从Google服务中独立出来。(<a href="https://imrannazar.com/articles/degoogle-otp">imrannazar.com</a>)</li> </ul>]]></content><author><name></name></author><category term="HNDailyReport"/><category term="HNDailyReport"/><summary type="html"><![CDATA[🔥 今日重点（Top Picks）]]></summary></entry><entry><title type="html">LeoTalk · Hacker News Daily · 2025.09.01</title><link href="https://ifuryst.github.io/blog/2025/leotalk-hacker-news-daily-september-1-2025/" rel="alternate" type="text/html" title="LeoTalk · Hacker News Daily · 2025.09.01"/><published>2025-09-01T00:00:00+00:00</published><updated>2025-09-01T00:00:00+00:00</updated><id>https://ifuryst.github.io/blog/2025/leotalk-hacker-news-daily-september-1-2025</id><content type="html" xml:base="https://ifuryst.github.io/blog/2025/leotalk-hacker-news-daily-september-1-2025/"><![CDATA[<h2 id="-今日重点top-picks">🔥 今日重点（Top Picks）</h2> <ul> <li><strong>谷歌手机应用安装权限争议</strong>：视频指出谷歌手机对应用安装的控制权日益增强，引发用户对其设备自由度的担忧。👉 <a href="https://www.youtube.com/watch?v=QBEKlIV_70E">YouTube</a></li> <li><strong>AI搜索对内容生态的冲击</strong>：文章探讨了AI搜索导致内容生产者点击量下降，预示着一个不可持续的互联网未来。👉 <a href="https://bradt.ca/blog/no-clicks-no-content/">bradt.ca</a></li> <li><strong>微软员工过劳死引反思</strong>：一名微软员工过劳死后，其家人呼吁科技公司关注员工健康，停止过度加班文化。👉 <a href="https://padailypost.com/2025/08/29/family-of-microsoft-employee-who-died-warn-tech-companies-not-to-overwork-workers/">padailypost.com</a></li> </ul> <h2 id="-ai--开发工具">📦 AI &amp; 开发工具</h2> <ul> <li><strong>[Jujutsu] 新一代版本控制工具</strong>：一个旨在替代Git的现代版本控制系统，提供更直观的操作。👉 <a href="https://jj-for-everyone.github.io/">jj-for-everyone.github.io</a></li> <li><strong>[Red] 受REBOL启发的编程语言</strong>：Red语言致力于成为一种全栈开发的现代编程语言。👉 <a href="https://github.com/red/red">GitHub</a></li> <li><strong>[Vlang] 初体验</strong>：作者分享了自己尝试Vlang编程语言的经历和初步体验。👉 <a href="https://kristun.dev/posts/my-foray-into-vlang/">kristun.dev</a></li> </ul> <h2 id="-思维激荡mind-food">🧠 思维激荡（Mind Food）</h2> <ul> <li><strong>电报“必须转述”的历史考量</strong>：一篇关于电报信息在沟通中为何需要被仔细转述的历史讨论。👉 <a href="https://history.stackexchange.com/questions/79371/this-telegram-must-be-closely-paraphrased-before-being-communicated-to-anyone">history.stackexchange.com</a></li> <li><strong>ADHD管理笔记</strong>：一篇关于管理ADHD的个人经验和实用策略分享。👉 <a href="https://borretti.me/article/notes-on-managing-adhd">borretti.me</a></li> <li><strong>永恒的斗争</strong>：探讨编程和学习的本质，以及如何持续适应和发展。👉 <a href="https://yoavg.github.io/eternal/">yoavg.github.io</a></li> <li><strong>量子计算机为何未分解21？</strong>：解释了为什么量子计算机未能分解数字21，澄清了关于量子计算能力的常见误解。👉 <a href="https://algassert.com/post/2500">algassert.com</a></li> <li><strong>大英帝国的“落日”</strong>：一篇探讨大英帝国残余影响力的文章，推测其“日不落”时代的终结。👉 <a href="https://oikofuge.com/sun-sets-on-british-empire/">oikofuge.com</a></li> <li><strong>对抗YouTube成瘾和拖延</strong>：Hacker News 上关于如何对抗YouTube成瘾和拖延症的讨论串。👉 <a href="https://news.ycombinator.com/item?id=45085014">news.ycombinator.com</a></li> <li><strong>代码即债务</strong>：一篇探讨“代码即债务”的理念，强调软件开发中技术债务管理的重要性。👉 <a href="https://tornikeo.com/code-is-debt/">tornikeo.com</a></li> <li><strong>数学精通的“层化”快车道</strong>：一种名为“层化”（Sheafification）的数学学习方法，旨在提供掌握数学的“快车道”。👉 <a href="https://sheafification.com/the-fast-track/">sheafification.com</a></li> </ul> <h2 id="-科技与社会趋势">🌐 科技与社会趋势</h2> <ul> <li><strong>FDA官员要求撤回批评疫苗视频</strong>：FDA官员要求撤下自己在YouTube上批评疫苗的视频，引发了言论自由和信息透明的争议。👉 <a href="https://www.theguardian.com/us-news/2025/aug/31/fda-official-youtube-videos">theguardian.com</a></li> <li><strong>音乐版权问题引关注</strong>：支持音乐人Rick Beato对音乐版权罢工的抗议，强调数字时代版权系统存在的问题。👉 <a href="https://savingcountrymusic.com/rick-beato-is-right-to-rant-about-music-copyright-strikes/">savingcountrymusic.com</a></li> <li><strong>职场AI工具使用调查</strong>：探讨职场中老板强制员工使用AI工具的现象，及其对工作方式的影响。👉 <a href="https://piccalil.li/blog/are-peoples-bosses-really-making-them-use-ai/">piccalil.li</a></li> <li><strong>ETF持仓头部美企市值超$3.1T</strong>：统计显示，ETF持有美国头部公司股票的总市值已超过3.1万亿美元，揭示了市场集中化趋势。👉 <a href="https://www.signalbloom.ai/etf/stats">signalbloom.ai</a></li> </ul> <h2 id="-新奇项目--show-hn">📱 新奇项目 / Show HN</h2> <ul> <li><strong>手机变身极简电子阅读器</strong>：作者分享将手机改造为极简电子阅读器，减少数字干扰的实践。👉 <a href="https://www.davepagurek.com/blog/minimal-phone/">davepagurek.com</a></li> <li><strong>我没有Spotify</strong>：一个网页项目，旨在反思个人与Spotify等大型音乐平台的依赖关系。👉 <a href="https://idonthavespotify.sjdonado.com/">idonthavespotify.sjdonado.com</a></li> </ul> <h2 id="-dev-tricks">🧰 Dev Tricks</h2> <ul> <li><strong>Git图解“The Weave”</strong>：一种可视化Git历史的新方法“The Weave”，帮助开发者更好地理解版本控制。👉 <a href="https://daverupert.com/2025/08/git-diagramming-the-weave/">daverupert.com</a></li> <li><strong>“一台大服务器”的架构哲学</strong>：一篇关于“使用一台大服务器”的架构哲学，挑战微服务等分布式系统范式。👉 <a href="https://specbranch.com/posts/one-big-server/">specbranch.com</a></li> </ul> <h2 id="-快速浏览">🎯 快速浏览</h2> <ul> <li><strong>F-Droid网站证书过期</strong>：F-Droid网站的SSL证书过期，导致用户访问受影响的技术问题。👉 <a href="https://gitlab.com/fdroid/fdroid-website/-/issues/883">gitlab.com</a></li> </ul>]]></content><author><name></name></author><category term="HNDailyReport"/><category term="HNDailyReport"/><summary type="html"><![CDATA[🔥 今日重点（Top Picks）]]></summary></entry><entry><title type="html">Gap了一个周末</title><link href="https://ifuryst.github.io/blog/2025/gap-a-weekend-start-anew/" rel="alternate" type="text/html" title="Gap了一个周末"/><published>2025-08-31T00:00:00+00:00</published><updated>2025-08-31T00:00:00+00:00</updated><id>https://ifuryst.github.io/blog/2025/gap-a-weekend-start-anew</id><content type="html" xml:base="https://ifuryst.github.io/blog/2025/gap-a-weekend-start-anew/"><![CDATA[<h1 id="workaholic的无缝衔接">Workaholic的无缝衔接</h1> <p>我Gap了一个周末，明天要开始新的征程了。经历了接近3周的离职交接，总算把东西都交接完了，也顺利的在8月的最后一个工作日结束了离职流程，并顺利拿到了离职证明。提交了必要的材料后，原定于9月第一个工作日的入职也正式确认了。</p> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-08-31-gap-a-weekend-start-anew/1756652770_1-480.webp 480w,/assets/img/2025-08-31-gap-a-weekend-start-anew/1756652770_1-800.webp 800w,/assets/img/2025-08-31-gap-a-weekend-start-anew/1756652770_1-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/2025-08-31-gap-a-weekend-start-anew/1756652770_1.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> </div> </div> <p>我Gap了一个周末，属实无缝衔接了，周五下班后我就直接开车到机场，把开了7年接近10w公里的车交给了父亲，从此我应该嫌有机会开它了，这老兄弟从我毕业后一直陪我走南闯北，承受了我的年轻与冲动。今天之后虽然回乡了，但是却能继续载着我家那人生事业第二春的老头子一起，在接下去的岁月里一起再冲一冲，对于它和他未尝不是一件快事。</p> <p>在机场等待之时，低头看了一下鹅厂公仔，也是有趣，我将工作交接给了一位新来的小朋友，顺便交了几招王八拳给他，离别之际，送了我一只他曾经在鹅厂实习的公仔，我高兴的收下了。当我写下这篇随笔的时候，这只企鹅就在我旁边，和我一起成为了沪漂，或许也是这魔幻人生的一个缩影。</p> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-08-31-gap-a-weekend-start-anew/1756652770_2-480.webp 480w,/assets/img/2025-08-31-gap-a-weekend-start-anew/1756652770_2-800.webp 800w,/assets/img/2025-08-31-gap-a-weekend-start-anew/1756652770_2-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/2025-08-31-gap-a-weekend-start-anew/1756652770_2.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> </div> </div> <p>虽然我自诩风光摄影师，但是我还蛮少拍这种照片。但这次我在廊桥登机之时，拍了一张厦门机场的照片，这个城市是我的第二故乡，承载了太多记忆，这也是我心中的浪浪山，我其实心里一直知道，有一天我会走出这里，没想到这一天就这么在眼前了。也不知道下次回来是什么时候，那时的我会是怎样的呢？</p> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-08-31-gap-a-weekend-start-anew/1756652772_3-480.webp 480w,/assets/img/2025-08-31-gap-a-weekend-start-anew/1756652772_3-800.webp 800w,/assets/img/2025-08-31-gap-a-weekend-start-anew/1756652772_3-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/2025-08-31-gap-a-weekend-start-anew/1756652772_3.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> </div> </div> <p>登上了飞往上海的航班，去往更大的舞台，迎接未知的未来。我的心绪倒是没有太大的起伏。</p> <h1 id="老友记">老友记</h1> <p>可能是一线城市也可能是因为是情人节的缘故，哪怕是夜间到的航班，依然人山人海。我们一路摸索到停车场，顺利搭上老友的车，夜间的上海，车在马路间穿梭的速度和厦门类似，可以有速度与激情的感觉。</p> <p>我们2对4人，一起吃了一顿深夜火锅，喝了点小酒，唠嗑了一下。我想这也许就是人类为什么需要社交，为什么人需要朋友的原因吧。过去30年来，能成为朋友的着实不多，并且每个阶段比较要好的朋友又都不太一样，是一个动态平衡的东西，珍惜能聊得来的人，这快速浮躁的世界，除了家人、爱人以外，就属朋友是值得珍惜的。</p> <p>我也毫不客气的霸占了他们那间空房间，我觉得适当的不客气，是对于朋友最大的认可，过于客气=见外。</p> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-08-31-gap-a-weekend-start-anew/1756652773_4-480.webp 480w,/assets/img/2025-08-31-gap-a-weekend-start-anew/1756652773_4-800.webp 800w,/assets/img/2025-08-31-gap-a-weekend-start-anew/1756652773_4-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/2025-08-31-gap-a-weekend-start-anew/1756652773_4.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> </div> </div> <p>第二天陪了我们一天，从看房子到逛宜家，再到最后去浦东看了黄昏景色。</p> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-08-31-gap-a-weekend-start-anew/1756652774_5-480.webp 480w,/assets/img/2025-08-31-gap-a-weekend-start-anew/1756652774_5-800.webp 800w,/assets/img/2025-08-31-gap-a-weekend-start-anew/1756652774_5-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/2025-08-31-gap-a-weekend-start-anew/1756652774_5.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> </div> </div> <p>这也是我第一次到陆家嘴这一侧，从下面看到这么大的东方明珠。</p> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-08-31-gap-a-weekend-start-anew/1756652775_6-480.webp 480w,/assets/img/2025-08-31-gap-a-weekend-start-anew/1756652775_6-800.webp 800w,/assets/img/2025-08-31-gap-a-weekend-start-anew/1756652775_6-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/2025-08-31-gap-a-weekend-start-anew/1756652775_6.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> </div> </div> <p>相信很多人都是因为小红书上的笔记来到了这个地方，确实可以很轻松的拍出好看的剪影照，只不过遗憾的还是人太多，这也是我不喜欢在国内旅游的一个很重要的原因。</p> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-08-31-gap-a-weekend-start-anew/1756652776_7-480.webp 480w,/assets/img/2025-08-31-gap-a-weekend-start-anew/1756652776_7-800.webp 800w,/assets/img/2025-08-31-gap-a-weekend-start-anew/1756652776_7-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/2025-08-31-gap-a-weekend-start-anew/1756652776_7.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> </div> </div> <p>黄浦江畔的风景，一度让我有了纽约的感觉，只不过纽约的建筑群更加密集。大城市的风光有趋同性，但是在里面生活后细细品味却又体会到各自的不同，相信未来一段时间内，探索这座城市会成为我们的一个主旋律</p> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-08-31-gap-a-weekend-start-anew/1756652777_8-480.webp 480w,/assets/img/2025-08-31-gap-a-weekend-start-anew/1756652777_8-800.webp 800w,/assets/img/2025-08-31-gap-a-weekend-start-anew/1756652777_8-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/2025-08-31-gap-a-weekend-start-anew/1756652777_8.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> </div> </div> <h1 id="cbd">CBD</h1> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-08-31-gap-a-weekend-start-anew/1756652778_9-480.webp 480w,/assets/img/2025-08-31-gap-a-weekend-start-anew/1756652778_9-800.webp 800w,/assets/img/2025-08-31-gap-a-weekend-start-anew/1756652778_9-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/2025-08-31-gap-a-weekend-start-anew/1756652778_9.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> </div> </div> <p>捣鼓完房子后，今天我们俩自己去溜达了，溜达到了字节的大楼，四栋楼在一起，下面挺多吃的。整体环境很清爽整洁，下面也有几家店，最让我开心的是下面有一家中信书店，进去逛了一下书很多，我感兴趣的书很多。</p> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-08-31-gap-a-weekend-start-anew/1756652780_10-480.webp 480w,/assets/img/2025-08-31-gap-a-weekend-start-anew/1756652780_10-800.webp 800w,/assets/img/2025-08-31-gap-a-weekend-start-anew/1756652780_10-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/2025-08-31-gap-a-weekend-start-anew/1756652780_10.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> </div> </div> <p>晚上又回到这里，在书店买了一本凯文·凯利的《5000天后的世界》，花了一个多小时看完了，写得挺好的，之前刚出来的时候就看到了，当时还想着买一本英文的回来看，这次看到就随手买了。</p> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-08-31-gap-a-weekend-start-anew/1756652781_11-480.webp 480w,/assets/img/2025-08-31-gap-a-weekend-start-anew/1756652781_11-800.webp 800w,/assets/img/2025-08-31-gap-a-weekend-start-anew/1756652781_11-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/2025-08-31-gap-a-weekend-start-anew/1756652781_11.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> </div> </div> <p>现在发现自己的阅读速度提升了不是一点半点，高强度的阅读积累，是会提升阅读和摄入速度的，之前看比尔盖茨的那个纪录片走进比尔，就非常震惊他的阅读速度，已经不是一目十行这种级别了。现在我相信那种是可以达到的。</p> <p>在书店还随手买了浪浪山的盲盒，真是应景，呼应了之前<a href="https://ifuryst.substack.com/p/2a2">走出浪浪山那篇文章</a>了。</p> <h1 id="适当的孤独感">适当的孤独感</h1> <p>以前我还自己一个人的时候，我还挺喜欢独处，喜欢自我思考，不断和自我对话，虽然听起来像个怪咖。不过那样的我可以不断去深化一些想法，我觉得也是这个习惯让我的想法能不断强化，进一步支撑我的思想输出和行动。</p> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-08-31-gap-a-weekend-start-anew/1756652783_12-480.webp 480w,/assets/img/2025-08-31-gap-a-weekend-start-anew/1756652783_12-800.webp 800w,/assets/img/2025-08-31-gap-a-weekend-start-anew/1756652783_12-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/2025-08-31-gap-a-weekend-start-anew/1756652783_12.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> </div> </div> <p>看完书吃了一份轻食，还挺好吃的，边听着播客边吃东西，整个店里就只有我一桌在吃，喜欢这种安静的时刻。我也顺手把微信做了一波清理，这几个月来我加了几百个人，我开始学会标签化的管理，我把一些人生过课做了一波清扫，同时把每个人都打了至少一个标签。因为随着好友不断增多，我觉得非常有必要区分管理一下信息，减少不必要的干扰，这算是重新开始。</p> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-08-31-gap-a-weekend-start-anew/1756652785_13-480.webp 480w,/assets/img/2025-08-31-gap-a-weekend-start-anew/1756652785_13-800.webp 800w,/assets/img/2025-08-31-gap-a-weekend-start-anew/1756652785_13-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/2025-08-31-gap-a-weekend-start-anew/1756652785_13.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> </div> </div> <p>从朴朴变成了盒马生鲜，过渡得还挺丝滑的。自己开了一罐苏打水，打开了整整两天没有打开的电脑，开始写下这篇随笔。本来其实不想写的，但是仔细思考了一下，我想要未来的自己可以知道现在的自己的一些想法和经历，有些东西不写下来，很容易就消逝在记忆的长河里了，毕竟我们没法做到大模型那么大的参数量，人脑的容量有限，增幅极其有限的压缩率下，我们只能保留常量级别的记忆，我们也需要外部的记忆系统和RAG来帮我们增强。</p> <p>想用一句我年初从美国旅行回来写的一篇文章里的一句话结尾</p> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-08-31-gap-a-weekend-start-anew/1756652786_14-480.webp 480w,/assets/img/2025-08-31-gap-a-weekend-start-anew/1756652786_14-800.webp 800w,/assets/img/2025-08-31-gap-a-weekend-start-anew/1756652786_14-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/2025-08-31-gap-a-weekend-start-anew/1756652786_14.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> </div> </div> <p>新的学期开始了，Let’s Rock!🪨</p>]]></content><author><name></name></author><category term="PersonalUpdate"/><category term="PersonalUpdate"/><summary type="html"><![CDATA[Workaholic的无缝衔接]]></summary></entry><entry><title type="html">LeoTalk · Hacker News Daily · 2025.08.31</title><link href="https://ifuryst.github.io/blog/2025/leotalk-hacker-news-daily-august-31-2025/" rel="alternate" type="text/html" title="LeoTalk · Hacker News Daily · 2025.08.31"/><published>2025-08-31T00:00:00+00:00</published><updated>2025-08-31T00:00:00+00:00</updated><id>https://ifuryst.github.io/blog/2025/leotalk-hacker-news-daily-august-31-2025</id><content type="html" xml:base="https://ifuryst.github.io/blog/2025/leotalk-hacker-news-daily-august-31-2025/"><![CDATA[<h2 id="-今日重点top-picks">🔥 今日重点（Top Picks）</h2> <ul> <li><strong>FBI网络警官称中国黑客入侵几乎所有美国公民数据</strong>：中国黑客组织”Salt Typhoon”被指控渗透了几乎所有美国公民的数据，引发重大网络安全担忧。<a href="https://www.theregister.com/2025/08/28/fbi_cyber_cop_salt_typhoon/">The Register</a></li> <li><strong>五角大楼计划利用AI宣传压制异议</strong>：泄露文件揭示美军意图利用AI进行信息战，以压制不同政见。<a href="https://theintercept.com/2025/08/25/pentagon-military-ai-propaganda-influence/">The Intercept</a></li> <li><strong>Meta和Yandex被曝通过Android本地主机进行隐蔽追踪</strong>：研究披露Meta和Yandex利用系统漏洞，通过本地主机秘密进行网页到应用的用户追踪。<a href="https://localmess.github.io/?new=">localmess.github.io</a></li> <li><strong>Google DeepMind推出AI内容水印与识别工具SynthID</strong>：SynthID旨在帮助用户识别和验证由AI生成的内容，以对抗虚假信息。<a href="https://deepmind.google/science/synthid/">Google DeepMind</a></li> <li><strong>美国取消小额包裹进口免税政策</strong>：美国“最低限度免税”政策的结束，可能导致国际订单取消和物流延误，影响跨境电商和消费者。<a href="https://www.washingtonpost.com/business/2025/08/30/de-minimis-tax-canceled-orders-delays/">Washington Post</a></li> </ul> <h2 id="-ai--开发工具">📦 AI &amp; 开发工具</h2> <ul> <li><strong>Agent Client Protocol (ACP)</strong>：一个为AI Agent提供客户端与服务端通用接口的新协议。<a href="https://agentclientprotocol.com/overview/introduction">agentclientprotocol.com</a></li> <li><strong>AI模型需要虚拟执行环境</strong>：一篇观点文章论证AI模型应在独立的虚拟机中运行以提高安全性和可控性。<a href="https://blog.sigplan.org/2025/08/29/ai-models-need-a-virtual-machine/">blog.sigplan.org</a></li> <li><strong>注意力机制的演变：从多头到潜在注意力</strong>：深入解析AI中注意力机制从多头到潜在形式的进化过程。<a href="https://vinithavn.medium.com/from-multi-head-to-latent-attention-the-evolution-of-attention-mechanisms-64e3c0505f24">vinithavn.medium.com</a></li> <li><strong>Condor在Hot Chips 2025展示Cuzco RISC-V核心</strong>：Condor公司发布了其高性能Cuzco RISC-V处理器核心的最新进展。<a href="https://chipsandcheese.com/p/condors-cuzco-risc-v-core-at-hot">chipsandcheese.com</a></li> <li><strong>Bcachefs文件系统变为“外部维护”状态</strong>：Bcachefs文件系统因主要维护者离职，项目进入“外部维护”状态。<a href="https://lwn.net/Articles/1035736/">LWN.net</a></li> </ul> <h2 id="-思维激荡mind-food">🧠 思维激荡（Mind Food）</h2> <ul> <li><strong>认知负荷的重要性</strong>：一篇探讨认知负荷在设计、学习和工作流程中关键作用的文档。<a href="https://github.com/zakirullin/cognitive-load">GitHub</a></li> <li><strong>罗马尼亚在国际奥林匹克竞赛中表现卓越的原因</strong>：探究罗马尼亚教育体系和文化如何使其在国际竞赛中屡获佳绩。<a href="https://www.palladiummag.com/2025/08/29/why-romania-excels-in-international-olympiads/">Palladium Magazine</a></li> <li><strong>你必须去感受它</strong>：一篇关于在工作中培养直觉和感受力的个人反思。<a href="https://mitchellh.com/writing/feel-it">mitchellh.com</a></li> <li><strong>博客不需要“分析”</strong>：主张博客运营不应过度依赖数据分析工具，以保持内容创作的纯粹性。<a href="https://www.thisdaysportion.com/posts/contra-analytics/">thisdaysportion.com</a></li> <li><strong>求职450次后成功上岸的建议</strong>：一位求职者在经历了大量申请后，分享了他宝贵的求职经验和心得。<a href="https://news.ycombinator.com/item?id=45073589">Hacker News</a></li> </ul> <h2 id="-科技与社会趋势">🌐 科技与社会趋势</h2> <ul> <li><strong>关税实施半年后，企业难以定价</strong>：新关税政策实施六个月后，企业因不确定性而难以有效定价。<a href="https://www.wsj.com/business/retail/trump-tariff-business-price-impact-37b630c8">Wall Street Journal</a></li> </ul> <h2 id="-新奇项目--show-hn">📱 新奇项目 / Show HN</h2> <ul> <li><strong>Hacker News用户破折号使用排行榜（ChatGPT前）</strong>：一个统计Hacker News用户在ChatGPT普及前使用em dash数量的有趣项目。<a href="https://www.gally.net/miscellaneous/hn-em-dash-user-leaderboard.html">gally.net</a></li> <li><strong>我们去中心化了吗？</strong>：一个实时追踪互联网、AI和Web3等系统去中心化程度的仪表盘网站。<a href="https://arewedecentralizedyet.online/">arewedecentralizedyet.online</a></li> </ul> <h2 id="-科学与健康">🔬 科学与健康</h2> <ul> <li><strong>“性衰退”：美国人规律性行为的比例持续下降</strong>：研究显示，美国人规律性行为的比例正在持续下降，引发社会趋势和健康讨论。<a href="https://ifstudies.org/blog/the-sex-recession-the-share-of-americans-having-regular-sex-keeps-dropping">ifstudies.org</a></li> </ul> <h2 id="-快速浏览">🎯 快速浏览</h2> <ul> <li><strong>诺基亚的传奇字体被发现非常适合作为通用用户界面字体</strong>。<a href="https://www.osnews.com/story/143222/it-turns-out-nokias-legendary-font-makes-for-a-great-general-user-interface-font/">OSNews</a></li> </ul> <h2 id="-dev-tricks">🧰 Dev Tricks</h2> <ul> <li><strong>Firefox浏览器隐私强化清单</strong>：一份详细的指南，提供了增强Firefox浏览器隐私设置的实用建议。<a href="https://andrewmarder.net/firefox/">andrewmarder.net</a></li> <li><strong>混合PHP的兴起：融合Go和Rust</strong>：探讨将PHP与Go和Rust等语言结合，构建高性能、高效率应用的新开发模式。<a href="https://yekdeveloper.com/p/4-the-rise-of-hybrid-php">yekdeveloper.com</a></li> </ul>]]></content><author><name></name></author><category term="HNDailyReport"/><category term="HNDailyReport"/><summary type="html"><![CDATA[🔥 今日重点（Top Picks）]]></summary></entry><entry><title type="html">LeoTalk · Hacker News Daily · 2025.08.30</title><link href="https://ifuryst.github.io/blog/2025/leotalk-hacker-news-daily-august-30-2025/" rel="alternate" type="text/html" title="LeoTalk · Hacker News Daily · 2025.08.30"/><published>2025-08-30T00:00:00+00:00</published><updated>2025-08-30T00:00:00+00:00</updated><id>https://ifuryst.github.io/blog/2025/leotalk-hacker-news-daily-august-30-2025</id><content type="html" xml:base="https://ifuryst.github.io/blog/2025/leotalk-hacker-news-daily-august-30-2025/"><![CDATA[<h2 id="-今日重点top-picks">🔥 今日重点（Top Picks）</h2> <ul> <li><strong>Anthropic和Meta隐私争议</strong>：Anthropic更新条款将用用户数据训练模型；Meta被指可能扫描并保留用户手机照片，引发广泛隐私担忧。(<a href="https://www.anthropic.com/news/updates-to-our-consumer-terms">Anthropic</a>, <a href="https://old.reddit.com/r/LocalLLaMA/comments/1n2ubjx/if_you_have_a-claude-personal-account-they-are/">Reddit</a>, <a href="https://www.zdnet.com/article/meta-might-be-secretly-scanning-your-phones-camera-roll-how-to-check-and-turn-it-off/">ZDNet</a>)</li> <li><strong>特斯拉致命车祸数据疑云</strong>：特斯拉此前否认拥有关键数据，后被黑客发现，引发数据透明度和责任问题。(<a href="https://www.washingtonpost.com/technology/2025/08/29/tesla-autopilot-crashes-evidence-testimony-wrongful-death/">Washington Post</a>)</li> <li><strong>Grok Code Fast 1 发布</strong>：xAI 推出其首个代码生成模型，旨在加速开发者工作流。(<a href="https://x.ai/news/grok-code-fast-1">x.ai</a>)</li> </ul> <h2 id="-ai--开发工具">📦 AI &amp; 开发工具</h2> <ul> <li><strong>Claude Sonnet 集成 Xcode</strong>：苹果 Xcode 26 将原生支持 Claude Sonnet，提升开发体验。(<a href="https://developer.apple.com/documentation/xcode-release-notes/xcode-26-release-notes">Apple Developer</a>)</li> <li><strong>DeepSeek 大规模部署经验</strong>：关于在 96 块 H100 GPU 上部署 DeepSeek 模型的实践分享。(<a href="https://lmsys.org/blog/2025-05-05-large-scale-ep/">LMSYS Blog</a>)</li> <li><strong>Debian 13 (Trixie) 深入分析</strong>：文章介绍 Debian 13 的新特性，并探讨 /tmp 目录的变化及应对方案。(<a href="https://lwn.net/Articles/1033474/">LWN.net</a>, <a href="https://lowendbox.com/blog/a-deep-dive-into-debian-13s-tmp-whats-new-and-what-to-do-if-you-dont-like-it/">LowEndBox</a>)</li> <li><strong>2025 离线优先趋势</strong>：概述离线优先技术（Offline-First）在 2025 年的发展现状与未来方向。(<a href="https://marcoapp.io/blog/offline-first-landscape">marcoapp.io</a>)</li> </ul> <h2 id="-思维激荡mind-food">🧠 思维激荡（Mind Food）</h2> <ul> <li><strong>“做最简单可行的事”</strong>：一篇关于软件开发中“精益”原则的哲学思考。(<a href="https://www.seangoedecke.com/the-simplest-thing-that-could-possibly-work/">Sean Goedecke</a>)</li> <li><strong>AI 未能成为“真”程序员</strong>：IEEE Spectrum 探讨 AI 在编程领域尚未成熟的深层原因。(<a href="https://spectrum.ieee.org/ai-for-coding">IEEE Spectrum</a>)</li> <li><strong>编码理论基础教程</strong>：一本关于编码理论的全面教程 PDF，深入理解数据传输与存储的原理。(<a href="https://cse.buffalo.edu/faculty/atri/courses/coding-theory/book/web-coding-book.pdf">Buffalo University</a>)</li> <li><strong>再战Anthropic面试失利</strong>：一位开发者分享了自己屡次面试 Anthropic 失败后的反思，提供职业发展视角。(<a href="https://taylor.town/flunking-anthropic">taylor.town</a>)</li> </ul> <h2 id="-科技与社会趋势">🌐 科技与社会趋势</h2> <ul> <li><strong>Cloudflare 反“守门人”主张</strong>：Cloudflare 提出的“签名代理”概念引发关于互联网开放性的讨论。(<a href="https://positiveblue.substack.com/p/the-web-does-not-need-gatekeepers">Positiveblue</a>)</li> <li><strong>Synology 的“结局”</strong>：一篇博客批评 Synology 产品策略背离初衷，引发用户对其未来发展的担忧。(<a href="https://lowendbox.com/blog/they-used-to-be-good-but-now-theyve-turned-to-evil-the-synology-end-game/">LowEndBox</a>)</li> <li><strong>卡马克驳斥 Meta XR OS</strong>：John Carmack 解释了反对 Meta 自研 XR 操作系统的主要论点。(<a href="https://twitter.com/ID_AA_Carmack/status/1961172409920491849">Twitter</a>)</li> <li><strong>私募股权收购残疾人服务</strong>：私营资本涌入残疾人服务领域，对现有监管体系构成挑战。(<a href="https://www.governing.com/management-and-administration/private-equity-snaps-up-disability-services-challenging-regulators">Governing.com</a>)</li> <li><strong>Sig Sauer 国家安全特权</strong>：Sig Sauer 公司援引国家安全条款，试图阻止公开相关法律文件。(<a href="https://practicalshootinginsights.com/eighth-circuit-fmeca-update/">Practical Shooting Insights</a>)</li> </ul> <h2 id="-新奇项目--show-hn">📱 新奇项目 / Show HN</h2> <ul> <li><strong>HN 遗珠发现器</strong>：一个帮助用户在 Hacker News 上寻找被低估或错过的项目的工具。(<a href="https://pj4533.com/hn-overlooked/">pj4533.com</a>)</li> <li><strong>Sosumi.ai</strong>：将 Apple 开发者文档转换为 AI 可读 Markdown 格式的工具。(<a href="https://sosumi.ai/">Sosumi.ai</a>)</li> <li><strong>Wikipedia 图谱化探索</strong>：将 Wikipedia 知识库可视化为图谱，帮助探索知识连接。(<a href="https://wikigrapher.com/paths">Wikigrapher</a>)</li> <li><strong>Seedbox Lite</strong>：一个轻量级种子流媒体应用，支持即时播放。(<a href="https://github.com/hotheadhacker/seedbox-lite">GitHub</a>)</li> </ul> <h2 id="-快速浏览">🎯 快速浏览</h2> <ul> <li><strong>Taco Bell AI 点餐事故</strong>：AI 得来速因用户点18,000份水而引发系统重审。(<a href="https://www.bbc.com/news/articles/ckgyk2p55g8o">BBC</a>)</li> <li><strong>奇怪的 CW 电键</strong>：一个展示各种非传统莫尔斯电码电键的网站。(<a href="https://sites.google.com/site/oh6dccw/strangecwkeys">sites.google.com</a>)</li> </ul> <h2 id="-dev-tricks">🧰 Dev Tricks</h2> <ul> <li><strong>Libxslt 安全警告</strong>：Libxslt 项目已停止维护，并存在5个未修复的安全漏洞，建议开发者警惕。(<a href="https://vuxml.freebsd.org/freebsd/b0a3466f-5efc-11f0-ae84-99047d0a6bcc.html">FreeBSD</a>)</li> <li><strong>SQLite 持久性文档模糊</strong>：指出 SQLite 官方文档中关于数据持久性保证的描述存在不明确之处。(<a href="https://www.agwa.name/blog/post/sqlite_durability">agwa.name</a>)</li> </ul>]]></content><author><name></name></author><category term="HNDailyReport"/><category term="HNDailyReport"/><summary type="html"><![CDATA[🔥 今日重点（Top Picks）]]></summary></entry><entry><title type="html">LeoTalk · Hacker News Daily · 2025.08.28</title><link href="https://ifuryst.github.io/blog/2025/leotalk-hacker-news-daily-august-28-2025/" rel="alternate" type="text/html" title="LeoTalk · Hacker News Daily · 2025.08.28"/><published>2025-08-28T00:00:00+00:00</published><updated>2025-08-28T00:00:00+00:00</updated><id>https://ifuryst.github.io/blog/2025/leotalk-hacker-news-daily-august-28-2025</id><content type="html" xml:base="https://ifuryst.github.io/blog/2025/leotalk-hacker-news-daily-august-28-2025/"><![CDATA[<h2 id="-今日重点top-picks">🔥 今日重点（Top Picks）</h2> <ul> <li><strong>Nx开发工具链遭恶意软件攻陷</strong>：攻击者利用Claude CLI探索文件系统，窃取钱包和凭据。(详见 <a href="https://semgrep.dev/blog/2025/security-alert-nx-compromised-to-steal-wallets-and-credentials/">Semgrep</a> 和 <a href="https://github.com/nrwl/nx/security/advisories/GHSA-cxm3-wv7p-598c">GitHub安全通告</a>)</li> <li><strong>SpaceX星舰成功完成第10次关键试飞</strong>：巨型火箭的又一里程碑，进一步推进火星探索目标。<a href="https://www.space.com/space-exploration/private-spaceflight/spacex-launches-starship-flight-10-critical-test-flight-video">Space.com</a></li> <li><strong>PayPal安全系统故障引德国银行担忧</strong>：故障导致德国银行冻结了数十亿欧元的付款。<a href="https://www.nordbayern.de/news-in-english/paypal-security-systems-down-german-banks-block-payments-in-the-billions-1.14811187">Nordbayern</a></li> <li><strong>谷歌一年内裁减三分之一小团队经理</strong>：反映了科技巨头内部组织架构的重大调整和效率优化趋势。<a href="https://www.cnbc.com/2025/08/27/google-executive-says-company-has-cut-a-third-of-its-managers.html">CNBC</a></li> <li><strong>科学家揭露反风力组织受石油资助</strong>：一位科学家因揭露反风力组织与石油公司的资金关联而面临打压。<a href="https://electrek.co/2025/08/25/scientist-exposes-anti-wind-groups-as-oil-funded-now-they-want-to-silence-him/">Electrek</a></li> </ul> <h2 id="-ai--开发工具">📦 AI &amp; 开发工具</h2> <ul> <li><strong>QEMU 10.1.0发布</strong>：著名开源虚拟化软件带来多项新功能和改进。<a href="https://wiki.qemu.org/ChangeLog/10.1">QEMU Wiki</a></li> <li><strong>Zed编辑器集成AI代理功能</strong>：支持用户在Zed中接入如Gemini CLI等AI工具。<a href="https://zed.dev/blog/bring-your-own-agent-to-zed">Zed Blog</a></li> </ul> <h2 id="-思维激荡mind-food">🧠 思维激荡（Mind Food）</h2> <ul> <li><strong>Therac-25事件回顾</strong>：一个关于软件缺陷导致致命后果的经典案例，强调软件可靠性。<a href="https://thedailywtf.com/articles/the-therac-25-incident">The Daily WTF</a></li> <li><strong>一位AI“厌恶者”的自白</strong>：一篇探讨AI负面影响和潜在风险的个人观点文章。<a href="https://anthonymoser.github.io/writing/ai/haterdom/2025/08/26/i-am-an-ai-hater.html">Anthony Moser</a></li> <li><strong>停止过度解读科技高管</strong>：文章批判性地指出科技高管的言论往往空洞无物。<a href="https://www.stilldrinking.org/stop-talking-to-technology-executives-like-they-have-anything-to-say">Stilldrinking</a></li> <li><strong>“可塑性软件”将改变SaaS世界</strong>：探讨软件设计的新范式，以实现更高的灵活性和定制化。<a href="https://www.mdubakov.me/malleable-software-will-eat-the-saas-world/">MDubakov</a></li> </ul> <h2 id="-科技与社会趋势">🌐 科技与社会趋势</h2> <ul> <li><strong>Android开发者验证流程引发质疑</strong>：文章对Google的Android开发者验证机制提出不适的问题。<a href="https://commonsware.com/blog/2025/08/26/uncomfortable-questions-android-developer-verification.html">CommonsWare</a></li> <li><strong>F-35飞行员坠机前与工程师空中通话50分钟</strong>：披露了一起F-35坠机事件中，飞行员在紧急情况下的长时间沟通细节。<a href="https://www.cnn.com/2025/08/27/us/alaska-f-35-crash-accident-report-hnk-ml">CNN</a></li> <li><strong>Windows将自动保存Word文档至云端</strong>：此举引发用户对数据隐私和控制权的担忧。<a href="https://www.ghacks.net/2025/08/27/your-word-documents-will-be-saved-to-the-cloud-automatically-on-windows-going-forward/">Ghacks.net</a></li> <li><strong>苹果撤销AltStore某应用欧盟分发权</strong>：此举凸显了平台对第三方应用生态的强大控制力。<a href="https://torrentfreak.com/apple-revokes-eu-distribution-rights-for-torrent-client-developer-left-in-the-dark/">TorrentFreak</a></li> <li><strong>丹麦就格陵兰岛影响力行动召见美外交官</strong>：丹麦要求美国就其在格陵兰岛的所谓影响力行动做出解释。<a href="https://www.bbc.com/news/articles/c0j9l08902eo">BBC News</a></li> <li><strong>研究揭示反离岸风电组织与律师的联系</strong>：一份报告映射了美国东海岸反离岸风电团体及其法律代表的关联网络。<a href="https://www.climatedevlab.brown.edu/post/legal-entanglements-mapping-connections-of-anti-offshore-wind-groups-and-their-lawyers-in-the-easte">ClimateDevLab</a></li> <li><strong>博客平台Typepad宣布即将关闭服务</strong>：又一个老牌互联网服务走向终结。<a href="https://everything.typepad.com/blog/2025/08/typepad-is-shutting-down.html">Typepad Blog</a></li> <li><strong>众议院将调查维基百科的偏见指控</strong>：美国众议院将对维基百科存在的有组织偏见指控进行审查。<a href="https://thehill.com/homenews/house/5473331-wikipedia-bias-probe-republicans/">The Hill</a></li> <li><strong>Dreamwidth因法律原因将地理封锁密西西比州IP</strong>：社交平台Dreamwidth宣布将从9月1日起对密西西比州的用户进行地域限制。<a href="https://dw-news.dreamwidth.org/44429.html">Dreamwidth News</a></li> <li><strong>举报人称政府官员复制社保号码</strong>：一名举报人指控DOGE（Department of Government Ethics）官员复制社会安全号码，引发隐私担忧。<a href="https://www.npr.org/2025/08/26/nx-s1-5517977/social-security-doge-privacy">NPR</a></li> </ul> <h2 id="-新奇项目--show-hn">📱 新奇项目 / Show HN</h2> <ul> <li><strong>Monodraw</strong>：Mac上用于创建文本艺术和ASCII流程图的强大工具。<a href="https://monodraw.helftone.com/">Helftone</a></li> <li><strong>ASCIIFlow</strong>：一个在线工具，可轻松绘制ASCII艺术流程图和图表。<a href="https://asciiflow.com/">ASCIIFlow</a></li> <li><strong>WebLibre：以隐私为中心的浏览器</strong>：一款注重用户数据隐私保护的新型网页浏览器。<a href="https://docs.weblibre.eu/">WebLibre Docs</a></li> <li><strong>Bitrig（YC S25）</strong>：一个允许开发者直接在iPhone上构建Swift应用的创新项目。<a href="https://news.ycombinator.com/item?id=45041185">Hacker News</a></li> </ul> <h2 id="-快速浏览">🎯 快速浏览</h2> <ul> <li><strong>GitHub网站在Safari上运行缓慢</strong>：社区讨论了GitHub在Safari浏览器上的性能问题。<a href="https://github.com/orgs/community/discussions/170758">GitHub Discussions</a></li> <li><strong>Firefox官方网站已迁移至Firefox.com</strong>：浏览器品牌的域名更新通知。<a href="https://www.firefox.com/">Firefox.com</a></li> <li><strong>Kiwi.com航班搜索MCP服务器</strong>：Kiwi.com航班搜索服务MCP服务器的相关技术说明。<a href="https://mcp-install-instructions.alpic.cloud/servers/kiwi-com-flight-search">Alpic Cloud</a></li> </ul> <h2 id="-dev-tricks">🧰 Dev Tricks</h2> <ul> <li><strong>Apple M1 GPU深度剖析（完结篇）</strong>：Asahi Linux团队对Apple M1 GPU逆向工程系列的最终章。<a href="https://rosenzweig.io/blog/asahi-gpu-part-n.html">Rosenzweig.io</a></li> <li><strong>Rust带来的意外生产力提升</strong>：作者分享了使用Rust编程语言提高工作效率的经验。<a href="https://lubeno.dev/blog/rusts-productivity-curve">Lubeno.dev</a></li> <li><strong>VIM Master</strong>：一个GitHub项目，旨在帮助Vim用户提升其编辑技能。<a href="https://github.com/renzorlive/vimmaster">GitHub</a></li> <li><strong>GMP库或损害AMD Zen 5 CPU</strong>：关于GMP数学库可能与AMD Zen 5处理器不兼容的警告。<a href="https://gmplib.org/gmp-zen5">GMP Lib</a></li> <li><strong>如何以及为何要减缓程序运行速度</strong>：探讨刻意降低程序速度的技巧及其在特定场景下的实用性。<a href="https://stefan-marr.de/2025/08/how-to-slow-down-a-program/">Stefan Marr</a></li> <li><strong>用Go和C实现Forth语言</strong>：一篇关于如何用Go和C语言构建Forth编程语言解释器的技术文章。<a href="https://eli.thegreenplace.net/2025/implementing-forth-in-go-and-c/">Eli Bendersky</a></li> </ul>]]></content><author><name></name></author><category term="HNDailyReport"/><category term="HNDailyReport"/><summary type="html"><![CDATA[🔥 今日重点（Top Picks）]]></summary></entry><entry><title type="html">大模型上下文工程实践指南-第1章：从提示词到上下文</title><link href="https://ifuryst.github.io/blog/2025/from-prompt-engineering-to-context-engineering/" rel="alternate" type="text/html" title="大模型上下文工程实践指南-第1章：从提示词到上下文"/><published>2025-08-25T00:00:00+00:00</published><updated>2025-08-25T00:00:00+00:00</updated><id>https://ifuryst.github.io/blog/2025/from-prompt-engineering-to-context-engineering</id><content type="html" xml:base="https://ifuryst.github.io/blog/2025/from-prompt-engineering-to-context-engineering/"><![CDATA[<h1 id="11-提示词工程prompt-engineering">1.1 提示词工程（Prompt Engineering）</h1> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-08-25-from-prompt-engineering-to-context-engineering/1756127937_5-480.webp 480w,/assets/img/2025-08-25-from-prompt-engineering-to-context-engineering/1756127937_5-800.webp 800w,/assets/img/2025-08-25-from-prompt-engineering-to-context-engineering/1756127937_5-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/2025-08-25-from-prompt-engineering-to-context-engineering/1756127937_5.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> </div> </div> <p>上面这个是OpenAI的CEO Sam Altman在2022年12月发的一条推文，预示着ChatGPT正式走上历史的舞台。在那之后，ChatGPT在5天内就达到了百万个用户</p> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-08-25-from-prompt-engineering-to-context-engineering/1756127937_6-480.webp 480w,/assets/img/2025-08-25-from-prompt-engineering-to-context-engineering/1756127937_6-800.webp 800w,/assets/img/2025-08-25-from-prompt-engineering-to-context-engineering/1756127937_6-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/2025-08-25-from-prompt-engineering-to-context-engineering/1756127937_6.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> </div> </div> <p>支撑ChatGPT风靡全球的根源是<strong>大语言模型（LLM，Large Language Model）</strong>。这是一个以神经网络为基础训练出来的模型，和早期的神经网络不同，ChatGPT是基于Google在<a href="https://arxiv.org/abs/1706.03762">2017发布的Transformer架构</a>所训练出来的大语言模型。</p> <p>Transformer架构引入了<strong>注意力机制（Self-Attention）</strong>，使得模型在处理每一个词语时，能够动态地关注序列中其他所有词的位置与关系，从而更有效地理解语境、捕捉长距离依赖信息。</p> <p>基于Transformer架构的强大能力，OpenAI掀起了新一轮人工智能革命的浪潮，大语言模型正式进入了大众的视野。各大科技公司和AI初创企业开始投入大语言模型军备赛，争相推出参数级别更大的模型以达到更好的智能水平。</p> <p>基于这个之下，<strong>提示词工程（Prompt Engineering）</strong>应运而生，成为激发大语言模型潜力的关键手段，也逐渐发展为一个全新的学科方向和新兴职业领域。提示工程主要关注提示词的设计、优化与策略制定，致力于帮助用户更高效地调动大语言模型的能力，进而推动其在各类实际场景和研究领域中的应用。</p> <p>掌握提示工程技能，不仅能够提升使用效率，还能深入理解大语言模型的能力边界与局限性。研究人员通过提示工程可以显著增强模型在问答、逻辑推理、数学计算等复杂任务上的表现；开发者则可以借助提示策略，构建与LLM或外部工具的协同工作流，推动AI系统的实用化落地。</p> <p>值得注意的是，提示工程不仅限于编写好提示词，它涵盖了与大语言模型交互、对接、调优等多项技术与方法，涵盖了从模型安全性提升、能力增强（如引入专业知识库或调用外部工具等）到产品级提示结构设计等多个维度。</p> <p>了解完背景之后，现在我们来进一步看看什么是提示词。首先我们用一简单的例子来展示：</p> <p>```plain text Leo: 我是</p> <p>ChatGPT: 你好呀！你可以继续补充“我是……”后面的内容，也可以直接告诉我你想聊什么、做什么～😊</p> <p>Leo: 补全这个句子： 我是</p> <p>ChatGPT: 我是一个热爱探索世界的旅行者。</p> <p>你也可以根据不同语境来补全，比如：</p> <p>介绍自己时：我是产品经理，正在开发一款AI应用。 抒发情感时：我是一个容易感动的人，总被小事打动。 写文艺句子时：我是月光下的一只猫，悄悄溜进了你的梦里。</p> <p>你想用在哪种场景里？我可以帮你写得更贴合。</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
上面是我和ChatGPT的对话，可以看到，一开始我们发送`我是`的时候，它并没有补全句子，这是因为ChatGPT在系统提示词里被设定为聊天导向型的助手了，所以它不会无脑的补充你发的话，虽然这个行为是大语言模型的本质（预测下一个Token）。

我们在第二次的时候，增加了提示词，也就是`补全这个句子：`这段话，这个就是一个简单的提示词，告诉大语言模型应该做什么，应该怎么做。这也是提示词的核心。聪明的你应该发现了，这边的提示词表现得和我们日常交流中的要求之类的表述一样，其实就是这么回事，提示词不是什么高大上的东西，他就是你通过自然语言的方式去告诉模型应该**做什么**，应该**怎么做**，**什么能做**，**什么不能做**，就这么简单。

在大家持续参与编写、优化和分享提示词的过程中，也陆续有一些相关的知识和方法论开始沉淀出来，这也是一个新兴学科会经历的一个过程。在我们实践过程中，提示词的写法也是有迹可循的，通常会包含以下这些部分：

- **指令（Instruction）**：明确告诉模型需要它做什么
- **上下文（Context）**：相关的背景信息，让模型有更多的上下文用于决策
- **输入数据（Input Data）**：必要的输入，可以是问题、目标等
- **输出提示（Output Constraints）**：约束输出格式、风格或长度，让结果更符合你的需求

给一段简单的提示词构成：

```plain text
You are ChatGPT, a large language model trained by OpenAI, based on the GPT-4.5 architecture.
Knowledge cutoff: 2023-10
Current date: 2025-06-29

Image input capabilities: Enabled
Personality: v2
You are a highly capable, thoughtful, and precise assistant. Your goal is to deeply understand the user's intent, ask clarifying questions when needed, think step-by-step through complex problems, provide clear and accurate answers, and proactively anticipate helpful follow-up information. Always prioritize being truthful, nuanced, insightful, and efficient, tailoring your responses specifically to the user's needs and preferences.
NEVER use the dalle tool unless the user specifically requests for an image to be generated.

# Tools

## bio

The `bio` tool is disabled. Do not send any messages to it. If the user explicitly asks you to remember something, politely ask them to go to Settings &gt; Personalization &gt; Memory to enable memory.

## canmore

The `canmore` tool creates and updates textdocs that are shown in a "canvas" next to the conversation.

This tool has 3 functions, listed below.

### `canmore.create_textdoc`

Creates a new textdoc to display in the canvas.

NEVER use this function. The ONLY acceptable use case is when the user EXPLICITLY asks for canvas. Other than that, NEVER use this function.

Expects a JSON string that adheres to this schema:
{
  name: string,
  type: "document" | "code/python" | "code/javascript" | "code/html" | "code/java" | ...,
  content: string,
}

For code languages besides those explicitly listed above, use "code/languagename", e.g. "code/cpp".

Types "code/react" and "code/html" can be previewed in ChatGPT's UI. Default to "code/react" if the user asks for code meant to be previewed (eg. app, game, website).

When writing React:
- Default export a React component.
- Use Tailwind for styling, no import needed.
- All NPM libraries are available to use.
- Use shadcn/ui for basic components (eg. `import { Card, CardContent } from "@/components/ui/card"` or `import { Button } from "@/components/ui/button"`), lucide-react for icons, and recharts for charts.
- Code should be production-ready with a minimal, clean aesthetic.
- Follow these style guides:
    - Varied font sizes (eg., xl for headlines, base for text).
    - Framer Motion for animations.
    - Grid-based layouts to avoid clutter.
    - 2xl rounded corners, soft shadows for cards/buttons.
    - Adequate padding (at least p-2).
    - Consider adding a filter/sort control, search input, or dropdown menu for organization.

### `canmore.update_textdoc`

Updates the current textdoc. Never use this function unless a textdoc has already been created.

Expects a JSON string that adheres to this schema:
{
  updates: {
    pattern: string,
    multiple: boolean,
    replacement: string,
  }[],
}

Each `pattern` and `replacement` must be a valid Python regular expression (used with re.finditer) and replacement string (used with re.Match.expand).
ALWAYS REWRITE CODE TEXTDOCS (type="code/*") USING A SINGLE UPDATE WITH ".*" FOR THE PATTERN.
Document textdocs (type="document") should typically be rewritten using ".*", unless the user has a request to change only an isolated, specific, and small section that does not affect other parts of the content.

### `canmore.comment_textdoc`

Comments on the current textdoc. Never use this function unless a textdoc has already been created.
Each comment must be a specific and actionable suggestion on how to improve the textdoc. For higher-level feedback, reply in the chat.

Expects a JSON string that adheres to this schema:
{
  comments: {
    pattern: string,
    comment: string,
  }[],
}

Each `pattern` must be a valid Python regular expression (used with re.search).

## python

When you send a message containing Python code to python, it will be executed in a stateful Jupyter notebook environment. python will respond with the output of the execution or time out after 60.0 seconds. The drive at '/mnt/data' can be used to save and persist user files. Internet access for this session is disabled. Do not make external web requests or API calls as they will fail.
Use ace_tools.display_dataframe_to_user(name: str, dataframe: pandas.DataFrame) -&gt; None to visually present pandas DataFrames when it benefits the user.
When making charts for the user: 1) never use seaborn, 2) give each chart its own distinct plot (no subplots), and 3) never set any specific colors – unless explicitly asked to by the user.
I REPEAT: when making charts for the user: 1) use matplotlib over seaborn, 2) give each chart its own distinct plot (no subplots), and 3) never, ever, specify colors or matplotlib styles – unless explicitly asked to by the user.

## image_gen_redirect

The `image_gen` tool enables image generation from descriptions and editing of existing images based on specific instructions.

Unfortunately, you do not have access to the image generation tool. If you run this tool, you will receive a text response that says you do not have access to the tool.

If a user requests an image, you should suggest that they switch to GPT-4o to use the image generation tool. It is enabled by default for GPT-4o.

## web

Use the `web` tool to access up-to-date information from the web or when responding to the user requires information about their location. Some examples of when to use the `web` tool include:

- **Local Information:** Use the `web` tool to respond to questions that require information about the user's location, such as the weather, local businesses, or events.
- **Freshness:** If up-to-date information on a topic could potentially change or enhance the answer, call the `web` tool any time you would otherwise refuse to answer a question because your knowledge might be out of date.
- **Niche Information:** If the answer would benefit from detailed information not widely known or understood (which might be found on the internet), such as details about a small neighborhood, a less well-known company, or arcane regulations, use web sources directly rather than relying on distilled knowledge from pretraining.
- **Accuracy:** If the cost of a small mistake or outdated information is high (e.g., using an outdated version of a software library or not knowing the date of the next game for a sports team), then use the `web` tool.

IMPORTANT: Do not attempt to use the old `browser` tool or generate responses from the `browser` tool anymore, as it is now deprecated or disabled.

The `web` tool has the following commands:
- `search()`: Issues a new query to a search engine and outputs the response.
- `open_url(url: str)`: Opens the given URL and displays it.

</code></pre></div></div> <p>这是一份GPT4.5的系统提示词（System Prompt），下面我翻译成一版中文的</p> <p>```plain text 你是ChatGPT，基于GPT-4.5架构的大型语言模型，由OpenAI训练。 知识截止日期：2023年10月 当前日期：2025年6月29日</p> <p>图像输入能力：已启用 个性：v2版本 你是一个高度能干、深思熟虑且精确的助手。你的目标是深度理解用户意图，在需要时提出澄清问题，逐步思考复杂问题，提供清晰准确的答案，并主动预测有用的后续信息。始终优先考虑真实性、细致入微、深刻见解和高效性，根据用户的需求和偏好专门定制你的回答。 除非用户明确要求生成图像，否则永远不要使用dalle工具。</p> <h1 id="工具">工具</h1> <h2 id="bio">bio</h2> <p><code class="language-plaintext highlighter-rouge">bio</code>工具已禁用。不要向其发送任何消息。如果用户明确要求你记住某些内容，请礼貌地要求他们前往设置&gt;个性化&gt;记忆来启用记忆功能。</p> <h2 id="canmore">canmore</h2> <p><code class="language-plaintext highlighter-rouge">canmore</code>工具创建和更新在对话旁边”画布”中显示的文本文档。</p> <p>此工具有3个功能，如下所列。</p> <h3 id="canmorecreate_textdoc"><code class="language-plaintext highlighter-rouge">canmore.create_textdoc</code></h3> <p>创建一个新的文本文档在画布中显示。</p> <p>永远不要使用此功能。唯一可接受的使用情况是用户明确要求使用画布。除此之外，永远不要使用此功能。</p> <p>期望一个符合此模式的JSON字符串： { name: string, type: “document” | “code/python” | “code/javascript” | “code/html” | “code/java” | …, content: string, }</p> <p>对于上述明确列出的代码语言之外的其他语言，使用”code/语言名称”，例如”code/cpp”。</p> <p>类型”code/react”和”code/html”可以在ChatGPT界面中预览。如果用户要求用于预览的代码（例如应用、游戏、网站），默认使用”code/react”。</p> <p>编写React时：</p> <ul> <li>默认导出一个React组件。</li> <li>使用Tailwind进行样式设计，无需导入。</li> <li>所有NPM库都可以使用。</li> <li>使用shadcn/ui作为基础组件（例如<code class="language-plaintext highlighter-rouge">import { Card, CardContent } from "@/components/ui/card"</code>或<code class="language-plaintext highlighter-rouge">import { Button } from "@/components/ui/button"</code>），lucide-react用于图标，recharts用于图表。</li> <li>代码应该是可投入生产的，具有简约、干净的美感。</li> <li>遵循以下样式指南： <ul> <li>多样化字体大小（例如，标题使用xl，文本使用base）。</li> <li>使用Framer Motion进行动画。</li> <li>基于网格的布局以避免杂乱。</li> <li>2xl圆角，卡片/按钮使用柔和阴影。</li> <li>充足的内边距（至少p-2）。</li> <li>考虑添加过滤器/排序控件、搜索输入或下拉菜单进行组织。</li> </ul> </li> </ul> <h3 id="canmoreupdate_textdoc"><code class="language-plaintext highlighter-rouge">canmore.update_textdoc</code></h3> <p>更新当前文本文档。除非已经创建了文本文档，否则永远不要使用此功能。</p> <p>期望一个符合此模式的JSON字符串： { updates: { pattern: string, multiple: boolean, replacement: string, }[], }</p> <p>每个<code class="language-plaintext highlighter-rouge">pattern</code>和<code class="language-plaintext highlighter-rouge">replacement</code>必须是有效的Python正则表达式（与re.finditer一起使用）和替换字符串（与re.Match.expand一起使用）。 始终使用单个更新重写代码文本文档（type=”code/<em>“），模式使用”.</em>“。 文档文本文档（type=”document”）通常应使用”.*“重写，除非用户要求仅更改不影响内容其他部分的孤立、特定且小的部分。</p> <h3 id="canmorecomment_textdoc"><code class="language-plaintext highlighter-rouge">canmore.comment_textdoc</code></h3> <p>对当前文本文档进行评论。除非已经创建了文本文档，否则永远不要使用此功能。 每个评论必须是关于如何改进文本文档的具体且可操作的建议。对于更高层次的反馈，请在聊天中回复。</p> <p>期望一个符合此模式的JSON字符串： { comments: { pattern: string, comment: string, }[], }</p> <p>每个<code class="language-plaintext highlighter-rouge">pattern</code>必须是有效的Python正则表达式（与re.search一起使用）。</p> <h2 id="python">python</h2> <p>当你向python发送包含Python代码的消息时，它将在有状态的Jupyter notebook环境中执行。python将响应执行的输出或在60.0秒后超时。’/mnt/data’驱动器可用于保存和持久化用户文件。此会话的互联网访问已禁用。不要进行外部网络请求或API调用，因为它们会失败。 当对用户有益时，使用ace_tools.display_dataframe_to_user(name: str, dataframe: pandas.DataFrame) -&gt; None来可视化呈现pandas DataFrames。 为用户制作图表时：1) 永远不要使用seaborn，2) 给每个图表自己独特的图（没有子图），3) 永远不要设置任何特定颜色 - 除非用户明确要求。 我重申：为用户制作图表时：1) 使用matplotlib而不是seaborn，2) 给每个图表自己独特的图（没有子图），3) 永远、永远不要指定颜色或matplotlib样式 - 除非用户明确要求。</p> <h2 id="image_gen_redirect">image_gen_redirect</h2> <p><code class="language-plaintext highlighter-rouge">image_gen</code>工具能够根据描述生成图像，并基于特定指令编辑现有图像。</p> <p>不幸的是，你没有访问图像生成工具的权限。如果你运行此工具，你将收到一个文本响应，说你没有访问该工具的权限。</p> <p>如果用户请求图像，你应该建议他们切换到GPT-4o以使用图像生成工具。该工具在GPT-4o中默认启用。</p> <h2 id="web">web</h2> <p>使用<code class="language-plaintext highlighter-rouge">web</code>工具来访问网络上的最新信息，或当回应用户需要关于他们位置的信息时。使用<code class="language-plaintext highlighter-rouge">web</code>工具的一些示例包括：</p> <ul> <li><strong>本地信息：</strong> 使用<code class="language-plaintext highlighter-rouge">web</code>工具回答需要用户位置信息的问题，如天气、本地商家或事件。</li> <li><strong>时效性：</strong> 如果某个主题的最新信息可能会改变或增强答案，在你因为知识可能过时而拒绝回答问题时，请随时调用<code class="language-plaintext highlighter-rouge">web</code>工具。</li> <li><strong>细分信息：</strong> 如果答案将受益于详细的、不广为人知或理解的信息（可能在互联网上找到），如小社区的详细信息、不太知名的公司或晦涩的法规，请直接使用网络资源，而不是依赖预训练中的蒸馏知识。</li> <li><strong>准确性：</strong> 如果小错误或过时信息的代价很高（例如，使用过时版本的软件库或不知道体育队下一场比赛的日期），则使用<code class="language-plaintext highlighter-rouge">web</code>工具。</li> </ul> <p>重要提示：不要再尝试使用旧的<code class="language-plaintext highlighter-rouge">browser</code>工具或从<code class="language-plaintext highlighter-rouge">browser</code>工具生成响应，因为它现在已被弃用或禁用。</p> <p><code class="language-plaintext highlighter-rouge">web</code>工具有以下命令：</p> <ul> <li><code class="language-plaintext highlighter-rouge">search()</code>：向搜索引擎发出新查询并输出响应。</li> <li><code class="language-plaintext highlighter-rouge">open_url(url: str)</code>：打开给定URL并显示它。</li> </ul> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
里面包含了明确的指示，比如：
`bio`工具已禁用。不要向其发送任何消息。如果用户明确要求你记住某些内容，请礼貌地要求他们前往设置&gt;个性化&gt;记忆来启用记忆功能

还提供了一些相关的背景信息，比如：

```plain text
你是ChatGPT，基于GPT-4.5架构的大型语言模型，由OpenAI训练。
知识截止日期：2023年10月
当前日期：2025年6月29日

</code></pre></div></div> <p>还有对于输出的一些限制和格式要求：</p> <p>```plain text 期望一个符合此模式的JSON字符串： { comments: { pattern: string, comment: string, }[], }</p> <p>每个<code class="language-plaintext highlighter-rouge">pattern</code>必须是有效的Python正则表达式（与re.search一起使用）。</p> <p>```</p> <p>因为这个是System Prompt，所以没有包含用户输入。</p> <p>我们可以通过观测一些主流的ChatBot、AI Agent的System Prompt来学习提示词的编写。我在附录里放了一些主流的Prompt供大家进行学习。</p> <p>不过现在很多提示词的学习资料已经略显过时了。随着模型能力不断演进，简单的Prompt已经不再是问题的全部，真正影响AI表现的，是它知道什么、记住什么以及如何组合信息。于是<strong>上下文工程（Context Engineering）</strong>逐渐浮出水面，也将提示词工程取而代之，成为目前人人追捧、研究的对象。</p> <h1 id="12-上下文工程context-engineering">1.2 上下文工程（Context Engineering）</h1> <h2 id="121-what上下文工程是什么">1.2.1 What：上下文工程是什么？</h2> <blockquote> <p>“Context engineering is the delicate art and science of filling the context window with just the right information for the next step.” ——Andrej Karpathy <strong>上下文工程（Context Engineering）</strong>这个名词并不新，但是在今年以来持续获得关注，尤其是当Karpathy在2025年6月25日引用了<a href="https://x.com/tobi/status/1935533422589399127">Shopify CEO Tobi Lutke那条推文</a>，并发表了简洁但深刻的<a href="https://x.com/karpathy/status/1937902205765607626">推文</a>之后，全行业开始认真对待上下文工程这个概念、艺术、实践，或者甚至可以说是一个学科。</p> </blockquote> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-08-25-from-prompt-engineering-to-context-engineering/1756127937_7-480.webp 480w,/assets/img/2025-08-25-from-prompt-engineering-to-context-engineering/1756127937_7-800.webp 800w,/assets/img/2025-08-25-from-prompt-engineering-to-context-engineering/1756127937_7-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/2025-08-25-from-prompt-engineering-to-context-engineering/1756127937_7.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> </div> </div> <p>Karpathy在Y Combinator Startup School的演讲里提出Software 3.0的概念，里面将大语言模型（LLM，Large Language Model）类比成新一代的操作系统（OS，Operating System），上下文窗口（Context Window）是它的 内存RAM，而上下文工程，就是这个操作系统中的调度器，负责把最重要的进程和数据装进有限的内存中。</p> <p>简单说，<strong>上下文工程是一种为大语言模型构建、优化、动态管理输入上下文的工程化方法</strong>。不单单是写好提示词，更是一个系统化的过程，包括：</p> <ol> <li>信息收集和整合：从多源数据中获取与任务高度相关的内容</li> <li>结构化和格式化：将信息结构化组织，按照一定格式提供给大模型</li> <li>上下文管理：在有限的上下文窗口内，通过裁剪、隔离、压缩、持久化等手段来管理</li> <li>工具和外部系统接入：通过与外部工具和系统交互，增强模型的能力</li> </ol> <p>本质上，上下文工程是让大模型在特定场景下具备即插即用的任务能力，大模型在推理的时候所拥有的只有训练阶段获得的能力+上下文内容，在前者无法改变的情况之下，后者显得尤为重要，不管大模型曾经执行或者交互过多少轮次，最新的这次只能依赖所提供的上下文去做推理，因此上下文在推理阶段才如此重要。</p> <h2 id="122-why为什么需要">1.2.2 Why：为什么需要？</h2> <p>为什么我们需要上下文工程呢？</p> <p>首先是<strong>大语言模型需要上下文</strong>，在上下文缺少的情况之下，哪怕模型能力特别强，也无法给出正确的结果，就好比我们需要一个人去送快递，却不告知收件地址，那无论这个快递员开车多么溜，对于这个城市或这个片区的路有多么的熟悉，也无法顺利将快递送到收件人手中。</p> <p>其次是，<strong>错误源于信息不足，而不是模型不够好</strong>。回到前面这个例子，当我们只告知快递员一个精确到楼栋的地址，却给了错误的手机号，快递员无法联系上收件人，这种情况之下如果快递员仍想努力送达，那么只能针对这栋楼挨家挨户的问了。这个在大模型的应用之中是很常见的一个情况，当我们需要大模型帮我改一个文件里面的代码，但是我们却没有给到其对应文件的代码，大模型是完全不知道怎么改的，或者说我们要改一个接口的功能，我们给了接口层的代码，却没有给数据库操作的代码，大模型依然无法帮我们从接口出发，一条龙的改下去。</p> <p>就好比前段时间Anthropic的Claude Code（下称CC）大火，很多技术人员纷纷从Cursor转投CC的怀抱，抛开商业，这背后就是CC的上下文工程完胜Cursor的上下文工程。就拿目前Coding能力最强的模型Sonnet4和Opus4来说，Cursor和CC底层都基于一样的模型的情况之下，出来的效果都大不相同，CC可以更好地调用系统命令，更智能地从一个需求，到计划处几个目标，再到执行，最后再结合编译或者运行来做验收，整个过程每一步都是在处理上下文，都是在上下文工程的范畴之内。CC也因此获得了很多专业人士的喜好。我们也能看到一些用户通过CC去调用Kimi的K2模型或者Qwen的Coder模型，都能获得不错的效果，这正是因为CC本身的上下文工程的底子足够好，不管底层调用什么大语言模型，都可以最大程度发挥出模型的能力。</p> <p>最后是<strong>复杂任务及多源信息融合的挑战</strong>。现实生活中的任务，通常并不是一个单一信息源就能完成的，就好比我们写一篇文章，我们需要浏览器查阅资料，需要通讯软件和别人交流和交换思想，也需要一个编辑器来写文章，最最后可能还需要有一定的平台或软件来分发我们的内容。这本身就涉及多个信息源，也需要和多个外部工具或系统交互。围绕着大模型，2025年是AI Agent大流行的一年，从单Agent到多Agent（Multi-Agent）追求的都是可以让大模型自主决定与外部交互的动作，并能在任务完成前持续的决策和交互。例如现在以Devin、OpenHands和Manus为主的AI Agent就为大模型配备了浏览器、编辑器、命令行（Shell），这可能就是一个程序员的标配，这样大模型就有了与外界交流的三个主要工具，因此可以自动化完成任务了。</p> <p>从告诉模型做什么的Prompt阶段，到为模型准备什么认知环境的Context阶段，这是一种根本性的思维方式转变。上下文工程不是锦上添花，而是AI应用时代的关键基础设施。它不仅决定了LLM是否聪明，更决定了它是否有用。换言之：<strong>训练和微调决定了模型的能力，上下文工程则决定了模型能发挥出多少能力</strong>。</p> <h2 id="123-how如何做呢">1.2.3 How：如何做呢？</h2> <p>在知道了上下文工程是什么以及为什么需要上下文工程之后，我们抛出最后一个问题，我们应该怎样做呢？</p> <p>虽然上下文工程今年火起来，但是背后的技术和解决方案一直在发展，这也符合发展规律，一个学科发展就是经历了高速发展的野蛮生长阶段，在这一阶段会针对不同的问题产生出不同的解决方案。直到各种技术发展趋稳，并被广泛接受和应用之后，体系化就会出现，也预示着学科的诞生。这也是上下文工程在这个时候出现并不是偶然的，而是发展阶段到达需要关注上下文工程的时候，同时配套的技术和解决方案也趋于成熟。</p> <p>我们看看<a href="https://www.philschmid.de/context-engineering">Philschmid</a>对于上下文工程的一个维恩图：</p> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <div class="row mt-3"> <div class="col-sm mt-0 mb-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-08-25-from-prompt-engineering-to-context-engineering/1756127938_8-480.webp 480w,/assets/img/2025-08-25-from-prompt-engineering-to-context-engineering/1756127938_8-800.webp 800w,/assets/img/2025-08-25-from-prompt-engineering-to-context-engineering/1756127938_8-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/2025-08-25-from-prompt-engineering-to-context-engineering/1756127938_8.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> </div> </div> <p>这张图用较为直观的方式展示了上下文工程中，目前涉及的一些技术手段，有我们场景的RAG、提示词技术（Prompt）、工具，也有一些记忆系统。这也是本书的核心，就是通过系统化的方式学会上下文工程的相关技术理论，并进一步学会如何实践。</p> <p>关于这些技术，我这边就不展开讨论了，我们在第二部分，也就是第四章开始，会有详细的介绍。</p> <h1 id="13-两种范式的本质差异">1.3 两种范式的本质差异</h1> <p><strong>提示词工程的目标，是用一句话、一段话、一个格式、一个role prompt来激发模型的潜力。</strong>它像是给模型下达精心措辞的指令，让它在你设定的框架内回答问题。这在早期以ChatBot这种聊天助手为主的AI应用场景里一度非常有效，尤其是当时大模型没有记忆、没有外部知识：</p> <ul> <li>静态、单轮、指令导向</li> <li>适用于封闭任务、结构化回答</li> <li>零样本提示/少样本提示/思维链提示 等技巧层出不穷</li> </ul> <p>但它的局限也很明显：</p> <ul> <li>缺乏灵活的记忆管理，每轮对话要么是孤岛，要么是历史记录堆积</li> <li>无法有效处理任务链条和复杂流程</li> </ul> <p>提示词（Prompt）和这个词本身透露出的含义是一致的，也就是围绕着提示这个目标来构建对应的文本，因为目前的大语言模型底层是依托于Transfomer架构，本身就是基于神经网络结合注意力机制来做的概率计算，因此在有提示词的情况之下，可以让大语言模型关联注意到这些提示词，进而在生成结果的时候，有更高的概率是在这个方向上去生成。</p> <p>但是随着技术的发展，尤其2024年以来，函数调用和MCP的发展普及，进一步推动了大模型调用外部工具的需求和场景，另外以Agent为主的AI应用形态开始大流行，各种Agent不断涌现，<strong>此时对于上下文的管理已经从早起的简单对话形态进展到了需要各类技术辅助才能有效管理的阶段。</strong>这样就有了上下文工程的出现。</p> <p>上下文工程的出发点不同，它不再把模型当作回答者，而是当作协作者或者说希望模型有一定的“自主性”。这也是目前AI Agent的实践中很重要的一个认知和目标，就是<strong>让模型可以在运行时持续的获取相关的信息，基于这些信息做出最佳的决策，产生最合适的结果。</strong>它更像是构建一个运行环境，包含：</p> <ul> <li>信息架构设计</li> <li>记忆系统（短期 / 长期）</li> <li>检索增强（RAG）</li> <li>工具调用</li> </ul> <p>特点：</p> <ul> <li>动态、多轮、环境导向</li> <li>支持状态管理、任务演进、链式推理</li> <li>具备Agent级别的操作能力</li> </ul> <p>在明确了上下文工程的概念、必要性与应用范式之后，我们将从下一章开始，深入拆解支撑上下文工程的关键技术栈与实现思路。</p>]]></content><author><name></name></author><category term="Blog"/><category term="Blog"/><category term="微信公众号"/><category term="Substack"/><summary type="html"><![CDATA[1.1 提示词工程（Prompt Engineering）]]></summary></entry><entry><title type="html">LeoTalk · Hacker News Daily · 2025.08.24</title><link href="https://ifuryst.github.io/blog/2025/leotalk-hacker-news-daily-august-24-2025/" rel="alternate" type="text/html" title="LeoTalk · Hacker News Daily · 2025.08.24"/><published>2025-08-24T00:00:00+00:00</published><updated>2025-08-24T00:00:00+00:00</updated><id>https://ifuryst.github.io/blog/2025/leotalk-hacker-news-daily-august-24-2025</id><content type="html" xml:base="https://ifuryst.github.io/blog/2025/leotalk-hacker-news-daily-august-24-2025/"><![CDATA[<h2 id="-今日重点top-picks">🔥 今日重点（Top Picks）</h2> <ul> <li><strong>AI推理的环境影响</strong>：Google称一年内将AI查询能耗降低33倍，探讨AI推理的环境影响。<a href="https://arstechnica.com/ai/2025/08/google-says-it-dropped-the-energy-cost-of-ai-queries-by-33x-in-one-year/">Ars Technica</a></li> <li><strong>计算机欺诈法被用于起诉泄密</strong>：调查人员使用计算机欺诈法起诉向CNN泄露空难录像的人。<a href="https://www.techdirt.com/2025/08/22/investigators-used-terrible-computer-fraud-laws-to-ensure-people-were-punished-for-leaking-air-crash-footage-to-cnn/">Techdirt</a></li> <li><strong>日本城市拟限智能手机使用</strong>：日本一城市草拟条例，拟将智能手机使用时间限制在每天2小时。<a href="https://english.kyodonews.net/articles/-/59582">Kyodo News</a></li> </ul> <h2 id="-ai--开发工具">📦 AI &amp; 开发工具</h2> <ul> <li><strong>Manim</strong>：一个动画引擎，用于创建数学解释视频。<a href="https://github.com/3b1b/manim">GitHub</a></li> <li><strong>Librebox</strong>：开源的Roblox兼容游戏引擎。<a href="https://github.com/librebox-devs/librebox-demo">GitHub</a></li> <li><strong>LLM编码Agent使用技巧</strong>：利用LLM编码Agent创建软件的经验分享与实用技巧。<a href="https://efitz-thoughts.blogspot.com/2025/08/my-experience-creating-software-with_22.html">Thoughts by Efitz</a></li> <li><strong>Claude Code的优秀之处</strong>：深入分析Claude AI在代码生成方面表现出色的原因。<a href="https://minusx.ai/blog/decoding-claude-code/">MinusX AI</a></li> <li><strong>为RTX 5090编写Flash Attention</strong>：使用CUDA C++为RTX 5090编写极速Flash Attention算法。<a href="https://gau-nernst.github.io/fa-5090/">Gau Nernst</a></li> <li><strong>Linux云栈与机密虚拟机</strong>：重新思考Linux云栈在机密虚拟机环境中的应用。<a href="https://lwn.net/Articles/1030818/">LWN.net</a></li> </ul> <h2 id="-思维激荡mind-food">🧠 思维激荡（Mind Food）</h2> <ul> <li><strong>RFC 9839与Bad Unicode</strong>：关于RFC 9839和Unicode字符编码中存在的问题的探讨。<a href="https://www.tbray.org/ongoing/When/202x/2025/08/14/RFC9839">Tim Bray</a></li> <li><strong>开发者障碍（Developer’s Block）</strong>：关于开发者在工作中的“卡壳”现象的思考。<a href="https://underlap.org/developers-block/">Underlap</a></li> <li><strong>锻炼的投资回报率</strong>：探讨锻炼的投资回报率及其对个人生活的价值。<a href="https://herman.bearblog.dev/exercise/">Herman’s Bear Blog</a></li> </ul> <h2 id="-科技与社会趋势">🌐 科技与社会趋势</h2> <ul> <li><strong>RFK Jr要求撤回疫苗研究被拒</strong>：小罗伯特·F·肯尼迪要求撤回一项疫苗研究，但期刊拒绝。<a href="https://www.nature.com/articles/d41586-025-02682-9">Nature</a></li> </ul> <h2 id="-新奇项目--show-hn">📱 新奇项目 / Show HN</h2> <ul> <li><strong>从零制作软盘</strong>：亲手从头制作一个软盘的独特体验。<a href="https://kottke.org/25/08/i-made-a-floppy-disk-from-scratch">Kottke.org</a></li> <li><strong>我黑了Monster Energy</strong>：一名黑客分享他如何“入侵”Monster Energy公司的经历。<a href="https://bobdahacker.com/blog/monster-energy">Bobdahacker.com</a></li> <li><strong>Libre反社交实验</strong>：一个匿名社交实验，旨在去除点赞、关注和广告的干扰。<a href="https://libreantisocial.com/">Libre Antisocial</a></li> </ul> <h2 id="-科学与健康">🔬 科学与健康</h2> <ul> <li><strong>全球闪电定位网络</strong>：提供实时闪电数据，用于研究和预警。<a href="https://wwlln.net/">WWLLN</a></li> </ul> <h2 id="-dev-tricks">🧰 Dev Tricks</h2> <ul> <li><strong>Zig新IO接口体验</strong>：一位开发者分享对Zig新IO接口的困惑和学习体会。<a href="https://www.openmymind.net/Im-Too-Dumb-For-Zigs-New-IO-Interface/">Open My Mind</a></li> <li><strong>火车摄影图像处理</strong>：针对火车摄影的线扫描相机图像处理技术。<a href="https://daniel.lawrence.lu/blog/y2025m09d21/">Daniel Lawrence</a></li> </ul>]]></content><author><name></name></author><category term="HNDailyReport"/><category term="HNDailyReport"/><summary type="html"><![CDATA[🔥 今日重点（Top Picks）]]></summary></entry><entry><title type="html">LeoTalk · Hacker News Daily · 2025.08.23</title><link href="https://ifuryst.github.io/blog/2025/leotalk-hacker-news-daily-august-23-2025/" rel="alternate" type="text/html" title="LeoTalk · Hacker News Daily · 2025.08.23"/><published>2025-08-23T00:00:00+00:00</published><updated>2025-08-23T00:00:00+00:00</updated><id>https://ifuryst.github.io/blog/2025/leotalk-hacker-news-daily-august-23-2025</id><content type="html" xml:base="https://ifuryst.github.io/blog/2025/leotalk-hacker-news-daily-august-23-2025/"><![CDATA[<h2 id="-今日重点top-picks">🔥 今日重点（Top Picks）</h2> <ul> <li><strong>美政府收购Intel 10%股份</strong>：美国政府对Intel进行战略性股权投资，显示对半导体产业的重视。 <a href="https://www.cnbc.com/2025/08/22/intel-goverment-equity-stake.html">CNBC</a></li> <li><strong>Waymo获准在纽约市测试</strong>：Waymo自动驾驶出租车业务获批，将扩展至纽约市进行测试。 <a href="https://www.cnbc.com/2025/08/22/waymo-permit-new-york-city-nyc-rides.html">CNBC</a></li> <li><strong>谷歌与Meta达成$100亿云服务协议</strong>：谷歌获得Meta六年期超百亿美元云服务大单，强化合作关系。 <a href="https://www.cnbc.com/2025/08/21/google-scores-six-year-meta-cloud-deal-worth-over-10-billion.html">CNBC</a></li> <li><strong>新蛋白逆转小鼠大脑衰老</strong>：科学家发现一种能逆转小鼠大脑衰老的蛋白质，有望用于人类抗衰老研究。 <a href="https://www.sciencedaily.com/releases/2025/08/250820000808.htm">ScienceDaily</a></li> <li><strong>美国医保费用飙升</strong>：明年ACA医保费用可能大幅上涨，从每月$479涨至$2,800，影响数百万美国人。 <a href="https://www.npr.org/sections/shots-health-news/2025/08/22/nx-s1-5511182/aca-tax-credits-health-insurance-open-enrollment">NPR</a></li> </ul> <h2 id="-ai--开发工具">📦 AI &amp; 开发工具</h2> <ul> <li><strong>FFmpeg 8.0 发布</strong>：知名多媒体处理工具FFmpeg发布新版本，带来多项改进。 <a href="https://ffmpeg.org/index.html#pr8.0">ffmpeg.org</a></li> <li><strong>LabPlot数据可视化与分析</strong>：免费开源、跨平台的数据可视化与分析工具，适用于科研与工程。 <a href="https://labplot.org/">labplot.org</a></li> <li><strong>Thunderbird Pro八月更新</strong>：邮件客户端Thunderbird Pro发布最新版本更新。 <a href="https://blog.thunderbird.net/2025/08/tbpro-august-2025-update/">Thunderbird Blog</a></li> <li><strong>Cloudflare推首个基于QUIC的CDN</strong>：Cloudflare发布首个通过QUIC协议传输媒体内容的CDN服务。 <a href="https://moq.dev/blog/first-cdn/">moq.dev</a></li> <li><strong>Nitro：轻量级init系统和进程监控</strong>：一个微小但灵活的init系统和进程管理器。 <a href="https://git.vuxu.org/nitro/about/">Git.vuxu.org</a></li> <li><strong>LLM性能效率优化路由</strong>：研究通过优化路由策略，使大型语言模型更便宜、性能更好。 <a href="https://arxiv.org/abs/2508.12631">arXiv</a></li> </ul> <h2 id="-思维激荡mind-food">🧠 思维激荡（Mind Food）</h2> <ul> <li><strong>Go语言仍不够好</strong>：一篇对Go语言当前设计和功能进行批判性分析的文章。 <a href="https://blog.habets.se/2025/07/Go-is-still-not-good.html">blog.habets.se</a></li> <li><strong>现在到底发生了什么？</strong>：一篇对当前社会和技术趋势的深刻反思。 <a href="https://catskull.net/what-the-hell-is-going-on-right-now.html">catskull.net</a></li> <li><strong>管理者犯错与修复</strong>：讨论了管理者承认并修复错误的被忽视但至关重要的技能。 <a href="https://terriblesoftware.org/2025/08/22/the-management-skill-nobody-talks-about/">terriblesoftware.org</a></li> <li><strong>万物皆相关 (2014–23)</strong>：一篇关于关联性思维和统计学中“万物皆相关”现象的深度探讨。 <a href="https://gwern.net/everything">gwern.net</a></li> <li><strong>离开Gmail，转向Mailbox.org</strong>：作者分享了从Gmail迁移至Mailbox.org的个人经历与选择理由。 <a href="https://giuliomagnifico.blog/post/2025-08-18-leaving-gmail/">giuliomagnifico.blog</a></li> <li><strong>“自信的错误”阻碍AI发展</strong>：讨论AI系统“自信地犯错”如何成为当前发展面临的一大挑战。 <a href="https://promptql.io/blog/being-confidently-wrong-is-holding-ai-back">promptql.io</a></li> <li><strong>在ChatGPT中加入自我怀疑</strong>：探讨通过设计让AI表现出“自我怀疑”来提高其输出质量和可靠性。 <a href="https://justin.searls.co/posts/sprinkling-self-doubt-on-chatgpt/">justin.searls.co</a></li> </ul> <h2 id="-科技与社会趋势">🌐 科技与社会趋势</h2> <ul> <li><strong>4chan拒付在线安全罚款</strong>：4chan的律师表示将拒绝支付英国在线安全法案规定的每日罚款。 <a href="https://www.bbc.co.uk/news/articles/cq68j5g2nr1o">BBC</a></li> <li><strong>美国农业部禁止支持可再生能源</strong>：美国农业部发布新规，禁止对农场可再生能源项目提供财政支持。 <a href="https://insideclimatenews.org/news/19082025/usda-bans-farm-renewables-support/">Inside Climate News</a></li> <li><strong>XSLT移除争议与澄清</strong>：关于XSLT移除可能影响政府网站的担忧，以及Google对并非单方面决定的澄清。 (<a href="https://github.com/whatwg/html/issues/11582">GitHub</a>, <a href="https://meyerweb.com/eric/thoughts/2025/08/22/no-google-did-not-unilaterally-decide-to-kill-xslt/">Meyerweb</a>)</li> </ul> <h2 id="-新奇项目--show-hn">📱 新奇项目 / Show HN</h2> <ul> <li><strong>用手机控制购物车轮子 (2021)</strong>：一个通过手机远程控制购物车轮子转动的趣味项目。 <a href="https://www.begaydocrime.com/">begaydocrime.com</a></li> </ul> <h2 id="-dev-tricks">🧰 Dev Tricks</h2> <ul> <li><strong>io_uring, kTLS与Rust构建零syscall HTTPS服务器</strong>：一篇关于如何使用这些先进技术构建高效HTTPS服务器的深度技术文章。 <a href="https://blog.habets.se/2025/04/io-uring-ktls-and-rust-for-zero-syscall-https-server.html">blog.habets.se</a></li> <li><strong>UTF-8字符串长度之惑</strong>：详细解释了UTF-8编码下，表情符号等复杂字符的<code class="language-plaintext highlighter-rouge">length</code>属性为何可能出乎意料 (2019)。 <a href="https://hsivonen.fi/string-length/">hsivonen.fi</a></li> <li><strong>专家程序员的Gen AI / LLM“vibecoding”指南</strong>：为有经验的程序员提供的关于生成式AI和LLM编程实践的实用指南。 <a href="https://www.stochasticlifestyle.com/a-guide-to-gen-ai-llm-vibecoding-for-expert-programmers/">stochasticlifestyle.com</a></li> </ul>]]></content><author><name></name></author><category term="HNDailyReport"/><category term="HNDailyReport"/><summary type="html"><![CDATA[🔥 今日重点（Top Picks）]]></summary></entry></feed>